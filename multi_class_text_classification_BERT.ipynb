{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-23T11:45:41.295207Z",
     "start_time": "2024-09-23T11:45:38.805057Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import sys\n",
    "import tqdm.notebook as tq\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('MEISD/MEISD_text.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:40:02.654532Z",
     "start_time": "2024-09-23T13:40:02.617158Z"
    }
   },
   "id": "73cab1258da20570",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#df_data = df_data.loc[df_data.iloc[:,2:].apply(sum, axis=1) == 1,:].sample(n = 10_000, random_state = 4)\n",
    "df_data = df_data.sample(n = 10_000, random_state = 4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:41:01.167963Z",
     "start_time": "2024-09-23T13:41:01.160318Z"
    }
   },
   "id": "45cd8c57317ddf0",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      TV Series                                         Utterances  \\\n2712         CA                       that's not all that was long   \n18590        TO                          or does somebody miss me?   \n19697        TO                why holly and i should be together,   \n16157       HOC      i'm sorry. i didn't mean for that to come off   \n11635       HMD   things got a little slow, so we made some wagers   \n...         ...                                                ...   \n13533        BD  how's her driving? driving. is she good behind...   \n15237        FR  No-no-no. I don't have a son named Jordie. We ...   \n10261       HMD  just because you got out of clinic duty doesn'...   \n11528       HMD                          yeah. your mother told me   \n18740        TO            what exactly is my responsibility here?   \n\n       dialog_ids  uttr_ids  seasons  episodes   start_times     end_times  \\\n2712          138         7        3         7  00:05:58:210  00:06:00:010   \n18590        1054        15        3         4  00:02:11:799  00:02:13:265   \n19697        1110         0        5        26  00:04:09:333  00:04:11:000   \n16157         931        18        1         4  00:14:58:040  00:14:59:724   \n11635         590        17        6        14  00:05:02:407  00:05:05:911   \n...           ...       ...      ...       ...           ...           ...   \n13533         684        18        3        13  00:18:45:626  00:18:49:046   \n15237         841         1        1        23  00:08:03,566  00:08:10,113   \n10261         521        14        1        13  00:10:22:227  00:10:24:771   \n11528         585         8        6         6  00:14:25:386  00:14:27:180   \n18740        1062         5        6         1  00:12:59:210  00:13:01:678   \n\n       sentiment     emotion intensity emotion2 intensity2 emotion3  \\\n2712    positive         joy         1  disgust          1      NaN   \n18590   Positive    surprise         2     like          1      NaN   \n19697   positive         joy         2  disgust          1      NaN   \n16157  negative     surprise         2  disgust          1      NaN   \n11635   negative     sadness         1      NaN        NaN      NaN   \n...          ...         ...       ...      ...        ...      ...   \n13533   Positive     neutral       NaN      NaN        NaN      NaN   \n15237   negative       anger         3      NaN        NaN      NaN   \n10261   negative       anger         1  disgust          2      NaN   \n11528    positve  acceptance         2      NaN        NaN      NaN   \n18740   Negative    surprise         3      NaN        NaN      NaN   \n\n       intensity3  \n2712          NaN  \n18590         NaN  \n19697         NaN  \n16157         NaN  \n11635         NaN  \n...           ...  \n13533         NaN  \n15237         NaN  \n10261         NaN  \n11528         NaN  \n18740         NaN  \n\n[10000 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV Series</th>\n      <th>Utterances</th>\n      <th>dialog_ids</th>\n      <th>uttr_ids</th>\n      <th>seasons</th>\n      <th>episodes</th>\n      <th>start_times</th>\n      <th>end_times</th>\n      <th>sentiment</th>\n      <th>emotion</th>\n      <th>intensity</th>\n      <th>emotion2</th>\n      <th>intensity2</th>\n      <th>emotion3</th>\n      <th>intensity3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2712</th>\n      <td>CA</td>\n      <td>that's not all that was long</td>\n      <td>138</td>\n      <td>7</td>\n      <td>3</td>\n      <td>7</td>\n      <td>00:05:58:210</td>\n      <td>00:06:00:010</td>\n      <td>positive</td>\n      <td>joy</td>\n      <td>1</td>\n      <td>disgust</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18590</th>\n      <td>TO</td>\n      <td>or does somebody miss me?</td>\n      <td>1054</td>\n      <td>15</td>\n      <td>3</td>\n      <td>4</td>\n      <td>00:02:11:799</td>\n      <td>00:02:13:265</td>\n      <td>Positive</td>\n      <td>surprise</td>\n      <td>2</td>\n      <td>like</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19697</th>\n      <td>TO</td>\n      <td>why holly and i should be together,</td>\n      <td>1110</td>\n      <td>0</td>\n      <td>5</td>\n      <td>26</td>\n      <td>00:04:09:333</td>\n      <td>00:04:11:000</td>\n      <td>positive</td>\n      <td>joy</td>\n      <td>2</td>\n      <td>disgust</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16157</th>\n      <td>HOC</td>\n      <td>i'm sorry. i didn't mean for that to come off</td>\n      <td>931</td>\n      <td>18</td>\n      <td>1</td>\n      <td>4</td>\n      <td>00:14:58:040</td>\n      <td>00:14:59:724</td>\n      <td>negative</td>\n      <td>surprise</td>\n      <td>2</td>\n      <td>disgust</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11635</th>\n      <td>HMD</td>\n      <td>things got a little slow, so we made some wagers</td>\n      <td>590</td>\n      <td>17</td>\n      <td>6</td>\n      <td>14</td>\n      <td>00:05:02:407</td>\n      <td>00:05:05:911</td>\n      <td>negative</td>\n      <td>sadness</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13533</th>\n      <td>BD</td>\n      <td>how's her driving? driving. is she good behind...</td>\n      <td>684</td>\n      <td>18</td>\n      <td>3</td>\n      <td>13</td>\n      <td>00:18:45:626</td>\n      <td>00:18:49:046</td>\n      <td>Positive</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15237</th>\n      <td>FR</td>\n      <td>No-no-no. I don't have a son named Jordie. We ...</td>\n      <td>841</td>\n      <td>1</td>\n      <td>1</td>\n      <td>23</td>\n      <td>00:08:03,566</td>\n      <td>00:08:10,113</td>\n      <td>negative</td>\n      <td>anger</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10261</th>\n      <td>HMD</td>\n      <td>just because you got out of clinic duty doesn'...</td>\n      <td>521</td>\n      <td>14</td>\n      <td>1</td>\n      <td>13</td>\n      <td>00:10:22:227</td>\n      <td>00:10:24:771</td>\n      <td>negative</td>\n      <td>anger</td>\n      <td>1</td>\n      <td>disgust</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11528</th>\n      <td>HMD</td>\n      <td>yeah. your mother told me</td>\n      <td>585</td>\n      <td>8</td>\n      <td>6</td>\n      <td>6</td>\n      <td>00:14:25:386</td>\n      <td>00:14:27:180</td>\n      <td>positve</td>\n      <td>acceptance</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18740</th>\n      <td>TO</td>\n      <td>what exactly is my responsibility here?</td>\n      <td>1062</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1</td>\n      <td>00:12:59:210</td>\n      <td>00:13:01:678</td>\n      <td>Negative</td>\n      <td>surprise</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:34.511836Z",
     "start_time": "2024-09-23T13:56:34.501616Z"
    }
   },
   "id": "324b1943e7c9426e",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split into train and test\n",
    "df_train, df_test = train_test_split(df_data, random_state=77, test_size=0.30, shuffle=True)\n",
    "# split test into test and validation datasets\n",
    "df_test, df_valid = train_test_split(df_test, random_state=88, test_size=0.50, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:55.092630Z",
     "start_time": "2024-09-23T13:56:55.085177Z"
    }
   },
   "id": "19c1e122f9b175f3",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (7000, 15), Test: (1500, 15), Valid: (1500, 15)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {df_train.shape}, Test: {df_test.shape}, Valid: {df_valid.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:55.533044Z",
     "start_time": "2024-09-23T13:56:55.529683Z"
    }
   },
   "id": "b248b504075cad56",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:55.903990Z",
     "start_time": "2024-09-23T13:56:55.901237Z"
    }
   },
   "id": "c70b897535f367b2",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:56.256203Z",
     "start_time": "2024-09-23T13:56:56.253370Z"
    }
   },
   "id": "5d7736491be4d95c",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:57.189449Z",
     "start_time": "2024-09-23T13:56:56.701716Z"
    }
   },
   "id": "de504b7119199cd1",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[  101,  2057,  2024,  5604, 14324, 19204, 17629,  1012,   102,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0]])}"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the tokenizer\n",
    "test_text = \"We are testing BERT tokenizer.\"\n",
    "# generate encodings\n",
    "encodings = tokenizer.encode_plus(test_text,\n",
    "                                  add_special_tokens = True,\n",
    "                                  max_length = 50,\n",
    "                                  truncation = True,\n",
    "                                  padding = \"max_length\",\n",
    "                                  return_attention_mask = True,\n",
    "                                  return_tensors = \"pt\")\n",
    "# we get a dictionary with three keys (see: https://huggingface.co/transformers/glossary.html) \n",
    "encodings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:57.195193Z",
     "start_time": "2024-09-23T13:56:57.190451Z"
    }
   },
   "id": "48b8c2f3b19252c0",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "15443                       I thought there wasn't a ball?\n13052                        what are you waiting for? go!\n4143                             this one time, she was at\n7275              while the victor still licks his wounds.\n16153    you've begged me to move you up, and now suddenly\n                               ...                        \n9360     anyway, i told you already, i'm taking a break...\n1232     you know what? you sound more and more like mo...\n2426                                      at the same time\n1237        did you say \"ham\"? - you're either ham or eggs\n6362     Every man who has tasted my cooking has told m...\nName: Utterances, Length: 7000, dtype: object"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Utterances']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:57.628344Z",
     "start_time": "2024-09-23T13:56:57.623683Z"
    }
   },
   "id": "c0f9839a6731f697",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len, target_list):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.title = list(df['Utterances'])\n",
    "        self.targets = self.df[target_list].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.title[index])\n",
    "        title = \" \".join(title.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
    "            'targets': torch.FloatTensor(self.targets[index]),\n",
    "            'title': title\n",
    "        }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:57.965269Z",
     "start_time": "2024-09-23T13:56:57.961339Z"
    }
   },
   "id": "bade010abf49702b",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['TV Series',\n 'Utterances',\n 'dialog_ids',\n 'uttr_ids',\n 'seasons',\n 'episodes',\n 'start_times',\n 'end_times',\n 'sentiment',\n 'emotion',\n 'intensity',\n 'emotion2',\n 'intensity2',\n 'emotion3',\n 'intensity3']"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list = list(df_data.columns)\n",
    "target_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:58.224305Z",
     "start_time": "2024-09-23T13:56:58.220666Z"
    }
   },
   "id": "c5effcfa7c15ec3b",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['dialog_ids',\n 'uttr_ids',\n 'seasons',\n 'episodes',\n 'start_times',\n 'end_times',\n 'sentiment',\n 'emotion',\n 'intensity',\n 'emotion2',\n 'intensity2',\n 'emotion3',\n 'intensity3']"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list = target_list[2:]\n",
    "target_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:58.439874Z",
     "start_time": "2024-09-23T13:56:58.436671Z"
    }
   },
   "id": "31bd093c807a6698",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN, target_list)\n",
    "valid_dataset = CustomDataset(df_valid, tokenizer, MAX_LEN, target_list)\n",
    "test_dataset = CustomDataset(df_test, tokenizer, MAX_LEN, target_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:58.644493Z",
     "start_time": "2024-09-23T13:56:58.636676Z"
    }
   },
   "id": "2354e6032a66c279",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                batch_size=TRAIN_BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0\n",
    "                                                )\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                              batch_size=VALID_BATCH_SIZE,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=0\n",
    "                                              )\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size=TEST_BATCH_SIZE,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0\n",
    "                                               )\n",
    "     \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:58.854526Z",
     "start_time": "2024-09-23T13:56:58.850682Z"
    }
   },
   "id": "de97faab83cd5a3f",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "BERTClass(\n  (bert_model): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (linear): Linear(in_features=768, out_features=8, bias=True)\n)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear = torch.nn.Linear(768, 8)\n",
    "\n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids,\n",
    "            attention_mask=attn_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n",
    "\n",
    "# # Freezing BERT layers: (tested, weaker convergence)\n",
    "# for param in model.bert_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:59.410516Z",
     "start_time": "2024-09-23T13:56:59.053282Z"
    }
   },
   "id": "de210dbae7af402a",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:59.413981Z",
     "start_time": "2024-09-23T13:56:59.411517Z"
    }
   },
   "id": "432278372602f2c9",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-5)         \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:59.475965Z",
     "start_time": "2024-09-23T13:56:59.470200Z"
    }
   },
   "id": "7798b65490adac40",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training of the model for one epoch\n",
    "def train_model(training_loader, model, optimizer):\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    # set model to training mode (activate droput, batch norm)\n",
    "    model.train()\n",
    "    # initialize the progress bar\n",
    "    loop = tq.tqdm(enumerate(training_loader), total=len(training_loader),\n",
    "                   leave=True, colour='steelblue')\n",
    "    for batch_idx, data in loop:\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(ids, mask, token_type_ids) # (batch,predict)=(32,8)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "        # training accuracy\n",
    "        _, preds = torch.max(outputs, dim=1) # batch dim \n",
    "        _, targ = torch.max(targets, dim=1)  # batch dim\n",
    "        num_samples += len(targ)  # technically adding batch size\n",
    "        correct_predictions += torch.sum(preds == targ)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        # grad descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        #loop.set_description(f\"\")\n",
    "        #loop.set_postfix(batch_loss=loss)\n",
    "\n",
    "    # returning: trained model, model accuracy, mean loss\n",
    "    return model, float(correct_predictions)/num_samples, np.mean(losses)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:56:59.938985Z",
     "start_time": "2024-09-23T13:56:59.932256Z"
    }
   },
   "id": "691ccb788da61ec2",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def eval_model(validation_loader, model, optimizer):\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    # set model to eval mode (turn off dropout, fix batch norm)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(validation_loader, 0):\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # validation accuracy\n",
    "            _, preds = torch.max(outputs, dim=1) # batch dim \n",
    "            _, targ = torch.max(targets, dim=1)  # batch dim\n",
    "            num_samples += len(targ)  # technically adding batch size\n",
    "            correct_predictions += torch.sum(preds == targ)\n",
    "\n",
    "    return float(correct_predictions)/num_samples, np.mean(losses)\n",
    "     \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:57:00.381901Z",
     "start_time": "2024-09-23T13:57:00.376243Z"
    }
   },
   "id": "30823516ff678b1e",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/219 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1fc1310f5cf14614847f8cd9ec800ac1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[50], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, EPOCHS\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mEPOCHS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m     model, train_acc, train_loss \u001B[38;5;241m=\u001B[39m train_model(train_data_loader, model, optimizer)\n\u001B[0;32m      7\u001B[0m     val_acc, val_loss \u001B[38;5;241m=\u001B[39m eval_model(val_data_loader, model, optimizer)\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_loss=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, val_loss=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m train_acc=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, val_acc=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[48], line 12\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(training_loader, model, optimizer)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# initialize the progress bar\u001B[39;00m\n\u001B[0;32m     10\u001B[0m loop \u001B[38;5;241m=\u001B[39m tq\u001B[38;5;241m.\u001B[39mtqdm(\u001B[38;5;28menumerate\u001B[39m(training_loader), total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(training_loader),\n\u001B[0;32m     11\u001B[0m                leave\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, colour\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msteelblue\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, data \u001B[38;5;129;01min\u001B[39;00m loop:\n\u001B[0;32m     13\u001B[0m     ids \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[0;32m     14\u001B[0m     mask \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlong)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\tqdm\\notebook.py:254\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    253\u001B[0m     it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(tqdm_notebook, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[1;32m--> 254\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[0;32m    255\u001B[0m         \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[0;32m    256\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m    257\u001B[0m \u001B[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\tqdm\\std.py:1178\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1175\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1178\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1179\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1180\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1181\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[1;32mIn[40], line 30\u001B[0m, in \u001B[0;36mCustomDataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m     14\u001B[0m title \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(title\u001B[38;5;241m.\u001B[39msplit())\n\u001B[0;32m     15\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mencode_plus(\n\u001B[0;32m     16\u001B[0m     title,\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     24\u001B[0m     return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     25\u001B[0m )\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m: inputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mflatten(),\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m: inputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mflatten(),\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m: inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mflatten(),\n\u001B[1;32m---> 30\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtargets\u001B[39m\u001B[38;5;124m'\u001B[39m: torch\u001B[38;5;241m.\u001B[39mFloatTensor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtargets[index]),\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle\u001B[39m\u001B[38;5;124m'\u001B[39m: title\n\u001B[0;32m     32\u001B[0m }\n",
      "\u001B[1;31mTypeError\u001B[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."
     ]
    }
   ],
   "source": [
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    model, train_acc, train_loss = train_model(train_data_loader, model, optimizer)\n",
    "    val_acc, val_loss = eval_model(val_data_loader, model, optimizer)\n",
    "\n",
    "    print(f'train_loss={train_loss:.4f}, val_loss={val_loss:.4f} train_acc={train_acc:.4f}, val_acc={val_acc:.4f}')\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    # save the best model\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), os.path.join('MEISD/',\"output\",\"best_model_state.bin\"))\n",
    "        best_accuracy = val_acc\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:57:00.866882Z",
     "start_time": "2024-09-23T13:57:00.783683Z"
    }
   },
   "id": "f909b4d1b7f21369",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "67e6b82c0a22a105"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
