{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:35.967622Z",
     "start_time": "2024-09-24T16:51:35.963754Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import sys\n",
    "import tqdm.notebook as tq\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('MEISD/MEISD_text.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:45.712551Z",
     "start_time": "2024-09-24T16:51:45.675757Z"
    }
   },
   "id": "73cab1258da20570",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#df_data = df_data.loc[df_data.iloc[:,2:].apply(sum, axis=1) == 1,:].sample(n = 10_000, random_state = 4)\n",
    "df_data = df_data.sample(n = 10_000, random_state = 4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:46.322045Z",
     "start_time": "2024-09-24T16:51:46.315715Z"
    }
   },
   "id": "45cd8c57317ddf0",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      TV Series                                         Utterances  \\\n2712         CA                       that's not all that was long   \n18590        TO                          or does somebody miss me?   \n19697        TO                why holly and i should be together,   \n16157       HOC      i'm sorry. i didn't mean for that to come off   \n11635       HMD   things got a little slow, so we made some wagers   \n...         ...                                                ...   \n13533        BD  how's her driving? driving. is she good behind...   \n15237        FR  No-no-no. I don't have a son named Jordie. We ...   \n10261       HMD  just because you got out of clinic duty doesn'...   \n11528       HMD                          yeah. your mother told me   \n18740        TO            what exactly is my responsibility here?   \n\n       dialog_ids  uttr_ids  seasons  episodes   start_times     end_times  \\\n2712          138         7        3         7  00:05:58:210  00:06:00:010   \n18590        1054        15        3         4  00:02:11:799  00:02:13:265   \n19697        1110         0        5        26  00:04:09:333  00:04:11:000   \n16157         931        18        1         4  00:14:58:040  00:14:59:724   \n11635         590        17        6        14  00:05:02:407  00:05:05:911   \n...           ...       ...      ...       ...           ...           ...   \n13533         684        18        3        13  00:18:45:626  00:18:49:046   \n15237         841         1        1        23  00:08:03,566  00:08:10,113   \n10261         521        14        1        13  00:10:22:227  00:10:24:771   \n11528         585         8        6         6  00:14:25:386  00:14:27:180   \n18740        1062         5        6         1  00:12:59:210  00:13:01:678   \n\n       sentiment     emotion intensity emotion2 intensity2 emotion3  \\\n2712    positive         joy         1  disgust          1      NaN   \n18590   Positive    surprise         2     like          1      NaN   \n19697   positive         joy         2  disgust          1      NaN   \n16157  negative     surprise         2  disgust          1      NaN   \n11635   negative     sadness         1      NaN        NaN      NaN   \n...          ...         ...       ...      ...        ...      ...   \n13533   Positive     neutral       NaN      NaN        NaN      NaN   \n15237   negative       anger         3      NaN        NaN      NaN   \n10261   negative       anger         1  disgust          2      NaN   \n11528    positve  acceptance         2      NaN        NaN      NaN   \n18740   Negative    surprise         3      NaN        NaN      NaN   \n\n       intensity3  \n2712          NaN  \n18590         NaN  \n19697         NaN  \n16157         NaN  \n11635         NaN  \n...           ...  \n13533         NaN  \n15237         NaN  \n10261         NaN  \n11528         NaN  \n18740         NaN  \n\n[10000 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV Series</th>\n      <th>Utterances</th>\n      <th>dialog_ids</th>\n      <th>uttr_ids</th>\n      <th>seasons</th>\n      <th>episodes</th>\n      <th>start_times</th>\n      <th>end_times</th>\n      <th>sentiment</th>\n      <th>emotion</th>\n      <th>intensity</th>\n      <th>emotion2</th>\n      <th>intensity2</th>\n      <th>emotion3</th>\n      <th>intensity3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2712</th>\n      <td>CA</td>\n      <td>that's not all that was long</td>\n      <td>138</td>\n      <td>7</td>\n      <td>3</td>\n      <td>7</td>\n      <td>00:05:58:210</td>\n      <td>00:06:00:010</td>\n      <td>positive</td>\n      <td>joy</td>\n      <td>1</td>\n      <td>disgust</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18590</th>\n      <td>TO</td>\n      <td>or does somebody miss me?</td>\n      <td>1054</td>\n      <td>15</td>\n      <td>3</td>\n      <td>4</td>\n      <td>00:02:11:799</td>\n      <td>00:02:13:265</td>\n      <td>Positive</td>\n      <td>surprise</td>\n      <td>2</td>\n      <td>like</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19697</th>\n      <td>TO</td>\n      <td>why holly and i should be together,</td>\n      <td>1110</td>\n      <td>0</td>\n      <td>5</td>\n      <td>26</td>\n      <td>00:04:09:333</td>\n      <td>00:04:11:000</td>\n      <td>positive</td>\n      <td>joy</td>\n      <td>2</td>\n      <td>disgust</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16157</th>\n      <td>HOC</td>\n      <td>i'm sorry. i didn't mean for that to come off</td>\n      <td>931</td>\n      <td>18</td>\n      <td>1</td>\n      <td>4</td>\n      <td>00:14:58:040</td>\n      <td>00:14:59:724</td>\n      <td>negative</td>\n      <td>surprise</td>\n      <td>2</td>\n      <td>disgust</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11635</th>\n      <td>HMD</td>\n      <td>things got a little slow, so we made some wagers</td>\n      <td>590</td>\n      <td>17</td>\n      <td>6</td>\n      <td>14</td>\n      <td>00:05:02:407</td>\n      <td>00:05:05:911</td>\n      <td>negative</td>\n      <td>sadness</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13533</th>\n      <td>BD</td>\n      <td>how's her driving? driving. is she good behind...</td>\n      <td>684</td>\n      <td>18</td>\n      <td>3</td>\n      <td>13</td>\n      <td>00:18:45:626</td>\n      <td>00:18:49:046</td>\n      <td>Positive</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15237</th>\n      <td>FR</td>\n      <td>No-no-no. I don't have a son named Jordie. We ...</td>\n      <td>841</td>\n      <td>1</td>\n      <td>1</td>\n      <td>23</td>\n      <td>00:08:03,566</td>\n      <td>00:08:10,113</td>\n      <td>negative</td>\n      <td>anger</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10261</th>\n      <td>HMD</td>\n      <td>just because you got out of clinic duty doesn'...</td>\n      <td>521</td>\n      <td>14</td>\n      <td>1</td>\n      <td>13</td>\n      <td>00:10:22:227</td>\n      <td>00:10:24:771</td>\n      <td>negative</td>\n      <td>anger</td>\n      <td>1</td>\n      <td>disgust</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11528</th>\n      <td>HMD</td>\n      <td>yeah. your mother told me</td>\n      <td>585</td>\n      <td>8</td>\n      <td>6</td>\n      <td>6</td>\n      <td>00:14:25:386</td>\n      <td>00:14:27:180</td>\n      <td>positve</td>\n      <td>acceptance</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18740</th>\n      <td>TO</td>\n      <td>what exactly is my responsibility here?</td>\n      <td>1062</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1</td>\n      <td>00:12:59:210</td>\n      <td>00:13:01:678</td>\n      <td>Negative</td>\n      <td>surprise</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:46.599987Z",
     "start_time": "2024-09-24T16:51:46.587882Z"
    }
   },
   "id": "324b1943e7c9426e",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define emotion and sentiment mappings\n",
    "emotion_map = {\n",
    "    'neutral': 0,\n",
    "    'acceptance': 1,\n",
    "    'disgust': 2,\n",
    "    'surprise': 3,\n",
    "    'joy': 4,\n",
    "    'sadness': 5,\n",
    "    'anger': 6,\n",
    "    'like': 7,\n",
    "    'fear': 8\n",
    "}\n",
    "\n",
    "sentiment_map = {\n",
    "    'positive': 1,\n",
    "    'negative': 0,\n",
    "    'neutral': 2\n",
    "}\n",
    "\n",
    "# Map and convert sentiment and emotion columns\n",
    "df_data['sentiment'] = pd.to_numeric(df_data['sentiment'].map(sentiment_map).fillna(2).astype(int))  # Use 2 as a default for unknown\n",
    "df_data['emotion'] = pd.to_numeric(df_data['emotion'].map(emotion_map).fillna(9).astype(int))  # Use 9 for unknown emotions\n",
    "df_data['emotion2'] = pd.to_numeric(df_data['emotion2'].map(emotion_map).fillna(9).astype(int))\n",
    "df_data['emotion3'] = pd.to_numeric(df_data['emotion3'].map(emotion_map).fillna(9).astype(int))\n",
    "\n",
    "# Convert intensity columns to numeric\n",
    "df_data['intensity'] = pd.to_numeric(df_data['intensity'], errors='coerce').fillna(0).astype(int)\n",
    "df_data['intensity2'] = pd.to_numeric(df_data['intensity2'], errors='coerce').fillna(0).astype(int)\n",
    "df_data['intensity3'] = pd.to_numeric(df_data['intensity3'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "\n",
    "# Convert start and end times to datetime\n",
    "df_data['start_times'] = pd.to_datetime(df_data['start_times'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df_data['end_times'] = pd.to_datetime(df_data['end_times'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "df_data.fillna({\n",
    "    'intensity': 0,\n",
    "    'intensity2': 0,\n",
    "    'intensity3': 0,\n",
    "    'sentiment': 2,  # Default sentiment to neutral\n",
    "    'emotion': 9,\n",
    "    'emotion2': 9,\n",
    "    'emotion3': 9,\n",
    "    'start_times': pd.NaT,  # Keep NaT for dates\n",
    "    'end_times': pd.NaT     # Keep NaT for dates\n",
    "}, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:47.200428Z",
     "start_time": "2024-09-24T16:51:47.153802Z"
    }
   },
   "id": "31cbb91b8cee9849",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df_data, random_state=77, test_size=0.30, shuffle=True)\n",
    "df_test, df_valid = train_test_split(df_test, random_state=88, test_size=0.50, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:47.572916Z",
     "start_time": "2024-09-24T16:51:47.451683Z"
    }
   },
   "id": "19c1e122f9b175f3",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (7000, 15), Test: (1500, 15), Valid: (1500, 15)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {df_train.shape}, Test: {df_test.shape}, Valid: {df_valid.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:47.647169Z",
     "start_time": "2024-09-24T16:51:47.643858Z"
    }
   },
   "id": "b248b504075cad56",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV Series              object\n",
      "Utterances             object\n",
      "dialog_ids              int64\n",
      "uttr_ids                int64\n",
      "seasons                 int64\n",
      "episodes                int64\n",
      "start_times    datetime64[ns]\n",
      "end_times      datetime64[ns]\n",
      "sentiment               int32\n",
      "emotion                 int32\n",
      "intensity               int32\n",
      "emotion2                int32\n",
      "intensity2              int32\n",
      "emotion3                int32\n",
      "intensity3              int32\n",
      "dtype: object\n",
      "[1 2 0]\n",
      "[4 3 5 6 0 1 2 9 8 7]\n",
      "[1 2 0 3]\n",
      "[1 0 3 2]\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(df_data.dtypes)\n",
    "\n",
    "# Check unique values in relevant columns\n",
    "print(df_data['sentiment'].unique())\n",
    "print(df_data['emotion'].unique())\n",
    "print(df_data['intensity'].unique())\n",
    "print(df_data['intensity2'].unique())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:47.801853Z",
     "start_time": "2024-09-24T16:51:47.795710Z"
    }
   },
   "id": "3297323184d9c1c8",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-05"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:47.949526Z",
     "start_time": "2024-09-24T16:51:47.945947Z"
    }
   },
   "id": "c70b897535f367b2",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:49.774955Z",
     "start_time": "2024-09-24T16:51:48.091850Z"
    }
   },
   "id": "5d7736491be4d95c",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[  101,  2057,  2024,  5604, 14324, 19204, 17629,  1012,   102,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0]])}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the tokenizer\n",
    "test_text = \"We are testing BERT tokenizer.\"\n",
    "# generate encodings\n",
    "encodings = tokenizer.encode_plus(test_text,\n",
    "                                  add_special_tokens = True,\n",
    "                                  max_length = 50,\n",
    "                                  truncation = True,\n",
    "                                  padding = \"max_length\",\n",
    "                                  return_attention_mask = True,\n",
    "                                  return_tensors = \"pt\")\n",
    "# we get a dictionary with three keys (see: https://huggingface.co/transformers/glossary.html) \n",
    "encodings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:49.781790Z",
     "start_time": "2024-09-24T16:51:49.775957Z"
    }
   },
   "id": "48b8c2f3b19252c0",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "15443                       I thought there wasn't a ball?\n13052                        what are you waiting for? go!\n4143                             this one time, she was at\n7275              while the victor still licks his wounds.\n16153    you've begged me to move you up, and now suddenly\n                               ...                        \n9360     anyway, i told you already, i'm taking a break...\n1232     you know what? you sound more and more like mo...\n2426                                      at the same time\n1237        did you say \"ham\"? - you're either ham or eggs\n6362     Every man who has tasted my cooking has told m...\nName: Utterances, Length: 7000, dtype: object"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Utterances']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:49.786865Z",
     "start_time": "2024-09-24T16:51:49.781790Z"
    }
   },
   "id": "c0f9839a6731f697",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len, target_list):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.title = list(df['Utterances'])\n",
    "        self.targets = self.df[target_list].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.title[index])\n",
    "        title = \" \".join(title.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
    "            # Ensure the correct type here\n",
    "            'targets': torch.FloatTensor(self.targets[index]),\n",
    "            #'targets': torch.tensor(self.targets[index], dtype=torch.float32),  \n",
    "            'title': title\n",
    "        }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:49.791703Z",
     "start_time": "2024-09-24T16:51:49.787867Z"
    }
   },
   "id": "bade010abf49702b",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['TV Series',\n 'Utterances',\n 'dialog_ids',\n 'uttr_ids',\n 'seasons',\n 'episodes',\n 'start_times',\n 'end_times',\n 'sentiment',\n 'emotion',\n 'intensity',\n 'emotion2',\n 'intensity2',\n 'emotion3',\n 'intensity3']"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list = list(df_data.columns)\n",
    "target_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:49.796169Z",
     "start_time": "2024-09-24T16:51:49.792709Z"
    }
   },
   "id": "c5effcfa7c15ec3b",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['dialog_ids',\n 'uttr_ids',\n 'seasons',\n 'episodes',\n 'sentiment',\n 'emotion',\n 'intensity',\n 'emotion2',\n 'intensity2',\n 'emotion3',\n 'intensity3']"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list = target_list[2:]\n",
    "target_list = [col for col in target_list if col not in ['start_times', 'end_times']]\n",
    "target_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:49.800328Z",
     "start_time": "2024-09-24T16:51:49.796169Z"
    }
   },
   "id": "31bd093c807a6698",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialog_ids    int64\n",
      "uttr_ids      int64\n",
      "seasons       int64\n",
      "episodes      int64\n",
      "sentiment     int32\n",
      "emotion       int32\n",
      "intensity     int32\n",
      "emotion2      int32\n",
      "intensity2    int32\n",
      "emotion3      int32\n",
      "intensity3    int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train[target_list].dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:49.804732Z",
     "start_time": "2024-09-24T16:51:49.800328Z"
    }
   },
   "id": "c170ae434d67e9f4",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN, target_list)\n",
    "valid_dataset = CustomDataset(df_valid, tokenizer, MAX_LEN, target_list)\n",
    "test_dataset = CustomDataset(df_test, tokenizer, MAX_LEN, target_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:49.811465Z",
     "start_time": "2024-09-24T16:51:49.804732Z"
    }
   },
   "id": "2354e6032a66c279",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                batch_size=TRAIN_BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0\n",
    "                                                )\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                              batch_size=VALID_BATCH_SIZE,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=0\n",
    "                                              )\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size=TEST_BATCH_SIZE,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0\n",
    "                                               )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:50.099863Z",
     "start_time": "2024-09-24T16:51:50.096012Z"
    }
   },
   "id": "de97faab83cd5a3f",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "BERTClass(\n  (bert_model): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (linear): Linear(in_features=768, out_features=11, bias=True)\n)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear = torch.nn.Linear(768, 11) #numer of classes\n",
    "\n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids,\n",
    "            attention_mask=attn_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n",
    "\n",
    "# # Freezing BERT layers: (tested, weaker convergence)\n",
    "# for param in model.bert_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:50.750445Z",
     "start_time": "2024-09-24T16:51:50.388217Z"
    }
   },
   "id": "de210dbae7af402a",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:50.754152Z",
     "start_time": "2024-09-24T16:51:50.751447Z"
    }
   },
   "id": "432278372602f2c9",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-5)         \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:51.597647Z",
     "start_time": "2024-09-24T16:51:51.085029Z"
    }
   },
   "id": "7798b65490adac40",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training of the model for one epoch\n",
    "def train_model(training_loader, model, optimizer):\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    # set model to training mode (activate droput, batch norm)\n",
    "    model.train()\n",
    "    # initialize the progress bar\n",
    "    loop = tq.tqdm(enumerate(training_loader), total=len(training_loader),\n",
    "                   leave=True, colour='steelblue')\n",
    "    for batch_idx, data in loop:\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "# forward\n",
    "        outputs = model(ids, mask, token_type_ids) # (batch,predict)=(32,8)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "        # training accuracy\n",
    "        _, preds = torch.max(outputs, dim=1) # batch dim \n",
    "        _, targ = torch.max(targets, dim=1)  # batch dim\n",
    "        num_samples += len(targ)  # technically adding batch size\n",
    "        correct_predictions += torch.sum(preds == targ)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        # grad descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        #loop.set_description(f\"\")\n",
    "        #loop.set_postfix(batch_loss=loss)\n",
    "\n",
    "    # returning: trained model, model accuracy, mean loss\n",
    "    return model, float(correct_predictions)/num_samples, np.mean(losses)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:51.602837Z",
     "start_time": "2024-09-24T16:51:51.598650Z"
    }
   },
   "id": "691ccb788da61ec2",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def eval_model(validation_loader, model, optimizer):\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    # set model to eval mode (turn off dropout, fix batch norm)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(validation_loader, 0):\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # validation accuracy\n",
    "            _, preds = torch.max(outputs, dim=1) # batch dim \n",
    "            _, targ = torch.max(targets, dim=1)  # batch dim\n",
    "            num_samples += len(targ)  # technically adding batch size\n",
    "            correct_predictions += torch.sum(preds == targ)\n",
    "\n",
    "    return float(correct_predictions)/num_samples, np.mean(losses)\n",
    "     \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:52.344324Z",
     "start_time": "2024-09-24T16:51:52.340022Z"
    }
   },
   "id": "30823516ff678b1e",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:51:52.687456Z",
     "start_time": "2024-09-24T16:51:52.684719Z"
    }
   },
   "id": "c632fc0a05f87a36",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/219 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9671d9ffc66e4ccc949e22c4d4c38425"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, EPOCHS\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mEPOCHS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m     model, train_acc, train_loss \u001B[38;5;241m=\u001B[39m train_model(train_data_loader, model, optimizer)\n\u001B[0;32m      7\u001B[0m     val_acc, val_loss \u001B[38;5;241m=\u001B[39m eval_model(val_data_loader, model, optimizer)\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_loss=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, val_loss=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m train_acc=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, val_acc=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[30], line 19\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(training_loader, model, optimizer)\u001B[0m\n\u001B[0;32m     16\u001B[0m         targets \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtargets\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# forward\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m model(ids, mask, token_type_ids) \u001B[38;5;66;03m# (batch,predict)=(32,8)\u001B[39;00m\n\u001B[0;32m     20\u001B[0m         loss \u001B[38;5;241m=\u001B[39m loss_fn(outputs, targets)\n\u001B[0;32m     21\u001B[0m         losses\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[27], line 9\u001B[0m, in \u001B[0;36mBERTClass.forward\u001B[1;34m(self, input_ids, attn_mask, token_type_ids)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_ids, attn_mask, token_type_ids):\n\u001B[1;32m----> 9\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbert_model(\n\u001B[0;32m     10\u001B[0m         input_ids,\n\u001B[0;32m     11\u001B[0m         attention_mask\u001B[38;5;241m=\u001B[39mattn_mask,\n\u001B[0;32m     12\u001B[0m         token_type_ids\u001B[38;5;241m=\u001B[39mtoken_type_ids\n\u001B[0;32m     13\u001B[0m     )\n\u001B[0;32m     14\u001B[0m     output_dropout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(output\u001B[38;5;241m.\u001B[39mpooler_output)\n\u001B[0;32m     15\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear(output_dropout)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1141\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1134\u001B[0m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[0;32m   1135\u001B[0m \u001B[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m \u001B[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001B[39;00m\n\u001B[0;32m   1137\u001B[0m \u001B[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001B[39;00m\n\u001B[0;32m   1138\u001B[0m \u001B[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001B[39;00m\n\u001B[0;32m   1139\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[1;32m-> 1141\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(\n\u001B[0;32m   1142\u001B[0m     embedding_output,\n\u001B[0;32m   1143\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mextended_attention_mask,\n\u001B[0;32m   1144\u001B[0m     head_mask\u001B[38;5;241m=\u001B[39mhead_mask,\n\u001B[0;32m   1145\u001B[0m     encoder_hidden_states\u001B[38;5;241m=\u001B[39mencoder_hidden_states,\n\u001B[0;32m   1146\u001B[0m     encoder_attention_mask\u001B[38;5;241m=\u001B[39mencoder_extended_attention_mask,\n\u001B[0;32m   1147\u001B[0m     past_key_values\u001B[38;5;241m=\u001B[39mpast_key_values,\n\u001B[0;32m   1148\u001B[0m     use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[0;32m   1149\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[0;32m   1150\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[0;32m   1151\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[0;32m   1152\u001B[0m )\n\u001B[0;32m   1153\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1154\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:694\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    683\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[0;32m    684\u001B[0m         layer_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[0;32m    685\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    691\u001B[0m         output_attentions,\n\u001B[0;32m    692\u001B[0m     )\n\u001B[0;32m    693\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 694\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m layer_module(\n\u001B[0;32m    695\u001B[0m         hidden_states,\n\u001B[0;32m    696\u001B[0m         attention_mask,\n\u001B[0;32m    697\u001B[0m         layer_head_mask,\n\u001B[0;32m    698\u001B[0m         encoder_hidden_states,\n\u001B[0;32m    699\u001B[0m         encoder_attention_mask,\n\u001B[0;32m    700\u001B[0m         past_key_value,\n\u001B[0;32m    701\u001B[0m         output_attentions,\n\u001B[0;32m    702\u001B[0m     )\n\u001B[0;32m    704\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:584\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    572\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    573\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    574\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    581\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[0;32m    582\u001B[0m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[0;32m    583\u001B[0m     self_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 584\u001B[0m     self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention(\n\u001B[0;32m    585\u001B[0m         hidden_states,\n\u001B[0;32m    586\u001B[0m         attention_mask,\n\u001B[0;32m    587\u001B[0m         head_mask,\n\u001B[0;32m    588\u001B[0m         output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[0;32m    589\u001B[0m         past_key_value\u001B[38;5;241m=\u001B[39mself_attn_past_key_value,\n\u001B[0;32m    590\u001B[0m     )\n\u001B[0;32m    591\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    593\u001B[0m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:514\u001B[0m, in \u001B[0;36mBertAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    504\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    505\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    506\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    512\u001B[0m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    513\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m--> 514\u001B[0m     self_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mself(\n\u001B[0;32m    515\u001B[0m         hidden_states,\n\u001B[0;32m    516\u001B[0m         attention_mask,\n\u001B[0;32m    517\u001B[0m         head_mask,\n\u001B[0;32m    518\u001B[0m         encoder_hidden_states,\n\u001B[0;32m    519\u001B[0m         encoder_attention_mask,\n\u001B[0;32m    520\u001B[0m         past_key_value,\n\u001B[0;32m    521\u001B[0m         output_attentions,\n\u001B[0;32m    522\u001B[0m     )\n\u001B[0;32m    523\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(self_outputs[\u001B[38;5;241m0\u001B[39m], hidden_states)\n\u001B[0;32m    524\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (attention_output,) \u001B[38;5;241m+\u001B[39m self_outputs[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439\u001B[0m, in \u001B[0;36mBertSdpaSelfAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    431\u001B[0m \u001B[38;5;66;03m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001B[39;00m\n\u001B[0;32m    432\u001B[0m \u001B[38;5;66;03m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001B[39;00m\n\u001B[0;32m    433\u001B[0m \u001B[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create\u001B[39;00m\n\u001B[0;32m    434\u001B[0m \u001B[38;5;66;03m# a causal mask in case tgt_len == 1.\u001B[39;00m\n\u001B[0;32m    435\u001B[0m is_causal \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    436\u001B[0m     \u001B[38;5;28;01mTrue\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_decoder \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_cross_attention \u001B[38;5;129;01mand\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m tgt_len \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    437\u001B[0m )\n\u001B[1;32m--> 439\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mscaled_dot_product_attention(\n\u001B[0;32m    440\u001B[0m     query_layer,\n\u001B[0;32m    441\u001B[0m     key_layer,\n\u001B[0;32m    442\u001B[0m     value_layer,\n\u001B[0;32m    443\u001B[0m     attn_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[0;32m    444\u001B[0m     dropout_p\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout_prob \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0.0\u001B[39m,\n\u001B[0;32m    445\u001B[0m     is_causal\u001B[38;5;241m=\u001B[39mis_causal,\n\u001B[0;32m    446\u001B[0m )\n\u001B[0;32m    448\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m attn_output\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    449\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m attn_output\u001B[38;5;241m.\u001B[39mreshape(bsz, tgt_len, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mall_head_size)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    model, train_acc, train_loss = train_model(train_data_loader, model, optimizer)\n",
    "    val_acc, val_loss = eval_model(val_data_loader, model, optimizer)\n",
    "\n",
    "    print(f'train_loss={train_loss:.4f}, val_loss={val_loss:.4f} train_acc={train_acc:.4f}, val_acc={val_acc:.4f}')\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    # save the best model\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), \"best_model_state.bin\")\n",
    "        best_accuracy = val_acc\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T17:39:11.965899Z",
     "start_time": "2024-09-24T16:56:18.620818Z"
    }
   },
   "id": "f909b4d1b7f21369",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T16:38:55.576717Z",
     "start_time": "2024-09-24T16:38:55.576717Z"
    }
   },
   "id": "67e6b82c0a22a105"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Loading pretrained model\n",
    "\n",
    "model = BERTClass()\n",
    "model.load_state_dict(torch.load(os.path.join(data_dir,\"output\",\"MCTC_model_state.bin\")))\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49561628da2e8db4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "test_acc, test_loss = eval_model(test_data_loader, model, optimizer)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-24T16:38:55.577718Z"
    }
   },
   "id": "7bfbbedd51f71b53"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# The accuracy looks OK, similar to the validation accuracy\n",
    "# The model generalizes well !\n",
    "test_acc\n",
    "     \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85af5326793bd7b8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "def get_predictions(model, data_loader):\n",
    "    model = model.eval()\n",
    "\n",
    "    titles = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    target_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            title = data[\"title\"]\n",
    "            ids = data[\"input_ids\"].to(device, dtype = torch.long)\n",
    "            mask = data[\"attention_mask\"].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data[\"targets\"].to(device, dtype = torch.float)\n",
    "\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            _, targ = torch.max(targets, dim=1)\n",
    "\n",
    "            titles.extend(title)\n",
    "            predictions.extend(preds)\n",
    "            prediction_probs.extend(outputs)\n",
    "            target_values.extend(targ)\n",
    "\n",
    "    predictions = torch.stack(predictions).cpu()\n",
    "    prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "    target_values = torch.stack(target_values).cpu()\n",
    "\n",
    "    return titles, predictions, prediction_probs, target_values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a9854f32d8f87bb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "titles, predictions, prediction_probs, target_values = get_predictions(model, test_data_loader)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ac7916444d15f9c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(classification_report(target_values, predictions, target_names=target_list))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3090f55192f416"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def show_confusion_matrix(confusion_matrix):\n",
    "    hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "    hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "    plt.ylabel('True category')\n",
    "    plt.xlabel('Predicted category');"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "807cbe8c6644283f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# raw text\n",
    "raw_text = \"Measurement of D-meson production as a function of charged-particle multiplicity in proton--proton collisions at sâˆš=13 TeV with ALICE at the LHC\"\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe0dc0d2b4f580c4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "encoded_text = tokenizer.encode_plus(\n",
    "    raw_text,\n",
    "    max_length=MAX_LEN,\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=True,\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt',\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cac6033a709cf721"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_ids = encoded_text['input_ids'].to(device)\n",
    "attention_mask = encoded_text['attention_mask'].to(device)\n",
    "token_type_ids = encoded_text['token_type_ids'].to(device)\n",
    "output = model(input_ids, attention_mask, token_type_ids)\n",
    "_, prediction = torch.max(output, dim=1)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da5a1e732a622ed2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Correctly predicted the topic of the paper: High energy physics \n",
    "print(f'Title: {raw_text}')\n",
    "print(f'Category: {target_list[prediction]}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a6695cfdbde9fad"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
