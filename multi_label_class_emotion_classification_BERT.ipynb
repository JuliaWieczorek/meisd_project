{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:54:52.029343Z",
     "start_time": "2024-11-22T15:54:41.187711Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "import sys\n",
    "import tqdm.notebook as tq\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from googletrans import Translator\n",
    "from deep_translator import GoogleTranslator\n",
    "import random\n",
    "\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('MEISD/MEISD_text.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:54:52.110835Z",
     "start_time": "2024-11-22T15:54:52.031327Z"
    }
   },
   "id": "191da412cb222efc",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  TV Series                                       Utterances  dialog_ids  \\\n0        GA                                  look around you           1   \n1        GA                    say hello to your competition           1   \n2        GA  eight of you will switch to an easier specialty           1   \n3        GA        five of you will crack under the pressure           1   \n4        GA                two of you will be asked to leave           1   \n\n   uttr_ids  seasons  episodes   start_times     end_times sentiment  emotion  \\\n0         0        1         1  00:02:27:589  00:02:28:567   neutral  neutral   \n1         1        1         1  00:02:28:910  00:02:30:513   neutral  neutral   \n2         2        1         1  00:02:31:387  00:02:34:060   neutral  neutral   \n3         3        1         1  00:02:34:134  00:02:36:002   neutral  neutral   \n4         4        1         1  00:02:36:059  00:02:37:723   neutral  neutral   \n\n  intensity emotion2 intensity2 emotion3  intensity3  \n0       NaN      NaN        NaN      NaN         NaN  \n1       NaN      NaN        NaN      NaN         NaN  \n2       NaN      NaN        NaN      NaN         NaN  \n3       NaN      NaN        NaN      NaN         NaN  \n4       NaN      NaN        NaN      NaN         NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV Series</th>\n      <th>Utterances</th>\n      <th>dialog_ids</th>\n      <th>uttr_ids</th>\n      <th>seasons</th>\n      <th>episodes</th>\n      <th>start_times</th>\n      <th>end_times</th>\n      <th>sentiment</th>\n      <th>emotion</th>\n      <th>intensity</th>\n      <th>emotion2</th>\n      <th>intensity2</th>\n      <th>emotion3</th>\n      <th>intensity3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GA</td>\n      <td>look around you</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>00:02:27:589</td>\n      <td>00:02:28:567</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GA</td>\n      <td>say hello to your competition</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>00:02:28:910</td>\n      <td>00:02:30:513</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GA</td>\n      <td>eight of you will switch to an easier specialty</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>00:02:31:387</td>\n      <td>00:02:34:060</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GA</td>\n      <td>five of you will crack under the pressure</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>00:02:34:134</td>\n      <td>00:02:36:002</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GA</td>\n      <td>two of you will be asked to leave</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>00:02:36:059</td>\n      <td>00:02:37:723</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:54:52.131330Z",
     "start_time": "2024-11-22T15:54:52.111805Z"
    }
   },
   "id": "be38c4ec0e98b8b0",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "emotion_map = {\n",
    "    'neutral': 0,\n",
    "    'Neutral': 0,\n",
    "    'Neutral ': 0,\n",
    "    'neutral ': 0,\n",
    "    'acceptance': 1,\n",
    "    'disgust': 2,\n",
    "    'Disgust': 2,\n",
    "    ' disgust': 2,\n",
    "    'surprise': 3,\n",
    "    'Surprise': 3,\n",
    "    'joy': 4,\n",
    "    'Joy': 4,\n",
    "    'sadness': 5,\n",
    "    'Sadness': 5,\n",
    "    'anger': 6,\n",
    "    'Anger': 6,\n",
    "    'ANGER': 6,\n",
    "    'like': 7,\n",
    "    'fear': 8,\n",
    "    'Fear': 8,\n",
    "    'Fear ': 8,\n",
    "    'faer': 8,\n",
    "    'fear ': 8,\n",
    "    'Fera': 8\n",
    "\n",
    "}\n",
    "\n",
    "data_emotion = pd.DataFrame()\n",
    "data_emotion['Utterances'] = df_data['Utterances']\n",
    "data_emotion['target1'] = df_data['emotion'].map(emotion_map).fillna(9).astype(int)\n",
    "data_emotion['target2'] = df_data['emotion2'].map(emotion_map).fillna(9).astype(int)\n",
    "data_emotion['target3'] = df_data['emotion3'].map(emotion_map).fillna(9).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:54:56.783456Z",
     "start_time": "2024-11-22T15:54:56.759398Z"
    }
   },
   "id": "5a8aaa8b880c6ccb",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                        Utterances  target1  target2  target3\n0                                  look around you        0        9        9\n1                    say hello to your competition        0        9        9\n2  eight of you will switch to an easier specialty        0        9        9\n3        five of you will crack under the pressure        0        9        9\n4                two of you will be asked to leave        0        9        9",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Utterances</th>\n      <th>target1</th>\n      <th>target2</th>\n      <th>target3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>look around you</td>\n      <td>0</td>\n      <td>9</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>say hello to your competition</td>\n      <td>0</td>\n      <td>9</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eight of you will switch to an easier specialty</td>\n      <td>0</td>\n      <td>9</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>five of you will crack under the pressure</td>\n      <td>0</td>\n      <td>9</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>two of you will be asked to leave</td>\n      <td>0</td>\n      <td>9</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_emotion.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:54:58.352514Z",
     "start_time": "2024-11-22T15:54:58.340515Z"
    }
   },
   "id": "e3f0b59de6e8e8b9",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_emotion['combined_emotions'] = data_emotion[['target1', 'target2', 'target3']].apply(lambda x: x.dropna().unique().astype(int).tolist(), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:55:01.103138Z",
     "start_time": "2024-11-22T15:54:59.803739Z"
    }
   },
   "id": "270a8a1cc8fd661a",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "mlb_emotion = MultiLabelBinarizer()\n",
    "emotion_binarized = mlb_emotion.fit_transform(data_emotion['combined_emotions'])\n",
    "emotion_df = pd.DataFrame(emotion_binarized)\n",
    "emotion_df.columns = [f'emotion_{i + 1}' for i in range(emotion_df.shape[1])]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:55:03.863466Z",
     "start_time": "2024-11-22T15:55:03.834256Z"
    }
   },
   "id": "4272a0bab8f57fd3",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Utterances  emotion_1  \\\n0                                        look around you          1   \n1                          say hello to your competition          1   \n2        eight of you will switch to an easier specialty          1   \n3              five of you will crack under the pressure          1   \n4                      two of you will be asked to leave          1   \n...                                                  ...        ...   \n20012  oh, that's right, you're a woman and you need ...          0   \n20013                                     i'll try again          0   \n20014           please, pam, reconsider and have a bagel          0   \n20015                              i have an early lunch          0   \n20016  michael's been trying to get jim and me to han...          0   \n\n       emotion_2  emotion_3  emotion_4  emotion_5  emotion_6  emotion_7  \\\n0              0          0          0          0          0          0   \n1              0          0          0          0          0          0   \n2              0          0          0          0          0          0   \n3              0          0          0          0          0          0   \n4              0          0          0          0          0          0   \n...          ...        ...        ...        ...        ...        ...   \n20012          0          1          0          0          0          1   \n20013          0          1          0          0          0          1   \n20014          1          1          0          0          0          0   \n20015          0          1          0          0          0          1   \n20016          0          0          0          1          0          0   \n\n       emotion_8  emotion_9  emotion_10  \n0              0          0           1  \n1              0          0           1  \n2              0          0           1  \n3              0          0           1  \n4              0          0           1  \n...          ...        ...         ...  \n20012          0          0           1  \n20013          0          0           1  \n20014          0          0           1  \n20015          0          0           1  \n20016          0          0           1  \n\n[20017 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Utterances</th>\n      <th>emotion_1</th>\n      <th>emotion_2</th>\n      <th>emotion_3</th>\n      <th>emotion_4</th>\n      <th>emotion_5</th>\n      <th>emotion_6</th>\n      <th>emotion_7</th>\n      <th>emotion_8</th>\n      <th>emotion_9</th>\n      <th>emotion_10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>look around you</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>say hello to your competition</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eight of you will switch to an easier specialty</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>five of you will crack under the pressure</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>two of you will be asked to leave</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20012</th>\n      <td>oh, that's right, you're a woman and you need ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20013</th>\n      <td>i'll try again</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20014</th>\n      <td>please, pam, reconsider and have a bagel</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20015</th>\n      <td>i have an early lunch</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20016</th>\n      <td>michael's been trying to get jim and me to han...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>20017 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_binarizer_MEISD = pd.concat([data_emotion['Utterances'], emotion_df], axis=1)\n",
    "multi_label_binarizer_MEISD"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:55:25.536741Z",
     "start_time": "2024-11-22T15:55:25.520869Z"
    }
   },
   "id": "754405fbae26709b",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def to_binary_vector(row, num_classes=9):\n",
    "    vector = np.zeros(num_classes)\n",
    "    for i in range(1, 4):  # iteracja po target1, target2, target3\n",
    "        if row[f'target{i}'] < num_classes:\n",
    "            vector[row[f'target{i}']] = int(1)\n",
    "    return vector\n",
    "\n",
    "#data_emotion['target_vector'] = data_emotion.apply(to_binary_vector, axis=1)\n",
    "#data_emotion[['Utterances', 'target_vector']].head(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bc9fb00777fe9ef",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "target_array = np.array(data_emotion['target_vector'].tolist())\n",
    "label_counts = target_array.sum(axis=0)\n",
    "for idx, count in enumerate(label_counts):\n",
    "    print(f\"Label {idx}: {count}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d54368a3db779508",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = data_emotion[['Utterances', 'target_vector']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb9720b1294c167b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5649642e251cdce0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split into train and test\n",
    "df_train, df_test = train_test_split(multi_label_binarizer_MEISD, random_state=77, test_size=0.30, shuffle=True)\n",
    "# split test into test and validation datasets\n",
    "df_test, df_valid = train_test_split(df_train, random_state=88, test_size=0.50, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:57:05.815045Z",
     "start_time": "2024-11-22T15:57:05.797238Z"
    }
   },
   "id": "f53fda54f02119db",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train size: (20017, 11)\n",
      "Train: (14011, 11), Test: (10008, 11), Valid: (10009, 11)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original train size: {multi_label_binarizer_MEISD.shape}\")\n",
    "print(f\"Train: {df_train.shape}, Test: {df_test.shape}, Valid: {df_valid.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:57:06.627203Z",
     "start_time": "2024-11-22T15:57:06.618783Z"
    }
   },
   "id": "359789b7b940660b",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_LEN = 30\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 16\n",
    "TEST_BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001 #1e-05\n",
    "THRESHOLD = 0.2 # threshold for the sigmoid"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:57:14.938975Z",
     "start_time": "2024-11-22T15:57:14.933782Z"
    }
   },
   "id": "574ce0170aca6621",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:57:18.562842Z",
     "start_time": "2024-11-22T15:57:18.558402Z"
    }
   },
   "id": "3ef7df799231ae81",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juwieczo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[  101,  1284,  1132,  5193,   139,  9637,  1942, 22559, 17260,   119,\n           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0]])}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "# Test the tokenizer\n",
    "test_text = \"We are testing BERT tokenizer.\"\n",
    "# generate encodings\n",
    "encodings = tokenizer.encode_plus(test_text,\n",
    "                                  add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                                  max_length = 50,\n",
    "                                  truncation = True,\n",
    "                                  padding = \"max_length\",\n",
    "                                  return_attention_mask = True,\n",
    "                                  return_tensors = \"pt\")\n",
    "# we get a dictionary with three keys (see: https://huggingface.co/transformers/glossary.html) \n",
    "encodings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:57:22.287175Z",
     "start_time": "2024-11-22T15:57:19.662842Z"
    }
   },
   "id": "d2a7b6b395283c1e",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len, target_list):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.title = list(df['Utterances'])\n",
    "        self.targets = self.df[target_list].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.title[index])\n",
    "        title = \" \".join(title.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
    "            'targets': torch.FloatTensor(self.targets[index]),\n",
    "            'title': title\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:59:57.222077Z",
     "start_time": "2024-11-22T15:59:57.213066Z"
    }
   },
   "id": "adf49bd828e86638",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['emotion_1',\n 'emotion_2',\n 'emotion_3',\n 'emotion_4',\n 'emotion_5',\n 'emotion_6',\n 'emotion_7',\n 'emotion_8',\n 'emotion_9',\n 'emotion_10']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list = list(multi_label_binarizer_MEISD.columns)[1:]\n",
    "target_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:58:08.401926Z",
     "start_time": "2024-11-22T15:58:08.395447Z"
    }
   },
   "id": "361e9ea292a89728",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN, target_list)\n",
    "valid_dataset = CustomDataset(df_valid, tokenizer, MAX_LEN, target_list)\n",
    "test_dataset = CustomDataset(df_test, tokenizer, MAX_LEN, target_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T16:00:00.120696Z",
     "start_time": "2024-11-22T16:00:00.102462Z"
    }
   },
   "id": "1a55ce92afe57a5d",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([ 101, 1125, 1128, 1455,  170, 2337, 1104, 2277, 2403,  102,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0]),\n 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0]),\n 'targets': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n 'title': 'had you asked a couple of weeks ago'}"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T16:00:11.645851Z",
     "start_time": "2024-11-22T16:00:11.599930Z"
    }
   },
   "id": "2c96e3a1eee73c69",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                batch_size=TRAIN_BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0\n",
    "                                                )\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                              batch_size=VALID_BATCH_SIZE,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=0\n",
    "                                              )\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size=TEST_BATCH_SIZE,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0\n",
    "                                               )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T16:00:35.396299Z",
     "start_time": "2024-11-22T16:00:35.378454Z"
    }
   },
   "id": "622c0d56e39c45e3",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear = torch.nn.Linear(768, 10)\n",
    "\n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids,\n",
    "            attention_mask=attn_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n",
    "\n",
    "# # Freezing BERT layers: (tested, weaker convergence)\n",
    "# for param in model.bert_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-22T16:10:26.084342Z"
    }
   },
   "id": "441d76eb4e430b39",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d641e9ac7052cf9e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = LEARNING_RATE)  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44632677a67f8475"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training of the model for one epoch\n",
    "def train_model(training_loader, model, optimizer):\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    # set model to training mode (activate droput, batch norm)\n",
    "    model.train()\n",
    "    # initialize the progress bar\n",
    "    loop = tq.tqdm(enumerate(training_loader), total=len(training_loader),\n",
    "                   leave=True, colour='steelblue')\n",
    "    for batch_idx, data in loop:\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(ids, mask, token_type_ids) # (batch,predict)=(32,8)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "        # training accuracy, apply sigmoid, round (apply thresh 0.5)\n",
    "        outputs = torch.sigmoid(outputs).cpu().detach().numpy().round()\n",
    "        targets = targets.cpu().detach().numpy()\n",
    "        correct_predictions += np.sum(outputs==targets)\n",
    "        num_samples += targets.size   # total number of elements in the 2D array\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        # grad descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        #loop.set_description(f\"\")\n",
    "        #loop.set_postfix(batch_loss=loss)\n",
    "\n",
    "    # returning: trained model, model accuracy, mean loss\n",
    "    return model, float(correct_predictions)/num_samples, np.mean(losses)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29fd8ff27bd907fa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def eval_model(validation_loader, model, optimizer):\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    # set model to eval mode (turn off dropout, fix batch norm)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(validation_loader, 0):\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # validation accuracy\n",
    "            # add sigmoid, for the training sigmoid is in BCEWithLogitsLoss\n",
    "            outputs = torch.sigmoid(outputs).cpu().detach().numpy().round()\n",
    "            targets = targets.cpu().detach().numpy()\n",
    "            correct_predictions += np.sum(outputs==targets)\n",
    "            num_samples += targets.size   # total number of elements in the 2D array\n",
    "\n",
    "    return float(correct_predictions)/num_samples, np.mean(losses)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3cc89a33aaa1e96"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    model, train_acc, train_loss = train_model(train_data_loader, model, optimizer)\n",
    "    val_acc, val_loss = eval_model(val_data_loader, model, optimizer)\n",
    "\n",
    "    print(f'train_loss={train_loss:.4f}, val_loss={val_loss:.4f} train_acc={train_acc:.4f}, val_acc={val_acc:.4f}')\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    # save the best model\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), os.path.join(\"emotion_best_model_state.bin\"))\n",
    "        best_accuracy = val_acc\n",
    "     "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b30b5bdf77d3d81"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "# Loading pretrained model (best model)\n",
    "model = BERTClass()\n",
    "model.load_state_dict(torch.load(os.path.join(\"emotion_best_model_state.bin\")))\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cb7e7c59826f82d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "test_acc, test_loss = eval_model(test_data_loader, model, optimizer)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8c968a95747fd97"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "59d4ed3a2929afa3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
