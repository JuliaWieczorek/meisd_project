{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-17T12:19:52.508445Z",
     "start_time": "2024-09-17T12:19:48.155180Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import sys\n",
    "import tqdm.notebook as tq\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T08:25:52.165244Z",
     "start_time": "2024-09-04T08:25:52.162224Z"
    }
   },
   "id": "b58363187b02e5b1",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_LEN = 256\n",
    "#MAX_LEN = 64\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "#TRAIN_BATCH_SIZE = 2\n",
    "VALID_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-05"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:00:19.228450Z",
     "start_time": "2024-09-04T12:00:19.225276Z"
    }
   },
   "id": "ad6570cf3d6f09f3",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMEISD/MEISD_text.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('MEISD/MEISD_text.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-20T15:39:49.155847Z",
     "start_time": "2024-09-20T15:39:48.275988Z"
    }
   },
   "id": "c27ee3520d15ff70",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#data = data.iloc[:int(0.1 * len(data))]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:00:20.392121Z",
     "start_time": "2024-09-04T12:00:20.389453Z"
    }
   },
   "id": "573fe00c8edf9fab",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-20T15:39:49.156849Z"
    }
   },
   "id": "14d52cb06e1d19ec"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['neutral', 'acceptance', 'disgust', 'surprise', 'joy', 'sadness',\n       'anger', 'like', 'fear', 'acceptance ', 'faer', 'Fear ', 'fear ',\n       'Fear', 'Anger', 'Disgust', 'Neutral', 'Surprise', 'Joy',\n       'Sadness', 'Fera', 'ANGER', ' disgust', 'Neutral ', 'neutral '],\n      dtype=object)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(list(data['emotion'])).unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:00:20.876531Z",
     "start_time": "2024-09-04T12:00:20.868039Z"
    }
   },
   "id": "7c4e328fd5974985",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "emotion_map = {\n",
    "    'neutral': 0,\n",
    "    'acceptance': 1,\n",
    "    'disgust': 2,\n",
    "    'surprise': 3,\n",
    "    'joy': 4,\n",
    "    'sadness': 5,\n",
    "    'anger': 6,\n",
    "    'like': 7,\n",
    "    'fear': 8\n",
    "}\n",
    "\n",
    "data_emotion = pd.DataFrame()\n",
    "data_emotion['Utterances'] = data['Utterances']\n",
    "data_emotion['target1'] = data['emotion'].map(emotion_map).fillna(9).astype(int)\n",
    "data_emotion['target2'] = data['emotion2'].map(emotion_map).fillna(9).astype(int)\n",
    "data_emotion['target3'] = data['emotion3'].map(emotion_map).fillna(9).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:00:21.300900Z",
     "start_time": "2024-09-04T12:00:21.290434Z"
    }
   },
   "id": "81156bc1987f27e0",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def to_binary_vector(row, num_classes=9):\n",
    "    vector = np.zeros(num_classes)\n",
    "    for i in range(1, 4):  # iteracja po target1, target2, target3\n",
    "        if row[f'target{i}'] < num_classes:\n",
    "            vector[row[f'target{i}']] = 1\n",
    "    return vector\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:00:21.757573Z",
     "start_time": "2024-09-04T12:00:21.754452Z"
    }
   },
   "id": "e5e4f465c1e95c66",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Utterances  \\\n0                                        look around you   \n1                          say hello to your competition   \n2        eight of you will switch to an easier specialty   \n3              five of you will crack under the pressure   \n4                      two of you will be asked to leave   \n...                                                  ...   \n20012  oh, that's right, you're a woman and you need ...   \n20013                                     i'll try again   \n20014           please, pam, reconsider and have a bagel   \n20015                              i have an early lunch   \n20016  michael's been trying to get jim and me to han...   \n\n                                       target_vector  \n0      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n1      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n2      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n3      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n4      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n...                                              ...  \n20012  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n20013  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n20014  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n20015  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n20016  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n\n[20017 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Utterances</th>\n      <th>target_vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>look around you</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>say hello to your competition</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eight of you will switch to an easier specialty</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>five of you will crack under the pressure</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>two of you will be asked to leave</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20012</th>\n      <td>oh, that's right, you're a woman and you need ...</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20013</th>\n      <td>i'll try again</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20014</th>\n      <td>please, pam, reconsider and have a bagel</td>\n      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20015</th>\n      <td>i have an early lunch</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20016</th>\n      <td>michael's been trying to get jim and me to han...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n  </tbody>\n</table>\n<p>20017 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_emotion['target_vector'] = data_emotion.apply(to_binary_vector, axis=1)\n",
    "data_emotion[['Utterances', 'target_vector']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:00:22.399430Z",
     "start_time": "2024-09-04T12:00:22.192271Z"
    }
   },
   "id": "49408862008bfc12",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(data_emotion[['Utterances', 'target_vector']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:06:25.421923Z",
     "start_time": "2024-09-04T12:06:25.399856Z"
    }
   },
   "id": "3d43f7604a2b809",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['Utterances', 'target_vector'],\n    num_rows: 20017\n})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:06:25.425584Z",
     "start_time": "2024-09-04T12:06:25.421923Z"
    }
   },
   "id": "bfdc4c043bba7277",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " #split = dataset['train'].train_test_split(test_size=0.3, seed=42)\n",
    "split = dataset.train_test_split(test_size=0.3, seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:06:25.434110Z",
     "start_time": "2024-09-04T12:06:25.426586Z"
    }
   },
   "id": "92ce2090f1b3a123",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['Utterances', 'target_vector'],\n        num_rows: 14011\n    })\n    test: Dataset({\n        features: ['Utterances', 'target_vector'],\n        num_rows: 6006\n    })\n})"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:06:25.438097Z",
     "start_time": "2024-09-04T12:06:25.434110Z"
    }
   },
   "id": "6a1d6e9624516e9",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = 'bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:06:25.910320Z",
     "start_time": "2024-09-04T12:06:25.439099Z"
    }
   },
   "id": "74e78a3884fd99e2",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = split['train']\n",
    "val_data = split['test']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:06:25.913324Z",
     "start_time": "2024-09-04T12:06:25.910320Z"
    }
   },
   "id": "3a18454d9c0324bd",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "D:\\conda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    train_data['Utterances'],\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=MAX_LEN,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    val_data['Utterances'],\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=MAX_LEN,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(train_data['target_vector'])\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(val_data['target_vector'])\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:06:28.273674Z",
     "start_time": "2024-09-04T12:06:25.913324Z"
    }
   },
   "id": "46fee38cb75061ea",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=9,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:06:28.604010Z",
     "start_time": "2024-09-04T12:06:28.274675Z"
    }
   },
   "id": "e356f3dac1f7aab4",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              sampler=RandomSampler(dataset_train),\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val,\n",
    "                                   sampler=SequentialSampler(dataset_val),\n",
    "                                   batch_size=batch_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:06:28.607633Z",
     "start_time": "2024-09-04T12:06:28.604010Z"
    }
   },
   "id": "b7fdd69253893f71",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5,\n",
    "                  eps=1e-8)\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:06:29.044691Z",
     "start_time": "2024-09-04T12:06:28.607633Z"
    }
   },
   "id": "f1b396beeebba70b",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    # Flatten both preds and labels\n",
    "    preds_flat = np.round(preds).astype(int).flatten()\n",
    "    labels_flat = labels.astype(int).flatten()\n",
    "\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted', zero_division=0)\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in emotion_map.items()}\n",
    "\n",
    "    preds_flat = np.round(preds).astype(int)\n",
    "    labels_flat = labels.astype(int)\n",
    "\n",
    "    # Iterate over each label/class\n",
    "    for i in range(labels_flat.shape[1]):\n",
    "        y_preds = preds_flat[:, i]\n",
    "        y_true = labels_flat[:, i]\n",
    "        class_name = label_dict_inverse[i]\n",
    "        accuracy = np.mean(y_preds == y_true)  # Calculate accuracy\n",
    "        print(f'Class: {class_name}')\n",
    "        print(f'Accuracy: {accuracy}\\n')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T12:06:29.129730Z",
     "start_time": "2024-09-04T12:06:29.045714Z"
    }
   },
   "id": "ed39f9f71bd10f49",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/438 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 1:   0%|          | 0/438 [00:17<?, ?it/s, training_loss=0.235]\u001B[A\n",
      "Epoch 1:   0%|          | 1/438 [00:17<2:09:48, 17.82s/it, training_loss=0.235]\u001B[A\n",
      "Epoch 1:   0%|          | 1/438 [00:36<2:09:48, 17.82s/it, training_loss=0.232]\u001B[A\n",
      "Epoch 1:   0%|          | 2/438 [00:36<2:12:43, 18.26s/it, training_loss=0.232]\u001B[A\n",
      "Epoch 1:   0%|          | 2/438 [00:52<2:12:43, 18.26s/it, training_loss=0.228]\u001B[A\n",
      "Epoch 1:   1%|          | 3/438 [00:52<2:05:38, 17.33s/it, training_loss=0.228]\u001B[A\n",
      "Epoch 1:   1%|          | 3/438 [01:08<2:05:38, 17.33s/it, training_loss=0.221]\u001B[A\n",
      "Epoch 1:   1%|          | 4/438 [01:08<2:00:11, 16.62s/it, training_loss=0.221]\u001B[A\n",
      "Epoch 1:   1%|          | 4/438 [01:23<2:00:11, 16.62s/it, training_loss=0.221]\u001B[A\n",
      "Epoch 1:   1%|          | 5/438 [01:23<1:56:06, 16.09s/it, training_loss=0.221]\u001B[A\n",
      "Epoch 1:   1%|          | 5/438 [01:38<1:56:06, 16.09s/it, training_loss=0.218]\u001B[A\n",
      "Epoch 1:   1%|▏         | 6/438 [01:38<1:52:58, 15.69s/it, training_loss=0.218]\u001B[A\n",
      "Epoch 1:   1%|▏         | 6/438 [01:53<1:52:58, 15.69s/it, training_loss=0.215]\u001B[A\n",
      "Epoch 1:   2%|▏         | 7/438 [01:53<1:51:14, 15.49s/it, training_loss=0.215]\u001B[A\n",
      "Epoch 1:   2%|▏         | 7/438 [02:08<1:51:14, 15.49s/it, training_loss=0.217]\u001B[A\n",
      "Epoch 1:   2%|▏         | 8/438 [02:08<1:50:47, 15.46s/it, training_loss=0.217]\u001B[A\n",
      "Epoch 1:   2%|▏         | 8/438 [02:24<1:50:47, 15.46s/it, training_loss=0.207]\u001B[A\n",
      "Epoch 1:   2%|▏         | 9/438 [02:24<1:51:17, 15.57s/it, training_loss=0.207]\u001B[A\n",
      "Epoch 1:   2%|▏         | 9/438 [02:40<1:51:17, 15.57s/it, training_loss=0.210]\u001B[A\n",
      "Epoch 1:   2%|▏         | 10/438 [02:40<1:51:30, 15.63s/it, training_loss=0.210]\u001B[A\n",
      "Epoch 1:   2%|▏         | 10/438 [02:56<1:51:30, 15.63s/it, training_loss=0.205]\u001B[A\n",
      "Epoch 1:   3%|▎         | 11/438 [02:56<1:51:31, 15.67s/it, training_loss=0.205]\u001B[A\n",
      "Epoch 1:   3%|▎         | 11/438 [03:11<1:51:31, 15.67s/it, training_loss=0.203]\u001B[A\n",
      "Epoch 1:   3%|▎         | 12/438 [03:11<1:50:47, 15.60s/it, training_loss=0.203]\u001B[A\n",
      "Epoch 1:   3%|▎         | 12/438 [03:27<1:50:47, 15.60s/it, training_loss=0.200]\u001B[A\n",
      "Epoch 1:   3%|▎         | 13/438 [03:27<1:51:36, 15.76s/it, training_loss=0.200]\u001B[A\n",
      "Epoch 1:   3%|▎         | 13/438 [03:44<1:51:36, 15.76s/it, training_loss=0.192]\u001B[A\n",
      "Epoch 1:   3%|▎         | 14/438 [03:44<1:54:34, 16.21s/it, training_loss=0.192]\u001B[A\n",
      "Epoch 1:   3%|▎         | 14/438 [04:00<1:54:34, 16.21s/it, training_loss=0.195]\u001B[A\n",
      "Epoch 1:   3%|▎         | 15/438 [04:00<1:53:12, 16.06s/it, training_loss=0.195]\u001B[A\n",
      "Epoch 1:   3%|▎         | 15/438 [04:16<1:53:12, 16.06s/it, training_loss=0.193]\u001B[A\n",
      "Epoch 1:   4%|▎         | 16/438 [04:16<1:52:13, 15.96s/it, training_loss=0.193]\u001B[A\n",
      "Epoch 1:   4%|▎         | 16/438 [04:31<1:52:13, 15.96s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:   4%|▍         | 17/438 [04:31<1:50:20, 15.73s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:   4%|▍         | 17/438 [04:46<1:50:20, 15.73s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:   4%|▍         | 18/438 [04:46<1:48:45, 15.54s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:   4%|▍         | 18/438 [05:01<1:48:45, 15.54s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:   4%|▍         | 19/438 [05:01<1:48:07, 15.48s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:   4%|▍         | 19/438 [05:17<1:48:07, 15.48s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:   5%|▍         | 20/438 [05:17<1:48:21, 15.55s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:   5%|▍         | 20/438 [05:32<1:48:21, 15.55s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:   5%|▍         | 21/438 [05:32<1:47:29, 15.47s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:   5%|▍         | 21/438 [05:48<1:47:29, 15.47s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:   5%|▌         | 22/438 [05:48<1:46:51, 15.41s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:   5%|▌         | 22/438 [06:03<1:46:51, 15.41s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:   5%|▌         | 23/438 [06:03<1:45:37, 15.27s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:   5%|▌         | 23/438 [06:18<1:45:37, 15.27s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:   5%|▌         | 24/438 [06:18<1:46:35, 15.45s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:   5%|▌         | 24/438 [06:35<1:46:35, 15.45s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:   6%|▌         | 25/438 [06:35<1:47:34, 15.63s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:   6%|▌         | 25/438 [06:50<1:47:34, 15.63s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:   6%|▌         | 26/438 [06:50<1:47:22, 15.64s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:   6%|▌         | 26/438 [07:06<1:47:22, 15.64s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:   6%|▌         | 27/438 [07:06<1:47:50, 15.74s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:   6%|▌         | 27/438 [07:22<1:47:50, 15.74s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:   6%|▋         | 28/438 [07:22<1:48:41, 15.91s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:   6%|▋         | 28/438 [07:39<1:48:41, 15.91s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:   7%|▋         | 29/438 [07:39<1:48:59, 15.99s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:   7%|▋         | 29/438 [07:54<1:48:59, 15.99s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:   7%|▋         | 30/438 [07:54<1:47:16, 15.78s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:   7%|▋         | 30/438 [08:09<1:47:16, 15.78s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:   7%|▋         | 31/438 [08:09<1:45:52, 15.61s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:   7%|▋         | 31/438 [08:24<1:45:52, 15.61s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:   7%|▋         | 32/438 [08:24<1:44:47, 15.49s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:   7%|▋         | 32/438 [08:40<1:44:47, 15.49s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:   8%|▊         | 33/438 [08:40<1:44:47, 15.52s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:   8%|▊         | 33/438 [08:55<1:44:47, 15.52s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:   8%|▊         | 34/438 [08:55<1:44:13, 15.48s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:   8%|▊         | 34/438 [09:11<1:44:13, 15.48s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:   8%|▊         | 35/438 [09:11<1:43:32, 15.42s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:   8%|▊         | 35/438 [09:26<1:43:32, 15.42s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:   8%|▊         | 36/438 [09:26<1:42:47, 15.34s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:   8%|▊         | 36/438 [09:41<1:42:47, 15.34s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:   8%|▊         | 37/438 [09:41<1:42:12, 15.29s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:   8%|▊         | 37/438 [09:57<1:42:12, 15.29s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   9%|▊         | 38/438 [09:57<1:42:43, 15.41s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   9%|▊         | 38/438 [10:12<1:42:43, 15.41s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   9%|▉         | 39/438 [10:12<1:41:24, 15.25s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   9%|▉         | 39/438 [10:27<1:41:24, 15.25s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   9%|▉         | 40/438 [10:27<1:40:46, 15.19s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   9%|▉         | 40/438 [10:42<1:40:46, 15.19s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:   9%|▉         | 41/438 [10:42<1:40:22, 15.17s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:   9%|▉         | 41/438 [10:57<1:40:22, 15.17s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  10%|▉         | 42/438 [10:57<1:39:41, 15.10s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  10%|▉         | 42/438 [11:12<1:39:41, 15.10s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  10%|▉         | 43/438 [11:12<1:39:18, 15.08s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  10%|▉         | 43/438 [11:27<1:39:18, 15.08s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  10%|█         | 44/438 [11:27<1:39:06, 15.09s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  10%|█         | 44/438 [11:43<1:39:06, 15.09s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  10%|█         | 45/438 [11:43<1:40:28, 15.34s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  10%|█         | 45/438 [11:58<1:40:28, 15.34s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  11%|█         | 46/438 [11:58<1:39:55, 15.29s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  11%|█         | 46/438 [12:13<1:39:55, 15.29s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  11%|█         | 47/438 [12:13<1:39:11, 15.22s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  11%|█         | 47/438 [12:28<1:39:11, 15.22s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  11%|█         | 48/438 [12:28<1:38:42, 15.19s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  11%|█         | 48/438 [12:44<1:38:42, 15.19s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  11%|█         | 49/438 [12:44<1:39:03, 15.28s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  11%|█         | 49/438 [12:59<1:39:03, 15.28s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 50/438 [12:59<1:39:10, 15.34s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 50/438 [13:14<1:39:10, 15.34s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 51/438 [13:14<1:38:39, 15.30s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 51/438 [13:29<1:38:39, 15.30s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 52/438 [13:29<1:38:09, 15.26s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 52/438 [13:45<1:38:09, 15.26s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 53/438 [13:45<1:37:51, 15.25s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 53/438 [14:00<1:37:51, 15.25s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 54/438 [14:00<1:37:13, 15.19s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 54/438 [14:15<1:37:13, 15.19s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 55/438 [14:15<1:36:41, 15.15s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 55/438 [14:30<1:36:41, 15.15s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 56/438 [14:30<1:36:20, 15.13s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 56/438 [14:45<1:36:20, 15.13s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 57/438 [14:45<1:36:31, 15.20s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 57/438 [15:00<1:36:31, 15.20s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 58/438 [15:00<1:36:07, 15.18s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 58/438 [15:15<1:36:07, 15.18s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 59/438 [15:15<1:35:30, 15.12s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 59/438 [15:30<1:35:30, 15.12s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 60/438 [15:30<1:35:22, 15.14s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 60/438 [15:46<1:35:22, 15.14s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 61/438 [15:46<1:35:05, 15.13s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 61/438 [16:00<1:35:05, 15.13s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 62/438 [16:00<1:34:17, 15.05s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 62/438 [16:15<1:34:17, 15.05s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 63/438 [16:15<1:34:05, 15.05s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 63/438 [16:31<1:34:05, 15.05s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 64/438 [16:31<1:35:00, 15.24s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 64/438 [16:46<1:35:00, 15.24s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 65/438 [16:46<1:34:39, 15.23s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 65/438 [17:03<1:34:39, 15.23s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 66/438 [17:03<1:36:49, 15.62s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 66/438 [17:19<1:36:49, 15.62s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 67/438 [17:19<1:36:58, 15.68s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 67/438 [17:34<1:36:58, 15.68s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 68/438 [17:34<1:36:25, 15.64s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 68/438 [17:51<1:36:25, 15.64s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 69/438 [17:51<1:37:32, 15.86s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 69/438 [18:07<1:37:32, 15.86s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 70/438 [18:07<1:39:06, 16.16s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 70/438 [18:24<1:39:06, 16.16s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 71/438 [18:24<1:40:16, 16.39s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 71/438 [18:41<1:40:16, 16.39s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 72/438 [18:41<1:41:08, 16.58s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 72/438 [18:57<1:41:08, 16.58s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 73/438 [18:57<1:39:25, 16.34s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 73/438 [19:13<1:39:25, 16.34s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 74/438 [19:13<1:38:00, 16.16s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 74/438 [19:29<1:38:00, 16.16s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 75/438 [19:29<1:36:55, 16.02s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 75/438 [19:44<1:36:55, 16.02s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 76/438 [19:44<1:35:50, 15.89s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 76/438 [19:59<1:35:50, 15.89s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 77/438 [19:59<1:34:20, 15.68s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 77/438 [20:15<1:34:20, 15.68s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 78/438 [20:15<1:33:14, 15.54s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 78/438 [20:30<1:33:14, 15.54s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 79/438 [20:30<1:32:13, 15.41s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 79/438 [20:46<1:32:13, 15.41s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 80/438 [20:46<1:32:39, 15.53s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 80/438 [21:02<1:32:39, 15.53s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 81/438 [21:02<1:33:16, 15.68s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 81/438 [21:17<1:33:16, 15.68s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 82/438 [21:17<1:32:21, 15.56s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 82/438 [21:32<1:32:21, 15.56s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 83/438 [21:32<1:31:08, 15.40s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 83/438 [21:47<1:31:08, 15.40s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 84/438 [21:47<1:30:21, 15.31s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 84/438 [22:02<1:30:21, 15.31s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 85/438 [22:02<1:29:48, 15.26s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 85/438 [22:19<1:29:48, 15.26s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 86/438 [22:19<1:31:49, 15.65s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 86/438 [22:34<1:31:49, 15.65s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 87/438 [22:34<1:30:48, 15.52s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 87/438 [22:49<1:30:48, 15.52s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  20%|██        | 88/438 [22:49<1:30:09, 15.45s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  20%|██        | 88/438 [23:04<1:30:09, 15.45s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  20%|██        | 89/438 [23:04<1:29:32, 15.39s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  20%|██        | 89/438 [23:20<1:29:32, 15.39s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  21%|██        | 90/438 [23:20<1:28:57, 15.34s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  21%|██        | 90/438 [23:35<1:28:57, 15.34s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  21%|██        | 91/438 [23:35<1:28:38, 15.33s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  21%|██        | 91/438 [23:50<1:28:38, 15.33s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  21%|██        | 92/438 [23:50<1:28:15, 15.30s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  21%|██        | 92/438 [24:05<1:28:15, 15.30s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  21%|██        | 93/438 [24:05<1:27:31, 15.22s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  21%|██        | 93/438 [24:21<1:27:31, 15.22s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 94/438 [24:21<1:27:24, 15.25s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 94/438 [24:36<1:27:24, 15.25s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 95/438 [24:36<1:27:07, 15.24s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 95/438 [24:52<1:27:07, 15.24s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 96/438 [24:52<1:27:47, 15.40s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 96/438 [25:07<1:27:47, 15.40s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 97/438 [25:07<1:27:31, 15.40s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 97/438 [25:22<1:27:31, 15.40s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 98/438 [25:22<1:27:01, 15.36s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 98/438 [25:37<1:27:01, 15.36s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 99/438 [25:37<1:26:25, 15.30s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 99/438 [25:53<1:26:25, 15.30s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 100/438 [25:53<1:26:24, 15.34s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 100/438 [26:09<1:26:24, 15.34s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 101/438 [26:09<1:26:42, 15.44s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 101/438 [26:24<1:26:42, 15.44s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 102/438 [26:24<1:25:59, 15.35s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 102/438 [26:39<1:25:59, 15.35s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 103/438 [26:39<1:25:24, 15.30s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 103/438 [26:54<1:25:24, 15.30s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 104/438 [26:54<1:24:51, 15.24s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 104/438 [27:09<1:24:51, 15.24s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 105/438 [27:09<1:24:15, 15.18s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 105/438 [27:24<1:24:15, 15.18s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 106/438 [27:24<1:24:06, 15.20s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 106/438 [27:39<1:24:06, 15.20s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 107/438 [27:39<1:23:46, 15.19s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 107/438 [27:55<1:23:46, 15.19s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 108/438 [27:55<1:23:55, 15.26s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 108/438 [28:10<1:23:55, 15.26s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 109/438 [28:10<1:24:18, 15.37s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 109/438 [28:26<1:24:18, 15.37s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 110/438 [28:26<1:24:50, 15.52s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 110/438 [28:42<1:24:50, 15.52s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 111/438 [28:42<1:24:10, 15.44s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 111/438 [28:57<1:24:10, 15.44s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 112/438 [28:57<1:23:27, 15.36s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 112/438 [29:12<1:23:27, 15.36s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 113/438 [29:12<1:23:05, 15.34s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 113/438 [29:27<1:23:05, 15.34s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 114/438 [29:27<1:22:31, 15.28s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 114/438 [29:43<1:22:31, 15.28s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 115/438 [29:43<1:22:51, 15.39s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 115/438 [29:58<1:22:51, 15.39s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 116/438 [29:58<1:22:34, 15.39s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 116/438 [30:13<1:22:34, 15.39s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 117/438 [30:13<1:22:07, 15.35s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 117/438 [30:29<1:22:07, 15.35s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 118/438 [30:29<1:21:30, 15.28s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 118/438 [30:44<1:21:30, 15.28s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 119/438 [30:44<1:21:06, 15.26s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 119/438 [30:59<1:21:06, 15.26s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 120/438 [30:59<1:20:55, 15.27s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 120/438 [31:14<1:20:55, 15.27s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 121/438 [31:14<1:20:19, 15.20s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 121/438 [31:30<1:20:19, 15.20s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 122/438 [31:30<1:20:27, 15.28s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 122/438 [31:46<1:20:27, 15.28s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 123/438 [31:46<1:21:17, 15.49s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 123/438 [32:01<1:21:17, 15.49s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 124/438 [32:01<1:21:11, 15.51s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 124/438 [32:16<1:21:11, 15.51s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 125/438 [32:16<1:19:37, 15.26s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 125/438 [32:30<1:19:37, 15.26s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 126/438 [32:30<1:18:26, 15.09s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 126/438 [32:46<1:18:26, 15.09s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 127/438 [32:46<1:19:28, 15.33s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 127/438 [33:02<1:19:28, 15.33s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 128/438 [33:02<1:18:56, 15.28s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 128/438 [33:16<1:18:56, 15.28s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 129/438 [33:16<1:18:04, 15.16s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 129/438 [33:31<1:18:04, 15.16s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 130/438 [33:31<1:17:08, 15.03s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 130/438 [33:46<1:17:08, 15.03s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 131/438 [33:46<1:16:20, 14.92s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 131/438 [34:02<1:16:20, 14.92s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  30%|███       | 132/438 [34:02<1:18:10, 15.33s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  30%|███       | 132/438 [34:17<1:18:10, 15.33s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  30%|███       | 133/438 [34:17<1:17:02, 15.16s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  30%|███       | 133/438 [34:32<1:17:02, 15.16s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  31%|███       | 134/438 [34:32<1:16:12, 15.04s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  31%|███       | 134/438 [34:46<1:16:12, 15.04s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  31%|███       | 135/438 [34:46<1:15:29, 14.95s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  31%|███       | 135/438 [35:02<1:15:29, 14.95s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  31%|███       | 136/438 [35:02<1:16:02, 15.11s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  31%|███       | 136/438 [35:17<1:16:02, 15.11s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 137/438 [35:17<1:15:26, 15.04s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 137/438 [35:32<1:15:26, 15.04s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 138/438 [35:32<1:14:56, 14.99s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 138/438 [35:48<1:14:56, 14.99s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 139/438 [35:48<1:16:37, 15.38s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 139/438 [36:03<1:16:37, 15.38s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 140/438 [36:03<1:15:39, 15.23s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 140/438 [36:18<1:15:39, 15.23s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 141/438 [36:18<1:14:54, 15.13s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 141/438 [36:32<1:14:54, 15.13s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 142/438 [36:32<1:14:03, 15.01s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 142/438 [36:48<1:14:03, 15.01s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 143/438 [36:48<1:14:27, 15.14s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 143/438 [37:03<1:14:27, 15.14s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 144/438 [37:03<1:14:00, 15.10s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 144/438 [37:18<1:14:00, 15.10s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 145/438 [37:18<1:13:29, 15.05s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 145/438 [37:33<1:13:29, 15.05s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 146/438 [37:33<1:13:09, 15.03s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 146/438 [37:48<1:13:09, 15.03s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 147/438 [37:48<1:12:50, 15.02s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 147/438 [38:03<1:12:50, 15.02s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 148/438 [38:03<1:12:28, 15.00s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 148/438 [38:18<1:12:28, 15.00s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 149/438 [38:18<1:12:25, 15.04s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 149/438 [38:33<1:12:25, 15.04s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 150/438 [38:33<1:12:05, 15.02s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 150/438 [38:48<1:12:05, 15.02s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 151/438 [38:48<1:11:43, 14.99s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 151/438 [39:03<1:11:43, 14.99s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 152/438 [39:03<1:11:28, 14.99s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 152/438 [39:18<1:11:28, 14.99s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 153/438 [39:18<1:11:08, 14.98s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 153/438 [39:33<1:11:08, 14.98s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 154/438 [39:33<1:10:50, 14.97s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 154/438 [39:48<1:10:50, 14.97s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 155/438 [39:48<1:10:44, 15.00s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 155/438 [40:03<1:10:44, 15.00s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 156/438 [40:03<1:10:25, 14.98s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 156/438 [40:17<1:10:25, 14.98s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 157/438 [40:17<1:09:53, 14.92s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 157/438 [40:32<1:09:53, 14.92s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 158/438 [40:32<1:09:27, 14.88s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 158/438 [40:48<1:09:27, 14.88s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 159/438 [40:48<1:09:49, 15.02s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 159/438 [41:03<1:09:49, 15.02s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 160/438 [41:03<1:09:32, 15.01s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 160/438 [41:17<1:09:32, 15.01s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 161/438 [41:17<1:09:00, 14.95s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 161/438 [41:33<1:09:00, 14.95s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 162/438 [41:33<1:09:06, 15.02s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 162/438 [41:48<1:09:06, 15.02s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 163/438 [41:48<1:09:33, 15.18s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 163/438 [42:03<1:09:33, 15.18s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 164/438 [42:03<1:09:02, 15.12s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 164/438 [42:18<1:09:02, 15.12s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 165/438 [42:18<1:08:40, 15.09s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 165/438 [42:33<1:08:40, 15.09s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 166/438 [42:33<1:08:12, 15.05s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 166/438 [42:49<1:08:12, 15.05s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 167/438 [42:49<1:08:41, 15.21s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 167/438 [43:04<1:08:41, 15.21s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 168/438 [43:04<1:08:24, 15.20s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 168/438 [43:19<1:08:24, 15.20s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 169/438 [43:19<1:08:03, 15.18s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 169/438 [43:34<1:08:03, 15.18s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 170/438 [43:34<1:07:24, 15.09s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 170/438 [43:49<1:07:24, 15.09s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 171/438 [43:49<1:07:14, 15.11s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 171/438 [44:04<1:07:14, 15.11s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 172/438 [44:04<1:06:50, 15.08s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 172/438 [44:19<1:06:50, 15.08s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 173/438 [44:19<1:06:34, 15.07s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 173/438 [44:34<1:06:34, 15.07s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 174/438 [44:34<1:06:11, 15.04s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 174/438 [44:50<1:06:11, 15.04s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 175/438 [44:50<1:06:36, 15.20s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 175/438 [45:05<1:06:36, 15.20s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  40%|████      | 176/438 [45:05<1:06:04, 15.13s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  40%|████      | 176/438 [45:20<1:06:04, 15.13s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  40%|████      | 177/438 [45:20<1:06:31, 15.29s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  40%|████      | 177/438 [45:36<1:06:31, 15.29s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  41%|████      | 178/438 [45:36<1:06:19, 15.30s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  41%|████      | 178/438 [45:51<1:06:19, 15.30s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  41%|████      | 179/438 [45:51<1:05:37, 15.20s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  41%|████      | 179/438 [46:06<1:05:37, 15.20s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  41%|████      | 180/438 [46:06<1:05:13, 15.17s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  41%|████      | 180/438 [46:21<1:05:13, 15.17s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 181/438 [46:21<1:05:27, 15.28s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 181/438 [46:36<1:05:27, 15.28s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 182/438 [46:36<1:05:04, 15.25s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 182/438 [46:51<1:05:04, 15.25s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 183/438 [46:51<1:04:32, 15.19s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 183/438 [47:07<1:04:32, 15.19s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 184/438 [47:07<1:04:27, 15.23s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 184/438 [47:22<1:04:27, 15.23s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 185/438 [47:22<1:04:16, 15.24s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 185/438 [47:37<1:04:16, 15.24s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 186/438 [47:37<1:04:15, 15.30s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 186/438 [47:53<1:04:15, 15.30s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 187/438 [47:53<1:04:12, 15.35s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 187/438 [48:09<1:04:12, 15.35s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 188/438 [48:09<1:04:21, 15.45s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 188/438 [48:24<1:04:21, 15.45s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 189/438 [48:24<1:04:10, 15.47s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 189/438 [48:40<1:04:10, 15.47s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 190/438 [48:40<1:04:03, 15.50s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 190/438 [48:56<1:04:03, 15.50s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 191/438 [48:56<1:05:10, 15.83s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 191/438 [49:12<1:05:10, 15.83s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 192/438 [49:12<1:05:02, 15.87s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 192/438 [49:27<1:05:02, 15.87s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 193/438 [49:27<1:03:58, 15.67s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 193/438 [49:43<1:03:58, 15.67s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 194/438 [49:43<1:03:06, 15.52s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 194/438 [49:58<1:03:06, 15.52s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 195/438 [49:58<1:02:21, 15.40s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 195/438 [50:13<1:02:21, 15.40s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 196/438 [50:13<1:02:35, 15.52s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 196/438 [50:29<1:02:35, 15.52s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 197/438 [50:29<1:01:57, 15.42s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 197/438 [50:44<1:01:57, 15.42s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 198/438 [50:44<1:01:19, 15.33s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 198/438 [50:59<1:01:19, 15.33s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 199/438 [50:59<1:01:14, 15.37s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 199/438 [51:14<1:01:14, 15.37s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 200/438 [51:14<1:00:25, 15.23s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 200/438 [51:29<1:00:25, 15.23s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 201/438 [51:29<59:52, 15.16s/it, training_loss=0.147]  \u001B[A\n",
      "Epoch 1:  46%|████▌     | 201/438 [51:44<59:52, 15.16s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 202/438 [51:44<59:33, 15.14s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 202/438 [52:00<59:33, 15.14s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 203/438 [52:00<59:50, 15.28s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 203/438 [52:15<59:50, 15.28s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 204/438 [52:15<59:15, 15.19s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 204/438 [52:30<59:15, 15.19s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 205/438 [52:30<58:55, 15.18s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 205/438 [52:45<58:55, 15.18s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 206/438 [52:45<58:58, 15.25s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 206/438 [53:00<58:58, 15.25s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 207/438 [53:00<58:25, 15.18s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 207/438 [53:16<58:25, 15.18s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 208/438 [53:16<58:39, 15.30s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 208/438 [53:31<58:39, 15.30s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 209/438 [53:31<58:05, 15.22s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 209/438 [53:46<58:05, 15.22s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 210/438 [53:46<57:43, 15.19s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 210/438 [54:01<57:43, 15.19s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 211/438 [54:01<57:23, 15.17s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 211/438 [54:17<57:23, 15.17s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 212/438 [54:17<57:45, 15.34s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 212/438 [54:32<57:45, 15.34s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 213/438 [54:32<57:13, 15.26s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 213/438 [54:47<57:13, 15.26s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 214/438 [54:47<56:46, 15.21s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 214/438 [55:02<56:46, 15.21s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 215/438 [55:02<56:12, 15.12s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 215/438 [55:17<56:12, 15.12s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 216/438 [55:17<55:50, 15.09s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 216/438 [55:32<55:50, 15.09s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 217/438 [55:32<55:28, 15.06s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 217/438 [55:47<55:28, 15.06s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 218/438 [55:47<55:12, 15.06s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 218/438 [56:02<55:12, 15.06s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  50%|█████     | 219/438 [56:02<54:47, 15.01s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  50%|█████     | 219/438 [56:17<54:47, 15.01s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  50%|█████     | 220/438 [56:17<54:32, 15.01s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  50%|█████     | 220/438 [56:32<54:32, 15.01s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  50%|█████     | 221/438 [56:32<54:19, 15.02s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  50%|█████     | 221/438 [56:47<54:19, 15.02s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  51%|█████     | 222/438 [56:47<54:08, 15.04s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  51%|█████     | 222/438 [57:02<54:08, 15.04s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  51%|█████     | 223/438 [57:02<53:57, 15.06s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  51%|█████     | 223/438 [57:17<53:57, 15.06s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  51%|█████     | 224/438 [57:17<53:37, 15.03s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  51%|█████     | 224/438 [57:32<53:37, 15.03s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 225/438 [57:32<53:25, 15.05s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 225/438 [57:48<53:25, 15.05s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 226/438 [57:48<54:03, 15.30s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 226/438 [58:03<54:03, 15.30s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 227/438 [58:03<53:37, 15.25s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 227/438 [58:19<53:37, 15.25s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 228/438 [58:19<53:23, 15.25s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 228/438 [58:34<53:23, 15.25s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 229/438 [58:34<53:42, 15.42s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 229/438 [58:50<53:42, 15.42s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 230/438 [58:50<53:09, 15.34s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 230/438 [59:05<53:09, 15.34s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 231/438 [59:05<52:35, 15.24s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 231/438 [59:20<52:35, 15.24s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 232/438 [59:20<52:14, 15.22s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 232/438 [59:35<52:14, 15.22s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 233/438 [59:35<52:24, 15.34s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 233/438 [59:51<52:24, 15.34s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 234/438 [59:51<52:28, 15.43s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 234/438 [1:00:06<52:28, 15.43s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 235/438 [1:00:06<51:48, 15.31s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 235/438 [1:00:21<51:48, 15.31s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 236/438 [1:00:21<51:19, 15.25s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 236/438 [1:00:36<51:19, 15.25s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 237/438 [1:00:36<50:57, 15.21s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 237/438 [1:00:52<50:57, 15.21s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 238/438 [1:00:52<51:08, 15.34s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 238/438 [1:01:07<51:08, 15.34s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 239/438 [1:01:07<50:48, 15.32s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 239/438 [1:01:22<50:48, 15.32s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 240/438 [1:01:22<50:13, 15.22s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 240/438 [1:01:37<50:13, 15.22s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 241/438 [1:01:37<49:52, 15.19s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 241/438 [1:01:52<49:52, 15.19s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 242/438 [1:01:52<49:27, 15.14s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 242/438 [1:02:07<49:27, 15.14s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 243/438 [1:02:07<49:08, 15.12s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 243/438 [1:02:23<49:08, 15.12s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 244/438 [1:02:23<48:52, 15.12s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 244/438 [1:02:38<48:52, 15.12s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 245/438 [1:02:38<48:37, 15.12s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 245/438 [1:02:53<48:37, 15.12s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 246/438 [1:02:53<48:21, 15.11s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 246/438 [1:03:08<48:21, 15.11s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 247/438 [1:03:08<48:29, 15.23s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 247/438 [1:03:23<48:29, 15.23s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 248/438 [1:03:23<48:04, 15.18s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 248/438 [1:03:38<48:04, 15.18s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 249/438 [1:03:38<47:48, 15.18s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 249/438 [1:03:54<47:48, 15.18s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 250/438 [1:03:54<47:32, 15.18s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 250/438 [1:04:10<47:32, 15.18s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 251/438 [1:04:10<48:39, 15.61s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 251/438 [1:04:26<48:39, 15.61s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 252/438 [1:04:26<48:04, 15.51s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 252/438 [1:04:41<48:04, 15.51s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 253/438 [1:04:41<47:26, 15.39s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 253/438 [1:04:56<47:26, 15.39s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 254/438 [1:04:56<47:02, 15.34s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 254/438 [1:05:11<47:02, 15.34s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 255/438 [1:05:11<46:40, 15.30s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 255/438 [1:05:27<46:40, 15.30s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 256/438 [1:05:27<46:39, 15.38s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 256/438 [1:05:42<46:39, 15.38s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 257/438 [1:05:42<46:29, 15.41s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 257/438 [1:05:58<46:29, 15.41s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 258/438 [1:05:58<46:10, 15.39s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 258/438 [1:06:13<46:10, 15.39s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 259/438 [1:06:13<45:36, 15.29s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 259/438 [1:06:28<45:36, 15.29s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 260/438 [1:06:28<45:11, 15.23s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 260/438 [1:06:43<45:11, 15.23s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 261/438 [1:06:43<45:25, 15.40s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 261/438 [1:06:59<45:25, 15.40s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 262/438 [1:06:59<45:10, 15.40s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 262/438 [1:07:14<45:10, 15.40s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  60%|██████    | 263/438 [1:07:14<44:49, 15.37s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  60%|██████    | 263/438 [1:07:29<44:49, 15.37s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  60%|██████    | 264/438 [1:07:29<44:11, 15.24s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  60%|██████    | 264/438 [1:07:44<44:11, 15.24s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  61%|██████    | 265/438 [1:07:44<43:58, 15.25s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  61%|██████    | 265/438 [1:08:00<43:58, 15.25s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  61%|██████    | 266/438 [1:08:00<43:42, 15.25s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  61%|██████    | 266/438 [1:08:15<43:42, 15.25s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  61%|██████    | 267/438 [1:08:15<43:36, 15.30s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  61%|██████    | 267/438 [1:08:30<43:36, 15.30s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  61%|██████    | 268/438 [1:08:30<43:16, 15.28s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  61%|██████    | 268/438 [1:08:45<43:16, 15.28s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 269/438 [1:08:45<43:00, 15.27s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 269/438 [1:09:01<43:00, 15.27s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 270/438 [1:09:01<42:45, 15.27s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 270/438 [1:09:16<42:45, 15.27s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 271/438 [1:09:16<42:24, 15.24s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 271/438 [1:09:31<42:24, 15.24s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 272/438 [1:09:31<42:05, 15.22s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 272/438 [1:09:46<42:05, 15.22s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 273/438 [1:09:46<41:55, 15.25s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 273/438 [1:10:02<41:55, 15.25s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 274/438 [1:10:02<41:38, 15.23s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 274/438 [1:10:17<41:38, 15.23s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 275/438 [1:10:17<41:16, 15.19s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 275/438 [1:10:32<41:16, 15.19s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 276/438 [1:10:32<41:13, 15.27s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 276/438 [1:10:48<41:13, 15.27s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 277/438 [1:10:48<41:23, 15.42s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 277/438 [1:11:03<41:23, 15.42s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 278/438 [1:11:03<41:05, 15.41s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 278/438 [1:11:18<41:05, 15.41s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 279/438 [1:11:18<40:37, 15.33s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 279/438 [1:11:33<40:37, 15.33s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 280/438 [1:11:33<40:04, 15.22s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 280/438 [1:11:49<40:04, 15.22s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 281/438 [1:11:49<40:10, 15.36s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 281/438 [1:12:04<40:10, 15.36s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 282/438 [1:12:04<39:43, 15.28s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 282/438 [1:12:19<39:43, 15.28s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 283/438 [1:12:19<39:22, 15.25s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 283/438 [1:12:35<39:22, 15.25s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 284/438 [1:12:35<39:13, 15.28s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 284/438 [1:12:50<39:13, 15.28s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 285/438 [1:12:50<38:58, 15.29s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 285/438 [1:13:05<38:58, 15.29s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 286/438 [1:13:05<38:40, 15.27s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 286/438 [1:13:20<38:40, 15.27s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 287/438 [1:13:20<38:21, 15.24s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 287/438 [1:13:36<38:21, 15.24s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 288/438 [1:13:36<38:23, 15.36s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 288/438 [1:13:51<38:23, 15.36s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 289/438 [1:13:51<37:56, 15.28s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 289/438 [1:14:06<37:56, 15.28s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 290/438 [1:14:06<37:39, 15.26s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 290/438 [1:14:21<37:39, 15.26s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 291/438 [1:14:21<37:12, 15.18s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 291/438 [1:14:36<37:12, 15.18s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 292/438 [1:14:36<36:52, 15.16s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 292/438 [1:14:52<36:52, 15.16s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 293/438 [1:14:52<36:33, 15.13s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 293/438 [1:15:07<36:33, 15.13s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 294/438 [1:15:07<36:44, 15.31s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 294/438 [1:15:22<36:44, 15.31s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 295/438 [1:15:22<36:25, 15.29s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 295/438 [1:15:38<36:25, 15.29s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 296/438 [1:15:38<36:02, 15.23s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 296/438 [1:15:53<36:02, 15.23s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 297/438 [1:15:53<35:37, 15.16s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 297/438 [1:16:08<35:37, 15.16s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 298/438 [1:16:08<35:24, 15.18s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 298/438 [1:16:23<35:24, 15.18s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 299/438 [1:16:23<35:02, 15.13s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 299/438 [1:16:38<35:02, 15.13s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 300/438 [1:16:38<34:53, 15.17s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 300/438 [1:16:53<34:53, 15.17s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 301/438 [1:16:53<34:36, 15.16s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 301/438 [1:17:09<34:36, 15.16s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 302/438 [1:17:09<34:38, 15.28s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 302/438 [1:17:24<34:38, 15.28s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 303/438 [1:17:24<34:24, 15.29s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 303/438 [1:17:39<34:24, 15.29s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 304/438 [1:17:39<34:11, 15.31s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 304/438 [1:17:55<34:11, 15.31s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 305/438 [1:17:55<33:48, 15.26s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 305/438 [1:18:10<33:48, 15.26s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 306/438 [1:18:10<33:50, 15.38s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 306/438 [1:18:25<33:50, 15.38s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  70%|███████   | 307/438 [1:18:25<33:28, 15.34s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  70%|███████   | 307/438 [1:18:41<33:28, 15.34s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  70%|███████   | 308/438 [1:18:41<33:13, 15.34s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  70%|███████   | 308/438 [1:18:56<33:13, 15.34s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  71%|███████   | 309/438 [1:18:56<33:00, 15.35s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  71%|███████   | 309/438 [1:19:13<33:00, 15.35s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  71%|███████   | 310/438 [1:19:13<33:52, 15.88s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  71%|███████   | 310/438 [1:19:28<33:52, 15.88s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  71%|███████   | 311/438 [1:19:28<33:09, 15.66s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  71%|███████   | 311/438 [1:19:44<33:09, 15.66s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  71%|███████   | 312/438 [1:19:44<32:43, 15.59s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  71%|███████   | 312/438 [1:19:59<32:43, 15.59s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 313/438 [1:19:59<32:11, 15.45s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 313/438 [1:20:15<32:11, 15.45s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 314/438 [1:20:15<32:03, 15.51s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 314/438 [1:20:30<32:03, 15.51s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 315/438 [1:20:30<31:34, 15.40s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 315/438 [1:20:45<31:34, 15.40s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 316/438 [1:20:45<31:08, 15.32s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 316/438 [1:21:00<31:08, 15.32s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 317/438 [1:21:00<30:42, 15.23s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 317/438 [1:21:15<30:42, 15.23s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 318/438 [1:21:15<30:21, 15.18s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 318/438 [1:21:30<30:21, 15.18s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 319/438 [1:21:30<30:04, 15.16s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 319/438 [1:21:45<30:04, 15.16s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 320/438 [1:21:45<29:50, 15.17s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 320/438 [1:22:00<29:50, 15.17s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 321/438 [1:22:00<29:31, 15.14s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 321/438 [1:22:16<29:31, 15.14s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 322/438 [1:22:16<29:15, 15.14s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 322/438 [1:22:30<29:15, 15.14s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 323/438 [1:22:30<28:53, 15.07s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 323/438 [1:22:46<28:53, 15.07s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 324/438 [1:22:46<28:38, 15.08s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 324/438 [1:23:01<28:38, 15.08s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 325/438 [1:23:01<28:23, 15.08s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 325/438 [1:23:16<28:23, 15.08s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 326/438 [1:23:16<28:18, 15.17s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 326/438 [1:23:31<28:18, 15.17s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 327/438 [1:23:31<27:59, 15.13s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 327/438 [1:23:47<27:59, 15.13s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 328/438 [1:23:47<27:57, 15.25s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 328/438 [1:24:02<27:57, 15.25s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 329/438 [1:24:02<27:51, 15.34s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 329/438 [1:24:18<27:51, 15.34s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 330/438 [1:24:18<27:42, 15.40s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 330/438 [1:24:33<27:42, 15.40s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 331/438 [1:24:33<27:16, 15.30s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 331/438 [1:24:48<27:16, 15.30s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 332/438 [1:24:48<26:49, 15.19s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 332/438 [1:25:03<26:49, 15.19s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 333/438 [1:25:03<26:26, 15.11s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 333/438 [1:25:18<26:26, 15.11s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 334/438 [1:25:18<26:21, 15.21s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 334/438 [1:25:33<26:21, 15.21s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 335/438 [1:25:33<25:58, 15.13s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 335/438 [1:25:48<25:58, 15.13s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 336/438 [1:25:48<25:39, 15.09s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 336/438 [1:26:03<25:39, 15.09s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 337/438 [1:26:03<25:25, 15.10s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 337/438 [1:26:18<25:25, 15.10s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 338/438 [1:26:18<25:04, 15.05s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 338/438 [1:26:34<25:04, 15.05s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 339/438 [1:26:34<25:06, 15.22s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 339/438 [1:26:49<25:06, 15.22s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 340/438 [1:26:49<24:55, 15.26s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 340/438 [1:27:04<24:55, 15.26s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 341/438 [1:27:04<24:32, 15.18s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 341/438 [1:27:19<24:32, 15.18s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 342/438 [1:27:19<24:09, 15.09s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 342/438 [1:27:34<24:09, 15.09s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 343/438 [1:27:34<23:51, 15.07s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 343/438 [1:27:49<23:51, 15.07s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 344/438 [1:27:49<23:38, 15.09s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 344/438 [1:28:04<23:38, 15.09s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 345/438 [1:28:04<23:19, 15.05s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 345/438 [1:28:20<23:19, 15.05s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 346/438 [1:28:20<23:32, 15.35s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 346/438 [1:28:35<23:32, 15.35s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 347/438 [1:28:35<23:15, 15.34s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 347/438 [1:28:50<23:15, 15.34s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 348/438 [1:28:50<22:52, 15.25s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 348/438 [1:29:06<22:52, 15.25s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 349/438 [1:29:06<22:36, 15.24s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 349/438 [1:29:21<22:36, 15.24s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 350/438 [1:29:21<22:18, 15.21s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 350/438 [1:29:36<22:18, 15.21s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  80%|████████  | 351/438 [1:29:36<21:59, 15.17s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  80%|████████  | 351/438 [1:29:51<21:59, 15.17s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  80%|████████  | 352/438 [1:29:51<21:45, 15.18s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  80%|████████  | 352/438 [1:30:07<21:45, 15.18s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  81%|████████  | 353/438 [1:30:07<21:44, 15.35s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  81%|████████  | 353/438 [1:30:22<21:44, 15.35s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  81%|████████  | 354/438 [1:30:22<21:31, 15.38s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  81%|████████  | 354/438 [1:30:37<21:31, 15.38s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  81%|████████  | 355/438 [1:30:37<21:12, 15.33s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  81%|████████  | 355/438 [1:30:53<21:12, 15.33s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 356/438 [1:30:53<20:53, 15.28s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 356/438 [1:31:08<20:53, 15.28s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 357/438 [1:31:08<20:36, 15.27s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 357/438 [1:31:23<20:36, 15.27s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 358/438 [1:31:23<20:16, 15.21s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 358/438 [1:31:38<20:16, 15.21s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 359/438 [1:31:38<20:02, 15.22s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 359/438 [1:31:54<20:02, 15.22s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 360/438 [1:31:54<19:59, 15.38s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 360/438 [1:32:09<19:59, 15.38s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 361/438 [1:32:09<19:46, 15.41s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 361/438 [1:32:25<19:46, 15.41s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 362/438 [1:32:25<19:28, 15.38s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 362/438 [1:32:40<19:28, 15.38s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 363/438 [1:32:40<19:08, 15.31s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 363/438 [1:32:55<19:08, 15.31s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 364/438 [1:32:55<18:48, 15.25s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 364/438 [1:33:10<18:48, 15.25s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 365/438 [1:33:10<18:35, 15.28s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 365/438 [1:33:26<18:35, 15.28s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 366/438 [1:33:26<18:21, 15.30s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 366/438 [1:33:41<18:21, 15.30s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 367/438 [1:33:41<18:05, 15.29s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 367/438 [1:33:56<18:05, 15.29s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 368/438 [1:33:56<17:48, 15.27s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 368/438 [1:34:13<17:48, 15.27s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 369/438 [1:34:13<18:01, 15.68s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 369/438 [1:34:28<18:01, 15.68s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 370/438 [1:34:28<17:44, 15.66s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 370/438 [1:34:44<17:44, 15.66s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 371/438 [1:34:44<17:20, 15.54s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 371/438 [1:34:59<17:20, 15.54s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 372/438 [1:34:59<17:01, 15.47s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 372/438 [1:35:14<17:01, 15.47s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 373/438 [1:35:14<16:42, 15.42s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 373/438 [1:35:30<16:42, 15.42s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 374/438 [1:35:30<16:24, 15.38s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 374/438 [1:35:45<16:24, 15.38s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 375/438 [1:35:45<16:06, 15.34s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 375/438 [1:36:00<16:06, 15.34s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 376/438 [1:36:00<15:47, 15.28s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 376/438 [1:36:15<15:47, 15.28s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 377/438 [1:36:15<15:29, 15.24s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 377/438 [1:36:30<15:29, 15.24s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 378/438 [1:36:30<15:12, 15.21s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 378/438 [1:36:46<15:12, 15.21s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 379/438 [1:36:46<15:00, 15.27s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 379/438 [1:37:01<15:00, 15.27s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 380/438 [1:37:01<14:46, 15.29s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 380/438 [1:37:16<14:46, 15.29s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 381/438 [1:37:16<14:28, 15.24s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 381/438 [1:37:31<14:28, 15.24s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 382/438 [1:37:31<14:15, 15.28s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 382/438 [1:37:47<14:15, 15.28s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 383/438 [1:37:47<13:57, 15.23s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 383/438 [1:38:02<13:57, 15.23s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 384/438 [1:38:02<13:42, 15.24s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 384/438 [1:38:17<13:42, 15.24s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 385/438 [1:38:17<13:29, 15.28s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 385/438 [1:38:32<13:29, 15.28s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 386/438 [1:38:32<13:14, 15.28s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 386/438 [1:38:49<13:14, 15.28s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 387/438 [1:38:49<13:11, 15.51s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 387/438 [1:39:04<13:11, 15.51s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 388/438 [1:39:04<12:55, 15.52s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 388/438 [1:39:20<12:55, 15.52s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 389/438 [1:39:20<12:39, 15.51s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 389/438 [1:39:35<12:39, 15.51s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 390/438 [1:39:35<12:17, 15.37s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 390/438 [1:39:50<12:17, 15.37s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 391/438 [1:39:50<12:05, 15.43s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 391/438 [1:40:06<12:05, 15.43s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 392/438 [1:40:06<11:51, 15.46s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 392/438 [1:40:21<11:51, 15.46s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 393/438 [1:40:21<11:32, 15.39s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 393/438 [1:40:36<11:32, 15.39s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 394/438 [1:40:36<11:14, 15.33s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 394/438 [1:40:51<11:14, 15.33s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 395/438 [1:40:51<10:58, 15.30s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 395/438 [1:41:07<10:58, 15.30s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 396/438 [1:41:07<10:44, 15.34s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 396/438 [1:41:22<10:44, 15.34s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 397/438 [1:41:22<10:27, 15.30s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 397/438 [1:41:37<10:27, 15.30s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 398/438 [1:41:37<10:09, 15.24s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 398/438 [1:41:52<10:09, 15.24s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 399/438 [1:41:52<09:52, 15.20s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 399/438 [1:42:07<09:52, 15.20s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 400/438 [1:42:07<09:36, 15.18s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 400/438 [1:42:22<09:36, 15.18s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 401/438 [1:42:22<09:21, 15.18s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 401/438 [1:42:38<09:21, 15.18s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 402/438 [1:42:38<09:06, 15.19s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 402/438 [1:42:54<09:06, 15.19s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 403/438 [1:42:54<09:00, 15.43s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 403/438 [1:43:09<09:00, 15.43s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 404/438 [1:43:09<08:40, 15.31s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 404/438 [1:43:24<08:40, 15.31s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 405/438 [1:43:24<08:23, 15.24s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 405/438 [1:43:39<08:23, 15.24s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 406/438 [1:43:39<08:07, 15.25s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 406/438 [1:43:54<08:07, 15.25s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 407/438 [1:43:54<07:51, 15.21s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 407/438 [1:44:09<07:51, 15.21s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 408/438 [1:44:09<07:36, 15.22s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 408/438 [1:44:25<07:36, 15.22s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 409/438 [1:44:25<07:20, 15.19s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 409/438 [1:44:40<07:20, 15.19s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 410/438 [1:44:40<07:03, 15.14s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 410/438 [1:44:55<07:03, 15.14s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 411/438 [1:44:55<06:48, 15.14s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 411/438 [1:45:10<06:48, 15.14s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 412/438 [1:45:10<06:33, 15.14s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 412/438 [1:45:25<06:33, 15.14s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 413/438 [1:45:25<06:19, 15.17s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 413/438 [1:45:40<06:19, 15.17s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 414/438 [1:45:40<06:03, 15.16s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 414/438 [1:45:56<06:03, 15.16s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 415/438 [1:45:56<05:49, 15.21s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 415/438 [1:46:11<05:49, 15.21s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 416/438 [1:46:11<05:34, 15.19s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 416/438 [1:46:26<05:34, 15.19s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 417/438 [1:46:26<05:18, 15.19s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 417/438 [1:46:41<05:18, 15.19s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 418/438 [1:46:41<05:04, 15.20s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 418/438 [1:46:56<05:04, 15.20s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 419/438 [1:46:56<04:48, 15.18s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 419/438 [1:47:12<04:48, 15.18s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 420/438 [1:47:12<04:33, 15.21s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 420/438 [1:47:27<04:33, 15.21s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 421/438 [1:47:27<04:17, 15.17s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 421/438 [1:47:42<04:17, 15.17s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 422/438 [1:47:42<04:03, 15.20s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 422/438 [1:47:57<04:03, 15.20s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 423/438 [1:47:57<03:47, 15.16s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 423/438 [1:48:12<03:47, 15.16s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 424/438 [1:48:12<03:33, 15.26s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 424/438 [1:48:28<03:33, 15.26s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 425/438 [1:48:28<03:18, 15.26s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 425/438 [1:48:43<03:18, 15.26s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 426/438 [1:48:43<03:03, 15.27s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 426/438 [1:48:58<03:03, 15.27s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 427/438 [1:48:58<02:47, 15.21s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 427/438 [1:49:13<02:47, 15.21s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 428/438 [1:49:13<02:31, 15.16s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 428/438 [1:49:30<02:31, 15.16s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 429/438 [1:49:30<02:20, 15.65s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 429/438 [1:49:45<02:20, 15.65s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 430/438 [1:49:45<02:04, 15.52s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 430/438 [1:50:00<02:04, 15.52s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 431/438 [1:50:00<01:48, 15.46s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 431/438 [1:50:16<01:48, 15.46s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 432/438 [1:50:16<01:32, 15.40s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 432/438 [1:50:31<01:32, 15.40s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 433/438 [1:50:31<01:16, 15.31s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 433/438 [1:50:46<01:16, 15.31s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 434/438 [1:50:46<01:01, 15.26s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 434/438 [1:51:01<01:01, 15.26s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 435/438 [1:51:01<00:45, 15.29s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 435/438 [1:51:16<00:45, 15.29s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 436/438 [1:51:16<00:30, 15.26s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 436/438 [1:51:32<00:30, 15.26s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 437/438 [1:51:32<00:15, 15.21s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 437/438 [1:51:45<00:15, 15.21s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1: 100%|██████████| 438/438 [1:51:45<00:00, 14.59s/it, training_loss=0.134]\u001B[A\n",
      "  0%|          | 0/3 [1:51:45<?, ?it/s]                                          \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Trainin loss: 0.4149661928959633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [2:10:38<4:21:16, 7838.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3976703238614062\n",
      "F1 Score (Weighted): 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2:   0%|          | 0/438 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 2:   0%|          | 0/438 [00:15<?, ?it/s, training_loss=0.149]\u001B[A\n",
      "Epoch 2:   0%|          | 1/438 [00:15<1:50:04, 15.11s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 2:   0%|          | 1/438 [00:30<1:50:04, 15.11s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:   0%|          | 2/438 [00:30<1:49:44, 15.10s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:   0%|          | 2/438 [00:45<1:49:44, 15.10s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:   1%|          | 3/438 [00:45<1:49:24, 15.09s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:   1%|          | 3/438 [01:00<1:49:24, 15.09s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:   1%|          | 4/438 [01:00<1:48:55, 15.06s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:   1%|          | 4/438 [01:15<1:48:55, 15.06s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   1%|          | 5/438 [01:15<1:48:41, 15.06s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   1%|          | 5/438 [01:30<1:48:41, 15.06s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   1%|▏         | 6/438 [01:30<1:48:21, 15.05s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   1%|▏         | 6/438 [01:45<1:48:21, 15.05s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:   2%|▏         | 7/438 [01:45<1:48:23, 15.09s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:   2%|▏         | 7/438 [02:00<1:48:23, 15.09s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:   2%|▏         | 8/438 [02:00<1:48:13, 15.10s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:   2%|▏         | 8/438 [02:15<1:48:13, 15.10s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:   2%|▏         | 9/438 [02:15<1:48:13, 15.14s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:   2%|▏         | 9/438 [02:31<1:48:13, 15.14s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:   2%|▏         | 10/438 [02:31<1:48:58, 15.28s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:   2%|▏         | 10/438 [02:46<1:48:58, 15.28s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:   3%|▎         | 11/438 [02:46<1:48:29, 15.24s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:   3%|▎         | 11/438 [03:01<1:48:29, 15.24s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   3%|▎         | 12/438 [03:01<1:47:55, 15.20s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   3%|▎         | 12/438 [03:16<1:47:55, 15.20s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:   3%|▎         | 13/438 [03:16<1:47:20, 15.15s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:   3%|▎         | 13/438 [03:31<1:47:20, 15.15s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:   3%|▎         | 14/438 [03:31<1:46:55, 15.13s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:   3%|▎         | 14/438 [03:46<1:46:55, 15.13s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:   3%|▎         | 15/438 [03:46<1:46:27, 15.10s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:   3%|▎         | 15/438 [04:01<1:46:27, 15.10s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:   4%|▎         | 16/438 [04:01<1:46:05, 15.08s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:   4%|▎         | 16/438 [04:17<1:46:05, 15.08s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:   4%|▍         | 17/438 [04:17<1:46:26, 15.17s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:   4%|▍         | 17/438 [04:32<1:46:26, 15.17s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   4%|▍         | 18/438 [04:32<1:45:33, 15.08s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   4%|▍         | 18/438 [04:47<1:45:33, 15.08s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:   4%|▍         | 19/438 [04:47<1:45:14, 15.07s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:   4%|▍         | 19/438 [05:02<1:45:14, 15.07s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:   5%|▍         | 20/438 [05:02<1:44:47, 15.04s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:   5%|▍         | 20/438 [05:17<1:44:47, 15.04s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:   5%|▍         | 21/438 [05:17<1:44:13, 15.00s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:   5%|▍         | 21/438 [05:32<1:44:13, 15.00s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:   5%|▌         | 22/438 [05:32<1:44:01, 15.00s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:   5%|▌         | 22/438 [05:47<1:44:01, 15.00s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:   5%|▌         | 23/438 [05:47<1:43:58, 15.03s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:   5%|▌         | 23/438 [06:02<1:43:58, 15.03s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:   5%|▌         | 24/438 [06:02<1:43:59, 15.07s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:   5%|▌         | 24/438 [06:17<1:43:59, 15.07s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   6%|▌         | 25/438 [06:17<1:43:20, 15.01s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   6%|▌         | 25/438 [06:32<1:43:20, 15.01s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:   6%|▌         | 26/438 [06:32<1:43:16, 15.04s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:   6%|▌         | 26/438 [06:47<1:43:16, 15.04s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   6%|▌         | 27/438 [06:47<1:43:16, 15.08s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   6%|▌         | 27/438 [07:02<1:43:16, 15.08s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   6%|▋         | 28/438 [07:02<1:42:47, 15.04s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   6%|▋         | 28/438 [07:17<1:42:47, 15.04s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:   7%|▋         | 29/438 [07:17<1:42:20, 15.01s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:   7%|▋         | 29/438 [07:32<1:42:20, 15.01s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:   7%|▋         | 30/438 [07:32<1:42:48, 15.12s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:   7%|▋         | 30/438 [07:48<1:42:48, 15.12s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:   7%|▋         | 31/438 [07:48<1:43:28, 15.25s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:   7%|▋         | 31/438 [08:03<1:43:28, 15.25s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:   7%|▋         | 32/438 [08:03<1:43:24, 15.28s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:   7%|▋         | 32/438 [08:18<1:43:24, 15.28s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:   8%|▊         | 33/438 [08:18<1:42:36, 15.20s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:   8%|▊         | 33/438 [08:33<1:42:36, 15.20s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:   8%|▊         | 34/438 [08:33<1:42:03, 15.16s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:   8%|▊         | 34/438 [08:49<1:42:03, 15.16s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:   8%|▊         | 35/438 [08:49<1:42:30, 15.26s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:   8%|▊         | 35/438 [09:05<1:42:30, 15.26s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:   8%|▊         | 36/438 [09:05<1:44:14, 15.56s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:   8%|▊         | 36/438 [09:20<1:44:14, 15.56s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   8%|▊         | 37/438 [09:20<1:42:58, 15.41s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   8%|▊         | 37/438 [09:35<1:42:58, 15.41s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   9%|▊         | 38/438 [09:35<1:42:03, 15.31s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   9%|▊         | 38/438 [09:50<1:42:03, 15.31s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   9%|▉         | 39/438 [09:50<1:41:11, 15.22s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   9%|▉         | 39/438 [10:05<1:41:11, 15.22s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   9%|▉         | 40/438 [10:05<1:40:45, 15.19s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   9%|▉         | 40/438 [10:20<1:40:45, 15.19s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:   9%|▉         | 41/438 [10:20<1:39:53, 15.10s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:   9%|▉         | 41/438 [10:35<1:39:53, 15.10s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  10%|▉         | 42/438 [10:35<1:39:35, 15.09s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  10%|▉         | 42/438 [10:50<1:39:35, 15.09s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  10%|▉         | 43/438 [10:50<1:39:16, 15.08s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  10%|▉         | 43/438 [11:05<1:39:16, 15.08s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  10%|█         | 44/438 [11:05<1:39:01, 15.08s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  10%|█         | 44/438 [11:20<1:39:01, 15.08s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  10%|█         | 45/438 [11:20<1:38:44, 15.07s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  10%|█         | 45/438 [11:36<1:38:44, 15.07s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  11%|█         | 46/438 [11:36<1:38:28, 15.07s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  11%|█         | 46/438 [11:51<1:38:28, 15.07s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  11%|█         | 47/438 [11:51<1:38:23, 15.10s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  11%|█         | 47/438 [12:06<1:38:23, 15.10s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  11%|█         | 48/438 [12:06<1:38:23, 15.14s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  11%|█         | 48/438 [12:21<1:38:23, 15.14s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  11%|█         | 49/438 [12:21<1:38:02, 15.12s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  11%|█         | 49/438 [12:36<1:38:02, 15.12s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  11%|█▏        | 50/438 [12:36<1:38:11, 15.18s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  11%|█▏        | 50/438 [12:51<1:38:11, 15.18s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 51/438 [12:51<1:37:48, 15.16s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 51/438 [13:07<1:37:48, 15.16s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 52/438 [13:07<1:37:57, 15.23s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 52/438 [13:22<1:37:57, 15.23s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 53/438 [13:22<1:37:34, 15.21s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 53/438 [13:37<1:37:34, 15.21s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 54/438 [13:37<1:37:29, 15.23s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 54/438 [13:52<1:37:29, 15.23s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 55/438 [13:52<1:36:57, 15.19s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 55/438 [14:07<1:36:57, 15.19s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 56/438 [14:07<1:36:19, 15.13s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 56/438 [14:22<1:36:19, 15.13s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 57/438 [14:22<1:35:43, 15.07s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 57/438 [14:37<1:35:43, 15.07s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 58/438 [14:37<1:35:35, 15.09s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 58/438 [14:53<1:35:35, 15.09s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 59/438 [14:53<1:35:16, 15.08s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 59/438 [15:08<1:35:16, 15.08s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  14%|█▎        | 60/438 [15:08<1:35:05, 15.10s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  14%|█▎        | 60/438 [15:23<1:35:05, 15.10s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  14%|█▍        | 61/438 [15:23<1:34:41, 15.07s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  14%|█▍        | 61/438 [15:38<1:34:41, 15.07s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  14%|█▍        | 62/438 [15:38<1:34:22, 15.06s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  14%|█▍        | 62/438 [15:53<1:34:22, 15.06s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  14%|█▍        | 63/438 [15:53<1:34:07, 15.06s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  14%|█▍        | 63/438 [16:08<1:34:07, 15.06s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 2:  15%|█▍        | 64/438 [16:08<1:34:10, 15.11s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 2:  15%|█▍        | 64/438 [16:24<1:34:10, 15.11s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  15%|█▍        | 65/438 [16:24<1:35:20, 15.34s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  15%|█▍        | 65/438 [16:39<1:35:20, 15.34s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  15%|█▌        | 66/438 [16:39<1:35:33, 15.41s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  15%|█▌        | 66/438 [16:55<1:35:33, 15.41s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  15%|█▌        | 67/438 [16:55<1:34:51, 15.34s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  15%|█▌        | 67/438 [17:10<1:34:51, 15.34s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 68/438 [17:10<1:34:09, 15.27s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 68/438 [17:25<1:34:09, 15.27s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 69/438 [17:25<1:33:11, 15.15s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 69/438 [17:40<1:33:11, 15.15s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 70/438 [17:40<1:33:55, 15.31s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 70/438 [17:55<1:33:55, 15.31s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 71/438 [17:55<1:33:31, 15.29s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 71/438 [18:11<1:33:31, 15.29s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 2:  16%|█▋        | 72/438 [18:11<1:32:52, 15.23s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 2:  16%|█▋        | 72/438 [18:25<1:32:52, 15.23s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 73/438 [18:25<1:31:58, 15.12s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 73/438 [18:40<1:31:58, 15.12s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 74/438 [18:40<1:31:24, 15.07s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 74/438 [18:55<1:31:24, 15.07s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 75/438 [18:55<1:30:56, 15.03s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 75/438 [19:10<1:30:56, 15.03s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 76/438 [19:10<1:30:22, 14.98s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 76/438 [19:25<1:30:22, 14.98s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 77/438 [19:25<1:29:46, 14.92s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 77/438 [19:40<1:29:46, 14.92s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 78/438 [19:40<1:29:35, 14.93s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 78/438 [19:55<1:29:35, 14.93s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 79/438 [19:55<1:29:29, 14.96s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 79/438 [20:10<1:29:29, 14.96s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 80/438 [20:10<1:29:16, 14.96s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 80/438 [20:25<1:29:16, 14.96s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 81/438 [20:25<1:28:59, 14.96s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 81/438 [20:40<1:28:59, 14.96s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  19%|█▊        | 82/438 [20:40<1:28:59, 15.00s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  19%|█▊        | 82/438 [20:55<1:28:59, 15.00s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  19%|█▉        | 83/438 [20:55<1:28:39, 14.98s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  19%|█▉        | 83/438 [21:10<1:28:39, 14.98s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  19%|█▉        | 84/438 [21:10<1:28:20, 14.97s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  19%|█▉        | 84/438 [21:25<1:28:20, 14.97s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  19%|█▉        | 85/438 [21:25<1:29:09, 15.15s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  19%|█▉        | 85/438 [21:40<1:29:09, 15.15s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  20%|█▉        | 86/438 [21:40<1:28:42, 15.12s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  20%|█▉        | 86/438 [21:55<1:28:42, 15.12s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  20%|█▉        | 87/438 [21:55<1:28:15, 15.09s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  20%|█▉        | 87/438 [22:11<1:28:15, 15.09s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  20%|██        | 88/438 [22:11<1:27:59, 15.08s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  20%|██        | 88/438 [22:26<1:27:59, 15.08s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  20%|██        | 89/438 [22:26<1:27:39, 15.07s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  20%|██        | 89/438 [22:41<1:27:39, 15.07s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  21%|██        | 90/438 [22:41<1:27:10, 15.03s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  21%|██        | 90/438 [22:56<1:27:10, 15.03s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 2:  21%|██        | 91/438 [22:56<1:27:11, 15.08s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 2:  21%|██        | 91/438 [23:11<1:27:11, 15.08s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  21%|██        | 92/438 [23:11<1:26:38, 15.02s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  21%|██        | 92/438 [23:26<1:26:38, 15.02s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  21%|██        | 93/438 [23:26<1:26:13, 14.99s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  21%|██        | 93/438 [23:41<1:26:13, 14.99s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  21%|██▏       | 94/438 [23:41<1:25:55, 14.99s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  21%|██▏       | 94/438 [23:56<1:25:55, 14.99s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 95/438 [23:56<1:27:09, 15.25s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 95/438 [24:12<1:27:09, 15.25s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 96/438 [24:12<1:27:37, 15.37s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 96/438 [24:27<1:27:37, 15.37s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 97/438 [24:27<1:26:46, 15.27s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 97/438 [24:42<1:26:46, 15.27s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 98/438 [24:42<1:25:46, 15.14s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 98/438 [24:57<1:25:46, 15.14s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 99/438 [24:57<1:24:47, 15.01s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 99/438 [25:11<1:24:47, 15.01s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 100/438 [25:11<1:24:18, 14.96s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 100/438 [25:26<1:24:18, 14.96s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 101/438 [25:26<1:23:57, 14.95s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 101/438 [25:41<1:23:57, 14.95s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 102/438 [25:41<1:23:51, 14.97s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 102/438 [25:56<1:23:51, 14.97s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  24%|██▎       | 103/438 [25:56<1:23:11, 14.90s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  24%|██▎       | 103/438 [26:11<1:23:11, 14.90s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  24%|██▎       | 104/438 [26:11<1:22:59, 14.91s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  24%|██▎       | 104/438 [26:26<1:22:59, 14.91s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  24%|██▍       | 105/438 [26:26<1:22:43, 14.91s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  24%|██▍       | 105/438 [26:41<1:22:43, 14.91s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  24%|██▍       | 106/438 [26:41<1:22:47, 14.96s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  24%|██▍       | 106/438 [26:56<1:22:47, 14.96s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  24%|██▍       | 107/438 [26:56<1:22:40, 14.98s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  24%|██▍       | 107/438 [27:11<1:22:40, 14.98s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  25%|██▍       | 108/438 [27:11<1:22:19, 14.97s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  25%|██▍       | 108/438 [27:26<1:22:19, 14.97s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:  25%|██▍       | 109/438 [27:26<1:21:58, 14.95s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:  25%|██▍       | 109/438 [27:41<1:21:58, 14.95s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  25%|██▌       | 110/438 [27:41<1:21:56, 14.99s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  25%|██▌       | 110/438 [27:56<1:21:56, 14.99s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  25%|██▌       | 111/438 [27:56<1:21:32, 14.96s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  25%|██▌       | 111/438 [28:11<1:21:32, 14.96s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  26%|██▌       | 112/438 [28:11<1:21:00, 14.91s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  26%|██▌       | 112/438 [28:27<1:21:00, 14.91s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  26%|██▌       | 113/438 [28:27<1:22:29, 15.23s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  26%|██▌       | 113/438 [28:42<1:22:29, 15.23s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  26%|██▌       | 114/438 [28:42<1:22:08, 15.21s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  26%|██▌       | 114/438 [28:57<1:22:08, 15.21s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  26%|██▋       | 115/438 [28:57<1:21:31, 15.14s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  26%|██▋       | 115/438 [29:12<1:21:31, 15.14s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  26%|██▋       | 116/438 [29:12<1:20:49, 15.06s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  26%|██▋       | 116/438 [29:27<1:20:49, 15.06s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 117/438 [29:27<1:20:51, 15.11s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 117/438 [29:43<1:20:51, 15.11s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 118/438 [29:43<1:21:27, 15.27s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 118/438 [29:57<1:21:27, 15.27s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 119/438 [29:57<1:20:37, 15.17s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 119/438 [30:12<1:20:37, 15.17s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 120/438 [30:12<1:19:57, 15.08s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 120/438 [30:27<1:19:57, 15.08s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 121/438 [30:27<1:19:20, 15.02s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 121/438 [30:42<1:19:20, 15.02s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 122/438 [30:42<1:19:11, 15.04s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 122/438 [30:57<1:19:11, 15.04s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 123/438 [30:57<1:18:43, 15.00s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 123/438 [31:12<1:18:43, 15.00s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 124/438 [31:12<1:18:09, 14.93s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 124/438 [31:27<1:18:09, 14.93s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  29%|██▊       | 125/438 [31:27<1:17:54, 14.93s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  29%|██▊       | 125/438 [31:42<1:17:54, 14.93s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 126/438 [31:42<1:17:39, 14.93s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 126/438 [31:57<1:17:39, 14.93s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 127/438 [31:57<1:17:36, 14.97s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 127/438 [32:12<1:17:36, 14.97s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 128/438 [32:12<1:17:22, 14.98s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 128/438 [32:27<1:17:22, 14.98s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 129/438 [32:27<1:17:10, 14.98s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 129/438 [32:42<1:17:10, 14.98s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  30%|██▉       | 130/438 [32:42<1:17:02, 15.01s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  30%|██▉       | 130/438 [32:57<1:17:02, 15.01s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  30%|██▉       | 131/438 [32:57<1:16:50, 15.02s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  30%|██▉       | 131/438 [33:12<1:16:50, 15.02s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  30%|███       | 132/438 [33:12<1:16:28, 15.00s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  30%|███       | 132/438 [33:27<1:16:28, 15.00s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  30%|███       | 133/438 [33:27<1:16:18, 15.01s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  30%|███       | 133/438 [33:42<1:16:18, 15.01s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  31%|███       | 134/438 [33:42<1:15:59, 15.00s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  31%|███       | 134/438 [33:57<1:15:59, 15.00s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  31%|███       | 135/438 [33:57<1:15:24, 14.93s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  31%|███       | 135/438 [34:12<1:15:24, 14.93s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  31%|███       | 136/438 [34:12<1:14:58, 14.90s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  31%|███       | 136/438 [34:26<1:14:58, 14.90s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  31%|███▏      | 137/438 [34:26<1:14:44, 14.90s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  31%|███▏      | 137/438 [34:41<1:14:44, 14.90s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 138/438 [34:41<1:14:18, 14.86s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 138/438 [34:56<1:14:18, 14.86s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 139/438 [34:56<1:13:58, 14.85s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 139/438 [35:11<1:13:58, 14.85s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 140/438 [35:11<1:14:07, 14.92s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 140/438 [35:26<1:14:07, 14.92s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 141/438 [35:26<1:13:49, 14.92s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 141/438 [35:41<1:13:49, 14.92s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 142/438 [35:41<1:13:15, 14.85s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 142/438 [35:56<1:13:15, 14.85s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 143/438 [35:56<1:12:57, 14.84s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 143/438 [36:10<1:12:57, 14.84s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 144/438 [36:10<1:12:43, 14.84s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 144/438 [36:25<1:12:43, 14.84s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 145/438 [36:25<1:12:27, 14.84s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 145/438 [36:41<1:12:27, 14.84s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 146/438 [36:41<1:14:09, 15.24s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 146/438 [36:58<1:14:09, 15.24s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  34%|███▎      | 147/438 [36:58<1:15:23, 15.55s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  34%|███▎      | 147/438 [37:13<1:15:23, 15.55s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 148/438 [37:13<1:14:19, 15.38s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 148/438 [37:28<1:14:19, 15.38s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 149/438 [37:28<1:14:01, 15.37s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 149/438 [37:43<1:14:01, 15.37s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 150/438 [37:43<1:13:28, 15.31s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 150/438 [37:59<1:13:28, 15.31s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 151/438 [37:59<1:13:15, 15.31s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 151/438 [38:14<1:13:15, 15.31s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  35%|███▍      | 152/438 [38:14<1:13:00, 15.32s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  35%|███▍      | 152/438 [38:29<1:13:00, 15.32s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  35%|███▍      | 153/438 [38:29<1:12:55, 15.35s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  35%|███▍      | 153/438 [38:44<1:12:55, 15.35s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  35%|███▌      | 154/438 [38:44<1:12:03, 15.22s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  35%|███▌      | 154/438 [38:59<1:12:03, 15.22s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 2:  35%|███▌      | 155/438 [38:59<1:11:33, 15.17s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 2:  35%|███▌      | 155/438 [39:16<1:11:33, 15.17s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  36%|███▌      | 156/438 [39:16<1:13:06, 15.56s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  36%|███▌      | 156/438 [39:31<1:13:06, 15.56s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  36%|███▌      | 157/438 [39:31<1:12:15, 15.43s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  36%|███▌      | 157/438 [39:46<1:12:15, 15.43s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  36%|███▌      | 158/438 [39:46<1:11:37, 15.35s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  36%|███▌      | 158/438 [40:01<1:11:37, 15.35s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  36%|███▋      | 159/438 [40:01<1:10:59, 15.27s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  36%|███▋      | 159/438 [40:16<1:10:59, 15.27s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 160/438 [40:16<1:10:23, 15.19s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 160/438 [40:31<1:10:23, 15.19s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 161/438 [40:31<1:09:37, 15.08s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 161/438 [40:47<1:09:37, 15.08s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 162/438 [40:47<1:10:35, 15.35s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 162/438 [41:03<1:10:35, 15.35s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 163/438 [41:03<1:10:51, 15.46s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 163/438 [41:18<1:10:51, 15.46s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 164/438 [41:18<1:10:12, 15.37s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 164/438 [41:33<1:10:12, 15.37s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 165/438 [41:33<1:09:40, 15.31s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 165/438 [41:48<1:09:40, 15.31s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 166/438 [41:48<1:09:04, 15.24s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 166/438 [42:03<1:09:04, 15.24s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 167/438 [42:03<1:08:31, 15.17s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 167/438 [42:19<1:08:31, 15.17s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 168/438 [42:19<1:08:46, 15.28s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 168/438 [42:34<1:08:46, 15.28s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 2:  39%|███▊      | 169/438 [42:34<1:08:25, 15.26s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 2:  39%|███▊      | 169/438 [42:49<1:08:25, 15.26s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 170/438 [42:49<1:07:55, 15.21s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 170/438 [43:04<1:07:55, 15.21s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 171/438 [43:04<1:07:24, 15.15s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 171/438 [43:19<1:07:24, 15.15s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 172/438 [43:19<1:07:02, 15.12s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 172/438 [43:34<1:07:02, 15.12s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 173/438 [43:34<1:06:33, 15.07s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 173/438 [43:49<1:06:33, 15.07s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  40%|███▉      | 174/438 [43:49<1:06:06, 15.02s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  40%|███▉      | 174/438 [44:04<1:06:06, 15.02s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  40%|███▉      | 175/438 [44:04<1:06:03, 15.07s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  40%|███▉      | 175/438 [44:19<1:06:03, 15.07s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  40%|████      | 176/438 [44:19<1:06:00, 15.12s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  40%|████      | 176/438 [44:34<1:06:00, 15.12s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  40%|████      | 177/438 [44:34<1:05:41, 15.10s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  40%|████      | 177/438 [44:49<1:05:41, 15.10s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  41%|████      | 178/438 [44:49<1:05:17, 15.07s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  41%|████      | 178/438 [45:04<1:05:17, 15.07s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  41%|████      | 179/438 [45:04<1:04:56, 15.05s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  41%|████      | 179/438 [45:20<1:04:56, 15.05s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  41%|████      | 180/438 [45:20<1:05:47, 15.30s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  41%|████      | 180/438 [45:36<1:05:47, 15.30s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  41%|████▏     | 181/438 [45:36<1:06:10, 15.45s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  41%|████▏     | 181/438 [45:51<1:06:10, 15.45s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 182/438 [45:51<1:05:51, 15.44s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 182/438 [46:07<1:05:51, 15.44s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 183/438 [46:07<1:05:21, 15.38s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 183/438 [46:22<1:05:21, 15.38s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 184/438 [46:22<1:05:01, 15.36s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 184/438 [46:38<1:05:01, 15.36s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 185/438 [46:38<1:05:15, 15.48s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 185/438 [46:53<1:05:15, 15.48s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 186/438 [46:53<1:05:02, 15.49s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 186/438 [47:08<1:05:02, 15.49s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 187/438 [47:08<1:04:31, 15.42s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 187/438 [47:24<1:04:31, 15.42s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 188/438 [47:24<1:04:01, 15.37s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 188/438 [47:40<1:04:01, 15.37s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 189/438 [47:40<1:04:25, 15.53s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 189/438 [47:55<1:04:25, 15.53s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 190/438 [47:55<1:04:19, 15.56s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 190/438 [48:11<1:04:19, 15.56s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  44%|████▎     | 191/438 [48:11<1:03:42, 15.47s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  44%|████▎     | 191/438 [48:26<1:03:42, 15.47s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  44%|████▍     | 192/438 [48:26<1:02:53, 15.34s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  44%|████▍     | 192/438 [48:41<1:02:53, 15.34s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  44%|████▍     | 193/438 [48:41<1:02:37, 15.34s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  44%|████▍     | 193/438 [48:56<1:02:37, 15.34s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  44%|████▍     | 194/438 [48:56<1:02:15, 15.31s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  44%|████▍     | 194/438 [49:11<1:02:15, 15.31s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  45%|████▍     | 195/438 [49:11<1:01:49, 15.27s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  45%|████▍     | 195/438 [49:26<1:01:49, 15.27s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  45%|████▍     | 196/438 [49:26<1:01:19, 15.21s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  45%|████▍     | 196/438 [49:42<1:01:19, 15.21s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  45%|████▍     | 197/438 [49:42<1:01:08, 15.22s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  45%|████▍     | 197/438 [49:57<1:01:08, 15.22s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  45%|████▌     | 198/438 [49:57<1:01:17, 15.32s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  45%|████▌     | 198/438 [50:12<1:01:17, 15.32s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  45%|████▌     | 199/438 [50:12<1:00:55, 15.29s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  45%|████▌     | 199/438 [50:28<1:00:55, 15.29s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  46%|████▌     | 200/438 [50:28<1:00:45, 15.32s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  46%|████▌     | 200/438 [50:43<1:00:45, 15.32s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  46%|████▌     | 201/438 [50:43<1:00:25, 15.30s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  46%|████▌     | 201/438 [50:58<1:00:25, 15.30s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  46%|████▌     | 202/438 [50:58<1:00:13, 15.31s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  46%|████▌     | 202/438 [51:14<1:00:13, 15.31s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  46%|████▋     | 203/438 [51:14<1:00:12, 15.37s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  46%|████▋     | 203/438 [51:29<1:00:12, 15.37s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 204/438 [51:29<1:00:10, 15.43s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 204/438 [51:45<1:00:10, 15.43s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 205/438 [51:45<59:58, 15.45s/it, training_loss=0.125]  \u001B[A\n",
      "Epoch 2:  47%|████▋     | 205/438 [52:00<59:58, 15.45s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 206/438 [52:00<59:41, 15.44s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 206/438 [52:16<59:41, 15.44s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 207/438 [52:16<59:08, 15.36s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 207/438 [52:31<59:08, 15.36s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 208/438 [52:31<58:59, 15.39s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 208/438 [52:46<58:59, 15.39s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 209/438 [52:46<58:32, 15.34s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 209/438 [53:02<58:32, 15.34s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 210/438 [53:02<58:22, 15.36s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 210/438 [53:17<58:22, 15.36s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 211/438 [53:17<57:56, 15.31s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 211/438 [53:32<57:56, 15.31s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 212/438 [53:32<57:44, 15.33s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 212/438 [53:47<57:44, 15.33s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  49%|████▊     | 213/438 [53:47<57:24, 15.31s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  49%|████▊     | 213/438 [54:03<57:24, 15.31s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  49%|████▉     | 214/438 [54:03<57:05, 15.29s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  49%|████▉     | 214/438 [54:19<57:05, 15.29s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  49%|████▉     | 215/438 [54:19<58:22, 15.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  49%|████▉     | 215/438 [54:35<58:22, 15.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  49%|████▉     | 216/438 [54:35<57:46, 15.62s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  49%|████▉     | 216/438 [54:50<57:46, 15.62s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  50%|████▉     | 217/438 [54:50<57:00, 15.48s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  50%|████▉     | 217/438 [55:05<57:00, 15.48s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 2:  50%|████▉     | 218/438 [55:05<56:26, 15.39s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 2:  50%|████▉     | 218/438 [55:20<56:26, 15.39s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  50%|█████     | 219/438 [55:20<56:09, 15.38s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  50%|█████     | 219/438 [55:36<56:09, 15.38s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  50%|█████     | 220/438 [55:36<55:48, 15.36s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  50%|█████     | 220/438 [55:51<55:48, 15.36s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  50%|█████     | 221/438 [55:51<55:29, 15.34s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  50%|█████     | 221/438 [56:06<55:29, 15.34s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  51%|█████     | 222/438 [56:06<55:11, 15.33s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  51%|█████     | 222/438 [56:22<55:11, 15.33s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 2:  51%|█████     | 223/438 [56:22<54:49, 15.30s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 2:  51%|█████     | 223/438 [56:37<54:49, 15.30s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  51%|█████     | 224/438 [56:37<54:21, 15.24s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  51%|█████     | 224/438 [56:52<54:21, 15.24s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  51%|█████▏    | 225/438 [56:52<54:11, 15.27s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  51%|█████▏    | 225/438 [57:07<54:11, 15.27s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 226/438 [57:07<54:08, 15.32s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 226/438 [57:23<54:08, 15.32s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 227/438 [57:23<53:44, 15.28s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 227/438 [57:38<53:44, 15.28s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 228/438 [57:38<53:40, 15.33s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 228/438 [57:54<53:40, 15.33s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 229/438 [57:54<53:30, 15.36s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 229/438 [58:09<53:30, 15.36s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 230/438 [58:09<53:10, 15.34s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 230/438 [58:24<53:10, 15.34s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 231/438 [58:24<52:54, 15.34s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 231/438 [58:39<52:54, 15.34s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 232/438 [58:39<52:38, 15.33s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 232/438 [58:55<52:38, 15.33s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 233/438 [58:55<52:27, 15.35s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 233/438 [59:10<52:27, 15.35s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 234/438 [59:10<52:08, 15.34s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 234/438 [59:25<52:08, 15.34s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  54%|█████▎    | 235/438 [59:25<51:50, 15.32s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  54%|█████▎    | 235/438 [59:41<51:50, 15.32s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  54%|█████▍    | 236/438 [59:41<51:34, 15.32s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  54%|█████▍    | 236/438 [59:56<51:34, 15.32s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  54%|█████▍    | 237/438 [59:56<51:15, 15.30s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  54%|█████▍    | 237/438 [1:00:11<51:15, 15.30s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  54%|█████▍    | 238/438 [1:00:11<50:59, 15.30s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  54%|█████▍    | 238/438 [1:00:27<50:59, 15.30s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  55%|█████▍    | 239/438 [1:00:27<50:42, 15.29s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  55%|█████▍    | 239/438 [1:00:42<50:42, 15.29s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  55%|█████▍    | 240/438 [1:00:42<50:27, 15.29s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  55%|█████▍    | 240/438 [1:00:57<50:27, 15.29s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  55%|█████▌    | 241/438 [1:00:57<50:15, 15.31s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  55%|█████▌    | 241/438 [1:01:13<50:15, 15.31s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  55%|█████▌    | 242/438 [1:01:13<50:00, 15.31s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  55%|█████▌    | 242/438 [1:01:28<50:00, 15.31s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  55%|█████▌    | 243/438 [1:01:28<49:37, 15.27s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  55%|█████▌    | 243/438 [1:01:43<49:37, 15.27s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  56%|█████▌    | 244/438 [1:01:43<49:25, 15.29s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  56%|█████▌    | 244/438 [1:01:58<49:25, 15.29s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  56%|█████▌    | 245/438 [1:01:58<49:06, 15.26s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  56%|█████▌    | 245/438 [1:02:13<49:06, 15.26s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 2:  56%|█████▌    | 246/438 [1:02:13<48:42, 15.22s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 2:  56%|█████▌    | 246/438 [1:02:29<48:42, 15.22s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  56%|█████▋    | 247/438 [1:02:29<48:40, 15.29s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  56%|█████▋    | 247/438 [1:02:44<48:40, 15.29s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 248/438 [1:02:44<48:34, 15.34s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 248/438 [1:03:01<48:34, 15.34s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 249/438 [1:03:01<49:36, 15.75s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 249/438 [1:03:16<49:36, 15.75s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 250/438 [1:03:16<49:01, 15.65s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 250/438 [1:03:31<49:01, 15.65s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 251/438 [1:03:31<48:10, 15.46s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 251/438 [1:03:46<48:10, 15.46s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 252/438 [1:03:46<47:33, 15.34s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 252/438 [1:04:02<47:33, 15.34s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 253/438 [1:04:02<47:08, 15.29s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 253/438 [1:04:17<47:08, 15.29s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 254/438 [1:04:17<46:47, 15.26s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 254/438 [1:04:32<46:47, 15.26s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 255/438 [1:04:32<46:30, 15.25s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 255/438 [1:04:47<46:30, 15.25s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 256/438 [1:04:47<46:15, 15.25s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 256/438 [1:05:03<46:15, 15.25s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  59%|█████▊    | 257/438 [1:05:03<46:19, 15.36s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  59%|█████▊    | 257/438 [1:05:18<46:19, 15.36s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  59%|█████▉    | 258/438 [1:05:18<46:07, 15.38s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  59%|█████▉    | 258/438 [1:05:34<46:07, 15.38s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  59%|█████▉    | 259/438 [1:05:34<45:43, 15.33s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  59%|█████▉    | 259/438 [1:05:49<45:43, 15.33s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 2:  59%|█████▉    | 260/438 [1:05:49<45:19, 15.28s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 2:  59%|█████▉    | 260/438 [1:06:04<45:19, 15.28s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  60%|█████▉    | 261/438 [1:06:04<44:51, 15.21s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  60%|█████▉    | 261/438 [1:06:19<44:51, 15.21s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  60%|█████▉    | 262/438 [1:06:19<44:37, 15.21s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  60%|█████▉    | 262/438 [1:06:34<44:37, 15.21s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 2:  60%|██████    | 263/438 [1:06:34<44:19, 15.20s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 2:  60%|██████    | 263/438 [1:06:49<44:19, 15.20s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  60%|██████    | 264/438 [1:06:49<43:58, 15.16s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  60%|██████    | 264/438 [1:07:04<43:58, 15.16s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  61%|██████    | 265/438 [1:07:04<43:35, 15.12s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  61%|██████    | 265/438 [1:07:19<43:35, 15.12s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  61%|██████    | 266/438 [1:07:19<43:26, 15.15s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  61%|██████    | 266/438 [1:07:36<43:26, 15.15s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  61%|██████    | 267/438 [1:07:36<43:55, 15.41s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  61%|██████    | 267/438 [1:07:51<43:55, 15.41s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  61%|██████    | 268/438 [1:07:51<43:43, 15.43s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  61%|██████    | 268/438 [1:08:06<43:43, 15.43s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  61%|██████▏   | 269/438 [1:08:06<43:24, 15.41s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  61%|██████▏   | 269/438 [1:08:21<43:24, 15.41s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 270/438 [1:08:21<42:48, 15.29s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 270/438 [1:08:37<42:48, 15.29s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 271/438 [1:08:37<42:54, 15.42s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 271/438 [1:08:52<42:54, 15.42s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 272/438 [1:08:52<42:37, 15.41s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 272/438 [1:09:08<42:37, 15.41s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 273/438 [1:09:08<42:13, 15.36s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 273/438 [1:09:24<42:13, 15.36s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 274/438 [1:09:24<43:08, 15.78s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 274/438 [1:09:40<43:08, 15.78s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 275/438 [1:09:40<42:28, 15.64s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 275/438 [1:09:55<42:28, 15.64s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 276/438 [1:09:55<42:00, 15.56s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 276/438 [1:10:10<42:00, 15.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 277/438 [1:10:10<41:28, 15.46s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 277/438 [1:10:26<41:28, 15.46s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 278/438 [1:10:26<41:01, 15.38s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 278/438 [1:10:41<41:01, 15.38s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  64%|██████▎   | 279/438 [1:10:41<40:27, 15.27s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  64%|██████▎   | 279/438 [1:10:56<40:27, 15.27s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  64%|██████▍   | 280/438 [1:10:56<40:16, 15.30s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  64%|██████▍   | 280/438 [1:11:11<40:16, 15.30s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  64%|██████▍   | 281/438 [1:11:11<39:53, 15.24s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  64%|██████▍   | 281/438 [1:11:26<39:53, 15.24s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  64%|██████▍   | 282/438 [1:11:26<39:27, 15.17s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  64%|██████▍   | 282/438 [1:11:42<39:27, 15.17s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  65%|██████▍   | 283/438 [1:11:42<40:04, 15.51s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  65%|██████▍   | 283/438 [1:11:58<40:04, 15.51s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  65%|██████▍   | 284/438 [1:11:58<39:34, 15.42s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  65%|██████▍   | 284/438 [1:12:13<39:34, 15.42s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  65%|██████▌   | 285/438 [1:12:13<39:09, 15.36s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  65%|██████▌   | 285/438 [1:12:28<39:09, 15.36s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  65%|██████▌   | 286/438 [1:12:28<38:54, 15.36s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  65%|██████▌   | 286/438 [1:12:44<38:54, 15.36s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 287/438 [1:12:44<38:40, 15.37s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 287/438 [1:12:59<38:40, 15.37s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 288/438 [1:12:59<38:14, 15.29s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 288/438 [1:13:14<38:14, 15.29s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 289/438 [1:13:14<37:58, 15.29s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 289/438 [1:13:29<37:58, 15.29s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 290/438 [1:13:29<37:41, 15.28s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 290/438 [1:13:45<37:41, 15.28s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  66%|██████▋   | 291/438 [1:13:45<37:33, 15.33s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  66%|██████▋   | 291/438 [1:14:00<37:33, 15.33s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 292/438 [1:14:00<37:08, 15.26s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 292/438 [1:14:15<37:08, 15.26s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 293/438 [1:14:15<36:50, 15.25s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 293/438 [1:14:30<36:50, 15.25s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 294/438 [1:14:30<36:43, 15.30s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 294/438 [1:14:46<36:43, 15.30s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 295/438 [1:14:46<36:30, 15.31s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 295/438 [1:15:01<36:30, 15.31s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 296/438 [1:15:01<36:17, 15.34s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 296/438 [1:15:16<36:17, 15.34s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 297/438 [1:15:16<35:54, 15.28s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 297/438 [1:15:32<35:54, 15.28s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 298/438 [1:15:32<35:41, 15.29s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 298/438 [1:15:47<35:41, 15.29s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 299/438 [1:15:47<35:23, 15.28s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 299/438 [1:16:02<35:23, 15.28s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 300/438 [1:16:02<35:07, 15.27s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 300/438 [1:16:17<35:07, 15.27s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  69%|██████▊   | 301/438 [1:16:17<34:45, 15.22s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  69%|██████▊   | 301/438 [1:16:32<34:45, 15.22s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  69%|██████▉   | 302/438 [1:16:32<34:29, 15.22s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  69%|██████▉   | 302/438 [1:16:47<34:29, 15.22s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  69%|██████▉   | 303/438 [1:16:47<34:08, 15.17s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  69%|██████▉   | 303/438 [1:17:03<34:08, 15.17s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  69%|██████▉   | 304/438 [1:17:03<33:53, 15.18s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  69%|██████▉   | 304/438 [1:17:18<33:53, 15.18s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  70%|██████▉   | 305/438 [1:17:18<33:36, 15.16s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  70%|██████▉   | 305/438 [1:17:33<33:36, 15.16s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  70%|██████▉   | 306/438 [1:17:33<33:27, 15.21s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  70%|██████▉   | 306/438 [1:17:49<33:27, 15.21s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 2:  70%|███████   | 307/438 [1:17:49<33:57, 15.56s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 2:  70%|███████   | 307/438 [1:18:05<33:57, 15.56s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  70%|███████   | 308/438 [1:18:05<33:22, 15.41s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  70%|███████   | 308/438 [1:18:20<33:22, 15.41s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  71%|███████   | 309/438 [1:18:20<32:57, 15.33s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  71%|███████   | 309/438 [1:18:35<32:57, 15.33s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  71%|███████   | 310/438 [1:18:35<32:34, 15.27s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  71%|███████   | 310/438 [1:18:50<32:34, 15.27s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  71%|███████   | 311/438 [1:18:50<32:20, 15.28s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  71%|███████   | 311/438 [1:19:05<32:20, 15.28s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  71%|███████   | 312/438 [1:19:05<32:07, 15.29s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  71%|███████   | 312/438 [1:19:21<32:07, 15.29s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  71%|███████▏  | 313/438 [1:19:21<31:45, 15.25s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  71%|███████▏  | 313/438 [1:19:36<31:45, 15.25s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 314/438 [1:19:36<31:27, 15.23s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 314/438 [1:19:51<31:27, 15.23s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 315/438 [1:19:51<31:15, 15.25s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 315/438 [1:20:06<31:15, 15.25s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 316/438 [1:20:06<31:03, 15.27s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 316/438 [1:20:22<31:03, 15.27s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 317/438 [1:20:22<30:44, 15.24s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 317/438 [1:20:37<30:44, 15.24s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 318/438 [1:20:37<30:29, 15.25s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 318/438 [1:20:52<30:29, 15.25s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 319/438 [1:20:52<30:14, 15.24s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 319/438 [1:21:07<30:14, 15.24s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 320/438 [1:21:07<29:58, 15.24s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 320/438 [1:21:22<29:58, 15.24s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 321/438 [1:21:22<29:38, 15.20s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 321/438 [1:21:38<29:38, 15.20s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  74%|███████▎  | 322/438 [1:21:38<29:22, 15.19s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  74%|███████▎  | 322/438 [1:21:53<29:22, 15.19s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  74%|███████▎  | 323/438 [1:21:53<29:05, 15.18s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  74%|███████▎  | 323/438 [1:22:08<29:05, 15.18s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  74%|███████▍  | 324/438 [1:22:08<28:49, 15.17s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  74%|███████▍  | 324/438 [1:22:23<28:49, 15.17s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  74%|███████▍  | 325/438 [1:22:23<28:49, 15.30s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  74%|███████▍  | 325/438 [1:22:39<28:49, 15.30s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 2:  74%|███████▍  | 326/438 [1:22:39<28:40, 15.36s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 2:  74%|███████▍  | 326/438 [1:22:54<28:40, 15.36s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  75%|███████▍  | 327/438 [1:22:54<28:24, 15.36s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  75%|███████▍  | 327/438 [1:23:10<28:24, 15.36s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  75%|███████▍  | 328/438 [1:23:10<28:03, 15.31s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  75%|███████▍  | 328/438 [1:23:25<28:03, 15.31s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  75%|███████▌  | 329/438 [1:23:25<27:43, 15.26s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  75%|███████▌  | 329/438 [1:23:40<27:43, 15.26s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  75%|███████▌  | 330/438 [1:23:40<27:25, 15.24s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  75%|███████▌  | 330/438 [1:23:55<27:25, 15.24s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  76%|███████▌  | 331/438 [1:23:55<27:14, 15.28s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  76%|███████▌  | 331/438 [1:24:10<27:14, 15.28s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  76%|███████▌  | 332/438 [1:24:10<26:52, 15.22s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  76%|███████▌  | 332/438 [1:24:27<26:52, 15.22s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  76%|███████▌  | 333/438 [1:24:27<27:21, 15.63s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  76%|███████▌  | 333/438 [1:24:42<27:21, 15.63s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  76%|███████▋  | 334/438 [1:24:42<26:55, 15.53s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  76%|███████▋  | 334/438 [1:24:57<26:55, 15.53s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  76%|███████▋  | 335/438 [1:24:57<26:26, 15.40s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  76%|███████▋  | 335/438 [1:25:13<26:26, 15.40s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 336/438 [1:25:13<26:08, 15.37s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 336/438 [1:25:28<26:08, 15.37s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 337/438 [1:25:28<25:45, 15.30s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 337/438 [1:25:43<25:45, 15.30s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 338/438 [1:25:43<25:27, 15.28s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 338/438 [1:25:58<25:27, 15.28s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 339/438 [1:25:58<25:10, 15.26s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 339/438 [1:26:13<25:10, 15.26s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 340/438 [1:26:13<24:56, 15.27s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 340/438 [1:26:29<24:56, 15.27s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 341/438 [1:26:29<24:38, 15.24s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 341/438 [1:26:45<24:38, 15.24s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 342/438 [1:26:45<24:43, 15.45s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 342/438 [1:27:00<24:43, 15.45s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 343/438 [1:27:00<24:20, 15.37s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 343/438 [1:27:15<24:20, 15.37s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  79%|███████▊  | 344/438 [1:27:15<23:59, 15.31s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  79%|███████▊  | 344/438 [1:27:30<23:59, 15.31s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 345/438 [1:27:30<23:41, 15.29s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 345/438 [1:27:45<23:41, 15.29s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 346/438 [1:27:45<23:25, 15.28s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 346/438 [1:28:01<23:25, 15.28s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 347/438 [1:28:01<23:09, 15.27s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 347/438 [1:28:16<23:09, 15.27s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 348/438 [1:28:16<22:53, 15.26s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 348/438 [1:28:31<22:53, 15.26s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  80%|███████▉  | 349/438 [1:28:31<22:37, 15.25s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  80%|███████▉  | 349/438 [1:28:46<22:37, 15.25s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  80%|███████▉  | 350/438 [1:28:46<22:20, 15.24s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  80%|███████▉  | 350/438 [1:29:02<22:20, 15.24s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  80%|████████  | 351/438 [1:29:02<22:04, 15.22s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  80%|████████  | 351/438 [1:29:17<22:04, 15.22s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  80%|████████  | 352/438 [1:29:17<21:50, 15.23s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  80%|████████  | 352/438 [1:29:32<21:50, 15.23s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  81%|████████  | 353/438 [1:29:32<21:34, 15.23s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  81%|████████  | 353/438 [1:29:47<21:34, 15.23s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  81%|████████  | 354/438 [1:29:47<21:19, 15.23s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  81%|████████  | 354/438 [1:30:03<21:19, 15.23s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  81%|████████  | 355/438 [1:30:03<21:07, 15.27s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  81%|████████  | 355/438 [1:30:18<21:07, 15.27s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  81%|████████▏ | 356/438 [1:30:18<20:51, 15.27s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  81%|████████▏ | 356/438 [1:30:33<20:51, 15.27s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 357/438 [1:30:33<20:36, 15.27s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 357/438 [1:30:48<20:36, 15.27s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 358/438 [1:30:48<20:19, 15.25s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 358/438 [1:31:03<20:19, 15.25s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 359/438 [1:31:03<20:01, 15.21s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 359/438 [1:31:19<20:01, 15.21s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 360/438 [1:31:19<19:47, 15.22s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 360/438 [1:31:34<19:47, 15.22s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 361/438 [1:31:34<19:33, 15.24s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 361/438 [1:31:49<19:33, 15.24s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 362/438 [1:31:49<19:14, 15.19s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 362/438 [1:32:04<19:14, 15.19s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 363/438 [1:32:04<18:59, 15.20s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 363/438 [1:32:20<18:59, 15.20s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 364/438 [1:32:20<18:45, 15.20s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 364/438 [1:32:35<18:45, 15.20s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 365/438 [1:32:35<18:31, 15.23s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 365/438 [1:32:50<18:31, 15.23s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  84%|████████▎ | 366/438 [1:32:50<18:18, 15.25s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  84%|████████▎ | 366/438 [1:33:05<18:18, 15.25s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 367/438 [1:33:05<18:03, 15.26s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 367/438 [1:33:21<18:03, 15.26s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 368/438 [1:33:21<18:00, 15.44s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 368/438 [1:33:38<18:00, 15.44s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 369/438 [1:33:38<18:02, 15.69s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 369/438 [1:33:53<18:02, 15.69s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 370/438 [1:33:53<17:34, 15.51s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 370/438 [1:34:08<17:34, 15.51s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  85%|████████▍ | 371/438 [1:34:08<17:12, 15.40s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  85%|████████▍ | 371/438 [1:34:23<17:12, 15.40s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  85%|████████▍ | 372/438 [1:34:23<16:50, 15.31s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  85%|████████▍ | 372/438 [1:34:38<16:50, 15.31s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  85%|████████▌ | 373/438 [1:34:38<16:38, 15.36s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  85%|████████▌ | 373/438 [1:34:54<16:38, 15.36s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  85%|████████▌ | 374/438 [1:34:54<16:22, 15.36s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  85%|████████▌ | 374/438 [1:35:09<16:22, 15.36s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  86%|████████▌ | 375/438 [1:35:09<16:06, 15.35s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  86%|████████▌ | 375/438 [1:35:24<16:06, 15.35s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  86%|████████▌ | 376/438 [1:35:24<15:44, 15.23s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  86%|████████▌ | 376/438 [1:35:39<15:44, 15.23s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  86%|████████▌ | 377/438 [1:35:39<15:21, 15.10s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  86%|████████▌ | 377/438 [1:35:54<15:21, 15.10s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  86%|████████▋ | 378/438 [1:35:54<15:08, 15.14s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  86%|████████▋ | 378/438 [1:36:09<15:08, 15.14s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 379/438 [1:36:09<14:52, 15.13s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 379/438 [1:36:24<14:52, 15.13s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 380/438 [1:36:24<14:36, 15.12s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 380/438 [1:36:39<14:36, 15.12s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 381/438 [1:36:39<14:21, 15.12s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 381/438 [1:36:54<14:21, 15.12s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 382/438 [1:36:54<14:04, 15.09s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 382/438 [1:37:09<14:04, 15.09s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 383/438 [1:37:09<13:47, 15.04s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 383/438 [1:37:25<13:47, 15.04s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 384/438 [1:37:25<13:35, 15.10s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 384/438 [1:37:40<13:35, 15.10s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 385/438 [1:37:40<13:19, 15.08s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 385/438 [1:37:55<13:19, 15.08s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 386/438 [1:37:55<13:04, 15.09s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 386/438 [1:38:10<13:04, 15.09s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 387/438 [1:38:10<12:48, 15.07s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 387/438 [1:38:25<12:48, 15.07s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  89%|████████▊ | 388/438 [1:38:25<12:37, 15.15s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  89%|████████▊ | 388/438 [1:38:40<12:37, 15.15s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 389/438 [1:38:40<12:23, 15.17s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 389/438 [1:38:55<12:23, 15.17s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 390/438 [1:38:55<12:09, 15.19s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 390/438 [1:39:11<12:09, 15.19s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 391/438 [1:39:11<11:53, 15.19s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 391/438 [1:39:27<11:53, 15.19s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 392/438 [1:39:27<11:47, 15.39s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 392/438 [1:39:42<11:47, 15.39s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  90%|████████▉ | 393/438 [1:39:42<11:37, 15.50s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  90%|████████▉ | 393/438 [1:39:57<11:37, 15.50s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  90%|████████▉ | 394/438 [1:39:57<11:17, 15.39s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  90%|████████▉ | 394/438 [1:40:13<11:17, 15.39s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  90%|█████████ | 395/438 [1:40:13<10:58, 15.32s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  90%|█████████ | 395/438 [1:40:28<10:58, 15.32s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  90%|█████████ | 396/438 [1:40:28<10:40, 15.26s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  90%|█████████ | 396/438 [1:40:43<10:40, 15.26s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  91%|█████████ | 397/438 [1:40:43<10:24, 15.23s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  91%|█████████ | 397/438 [1:40:58<10:24, 15.23s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  91%|█████████ | 398/438 [1:40:58<10:07, 15.19s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  91%|█████████ | 398/438 [1:41:13<10:07, 15.19s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  91%|█████████ | 399/438 [1:41:13<09:51, 15.17s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  91%|█████████ | 399/438 [1:41:28<09:51, 15.17s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  91%|█████████▏| 400/438 [1:41:28<09:36, 15.16s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  91%|█████████▏| 400/438 [1:41:44<09:36, 15.16s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 401/438 [1:41:44<09:23, 15.23s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 401/438 [1:41:59<09:23, 15.23s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 402/438 [1:41:59<09:09, 15.26s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 402/438 [1:42:14<09:09, 15.26s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 403/438 [1:42:14<08:51, 15.18s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 403/438 [1:42:29<08:51, 15.18s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 404/438 [1:42:29<08:36, 15.18s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 404/438 [1:42:44<08:36, 15.18s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 405/438 [1:42:44<08:22, 15.22s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 405/438 [1:43:00<08:22, 15.22s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 406/438 [1:43:00<08:07, 15.23s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 406/438 [1:43:15<08:07, 15.23s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 407/438 [1:43:15<07:50, 15.19s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 407/438 [1:43:30<07:50, 15.19s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 408/438 [1:43:30<07:35, 15.20s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 408/438 [1:43:45<07:35, 15.20s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 409/438 [1:43:45<07:21, 15.21s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 409/438 [1:44:00<07:21, 15.21s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  94%|█████████▎| 410/438 [1:44:00<07:05, 15.19s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  94%|█████████▎| 410/438 [1:44:16<07:05, 15.19s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  94%|█████████▍| 411/438 [1:44:16<06:50, 15.21s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  94%|█████████▍| 411/438 [1:44:31<06:50, 15.21s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  94%|█████████▍| 412/438 [1:44:31<06:36, 15.24s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  94%|█████████▍| 412/438 [1:44:46<06:36, 15.24s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  94%|█████████▍| 413/438 [1:44:46<06:20, 15.23s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  94%|█████████▍| 413/438 [1:45:01<06:20, 15.23s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  95%|█████████▍| 414/438 [1:45:01<06:05, 15.24s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  95%|█████████▍| 414/438 [1:45:17<06:05, 15.24s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  95%|█████████▍| 415/438 [1:45:17<05:50, 15.24s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  95%|█████████▍| 415/438 [1:45:32<05:50, 15.24s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  95%|█████████▍| 416/438 [1:45:32<05:34, 15.21s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  95%|█████████▍| 416/438 [1:45:47<05:34, 15.21s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  95%|█████████▌| 417/438 [1:45:47<05:18, 15.17s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  95%|█████████▌| 417/438 [1:46:02<05:18, 15.17s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  95%|█████████▌| 418/438 [1:46:02<05:03, 15.19s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  95%|█████████▌| 418/438 [1:46:17<05:03, 15.19s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  96%|█████████▌| 419/438 [1:46:17<04:49, 15.23s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  96%|█████████▌| 419/438 [1:46:33<04:49, 15.23s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 2:  96%|█████████▌| 420/438 [1:46:33<04:36, 15.38s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 2:  96%|█████████▌| 420/438 [1:46:48<04:36, 15.38s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  96%|█████████▌| 421/438 [1:46:48<04:21, 15.36s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  96%|█████████▌| 421/438 [1:47:04<04:21, 15.36s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  96%|█████████▋| 422/438 [1:47:04<04:04, 15.31s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  96%|█████████▋| 422/438 [1:47:19<04:04, 15.31s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 423/438 [1:47:19<03:48, 15.24s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 423/438 [1:47:34<03:48, 15.24s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 424/438 [1:47:34<03:34, 15.35s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 424/438 [1:47:50<03:34, 15.35s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 425/438 [1:47:50<03:19, 15.34s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 425/438 [1:48:05<03:19, 15.34s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 426/438 [1:48:05<03:03, 15.28s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 426/438 [1:48:20<03:03, 15.28s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 427/438 [1:48:20<02:47, 15.27s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 427/438 [1:48:35<02:47, 15.27s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 428/438 [1:48:35<02:32, 15.22s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 428/438 [1:48:50<02:32, 15.22s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 429/438 [1:48:50<02:16, 15.18s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 429/438 [1:49:05<02:16, 15.18s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 430/438 [1:49:05<02:01, 15.21s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 430/438 [1:49:21<02:01, 15.21s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 431/438 [1:49:21<01:46, 15.21s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 431/438 [1:49:36<01:46, 15.21s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  99%|█████████▊| 432/438 [1:49:36<01:30, 15.16s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  99%|█████████▊| 432/438 [1:49:51<01:30, 15.16s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  99%|█████████▉| 433/438 [1:49:51<01:15, 15.17s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  99%|█████████▉| 433/438 [1:50:06<01:15, 15.17s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  99%|█████████▉| 434/438 [1:50:06<01:00, 15.19s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  99%|█████████▉| 434/438 [1:50:21<01:00, 15.19s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  99%|█████████▉| 435/438 [1:50:21<00:45, 15.20s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  99%|█████████▉| 435/438 [1:50:36<00:45, 15.20s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2: 100%|█████████▉| 436/438 [1:50:36<00:30, 15.16s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2: 100%|█████████▉| 436/438 [1:50:52<00:30, 15.16s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2: 100%|█████████▉| 437/438 [1:50:52<00:15, 15.15s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2: 100%|█████████▉| 437/438 [1:51:04<00:15, 15.15s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2: 100%|██████████| 438/438 [1:51:04<00:00, 14.48s/it, training_loss=0.124]\u001B[A\n",
      " 33%|███▎      | 1/3 [4:01:43<4:21:16, 7838.49s/it]                              \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Trainin loss: 0.39360376151457227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [4:20:32<2:10:12, 7812.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.39125105104547864\n",
      "F1 Score (Weighted): 0.006830920934844583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3:   0%|          | 0/438 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 3:   0%|          | 0/438 [00:14<?, ?it/s, training_loss=0.126]\u001B[A\n",
      "Epoch 3:   0%|          | 1/438 [00:14<1:48:22, 14.88s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:   0%|          | 1/438 [00:29<1:48:22, 14.88s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:   0%|          | 2/438 [00:29<1:48:11, 14.89s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:   0%|          | 2/438 [00:44<1:48:11, 14.89s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:   1%|          | 3/438 [00:44<1:47:53, 14.88s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:   1%|          | 3/438 [00:59<1:47:53, 14.88s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:   1%|          | 4/438 [00:59<1:47:30, 14.86s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:   1%|          | 4/438 [01:14<1:47:30, 14.86s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   1%|          | 5/438 [01:14<1:47:26, 14.89s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   1%|          | 5/438 [01:29<1:47:26, 14.89s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:   1%|▏         | 6/438 [01:29<1:47:01, 14.87s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:   1%|▏         | 6/438 [01:44<1:47:01, 14.87s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:   2%|▏         | 7/438 [01:44<1:46:47, 14.87s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:   2%|▏         | 7/438 [01:59<1:46:47, 14.87s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:   2%|▏         | 8/438 [01:59<1:48:34, 15.15s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:   2%|▏         | 8/438 [02:14<1:48:34, 15.15s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:   2%|▏         | 9/438 [02:14<1:47:29, 15.03s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:   2%|▏         | 9/438 [02:29<1:47:29, 15.03s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:   2%|▏         | 10/438 [02:29<1:47:08, 15.02s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:   2%|▏         | 10/438 [02:44<1:47:08, 15.02s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:   3%|▎         | 11/438 [02:44<1:46:49, 15.01s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:   3%|▎         | 11/438 [02:59<1:46:49, 15.01s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   3%|▎         | 12/438 [02:59<1:46:27, 14.99s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   3%|▎         | 12/438 [03:14<1:46:27, 14.99s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:   3%|▎         | 13/438 [03:14<1:46:00, 14.97s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:   3%|▎         | 13/438 [03:29<1:46:00, 14.97s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:   3%|▎         | 14/438 [03:29<1:45:53, 14.98s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:   3%|▎         | 14/438 [03:44<1:45:53, 14.98s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:   3%|▎         | 15/438 [03:44<1:45:39, 14.99s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:   3%|▎         | 15/438 [03:59<1:45:39, 14.99s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:   4%|▎         | 16/438 [03:59<1:45:27, 15.00s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:   4%|▎         | 16/438 [04:14<1:45:27, 15.00s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:   4%|▍         | 17/438 [04:14<1:45:03, 14.97s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:   4%|▍         | 17/438 [04:29<1:45:03, 14.97s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:   4%|▍         | 18/438 [04:29<1:44:33, 14.94s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:   4%|▍         | 18/438 [04:44<1:44:33, 14.94s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:   4%|▍         | 19/438 [04:44<1:44:27, 14.96s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:   4%|▍         | 19/438 [04:59<1:44:27, 14.96s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:   5%|▍         | 20/438 [04:59<1:43:45, 14.89s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:   5%|▍         | 20/438 [05:13<1:43:45, 14.89s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:   5%|▍         | 21/438 [05:13<1:43:37, 14.91s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:   5%|▍         | 21/438 [05:28<1:43:37, 14.91s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   5%|▌         | 22/438 [05:28<1:43:02, 14.86s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   5%|▌         | 22/438 [05:43<1:43:02, 14.86s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:   5%|▌         | 23/438 [05:43<1:42:41, 14.85s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:   5%|▌         | 23/438 [05:58<1:42:41, 14.85s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:   5%|▌         | 24/438 [05:58<1:43:10, 14.95s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:   5%|▌         | 24/438 [06:13<1:43:10, 14.95s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:   6%|▌         | 25/438 [06:13<1:42:39, 14.91s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:   6%|▌         | 25/438 [06:28<1:42:39, 14.91s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:   6%|▌         | 26/438 [06:28<1:42:10, 14.88s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:   6%|▌         | 26/438 [06:43<1:42:10, 14.88s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:   6%|▌         | 27/438 [06:43<1:41:58, 14.89s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:   6%|▌         | 27/438 [06:58<1:41:58, 14.89s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:   6%|▋         | 28/438 [06:58<1:42:02, 14.93s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:   6%|▋         | 28/438 [07:13<1:42:02, 14.93s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:   7%|▋         | 29/438 [07:13<1:41:36, 14.91s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:   7%|▋         | 29/438 [07:28<1:41:36, 14.91s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:   7%|▋         | 30/438 [07:28<1:41:22, 14.91s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:   7%|▋         | 30/438 [07:43<1:41:22, 14.91s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   7%|▋         | 31/438 [07:43<1:41:20, 14.94s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   7%|▋         | 31/438 [07:57<1:41:20, 14.94s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:   7%|▋         | 32/438 [07:57<1:41:02, 14.93s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:   7%|▋         | 32/438 [08:12<1:41:02, 14.93s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:   8%|▊         | 33/438 [08:12<1:40:49, 14.94s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:   8%|▊         | 33/438 [08:27<1:40:49, 14.94s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:   8%|▊         | 34/438 [08:27<1:40:29, 14.93s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:   8%|▊         | 34/438 [08:42<1:40:29, 14.93s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:   8%|▊         | 35/438 [08:42<1:40:15, 14.93s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:   8%|▊         | 35/438 [08:57<1:40:15, 14.93s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:   8%|▊         | 36/438 [08:57<1:40:04, 14.94s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:   8%|▊         | 36/438 [09:12<1:40:04, 14.94s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:   8%|▊         | 37/438 [09:12<1:39:51, 14.94s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:   8%|▊         | 37/438 [09:27<1:39:51, 14.94s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:   9%|▊         | 38/438 [09:27<1:39:36, 14.94s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:   9%|▊         | 38/438 [09:42<1:39:36, 14.94s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   9%|▉         | 39/438 [09:42<1:38:57, 14.88s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   9%|▉         | 39/438 [09:57<1:38:57, 14.88s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   9%|▉         | 40/438 [09:57<1:39:00, 14.93s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   9%|▉         | 40/438 [10:12<1:39:00, 14.93s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:   9%|▉         | 41/438 [10:12<1:38:38, 14.91s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:   9%|▉         | 41/438 [10:27<1:38:38, 14.91s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  10%|▉         | 42/438 [10:27<1:38:26, 14.92s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  10%|▉         | 42/438 [10:41<1:38:26, 14.92s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  10%|▉         | 43/438 [10:41<1:37:54, 14.87s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  10%|▉         | 43/438 [10:56<1:37:54, 14.87s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  10%|█         | 44/438 [10:56<1:37:41, 14.88s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  10%|█         | 44/438 [11:11<1:37:41, 14.88s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  10%|█         | 45/438 [11:11<1:37:25, 14.87s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  10%|█         | 45/438 [11:26<1:37:25, 14.87s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  11%|█         | 46/438 [11:26<1:37:14, 14.88s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  11%|█         | 46/438 [11:41<1:37:14, 14.88s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  11%|█         | 47/438 [11:41<1:36:39, 14.83s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  11%|█         | 47/438 [11:56<1:36:39, 14.83s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  11%|█         | 48/438 [11:56<1:36:29, 14.85s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  11%|█         | 48/438 [12:11<1:36:29, 14.85s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  11%|█         | 49/438 [12:11<1:36:20, 14.86s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  11%|█         | 49/438 [12:26<1:36:20, 14.86s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  11%|█▏        | 50/438 [12:26<1:36:22, 14.90s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  11%|█▏        | 50/438 [12:41<1:36:22, 14.90s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 51/438 [12:41<1:36:10, 14.91s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 51/438 [12:56<1:36:10, 14.91s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 52/438 [12:56<1:36:01, 14.93s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 52/438 [13:11<1:36:01, 14.93s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 53/438 [13:11<1:36:09, 14.99s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 53/438 [13:25<1:36:09, 14.99s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 54/438 [13:25<1:35:39, 14.95s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 54/438 [13:40<1:35:39, 14.95s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 55/438 [13:40<1:35:31, 14.96s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 55/438 [13:55<1:35:31, 14.96s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 56/438 [13:55<1:34:56, 14.91s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 56/438 [14:10<1:34:56, 14.91s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 57/438 [14:10<1:34:24, 14.87s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 57/438 [14:25<1:34:24, 14.87s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 58/438 [14:25<1:34:06, 14.86s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 58/438 [14:40<1:34:06, 14.86s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 59/438 [14:40<1:34:06, 14.90s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 59/438 [14:56<1:34:06, 14.90s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  14%|█▎        | 60/438 [14:56<1:36:23, 15.30s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  14%|█▎        | 60/438 [15:11<1:36:23, 15.30s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 3:  14%|█▍        | 61/438 [15:11<1:35:08, 15.14s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 3:  14%|█▍        | 61/438 [15:26<1:35:08, 15.14s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 3:  14%|█▍        | 62/438 [15:26<1:34:30, 15.08s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 3:  14%|█▍        | 62/438 [15:41<1:34:30, 15.08s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  14%|█▍        | 63/438 [15:41<1:33:53, 15.02s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  14%|█▍        | 63/438 [15:56<1:33:53, 15.02s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  15%|█▍        | 64/438 [15:56<1:33:23, 14.98s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  15%|█▍        | 64/438 [16:11<1:33:23, 14.98s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  15%|█▍        | 65/438 [16:11<1:33:08, 14.98s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  15%|█▍        | 65/438 [16:26<1:33:08, 14.98s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  15%|█▌        | 66/438 [16:26<1:32:54, 14.98s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  15%|█▌        | 66/438 [16:40<1:32:54, 14.98s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  15%|█▌        | 67/438 [16:40<1:32:30, 14.96s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  15%|█▌        | 67/438 [16:55<1:32:30, 14.96s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 68/438 [16:55<1:32:16, 14.96s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 68/438 [17:11<1:32:16, 14.96s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 69/438 [17:11<1:33:29, 15.20s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 69/438 [17:26<1:33:29, 15.20s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 70/438 [17:26<1:32:10, 15.03s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 70/438 [17:41<1:32:10, 15.03s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 71/438 [17:41<1:31:49, 15.01s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 71/438 [17:56<1:31:49, 15.01s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  16%|█▋        | 72/438 [17:56<1:31:38, 15.02s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  16%|█▋        | 72/438 [18:11<1:31:38, 15.02s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 73/438 [18:11<1:30:58, 14.96s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 73/438 [18:26<1:30:58, 14.96s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 74/438 [18:26<1:30:45, 14.96s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 74/438 [18:41<1:30:45, 14.96s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 75/438 [18:41<1:30:49, 15.01s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 75/438 [18:55<1:30:49, 15.01s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 76/438 [18:55<1:30:00, 14.92s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 76/438 [19:11<1:30:00, 14.92s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 77/438 [19:11<1:30:06, 14.98s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 77/438 [19:26<1:30:06, 14.98s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 78/438 [19:26<1:30:06, 15.02s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 78/438 [19:40<1:30:06, 15.02s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 79/438 [19:40<1:29:26, 14.95s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 79/438 [19:55<1:29:26, 14.95s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 80/438 [19:55<1:29:13, 14.96s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 80/438 [20:10<1:29:13, 14.96s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 81/438 [20:10<1:28:52, 14.94s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 81/438 [20:25<1:28:52, 14.94s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  19%|█▊        | 82/438 [20:25<1:28:26, 14.90s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  19%|█▊        | 82/438 [20:40<1:28:26, 14.90s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  19%|█▉        | 83/438 [20:40<1:28:07, 14.89s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  19%|█▉        | 83/438 [20:55<1:28:07, 14.89s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  19%|█▉        | 84/438 [20:55<1:27:48, 14.88s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  19%|█▉        | 84/438 [21:10<1:27:48, 14.88s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  19%|█▉        | 85/438 [21:10<1:27:36, 14.89s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  19%|█▉        | 85/438 [21:25<1:27:36, 14.89s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  20%|█▉        | 86/438 [21:25<1:27:12, 14.86s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  20%|█▉        | 86/438 [21:40<1:27:12, 14.86s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  20%|█▉        | 87/438 [21:40<1:27:02, 14.88s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  20%|█▉        | 87/438 [21:54<1:27:02, 14.88s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  20%|██        | 88/438 [21:54<1:26:41, 14.86s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  20%|██        | 88/438 [22:09<1:26:41, 14.86s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  20%|██        | 89/438 [22:09<1:26:40, 14.90s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  20%|██        | 89/438 [22:24<1:26:40, 14.90s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  21%|██        | 90/438 [22:24<1:26:19, 14.88s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  21%|██        | 90/438 [22:39<1:26:19, 14.88s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  21%|██        | 91/438 [22:39<1:26:15, 14.92s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  21%|██        | 91/438 [22:54<1:26:15, 14.92s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 3:  21%|██        | 92/438 [22:54<1:26:16, 14.96s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 3:  21%|██        | 92/438 [23:09<1:26:16, 14.96s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  21%|██        | 93/438 [23:09<1:26:08, 14.98s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  21%|██        | 93/438 [23:24<1:26:08, 14.98s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  21%|██▏       | 94/438 [23:24<1:25:34, 14.93s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  21%|██▏       | 94/438 [23:39<1:25:34, 14.93s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 95/438 [23:39<1:25:15, 14.91s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 95/438 [23:54<1:25:15, 14.91s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 96/438 [23:54<1:24:58, 14.91s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 96/438 [24:09<1:24:58, 14.91s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 97/438 [24:09<1:24:22, 14.85s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 97/438 [24:24<1:24:22, 14.85s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 98/438 [24:24<1:24:26, 14.90s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 98/438 [24:39<1:24:26, 14.90s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 99/438 [24:39<1:24:14, 14.91s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 99/438 [24:53<1:24:14, 14.91s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 100/438 [24:53<1:24:04, 14.92s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 100/438 [25:09<1:24:04, 14.92s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 101/438 [25:09<1:24:02, 14.96s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 101/438 [25:23<1:24:02, 14.96s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 102/438 [25:23<1:23:25, 14.90s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 102/438 [25:38<1:23:25, 14.90s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  24%|██▎       | 103/438 [25:38<1:23:07, 14.89s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  24%|██▎       | 103/438 [25:53<1:23:07, 14.89s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  24%|██▎       | 104/438 [25:53<1:22:51, 14.88s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  24%|██▎       | 104/438 [26:08<1:22:51, 14.88s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  24%|██▍       | 105/438 [26:08<1:22:43, 14.90s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  24%|██▍       | 105/438 [26:23<1:22:43, 14.90s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  24%|██▍       | 106/438 [26:23<1:22:20, 14.88s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  24%|██▍       | 106/438 [26:38<1:22:20, 14.88s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  24%|██▍       | 107/438 [26:38<1:22:06, 14.88s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  24%|██▍       | 107/438 [26:53<1:22:06, 14.88s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  25%|██▍       | 108/438 [26:53<1:21:51, 14.88s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  25%|██▍       | 108/438 [27:07<1:21:51, 14.88s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  25%|██▍       | 109/438 [27:07<1:21:39, 14.89s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  25%|██▍       | 109/438 [27:22<1:21:39, 14.89s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  25%|██▌       | 110/438 [27:22<1:21:32, 14.92s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  25%|██▌       | 110/438 [27:38<1:21:32, 14.92s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  25%|██▌       | 111/438 [27:38<1:21:33, 14.96s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  25%|██▌       | 111/438 [27:53<1:21:33, 14.96s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  26%|██▌       | 112/438 [27:53<1:21:36, 15.02s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  26%|██▌       | 112/438 [28:08<1:21:36, 15.02s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  26%|██▌       | 113/438 [28:08<1:21:05, 14.97s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  26%|██▌       | 113/438 [28:22<1:21:05, 14.97s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  26%|██▌       | 114/438 [28:22<1:20:48, 14.96s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  26%|██▌       | 114/438 [28:38<1:20:48, 14.96s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  26%|██▋       | 115/438 [28:38<1:20:41, 14.99s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  26%|██▋       | 115/438 [28:52<1:20:41, 14.99s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  26%|██▋       | 116/438 [28:52<1:20:23, 14.98s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  26%|██▋       | 116/438 [29:07<1:20:23, 14.98s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 117/438 [29:07<1:20:06, 14.97s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 117/438 [29:22<1:20:06, 14.97s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 118/438 [29:22<1:19:50, 14.97s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 118/438 [29:37<1:19:50, 14.97s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 119/438 [29:37<1:19:26, 14.94s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 119/438 [29:52<1:19:26, 14.94s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 120/438 [29:52<1:18:54, 14.89s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 120/438 [30:08<1:18:54, 14.89s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 121/438 [30:08<1:21:04, 15.35s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 121/438 [30:23<1:21:04, 15.35s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 122/438 [30:23<1:20:18, 15.25s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 122/438 [30:38<1:20:18, 15.25s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 123/438 [30:38<1:19:39, 15.17s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 123/438 [30:53<1:19:39, 15.17s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 124/438 [30:53<1:18:48, 15.06s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 124/438 [31:08<1:18:48, 15.06s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  29%|██▊       | 125/438 [31:08<1:18:18, 15.01s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  29%|██▊       | 125/438 [31:23<1:18:18, 15.01s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 126/438 [31:23<1:17:41, 14.94s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 126/438 [31:38<1:17:41, 14.94s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 127/438 [31:38<1:17:26, 14.94s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 127/438 [31:53<1:17:26, 14.94s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 128/438 [31:53<1:17:18, 14.96s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 128/438 [32:09<1:17:18, 14.96s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 129/438 [32:09<1:18:20, 15.21s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 129/438 [32:24<1:18:20, 15.21s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  30%|██▉       | 130/438 [32:24<1:17:40, 15.13s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  30%|██▉       | 130/438 [32:39<1:17:40, 15.13s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  30%|██▉       | 131/438 [32:39<1:17:04, 15.06s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  30%|██▉       | 131/438 [32:53<1:17:04, 15.06s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  30%|███       | 132/438 [32:53<1:16:34, 15.02s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  30%|███       | 132/438 [33:08<1:16:34, 15.02s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  30%|███       | 133/438 [33:08<1:16:08, 14.98s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  30%|███       | 133/438 [33:23<1:16:08, 14.98s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  31%|███       | 134/438 [33:23<1:15:45, 14.95s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  31%|███       | 134/438 [33:38<1:15:45, 14.95s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  31%|███       | 135/438 [33:38<1:15:46, 15.01s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  31%|███       | 135/438 [33:53<1:15:46, 15.01s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  31%|███       | 136/438 [33:53<1:15:22, 14.98s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  31%|███       | 136/438 [34:08<1:15:22, 14.98s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  31%|███▏      | 137/438 [34:08<1:14:59, 14.95s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  31%|███▏      | 137/438 [34:23<1:14:59, 14.95s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 138/438 [34:23<1:15:08, 15.03s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 138/438 [34:38<1:15:08, 15.03s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 139/438 [34:38<1:14:33, 14.96s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 139/438 [34:53<1:14:33, 14.96s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 140/438 [34:53<1:14:06, 14.92s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 140/438 [35:08<1:14:06, 14.92s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 141/438 [35:08<1:13:42, 14.89s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 141/438 [35:23<1:13:42, 14.89s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 142/438 [35:23<1:13:31, 14.90s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 142/438 [35:38<1:13:31, 14.90s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 143/438 [35:38<1:13:09, 14.88s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 143/438 [35:52<1:13:09, 14.88s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 144/438 [35:52<1:12:46, 14.85s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 144/438 [36:07<1:12:46, 14.85s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 145/438 [36:07<1:12:39, 14.88s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 145/438 [36:22<1:12:39, 14.88s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 146/438 [36:22<1:12:39, 14.93s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 146/438 [36:37<1:12:39, 14.93s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  34%|███▎      | 147/438 [36:37<1:12:32, 14.96s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  34%|███▎      | 147/438 [36:52<1:12:32, 14.96s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 148/438 [36:52<1:12:20, 14.97s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 148/438 [37:07<1:12:20, 14.97s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 149/438 [37:07<1:11:49, 14.91s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 149/438 [37:22<1:11:49, 14.91s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 150/438 [37:22<1:11:38, 14.93s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 150/438 [37:37<1:11:38, 14.93s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 151/438 [37:37<1:11:18, 14.91s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 151/438 [37:52<1:11:18, 14.91s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  35%|███▍      | 152/438 [37:52<1:11:17, 14.95s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  35%|███▍      | 152/438 [38:07<1:11:17, 14.95s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  35%|███▍      | 153/438 [38:07<1:11:17, 15.01s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  35%|███▍      | 153/438 [38:22<1:11:17, 15.01s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  35%|███▌      | 154/438 [38:22<1:10:54, 14.98s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  35%|███▌      | 154/438 [38:37<1:10:54, 14.98s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  35%|███▌      | 155/438 [38:37<1:10:42, 14.99s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  35%|███▌      | 155/438 [38:52<1:10:42, 14.99s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  36%|███▌      | 156/438 [38:52<1:10:24, 14.98s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  36%|███▌      | 156/438 [39:07<1:10:24, 14.98s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  36%|███▌      | 157/438 [39:07<1:09:57, 14.94s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  36%|███▌      | 157/438 [39:22<1:09:57, 14.94s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  36%|███▌      | 158/438 [39:22<1:09:43, 14.94s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  36%|███▌      | 158/438 [39:37<1:09:43, 14.94s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  36%|███▋      | 159/438 [39:37<1:09:46, 15.00s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  36%|███▋      | 159/438 [39:54<1:09:46, 15.00s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 160/438 [39:54<1:11:38, 15.46s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 160/438 [40:09<1:11:38, 15.46s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 161/438 [40:09<1:11:15, 15.43s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 161/438 [40:24<1:11:15, 15.43s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 162/438 [40:24<1:10:36, 15.35s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 162/438 [40:39<1:10:36, 15.35s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 163/438 [40:39<1:09:46, 15.22s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 163/438 [40:54<1:09:46, 15.22s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 164/438 [40:54<1:09:24, 15.20s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 164/438 [41:10<1:09:24, 15.20s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 165/438 [41:10<1:09:44, 15.33s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 165/438 [41:25<1:09:44, 15.33s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 166/438 [41:25<1:09:08, 15.25s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 166/438 [41:40<1:09:08, 15.25s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 167/438 [41:40<1:08:45, 15.22s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 167/438 [41:55<1:08:45, 15.22s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 168/438 [41:55<1:08:10, 15.15s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 168/438 [42:10<1:08:10, 15.15s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  39%|███▊      | 169/438 [42:10<1:07:33, 15.07s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  39%|███▊      | 169/438 [42:25<1:07:33, 15.07s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 170/438 [42:25<1:07:11, 15.04s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 170/438 [42:40<1:07:11, 15.04s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 171/438 [42:40<1:06:53, 15.03s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 171/438 [42:55<1:06:53, 15.03s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 172/438 [42:55<1:06:44, 15.05s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 172/438 [43:10<1:06:44, 15.05s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 173/438 [43:10<1:06:31, 15.06s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 173/438 [43:25<1:06:31, 15.06s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  40%|███▉      | 174/438 [43:25<1:06:03, 15.01s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  40%|███▉      | 174/438 [43:40<1:06:03, 15.01s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  40%|███▉      | 175/438 [43:40<1:05:56, 15.04s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  40%|███▉      | 175/438 [43:55<1:05:56, 15.04s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  40%|████      | 176/438 [43:55<1:05:49, 15.07s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  40%|████      | 176/438 [44:10<1:05:49, 15.07s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  40%|████      | 177/438 [44:10<1:05:24, 15.04s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  40%|████      | 177/438 [44:25<1:05:24, 15.04s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  41%|████      | 178/438 [44:25<1:05:01, 15.01s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  41%|████      | 178/438 [44:40<1:05:01, 15.01s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  41%|████      | 179/438 [44:40<1:04:35, 14.96s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  41%|████      | 179/438 [44:55<1:04:35, 14.96s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  41%|████      | 180/438 [44:55<1:04:19, 14.96s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  41%|████      | 180/438 [45:12<1:04:19, 14.96s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  41%|████▏     | 181/438 [45:12<1:06:24, 15.51s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  41%|████▏     | 181/438 [45:27<1:06:24, 15.51s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 182/438 [45:27<1:05:33, 15.37s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 182/438 [45:41<1:05:33, 15.37s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 183/438 [45:41<1:04:35, 15.20s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 183/438 [45:56<1:04:35, 15.20s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 184/438 [45:56<1:03:52, 15.09s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 184/438 [46:11<1:03:52, 15.09s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 185/438 [46:11<1:03:33, 15.07s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 185/438 [46:26<1:03:33, 15.07s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 186/438 [46:26<1:03:13, 15.06s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 186/438 [46:41<1:03:13, 15.06s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 187/438 [46:41<1:02:56, 15.05s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 187/438 [46:56<1:02:56, 15.05s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 188/438 [46:56<1:02:45, 15.06s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 188/438 [47:12<1:02:45, 15.06s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 189/438 [47:12<1:03:38, 15.34s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 189/438 [47:27<1:03:38, 15.34s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 190/438 [47:27<1:02:56, 15.23s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 190/438 [47:43<1:02:56, 15.23s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  44%|████▎     | 191/438 [47:43<1:02:36, 15.21s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  44%|████▎     | 191/438 [47:57<1:02:36, 15.21s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  44%|████▍     | 192/438 [47:57<1:01:54, 15.10s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  44%|████▍     | 192/438 [48:13<1:01:54, 15.10s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  44%|████▍     | 193/438 [48:13<1:01:39, 15.10s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  44%|████▍     | 193/438 [48:27<1:01:39, 15.10s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  44%|████▍     | 194/438 [48:27<1:01:00, 15.00s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  44%|████▍     | 194/438 [48:42<1:01:00, 15.00s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  45%|████▍     | 195/438 [48:42<1:00:49, 15.02s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  45%|████▍     | 195/438 [48:57<1:00:49, 15.02s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  45%|████▍     | 196/438 [48:57<1:00:26, 14.99s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  45%|████▍     | 196/438 [49:12<1:00:26, 14.99s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  45%|████▍     | 197/438 [49:12<1:00:11, 14.98s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  45%|████▍     | 197/438 [49:27<1:00:11, 14.98s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  45%|████▌     | 198/438 [49:27<1:00:06, 15.03s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  45%|████▌     | 198/438 [49:42<1:00:06, 15.03s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  45%|████▌     | 199/438 [49:42<59:32, 14.95s/it, training_loss=0.119]  \u001B[A\n",
      "Epoch 3:  45%|████▌     | 199/438 [49:57<59:32, 14.95s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  46%|████▌     | 200/438 [49:57<59:18, 14.95s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  46%|████▌     | 200/438 [50:12<59:18, 14.95s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  46%|████▌     | 201/438 [50:12<59:07, 14.97s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  46%|████▌     | 201/438 [50:27<59:07, 14.97s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  46%|████▌     | 202/438 [50:27<58:43, 14.93s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  46%|████▌     | 202/438 [50:42<58:43, 14.93s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  46%|████▋     | 203/438 [50:42<58:29, 14.93s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  46%|████▋     | 203/438 [50:57<58:29, 14.93s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 204/438 [50:57<58:18, 14.95s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 204/438 [51:12<58:18, 14.95s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 205/438 [51:12<58:11, 14.99s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 205/438 [51:27<58:11, 14.99s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 206/438 [51:27<57:46, 14.94s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 206/438 [51:42<57:46, 14.94s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 207/438 [51:42<57:39, 14.98s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 207/438 [51:57<57:39, 14.98s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 208/438 [51:57<57:28, 14.99s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 208/438 [52:12<57:28, 14.99s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 209/438 [52:12<57:09, 14.97s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 209/438 [52:27<57:09, 14.97s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 210/438 [52:27<56:59, 15.00s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 210/438 [52:42<56:59, 15.00s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 211/438 [52:42<56:55, 15.05s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 211/438 [52:57<56:55, 15.05s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 212/438 [52:57<56:36, 15.03s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 212/438 [53:12<56:36, 15.03s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  49%|████▊     | 213/438 [53:12<56:14, 15.00s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  49%|████▊     | 213/438 [53:27<56:14, 15.00s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  49%|████▉     | 214/438 [53:27<55:56, 14.99s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  49%|████▉     | 214/438 [53:42<55:56, 14.99s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  49%|████▉     | 215/438 [53:42<55:41, 14.99s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  49%|████▉     | 215/438 [53:57<55:41, 14.99s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  49%|████▉     | 216/438 [53:57<55:35, 15.02s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  49%|████▉     | 216/438 [54:12<55:35, 15.02s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  50%|████▉     | 217/438 [54:12<55:16, 15.01s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  50%|████▉     | 217/438 [54:27<55:16, 15.01s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  50%|████▉     | 218/438 [54:27<54:50, 14.96s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  50%|████▉     | 218/438 [54:42<54:50, 14.96s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  50%|█████     | 219/438 [54:42<54:42, 14.99s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  50%|█████     | 219/438 [54:57<54:42, 14.99s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  50%|█████     | 220/438 [54:57<54:23, 14.97s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  50%|█████     | 220/438 [55:12<54:23, 14.97s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  50%|█████     | 221/438 [55:12<54:07, 14.97s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  50%|█████     | 221/438 [55:27<54:07, 14.97s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  51%|█████     | 222/438 [55:27<53:44, 14.93s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  51%|█████     | 222/438 [55:41<53:44, 14.93s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  51%|█████     | 223/438 [55:41<53:26, 14.92s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  51%|█████     | 223/438 [55:57<53:26, 14.92s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  51%|█████     | 224/438 [55:57<53:28, 14.99s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  51%|█████     | 224/438 [56:12<53:28, 14.99s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  51%|█████▏    | 225/438 [56:12<53:10, 14.98s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  51%|█████▏    | 225/438 [56:27<53:10, 14.98s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  52%|█████▏    | 226/438 [56:27<52:49, 14.95s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  52%|█████▏    | 226/438 [56:41<52:49, 14.95s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  52%|█████▏    | 227/438 [56:41<52:36, 14.96s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  52%|█████▏    | 227/438 [56:56<52:36, 14.96s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  52%|█████▏    | 228/438 [56:56<52:03, 14.87s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  52%|█████▏    | 228/438 [57:11<52:03, 14.87s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  52%|█████▏    | 229/438 [57:11<51:52, 14.89s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  52%|█████▏    | 229/438 [57:26<51:52, 14.89s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 230/438 [57:26<51:50, 14.96s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 230/438 [57:41<51:50, 14.96s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 231/438 [57:41<51:53, 15.04s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 231/438 [57:57<51:53, 15.04s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 232/438 [57:57<51:46, 15.08s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 232/438 [58:12<51:46, 15.08s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 233/438 [58:12<51:26, 15.06s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 233/438 [58:27<51:26, 15.06s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 234/438 [58:27<51:03, 15.01s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 234/438 [58:42<51:03, 15.01s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  54%|█████▎    | 235/438 [58:42<50:52, 15.04s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  54%|█████▎    | 235/438 [58:57<50:52, 15.04s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 3:  54%|█████▍    | 236/438 [58:57<50:30, 15.00s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 3:  54%|█████▍    | 236/438 [59:12<50:30, 15.00s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  54%|█████▍    | 237/438 [59:12<50:14, 15.00s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  54%|█████▍    | 237/438 [59:26<50:14, 15.00s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  54%|█████▍    | 238/438 [59:26<49:56, 14.98s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  54%|█████▍    | 238/438 [59:42<49:56, 14.98s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  55%|█████▍    | 239/438 [59:42<49:46, 15.01s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  55%|█████▍    | 239/438 [59:57<49:46, 15.01s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  55%|█████▍    | 240/438 [59:57<49:29, 15.00s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  55%|█████▍    | 240/438 [1:00:13<49:29, 15.00s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  55%|█████▌    | 241/438 [1:00:13<50:19, 15.33s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  55%|█████▌    | 241/438 [1:00:28<50:19, 15.33s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  55%|█████▌    | 242/438 [1:00:28<50:03, 15.32s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  55%|█████▌    | 242/438 [1:00:43<50:03, 15.32s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  55%|█████▌    | 243/438 [1:00:43<49:24, 15.20s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  55%|█████▌    | 243/438 [1:00:58<49:24, 15.20s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  56%|█████▌    | 244/438 [1:00:58<49:03, 15.17s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  56%|█████▌    | 244/438 [1:01:13<49:03, 15.17s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  56%|█████▌    | 245/438 [1:01:13<48:35, 15.11s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  56%|█████▌    | 245/438 [1:01:28<48:35, 15.11s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  56%|█████▌    | 246/438 [1:01:28<48:04, 15.03s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  56%|█████▌    | 246/438 [1:01:43<48:04, 15.03s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  56%|█████▋    | 247/438 [1:01:43<47:40, 14.98s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  56%|█████▋    | 247/438 [1:01:58<47:40, 14.98s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 248/438 [1:01:58<47:34, 15.02s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 248/438 [1:02:13<47:34, 15.02s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 249/438 [1:02:13<47:35, 15.11s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 249/438 [1:02:28<47:35, 15.11s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 250/438 [1:02:28<47:13, 15.07s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 250/438 [1:02:43<47:13, 15.07s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 251/438 [1:02:43<46:59, 15.08s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 251/438 [1:02:58<46:59, 15.08s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 252/438 [1:02:58<46:29, 15.00s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 252/438 [1:03:13<46:29, 15.00s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 253/438 [1:03:13<46:15, 15.00s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 253/438 [1:03:28<46:15, 15.00s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 254/438 [1:03:28<46:09, 15.05s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 254/438 [1:03:43<46:09, 15.05s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 255/438 [1:03:43<45:48, 15.02s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 255/438 [1:03:58<45:48, 15.02s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 256/438 [1:03:58<45:28, 14.99s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 256/438 [1:04:13<45:28, 14.99s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  59%|█████▊    | 257/438 [1:04:13<45:12, 14.98s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  59%|█████▊    | 257/438 [1:04:28<45:12, 14.98s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  59%|█████▉    | 258/438 [1:04:28<44:40, 14.89s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  59%|█████▉    | 258/438 [1:04:43<44:40, 14.89s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  59%|█████▉    | 259/438 [1:04:43<44:29, 14.92s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  59%|█████▉    | 259/438 [1:04:58<44:29, 14.92s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  59%|█████▉    | 260/438 [1:04:58<44:15, 14.92s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  59%|█████▉    | 260/438 [1:05:12<44:15, 14.92s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  60%|█████▉    | 261/438 [1:05:12<44:03, 14.93s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  60%|█████▉    | 261/438 [1:05:27<44:03, 14.93s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  60%|█████▉    | 262/438 [1:05:27<43:50, 14.95s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  60%|█████▉    | 262/438 [1:05:42<43:50, 14.95s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  60%|██████    | 263/438 [1:05:42<43:37, 14.96s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  60%|██████    | 263/438 [1:05:57<43:37, 14.96s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  60%|██████    | 264/438 [1:05:57<43:23, 14.96s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  60%|██████    | 264/438 [1:06:12<43:23, 14.96s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  61%|██████    | 265/438 [1:06:12<43:11, 14.98s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  61%|██████    | 265/438 [1:06:27<43:11, 14.98s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  61%|██████    | 266/438 [1:06:27<42:55, 14.97s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  61%|██████    | 266/438 [1:06:42<42:55, 14.97s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  61%|██████    | 267/438 [1:06:42<42:43, 14.99s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  61%|██████    | 267/438 [1:06:58<42:43, 14.99s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  61%|██████    | 268/438 [1:06:58<42:37, 15.04s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  61%|██████    | 268/438 [1:07:13<42:37, 15.04s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  61%|██████▏   | 269/438 [1:07:13<42:21, 15.04s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  61%|██████▏   | 269/438 [1:07:28<42:21, 15.04s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 270/438 [1:07:28<42:12, 15.07s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 270/438 [1:07:43<42:12, 15.07s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 271/438 [1:07:43<42:08, 15.14s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 271/438 [1:07:58<42:08, 15.14s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 272/438 [1:07:58<41:50, 15.12s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 272/438 [1:08:13<41:50, 15.12s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 273/438 [1:08:13<41:22, 15.05s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 273/438 [1:08:28<41:22, 15.05s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 274/438 [1:08:28<41:02, 15.02s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 274/438 [1:08:43<41:02, 15.02s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 275/438 [1:08:43<40:53, 15.05s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 275/438 [1:08:58<40:53, 15.05s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 276/438 [1:08:58<40:28, 14.99s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 276/438 [1:09:13<40:28, 14.99s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 277/438 [1:09:13<40:13, 14.99s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 277/438 [1:09:28<40:13, 14.99s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 278/438 [1:09:28<40:01, 15.01s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 278/438 [1:09:43<40:01, 15.01s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  64%|██████▎   | 279/438 [1:09:43<39:38, 14.96s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  64%|██████▎   | 279/438 [1:09:58<39:38, 14.96s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  64%|██████▍   | 280/438 [1:09:58<39:18, 14.93s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  64%|██████▍   | 280/438 [1:10:13<39:18, 14.93s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 3:  64%|██████▍   | 281/438 [1:10:13<39:09, 14.96s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 3:  64%|██████▍   | 281/438 [1:10:28<39:09, 14.96s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  64%|██████▍   | 282/438 [1:10:28<38:53, 14.96s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  64%|██████▍   | 282/438 [1:10:43<38:53, 14.96s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  65%|██████▍   | 283/438 [1:10:43<38:39, 14.97s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  65%|██████▍   | 283/438 [1:10:58<38:39, 14.97s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  65%|██████▍   | 284/438 [1:10:58<38:23, 14.96s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  65%|██████▍   | 284/438 [1:11:13<38:23, 14.96s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  65%|██████▌   | 285/438 [1:11:13<38:05, 14.94s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  65%|██████▌   | 285/438 [1:11:27<38:05, 14.94s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  65%|██████▌   | 286/438 [1:11:27<37:42, 14.88s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  65%|██████▌   | 286/438 [1:11:42<37:42, 14.88s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 287/438 [1:11:42<37:35, 14.94s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 287/438 [1:11:57<37:35, 14.94s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 288/438 [1:11:57<37:24, 14.96s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 288/438 [1:12:12<37:24, 14.96s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 289/438 [1:12:12<37:12, 14.98s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 289/438 [1:12:28<37:12, 14.98s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 290/438 [1:12:28<37:06, 15.04s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 290/438 [1:12:43<37:06, 15.04s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  66%|██████▋   | 291/438 [1:12:43<36:56, 15.08s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  66%|██████▋   | 291/438 [1:12:58<36:56, 15.08s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 292/438 [1:12:58<36:40, 15.07s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 292/438 [1:13:13<36:40, 15.07s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 293/438 [1:13:13<36:32, 15.12s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 293/438 [1:13:28<36:32, 15.12s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 294/438 [1:13:28<36:04, 15.03s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 294/438 [1:13:43<36:04, 15.03s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 295/438 [1:13:43<35:49, 15.03s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 295/438 [1:13:58<35:49, 15.03s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 296/438 [1:13:58<35:36, 15.04s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 296/438 [1:14:13<35:36, 15.04s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 297/438 [1:14:13<35:18, 15.03s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 297/438 [1:14:28<35:18, 15.03s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 298/438 [1:14:28<35:02, 15.02s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 298/438 [1:14:43<35:02, 15.02s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 299/438 [1:14:43<34:51, 15.05s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 299/438 [1:14:58<34:51, 15.05s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 300/438 [1:14:58<34:34, 15.03s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 300/438 [1:15:13<34:34, 15.03s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  69%|██████▊   | 301/438 [1:15:13<34:11, 14.97s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  69%|██████▊   | 301/438 [1:15:29<34:11, 14.97s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  69%|██████▉   | 302/438 [1:15:29<34:59, 15.44s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  69%|██████▉   | 302/438 [1:15:45<34:59, 15.44s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 3:  69%|██████▉   | 303/438 [1:15:45<34:31, 15.35s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 3:  69%|██████▉   | 303/438 [1:15:59<34:31, 15.35s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  69%|██████▉   | 304/438 [1:15:59<33:56, 15.20s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  69%|██████▉   | 304/438 [1:16:14<33:56, 15.20s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  70%|██████▉   | 305/438 [1:16:14<33:37, 15.17s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  70%|██████▉   | 305/438 [1:16:29<33:37, 15.17s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  70%|██████▉   | 306/438 [1:16:29<33:11, 15.09s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  70%|██████▉   | 306/438 [1:16:44<33:11, 15.09s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  70%|███████   | 307/438 [1:16:44<32:55, 15.08s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  70%|███████   | 307/438 [1:17:00<32:55, 15.08s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  70%|███████   | 308/438 [1:17:00<32:40, 15.08s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  70%|███████   | 308/438 [1:17:15<32:40, 15.08s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  71%|███████   | 309/438 [1:17:15<32:34, 15.15s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  71%|███████   | 309/438 [1:17:30<32:34, 15.15s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  71%|███████   | 310/438 [1:17:30<32:31, 15.25s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  71%|███████   | 310/438 [1:17:46<32:31, 15.25s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 3:  71%|███████   | 311/438 [1:17:46<32:15, 15.24s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 3:  71%|███████   | 311/438 [1:18:01<32:15, 15.24s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  71%|███████   | 312/438 [1:18:01<31:51, 15.17s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  71%|███████   | 312/438 [1:18:16<31:51, 15.17s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  71%|███████▏  | 313/438 [1:18:16<31:35, 15.17s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  71%|███████▏  | 313/438 [1:18:31<31:35, 15.17s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 314/438 [1:18:31<31:17, 15.14s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 314/438 [1:18:46<31:17, 15.14s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 315/438 [1:18:46<30:54, 15.08s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 315/438 [1:19:01<30:54, 15.08s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 316/438 [1:19:01<30:33, 15.03s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 316/438 [1:19:16<30:33, 15.03s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 317/438 [1:19:16<30:22, 15.06s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 317/438 [1:19:31<30:22, 15.06s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 318/438 [1:19:31<30:03, 15.03s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 318/438 [1:19:46<30:03, 15.03s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 319/438 [1:19:46<29:45, 15.01s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 319/438 [1:20:01<29:45, 15.01s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 320/438 [1:20:01<29:30, 15.01s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 320/438 [1:20:16<29:30, 15.01s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 321/438 [1:20:16<29:15, 15.01s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 321/438 [1:20:31<29:15, 15.01s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  74%|███████▎  | 322/438 [1:20:31<28:56, 14.97s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  74%|███████▎  | 322/438 [1:20:46<28:56, 14.97s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  74%|███████▎  | 323/438 [1:20:46<28:43, 14.98s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  74%|███████▎  | 323/438 [1:21:01<28:43, 14.98s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  74%|███████▍  | 324/438 [1:21:01<28:28, 14.99s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  74%|███████▍  | 324/438 [1:21:15<28:28, 14.99s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  74%|███████▍  | 325/438 [1:21:15<28:10, 14.96s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  74%|███████▍  | 325/438 [1:21:30<28:10, 14.96s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  74%|███████▍  | 326/438 [1:21:30<27:53, 14.94s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  74%|███████▍  | 326/438 [1:21:45<27:53, 14.94s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  75%|███████▍  | 327/438 [1:21:45<27:41, 14.97s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  75%|███████▍  | 327/438 [1:22:01<27:41, 14.97s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  75%|███████▍  | 328/438 [1:22:01<27:30, 15.01s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  75%|███████▍  | 328/438 [1:22:15<27:30, 15.01s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  75%|███████▌  | 329/438 [1:22:15<27:12, 14.97s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  75%|███████▌  | 329/438 [1:22:30<27:12, 14.97s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  75%|███████▌  | 330/438 [1:22:30<26:59, 14.99s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  75%|███████▌  | 330/438 [1:22:45<26:59, 14.99s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  76%|███████▌  | 331/438 [1:22:45<26:42, 14.98s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  76%|███████▌  | 331/438 [1:23:00<26:42, 14.98s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  76%|███████▌  | 332/438 [1:23:00<26:28, 14.99s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  76%|███████▌  | 332/438 [1:23:15<26:28, 14.99s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  76%|███████▌  | 333/438 [1:23:15<26:15, 15.00s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  76%|███████▌  | 333/438 [1:23:30<26:15, 15.00s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  76%|███████▋  | 334/438 [1:23:30<26:00, 15.00s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  76%|███████▋  | 334/438 [1:23:45<26:00, 15.00s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  76%|███████▋  | 335/438 [1:23:45<25:46, 15.02s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  76%|███████▋  | 335/438 [1:24:01<25:46, 15.02s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 336/438 [1:24:01<25:36, 15.06s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 336/438 [1:24:16<25:36, 15.06s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 337/438 [1:24:16<25:23, 15.08s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 337/438 [1:24:31<25:23, 15.08s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 338/438 [1:24:31<25:03, 15.04s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 338/438 [1:24:46<25:03, 15.04s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 339/438 [1:24:46<24:43, 14.98s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 339/438 [1:25:01<24:43, 14.98s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 340/438 [1:25:01<24:27, 14.98s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 340/438 [1:25:16<24:27, 14.98s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 341/438 [1:25:16<24:12, 14.98s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 341/438 [1:25:31<24:12, 14.98s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 342/438 [1:25:31<24:03, 15.04s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 342/438 [1:25:46<24:03, 15.04s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 343/438 [1:25:46<23:45, 15.01s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 343/438 [1:26:01<23:45, 15.01s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  79%|███████▊  | 344/438 [1:26:01<23:33, 15.04s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  79%|███████▊  | 344/438 [1:26:16<23:33, 15.04s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 345/438 [1:26:16<23:14, 15.00s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 345/438 [1:26:30<23:14, 15.00s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 346/438 [1:26:30<22:55, 14.95s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 346/438 [1:26:46<22:55, 14.95s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 347/438 [1:26:46<22:42, 14.97s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 347/438 [1:27:01<22:42, 14.97s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 348/438 [1:27:01<22:31, 15.02s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 348/438 [1:27:15<22:31, 15.02s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  80%|███████▉  | 349/438 [1:27:15<22:11, 14.96s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  80%|███████▉  | 349/438 [1:27:30<22:11, 14.96s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  80%|███████▉  | 350/438 [1:27:30<21:56, 14.96s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  80%|███████▉  | 350/438 [1:27:46<21:56, 14.96s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  80%|████████  | 351/438 [1:27:46<21:48, 15.04s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  80%|████████  | 351/438 [1:28:01<21:48, 15.04s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  80%|████████  | 352/438 [1:28:01<21:33, 15.04s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  80%|████████  | 352/438 [1:28:16<21:33, 15.04s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  81%|████████  | 353/438 [1:28:16<21:17, 15.04s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  81%|████████  | 353/438 [1:28:31<21:17, 15.04s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  81%|████████  | 354/438 [1:28:31<21:03, 15.04s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  81%|████████  | 354/438 [1:28:46<21:03, 15.04s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  81%|████████  | 355/438 [1:28:46<20:46, 15.02s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  81%|████████  | 355/438 [1:29:01<20:46, 15.02s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  81%|████████▏ | 356/438 [1:29:01<20:30, 15.00s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  81%|████████▏ | 356/438 [1:29:16<20:30, 15.00s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 357/438 [1:29:16<20:25, 15.13s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 357/438 [1:29:31<20:25, 15.13s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 358/438 [1:29:31<20:08, 15.11s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 358/438 [1:29:46<20:08, 15.11s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 359/438 [1:29:46<19:51, 15.09s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 359/438 [1:30:01<19:51, 15.09s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 360/438 [1:30:01<19:34, 15.06s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 360/438 [1:30:16<19:34, 15.06s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 361/438 [1:30:16<19:17, 15.04s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 361/438 [1:30:33<19:17, 15.04s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 362/438 [1:30:33<19:36, 15.48s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 362/438 [1:30:48<19:36, 15.48s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 363/438 [1:30:48<19:09, 15.32s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 363/438 [1:31:03<19:09, 15.32s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 364/438 [1:31:03<18:47, 15.24s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 364/438 [1:31:18<18:47, 15.24s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 365/438 [1:31:18<18:25, 15.14s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 365/438 [1:31:33<18:25, 15.14s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  84%|████████▎ | 366/438 [1:31:33<18:04, 15.06s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  84%|████████▎ | 366/438 [1:31:48<18:04, 15.06s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 367/438 [1:31:48<17:48, 15.04s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 367/438 [1:32:02<17:48, 15.04s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 368/438 [1:32:02<17:29, 14.99s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 368/438 [1:32:18<17:29, 14.99s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 369/438 [1:32:18<17:23, 15.12s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 369/438 [1:32:33<17:23, 15.12s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 370/438 [1:32:33<17:08, 15.12s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 370/438 [1:32:48<17:08, 15.12s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  85%|████████▍ | 371/438 [1:32:48<16:53, 15.13s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  85%|████████▍ | 371/438 [1:33:03<16:53, 15.13s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  85%|████████▍ | 372/438 [1:33:03<16:38, 15.12s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  85%|████████▍ | 372/438 [1:33:18<16:38, 15.12s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  85%|████████▌ | 373/438 [1:33:18<16:22, 15.12s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  85%|████████▌ | 373/438 [1:33:33<16:22, 15.12s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  85%|████████▌ | 374/438 [1:33:33<16:05, 15.08s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  85%|████████▌ | 374/438 [1:33:48<16:05, 15.08s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  86%|████████▌ | 375/438 [1:33:48<15:48, 15.06s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  86%|████████▌ | 375/438 [1:34:03<15:48, 15.06s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  86%|████████▌ | 376/438 [1:34:03<15:33, 15.06s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  86%|████████▌ | 376/438 [1:34:18<15:33, 15.06s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 3:  86%|████████▌ | 377/438 [1:34:18<15:16, 15.02s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 3:  86%|████████▌ | 377/438 [1:34:33<15:16, 15.02s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  86%|████████▋ | 378/438 [1:34:33<15:02, 15.05s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  86%|████████▋ | 378/438 [1:34:48<15:02, 15.05s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 379/438 [1:34:48<14:45, 15.01s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 379/438 [1:35:03<14:45, 15.01s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 380/438 [1:35:03<14:27, 14.96s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 380/438 [1:35:18<14:27, 14.96s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 381/438 [1:35:18<14:10, 14.92s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 381/438 [1:35:33<14:10, 14.92s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 382/438 [1:35:33<13:59, 15.00s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 382/438 [1:35:48<13:59, 15.00s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 383/438 [1:35:48<13:45, 15.00s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 383/438 [1:36:03<13:45, 15.00s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 384/438 [1:36:03<13:30, 15.01s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 384/438 [1:36:18<13:30, 15.01s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 385/438 [1:36:18<13:13, 14.98s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 385/438 [1:36:33<13:13, 14.98s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 386/438 [1:36:33<12:59, 14.98s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 386/438 [1:36:48<12:59, 14.98s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 387/438 [1:36:48<12:44, 14.99s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 387/438 [1:37:03<12:44, 14.99s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  89%|████████▊ | 388/438 [1:37:03<12:29, 14.99s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  89%|████████▊ | 388/438 [1:37:18<12:29, 14.99s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 389/438 [1:37:18<12:14, 14.99s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 389/438 [1:37:33<12:14, 14.99s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 390/438 [1:37:33<12:04, 15.10s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 390/438 [1:37:48<12:04, 15.10s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 391/438 [1:37:48<11:48, 15.07s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 391/438 [1:38:03<11:48, 15.07s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 392/438 [1:38:03<11:32, 15.06s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 392/438 [1:38:19<11:32, 15.06s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  90%|████████▉ | 393/438 [1:38:19<11:17, 15.05s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  90%|████████▉ | 393/438 [1:38:34<11:17, 15.05s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  90%|████████▉ | 394/438 [1:38:34<11:03, 15.08s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  90%|████████▉ | 394/438 [1:38:49<11:03, 15.08s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  90%|█████████ | 395/438 [1:38:49<10:48, 15.08s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  90%|█████████ | 395/438 [1:39:04<10:48, 15.08s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  90%|█████████ | 396/438 [1:39:04<10:32, 15.06s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  90%|█████████ | 396/438 [1:39:19<10:32, 15.06s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  91%|█████████ | 397/438 [1:39:19<10:16, 15.05s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  91%|█████████ | 397/438 [1:39:34<10:16, 15.05s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  91%|█████████ | 398/438 [1:39:34<10:03, 15.09s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  91%|█████████ | 398/438 [1:39:49<10:03, 15.09s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  91%|█████████ | 399/438 [1:39:49<09:45, 15.01s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  91%|█████████ | 399/438 [1:40:04<09:45, 15.01s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  91%|█████████▏| 400/438 [1:40:04<09:31, 15.03s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  91%|█████████▏| 400/438 [1:40:19<09:31, 15.03s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 401/438 [1:40:19<09:16, 15.03s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 401/438 [1:40:34<09:16, 15.03s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 402/438 [1:40:34<08:58, 14.94s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 402/438 [1:40:49<08:58, 14.94s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 403/438 [1:40:49<08:42, 14.92s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 403/438 [1:41:04<08:42, 14.92s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 404/438 [1:41:04<08:28, 14.95s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 404/438 [1:41:19<08:28, 14.95s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 405/438 [1:41:19<08:15, 15.01s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 405/438 [1:41:34<08:15, 15.01s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 406/438 [1:41:34<08:00, 15.03s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 406/438 [1:41:49<08:00, 15.03s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 407/438 [1:41:49<07:45, 15.01s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 407/438 [1:42:04<07:45, 15.01s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 408/438 [1:42:04<07:30, 15.02s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 408/438 [1:42:19<07:30, 15.02s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 409/438 [1:42:19<07:13, 14.94s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 409/438 [1:42:34<07:13, 14.94s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  94%|█████████▎| 410/438 [1:42:34<06:59, 14.99s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  94%|█████████▎| 410/438 [1:42:49<06:59, 14.99s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  94%|█████████▍| 411/438 [1:42:49<06:45, 15.03s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  94%|█████████▍| 411/438 [1:43:04<06:45, 15.03s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  94%|█████████▍| 412/438 [1:43:04<06:30, 15.01s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  94%|█████████▍| 412/438 [1:43:19<06:30, 15.01s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  94%|█████████▍| 413/438 [1:43:19<06:15, 15.00s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  94%|█████████▍| 413/438 [1:43:34<06:15, 15.00s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  95%|█████████▍| 414/438 [1:43:34<06:00, 15.03s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  95%|█████████▍| 414/438 [1:43:49<06:00, 15.03s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 3:  95%|█████████▍| 415/438 [1:43:49<05:45, 15.01s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 3:  95%|█████████▍| 415/438 [1:44:04<05:45, 15.01s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  95%|█████████▍| 416/438 [1:44:04<05:30, 15.00s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  95%|█████████▍| 416/438 [1:44:19<05:30, 15.00s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  95%|█████████▌| 417/438 [1:44:19<05:14, 14.96s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  95%|█████████▌| 417/438 [1:44:34<05:14, 14.96s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  95%|█████████▌| 418/438 [1:44:34<04:59, 14.98s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  95%|█████████▌| 418/438 [1:44:48<04:59, 14.98s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  96%|█████████▌| 419/438 [1:44:48<04:43, 14.94s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  96%|█████████▌| 419/438 [1:45:04<04:43, 14.94s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  96%|█████████▌| 420/438 [1:45:04<04:30, 15.00s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  96%|█████████▌| 420/438 [1:45:19<04:30, 15.00s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  96%|█████████▌| 421/438 [1:45:19<04:14, 14.99s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  96%|█████████▌| 421/438 [1:45:35<04:14, 14.99s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  96%|█████████▋| 422/438 [1:45:35<04:07, 15.49s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  96%|█████████▋| 422/438 [1:45:50<04:07, 15.49s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 423/438 [1:45:50<03:49, 15.30s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 423/438 [1:46:05<03:49, 15.30s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 424/438 [1:46:05<03:32, 15.18s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 424/438 [1:46:20<03:32, 15.18s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 425/438 [1:46:20<03:16, 15.13s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 425/438 [1:46:35<03:16, 15.13s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 426/438 [1:46:35<03:00, 15.07s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 426/438 [1:46:50<03:00, 15.07s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 427/438 [1:46:50<02:45, 15.03s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 427/438 [1:47:05<02:45, 15.03s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 428/438 [1:47:05<02:30, 15.05s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 428/438 [1:47:20<02:30, 15.05s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 429/438 [1:47:20<02:15, 15.09s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 429/438 [1:47:35<02:15, 15.09s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 430/438 [1:47:35<02:00, 15.10s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 430/438 [1:47:50<02:00, 15.10s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 431/438 [1:47:50<01:45, 15.09s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 431/438 [1:48:05<01:45, 15.09s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 3:  99%|█████████▊| 432/438 [1:48:05<01:30, 15.09s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 3:  99%|█████████▊| 432/438 [1:48:20<01:30, 15.09s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  99%|█████████▉| 433/438 [1:48:20<01:15, 15.04s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  99%|█████████▉| 433/438 [1:48:35<01:15, 15.04s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  99%|█████████▉| 434/438 [1:48:35<01:00, 15.02s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  99%|█████████▉| 434/438 [1:48:50<01:00, 15.02s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  99%|█████████▉| 435/438 [1:48:50<00:45, 15.04s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  99%|█████████▉| 435/438 [1:49:05<00:45, 15.04s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3: 100%|█████████▉| 436/438 [1:49:05<00:30, 15.02s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3: 100%|█████████▉| 436/438 [1:49:20<00:30, 15.02s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3: 100%|█████████▉| 437/438 [1:49:20<00:14, 14.99s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3: 100%|█████████▉| 437/438 [1:49:33<00:14, 14.99s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3: 100%|██████████| 438/438 [1:49:33<00:00, 14.26s/it, training_loss=0.131]\u001B[A\n",
      " 67%|██████▋   | 2/3 [6:10:05<2:10:12, 7812.09s/it]                              \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Trainin loss: 0.388516952730205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [6:28:38<00:00, 7772.77s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.38937313854694366\n",
      "F1 Score (Weighted): 0.0228100907840582\n"
     ]
    }
   ],
   "source": [
    "  import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2],\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids) \n",
    "\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "for epoch in tqdm(range(1, EPOCHS + 1)):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2],\n",
    "        }\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "\n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    tqdm.write(f'Trainin loss: {loss_train_avg}')\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "\n",
    "torch.save(model.state_dict(), 'finetuned_BERT_final.model')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T18:35:07.798580Z",
     "start_time": "2024-09-04T12:06:29.130745Z"
    }
   },
   "id": "29d5031168643adf",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: neutral\n",
      "Accuracy: 0.0\n",
      "\n",
      "Class: acceptance\n",
      "Accuracy: 0.0\n",
      "\n",
      "Class: disgust\n",
      "Accuracy: 0.08191808191808192\n",
      "\n",
      "Class: surprise\n",
      "Accuracy: 0.01898101898101898\n",
      "\n",
      "Class: joy\n",
      "Accuracy: 0.004329004329004329\n",
      "\n",
      "Class: sadness\n",
      "Accuracy: 0.0\n",
      "\n",
      "Class: anger\n",
      "Accuracy: 0.0\n",
      "\n",
      "Class: like\n",
      "Accuracy: 0.0\n",
      "\n",
      "Class: fear\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=9,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "  \n",
    "\n",
    "        \n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('finetuned_BERT_final.model', map_location=torch.device('cpu')))\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "accuracy_per_class(predictions, true_vals)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-04T18:53:47.785164Z",
     "start_time": "2024-09-04T18:35:07.815595Z"
    }
   },
   "id": "7e47ff3a6c533966",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3c74cf1113af2ceb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "539b0d3cd1dc56d5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch['Utterances'], padding=True, truncation=True, max_length=MAX_LEN, return_tensors='pt')\n",
    "#    \n",
    "# def tokenize_fn(batch):\n",
    "#     return tokenizer(batch['Utterances'], padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors='pt')\n",
    "\n",
    "tokenized_dataset = split.map(tokenize_fn, batched=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf4725b4b0c2938a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d0f646dfa3841d6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenized_dataset['train'][0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8e43d3d7ead6d29",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#trainer.train()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afb8fdf882f8a7be",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear = torch.nn.Linear(768, 9) #number of classs\n",
    "\n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids,\n",
    "            attention_mask=attn_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n",
    "\n",
    "# # Freezing BERT layers: (tested, weaker convergence)\n",
    "# for param in model.bert_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83a4aefea952e049",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b83ab6df019c59b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f7e6618581d72a0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training of the model for one epoch\n",
    "def train_model(training_loader, model, optimizer):\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    # set model to training mode (activate droput, batch norm)\n",
    "    model.train()\n",
    "    # initialize the progress bar\n",
    "    loop = tq.tqdm(enumerate(training_loader), total=len(training_loader),\n",
    "                   leave=True, colour='steelblue')\n",
    "    for batch_idx, data in loop:\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(ids, mask, token_type_ids) # (batch,predict)=(32,8)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "        # training accuracy\n",
    "        _, preds = torch.max(outputs, dim=1) # batch dim \n",
    "        _, targ = torch.max(targets, dim=1)  # batch dim\n",
    "        num_samples += len(targ)  # technically adding batch size\n",
    "        correct_predictions += torch.sum(preds == targ)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        # grad descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        #loop.set_description(f\"\")\n",
    "        #loop.set_postfix(batch_loss=loss)\n",
    "\n",
    "    # returning: trained model, model accuracy, mean loss\n",
    "    return model, float(correct_predictions)/num_samples, np.mean(losses)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0b3b0b0de857d67",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def eval_model(validation_loader, model, optimizer):\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    # set model to eval mode (turn off dropout, fix batch norm)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(validation_loader, 0):\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # validation accuracy\n",
    "            _, preds = torch.max(outputs, dim=1) # batch dim \n",
    "            _, targ = torch.max(targets, dim=1)  # batch dim\n",
    "            num_samples += len(targ)  # technically adding batch size\n",
    "            correct_predictions += torch.sum(preds == targ)\n",
    "\n",
    "    return float(correct_predictions)/num_samples, np.mean(losses)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "187cd4131ce94ba1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "be212df01fd54147",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(tokenized_dataset['train'],\n",
    "                                                batch_size=TRAIN_BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0,\n",
    "                                                collate_fn=data_collator\n",
    "                                                )\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(tokenized_dataset['test'],\n",
    "                                              batch_size=VALID_BATCH_SIZE,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=0,\n",
    "                                              collate_fn=data_collator\n",
    "                                              )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae5a736bb41df71b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    model, train_acc, train_loss = train_model(train_data_loader, model, optimizer)\n",
    "    val_acc, val_loss = eval_model(val_data_loader, model, optimizer)\n",
    "\n",
    "    print(f'train_loss={train_loss:.4f}, val_loss={val_loss:.4f} train_acc={train_acc:.4f}, val_acc={val_acc:.4f}')\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    # save the best model\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), os.path.join(data_dir,\"output\",\"best_model_state.bin\"))\n",
    "        best_accuracy = val_acc\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea9c6fdc49bb8be0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3cc86c32beae981"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d78b86e9f9b698e9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "target_list = list(tokenized_dataset.columns)\n",
    "target_list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "120e2360fa4aefab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6949581129d91408"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                batch_size=TRAIN_BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0\n",
    "                                                )\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                              batch_size=VALID_BATCH_SIZE,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=0\n",
    "                                              )\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size=TEST_BATCH_SIZE,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0\n",
    "                                               )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35de033e82340e8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df4088691d16b159",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "12c67e0f261051bc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
