{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:39:59.382943Z",
     "start_time": "2024-09-03T07:39:56.256029Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import sys\n",
    "import tqdm.notebook as tq\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:39:59.386407Z",
     "start_time": "2024-09-03T07:39:59.383945Z"
    }
   },
   "id": "b58363187b02e5b1",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-05"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:39:59.389679Z",
     "start_time": "2024-09-03T07:39:59.386407Z"
    }
   },
   "id": "ad6570cf3d6f09f3",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = pd.read_csv('MEISD/MEISD_text.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:39:59.429179Z",
     "start_time": "2024-09-03T07:39:59.390681Z"
    }
   },
   "id": "c27ee3520d15ff70",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['neutral', 'acceptance', 'disgust', 'surprise', 'joy', 'sadness',\n       'anger', 'like', 'fear', 'acceptance ', 'faer', 'Fear ', 'fear ',\n       'Fear', 'Anger', 'Disgust', 'Neutral', 'Surprise', 'Joy',\n       'Sadness', 'Fera', 'ANGER', ' disgust', 'Neutral ', 'neutral '],\n      dtype=object)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(list(data['emotion'])).unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:39:59.439456Z",
     "start_time": "2024-09-03T07:39:59.430181Z"
    }
   },
   "id": "7c4e328fd5974985",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "emotion_map = {\n",
    "    'neutral': 0,\n",
    "    'acceptance': 1,\n",
    "    'disgust': 2,\n",
    "    'surprise': 3,\n",
    "    'joy': 4,\n",
    "    'sadness': 5,\n",
    "    'anger': 6,\n",
    "    'like': 7,\n",
    "    'fear': 8\n",
    "}\n",
    "\n",
    "data_emotion = pd.DataFrame()\n",
    "data_emotion['Utterances'] = data['Utterances']\n",
    "data_emotion['target1'] = data['emotion'].map(emotion_map).fillna(9).astype(int)\n",
    "data_emotion['target2'] = data['emotion2'].map(emotion_map).fillna(9).astype(int)\n",
    "data_emotion['target3'] = data['emotion3'].map(emotion_map).fillna(9).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:39:59.449592Z",
     "start_time": "2024-09-03T07:39:59.439456Z"
    }
   },
   "id": "81156bc1987f27e0",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def to_binary_vector(row, num_classes=9):\n",
    "    vector = np.zeros(num_classes)\n",
    "    for i in range(1, 4):  # iteracja po target1, target2, target3\n",
    "        if row[f'target{i}'] < num_classes:\n",
    "            vector[row[f'target{i}']] = 1\n",
    "    return vector\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:39:59.453917Z",
     "start_time": "2024-09-03T07:39:59.450594Z"
    }
   },
   "id": "e5e4f465c1e95c66",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Utterances  \\\n0                                        look around you   \n1                          say hello to your competition   \n2        eight of you will switch to an easier specialty   \n3              five of you will crack under the pressure   \n4                      two of you will be asked to leave   \n...                                                  ...   \n20012  oh, that's right, you're a woman and you need ...   \n20013                                     i'll try again   \n20014           please, pam, reconsider and have a bagel   \n20015                              i have an early lunch   \n20016  michael's been trying to get jim and me to han...   \n\n                                       target_vector  \n0      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n1      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n2      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n3      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n4      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n...                                              ...  \n20012  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n20013  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n20014  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n20015  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n20016  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n\n[20017 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Utterances</th>\n      <th>target_vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>look around you</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>say hello to your competition</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eight of you will switch to an easier specialty</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>five of you will crack under the pressure</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>two of you will be asked to leave</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20012</th>\n      <td>oh, that's right, you're a woman and you need ...</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20013</th>\n      <td>i'll try again</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20014</th>\n      <td>please, pam, reconsider and have a bagel</td>\n      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20015</th>\n      <td>i have an early lunch</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20016</th>\n      <td>michael's been trying to get jim and me to han...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n  </tbody>\n</table>\n<p>20017 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_emotion['target_vector'] = data_emotion.apply(to_binary_vector, axis=1)\n",
    "data_emotion[['Utterances', 'target_vector']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:39:59.668174Z",
     "start_time": "2024-09-03T07:39:59.454920Z"
    }
   },
   "id": "49408862008bfc12",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(data_emotion[['Utterances', 'target_vector']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:39:59.691882Z",
     "start_time": "2024-09-03T07:39:59.668174Z"
    }
   },
   "id": "3d43f7604a2b809",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['Utterances', 'target_vector'],\n    num_rows: 20017\n})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:39:59.696497Z",
     "start_time": "2024-09-03T07:39:59.692888Z"
    }
   },
   "id": "bfdc4c043bba7277",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " #split = dataset['train'].train_test_split(test_size=0.3, seed=42)\n",
    "split = dataset.train_test_split(test_size=0.3, seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:45:53.633668Z",
     "start_time": "2024-09-03T07:45:53.625121Z"
    }
   },
   "id": "92ce2090f1b3a123",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['Utterances', 'target_vector'],\n        num_rows: 14011\n    })\n    test: Dataset({\n        features: ['Utterances', 'target_vector'],\n        num_rows: 6006\n    })\n})"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:45:53.637428Z",
     "start_time": "2024-09-03T07:45:53.633668Z"
    }
   },
   "id": "6a1d6e9624516e9",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = 'bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:45:54.315614Z",
     "start_time": "2024-09-03T07:45:53.637428Z"
    }
   },
   "id": "74e78a3884fd99e2",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = split['train']\n",
    "val_data = split['test']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:45:54.318605Z",
     "start_time": "2024-09-03T07:45:54.315614Z"
    }
   },
   "id": "3a18454d9c0324bd",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "D:\\conda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    train_data['Utterances'],\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=MAX_LEN,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    val_data['Utterances'],\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=MAX_LEN,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(train_data['target_vector'])\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(val_data['target_vector'])\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:45:56.702890Z",
     "start_time": "2024-09-03T07:45:54.319606Z"
    }
   },
   "id": "46fee38cb75061ea",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=9,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:45:57.034429Z",
     "start_time": "2024-09-03T07:45:56.702890Z"
    }
   },
   "id": "e356f3dac1f7aab4",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              sampler=RandomSampler(dataset_train),\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val,\n",
    "                                   sampler=SequentialSampler(dataset_val),\n",
    "                                   batch_size=batch_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:45:57.038194Z",
     "start_time": "2024-09-03T07:45:57.035431Z"
    }
   },
   "id": "b7fdd69253893f71",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5,\n",
    "                  eps=1e-8)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:45:57.485816Z",
     "start_time": "2024-09-03T07:45:57.038194Z"
    }
   },
   "id": "f1b396beeebba70b",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "label_dict_inverse = {v: k for k, v in emotion_map.items()}\n",
    "\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.round(preds).astype(int)\n",
    "    labels_flat = labels.astype(int)\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in emotion_map.items()}\n",
    "\n",
    "    preds_flat = np.round(preds).astype(int)  \n",
    "    labels_flat = labels.astype(int)\n",
    "\n",
    "    for i in range(labels_flat.shape[1]): \n",
    "        y_preds = preds_flat[:, i]\n",
    "        y_true = labels_flat[:, i]\n",
    "        class_name = label_dict_inverse[i]\n",
    "        accuracy = len(y_preds[y_preds == y_true]) / len(y_true)\n",
    "        print(f'Class: {class_name}')\n",
    "        print(f'Accuracy: {accuracy}\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:45:57.572737Z",
     "start_time": "2024-09-03T07:45:57.486818Z"
    }
   },
   "id": "ed39f9f71bd10f49",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/4671 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 1:   0%|          | 0/4671 [00:01<?, ?it/s, training_loss=0.233]\u001B[A\n",
      "Epoch 1:   0%|          | 1/4671 [00:01<2:33:32,  1.97s/it, training_loss=0.233]\u001B[A\n",
      "Epoch 1:   0%|          | 1/4671 [00:03<2:33:32,  1.97s/it, training_loss=0.226]\u001B[A\n",
      "Epoch 1:   0%|          | 2/4671 [00:03<2:30:13,  1.93s/it, training_loss=0.226]\u001B[A\n",
      "Epoch 1:   0%|          | 2/4671 [00:05<2:30:13,  1.93s/it, training_loss=0.234]\u001B[A\n",
      "Epoch 1:   0%|          | 3/4671 [00:05<2:22:43,  1.83s/it, training_loss=0.234]\u001B[A\n",
      "Epoch 1:   0%|          | 3/4671 [00:07<2:22:43,  1.83s/it, training_loss=0.218]\u001B[A\n",
      "Epoch 1:   0%|          | 4/4671 [00:07<2:18:03,  1.77s/it, training_loss=0.218]\u001B[A\n",
      "Epoch 1:   0%|          | 4/4671 [00:08<2:18:03,  1.77s/it, training_loss=0.223]\u001B[A\n",
      "Epoch 1:   0%|          | 5/4671 [00:08<2:14:42,  1.73s/it, training_loss=0.223]\u001B[A\n",
      "Epoch 1:   0%|          | 5/4671 [00:10<2:14:42,  1.73s/it, training_loss=0.219]\u001B[A\n",
      "Epoch 1:   0%|          | 6/4671 [00:10<2:13:17,  1.71s/it, training_loss=0.219]\u001B[A\n",
      "Epoch 1:   0%|          | 6/4671 [00:12<2:13:17,  1.71s/it, training_loss=0.219]\u001B[A\n",
      "Epoch 1:   0%|          | 7/4671 [00:12<2:14:09,  1.73s/it, training_loss=0.219]\u001B[A\n",
      "Epoch 1:   0%|          | 7/4671 [00:14<2:14:09,  1.73s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:   0%|          | 8/4671 [00:14<2:13:15,  1.71s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:   0%|          | 8/4671 [00:15<2:13:15,  1.71s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:   0%|          | 9/4671 [00:15<2:12:28,  1.70s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:   0%|          | 9/4671 [00:17<2:12:28,  1.70s/it, training_loss=0.207]\u001B[A\n",
      "Epoch 1:   0%|          | 10/4671 [00:17<2:13:00,  1.71s/it, training_loss=0.207]\u001B[A\n",
      "Epoch 1:   0%|          | 10/4671 [00:19<2:13:00,  1.71s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:   0%|          | 11/4671 [00:19<2:12:52,  1.71s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:   0%|          | 11/4671 [00:20<2:12:52,  1.71s/it, training_loss=0.199]\u001B[A\n",
      "Epoch 1:   0%|          | 12/4671 [00:20<2:12:41,  1.71s/it, training_loss=0.199]\u001B[A\n",
      "Epoch 1:   0%|          | 12/4671 [00:22<2:12:41,  1.71s/it, training_loss=0.213]\u001B[A\n",
      "Epoch 1:   0%|          | 13/4671 [00:22<2:12:04,  1.70s/it, training_loss=0.213]\u001B[A\n",
      "Epoch 1:   0%|          | 13/4671 [00:24<2:12:04,  1.70s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:   0%|          | 14/4671 [00:24<2:11:36,  1.70s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:   0%|          | 14/4671 [00:25<2:11:36,  1.70s/it, training_loss=0.190]\u001B[A\n",
      "Epoch 1:   0%|          | 15/4671 [00:25<2:10:06,  1.68s/it, training_loss=0.190]\u001B[A\n",
      "Epoch 1:   0%|          | 15/4671 [00:27<2:10:06,  1.68s/it, training_loss=0.194]\u001B[A\n",
      "Epoch 1:   0%|          | 16/4671 [00:27<2:10:09,  1.68s/it, training_loss=0.194]\u001B[A\n",
      "Epoch 1:   0%|          | 16/4671 [00:29<2:10:09,  1.68s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:   0%|          | 17/4671 [00:29<2:10:51,  1.69s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:   0%|          | 17/4671 [00:30<2:10:51,  1.69s/it, training_loss=0.195]\u001B[A\n",
      "Epoch 1:   0%|          | 18/4671 [00:30<2:11:42,  1.70s/it, training_loss=0.195]\u001B[A\n",
      "Epoch 1:   0%|          | 18/4671 [00:32<2:11:42,  1.70s/it, training_loss=0.195]\u001B[A\n",
      "Epoch 1:   0%|          | 19/4671 [00:32<2:11:46,  1.70s/it, training_loss=0.195]\u001B[A\n",
      "Epoch 1:   0%|          | 19/4671 [00:34<2:11:46,  1.70s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:   0%|          | 20/4671 [00:34<2:12:09,  1.70s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:   0%|          | 20/4671 [00:36<2:12:09,  1.70s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:   0%|          | 21/4671 [00:36<2:11:57,  1.70s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:   0%|          | 21/4671 [00:37<2:11:57,  1.70s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:   0%|          | 22/4671 [00:37<2:12:23,  1.71s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:   0%|          | 22/4671 [00:39<2:12:23,  1.71s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:   0%|          | 23/4671 [00:39<2:12:42,  1.71s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:   0%|          | 23/4671 [00:41<2:12:42,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:   1%|          | 24/4671 [00:41<2:11:39,  1.70s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:   1%|          | 24/4671 [00:42<2:11:39,  1.70s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:   1%|          | 25/4671 [00:42<2:10:44,  1.69s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:   1%|          | 25/4671 [00:44<2:10:44,  1.69s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:   1%|          | 26/4671 [00:44<2:10:31,  1.69s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:   1%|          | 26/4671 [00:46<2:10:31,  1.69s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:   1%|          | 27/4671 [00:46<2:10:16,  1.68s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:   1%|          | 27/4671 [00:47<2:10:16,  1.68s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:   1%|          | 28/4671 [00:47<2:10:39,  1.69s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:   1%|          | 28/4671 [00:49<2:10:39,  1.69s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:   1%|          | 29/4671 [00:49<2:11:30,  1.70s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:   1%|          | 29/4671 [00:51<2:11:30,  1.70s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:   1%|          | 30/4671 [00:51<2:10:28,  1.69s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:   1%|          | 30/4671 [00:53<2:10:28,  1.69s/it, training_loss=0.188]\u001B[A\n",
      "Epoch 1:   1%|          | 31/4671 [00:53<2:10:58,  1.69s/it, training_loss=0.188]\u001B[A\n",
      "Epoch 1:   1%|          | 31/4671 [00:54<2:10:58,  1.69s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   1%|          | 32/4671 [00:54<2:11:42,  1.70s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   1%|          | 32/4671 [00:56<2:11:42,  1.70s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:   1%|          | 33/4671 [00:56<2:11:24,  1.70s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:   1%|          | 33/4671 [00:58<2:11:24,  1.70s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:   1%|          | 34/4671 [00:58<2:10:15,  1.69s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:   1%|          | 34/4671 [00:59<2:10:15,  1.69s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   1%|          | 35/4671 [00:59<2:09:29,  1.68s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   1%|          | 35/4671 [01:01<2:09:29,  1.68s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:   1%|          | 36/4671 [01:01<2:09:11,  1.67s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:   1%|          | 36/4671 [01:03<2:09:11,  1.67s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:   1%|          | 37/4671 [01:03<2:07:59,  1.66s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:   1%|          | 37/4671 [01:04<2:07:59,  1.66s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:   1%|          | 38/4671 [01:04<2:09:02,  1.67s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:   1%|          | 38/4671 [01:06<2:09:02,  1.67s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:   1%|          | 39/4671 [01:06<2:09:20,  1.68s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:   1%|          | 39/4671 [01:08<2:09:20,  1.68s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:   1%|          | 40/4671 [01:08<2:09:20,  1.68s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:   1%|          | 40/4671 [01:09<2:09:20,  1.68s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:   1%|          | 41/4671 [01:09<2:09:36,  1.68s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:   1%|          | 41/4671 [01:11<2:09:36,  1.68s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:   1%|          | 42/4671 [01:11<2:11:06,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:   1%|          | 42/4671 [01:13<2:11:06,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   1%|          | 43/4671 [01:13<2:09:49,  1.68s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   1%|          | 43/4671 [01:14<2:09:49,  1.68s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:   1%|          | 44/4671 [01:14<2:10:06,  1.69s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:   1%|          | 44/4671 [01:16<2:10:06,  1.69s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   1%|          | 45/4671 [01:16<2:10:15,  1.69s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   1%|          | 45/4671 [01:18<2:10:15,  1.69s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:   1%|          | 46/4671 [01:18<2:09:32,  1.68s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:   1%|          | 46/4671 [01:19<2:09:32,  1.68s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   1%|          | 47/4671 [01:19<2:09:34,  1.68s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   1%|          | 47/4671 [01:21<2:09:34,  1.68s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:   1%|          | 48/4671 [01:21<2:10:17,  1.69s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:   1%|          | 48/4671 [01:23<2:10:17,  1.69s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:   1%|          | 49/4671 [01:23<2:09:51,  1.69s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:   1%|          | 49/4671 [01:25<2:09:51,  1.69s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   1%|          | 50/4671 [01:25<2:10:15,  1.69s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   1%|          | 50/4671 [01:26<2:10:15,  1.69s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:   1%|          | 51/4671 [01:26<2:10:35,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:   1%|          | 51/4671 [01:28<2:10:35,  1.70s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:   1%|          | 52/4671 [01:28<2:10:51,  1.70s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:   1%|          | 52/4671 [01:30<2:10:51,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:   1%|          | 53/4671 [01:30<2:11:25,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:   1%|          | 53/4671 [01:31<2:11:25,  1.71s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   1%|          | 54/4671 [01:31<2:11:13,  1.71s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   1%|          | 54/4671 [01:33<2:11:13,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   1%|          | 55/4671 [01:33<2:09:50,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   1%|          | 55/4671 [01:35<2:09:50,  1.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   1%|          | 56/4671 [01:35<2:10:37,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   1%|          | 56/4671 [01:36<2:10:37,  1.70s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:   1%|          | 57/4671 [01:36<2:11:29,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:   1%|          | 57/4671 [01:38<2:11:29,  1.71s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:   1%|          | 58/4671 [01:38<2:11:17,  1.71s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:   1%|          | 58/4671 [01:40<2:11:17,  1.71s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:   1%|▏         | 59/4671 [01:40<2:10:48,  1.70s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:   1%|▏         | 59/4671 [01:42<2:10:48,  1.70s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:   1%|▏         | 60/4671 [01:42<2:11:20,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:   1%|▏         | 60/4671 [01:43<2:11:20,  1.71s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:   1%|▏         | 61/4671 [01:43<2:10:43,  1.70s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:   1%|▏         | 61/4671 [01:45<2:10:43,  1.70s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:   1%|▏         | 62/4671 [01:45<2:10:19,  1.70s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:   1%|▏         | 62/4671 [01:47<2:10:19,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   1%|▏         | 63/4671 [01:47<2:10:37,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   1%|▏         | 63/4671 [01:48<2:10:37,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   1%|▏         | 64/4671 [01:48<2:09:37,  1.69s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   1%|▏         | 64/4671 [01:50<2:09:37,  1.69s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   1%|▏         | 65/4671 [01:50<2:09:27,  1.69s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   1%|▏         | 65/4671 [01:52<2:09:27,  1.69s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   1%|▏         | 66/4671 [01:52<2:09:49,  1.69s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   1%|▏         | 66/4671 [01:53<2:09:49,  1.69s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:   1%|▏         | 67/4671 [01:53<2:10:07,  1.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:   1%|▏         | 67/4671 [01:55<2:10:07,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:   1%|▏         | 68/4671 [01:55<2:10:08,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:   1%|▏         | 68/4671 [01:57<2:10:08,  1.70s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:   1%|▏         | 69/4671 [01:57<2:10:12,  1.70s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:   1%|▏         | 69/4671 [01:58<2:10:12,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   1%|▏         | 70/4671 [01:58<2:10:03,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   1%|▏         | 70/4671 [02:00<2:10:03,  1.70s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   2%|▏         | 71/4671 [02:00<2:10:09,  1.70s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   2%|▏         | 71/4671 [02:02<2:10:09,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   2%|▏         | 72/4671 [02:02<2:10:13,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   2%|▏         | 72/4671 [02:04<2:10:13,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:   2%|▏         | 73/4671 [02:04<2:09:04,  1.68s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:   2%|▏         | 73/4671 [02:05<2:09:04,  1.68s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   2%|▏         | 74/4671 [02:05<2:10:31,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   2%|▏         | 74/4671 [02:07<2:10:31,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:   2%|▏         | 75/4671 [02:07<2:09:30,  1.69s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:   2%|▏         | 75/4671 [02:09<2:09:30,  1.69s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   2%|▏         | 76/4671 [02:09<2:09:14,  1.69s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   2%|▏         | 76/4671 [02:10<2:09:14,  1.69s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   2%|▏         | 77/4671 [02:10<2:09:37,  1.69s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   2%|▏         | 77/4671 [02:12<2:09:37,  1.69s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   2%|▏         | 78/4671 [02:12<2:10:16,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   2%|▏         | 78/4671 [02:14<2:10:16,  1.70s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:   2%|▏         | 79/4671 [02:14<2:10:04,  1.70s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:   2%|▏         | 79/4671 [02:15<2:10:04,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   2%|▏         | 80/4671 [02:15<2:09:52,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   2%|▏         | 80/4671 [02:17<2:09:52,  1.70s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:   2%|▏         | 81/4671 [02:17<2:11:13,  1.72s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:   2%|▏         | 81/4671 [02:19<2:11:13,  1.72s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:   2%|▏         | 82/4671 [02:19<2:10:51,  1.71s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:   2%|▏         | 82/4671 [02:21<2:10:51,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   2%|▏         | 83/4671 [02:21<2:11:08,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   2%|▏         | 83/4671 [02:22<2:11:08,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   2%|▏         | 84/4671 [02:22<2:09:46,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   2%|▏         | 84/4671 [02:24<2:09:46,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   2%|▏         | 85/4671 [02:24<2:09:44,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   2%|▏         | 85/4671 [02:26<2:09:44,  1.70s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:   2%|▏         | 86/4671 [02:26<2:10:17,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:   2%|▏         | 86/4671 [02:27<2:10:17,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   2%|▏         | 87/4671 [02:27<2:09:43,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   2%|▏         | 87/4671 [02:29<2:09:43,  1.70s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:   2%|▏         | 88/4671 [02:29<2:09:17,  1.69s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:   2%|▏         | 88/4671 [02:31<2:09:17,  1.69s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:   2%|▏         | 89/4671 [02:31<2:10:13,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:   2%|▏         | 89/4671 [02:33<2:10:13,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   2%|▏         | 90/4671 [02:33<2:10:31,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   2%|▏         | 90/4671 [02:34<2:10:31,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   2%|▏         | 91/4671 [02:34<2:09:30,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   2%|▏         | 91/4671 [02:36<2:09:30,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   2%|▏         | 92/4671 [02:36<2:09:12,  1.69s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   2%|▏         | 92/4671 [02:38<2:09:12,  1.69s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   2%|▏         | 93/4671 [02:38<2:10:23,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   2%|▏         | 93/4671 [02:39<2:10:23,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   2%|▏         | 94/4671 [02:39<2:10:55,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   2%|▏         | 94/4671 [02:41<2:10:55,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   2%|▏         | 95/4671 [02:41<2:10:46,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   2%|▏         | 95/4671 [02:43<2:10:46,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   2%|▏         | 96/4671 [02:43<2:09:29,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   2%|▏         | 96/4671 [02:44<2:09:29,  1.70s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:   2%|▏         | 97/4671 [02:44<2:09:47,  1.70s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:   2%|▏         | 97/4671 [02:46<2:09:47,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:   2%|▏         | 98/4671 [02:46<2:09:48,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:   2%|▏         | 98/4671 [02:48<2:09:48,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   2%|▏         | 99/4671 [02:48<2:10:31,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   2%|▏         | 99/4671 [02:50<2:10:31,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:   2%|▏         | 100/4671 [02:50<2:10:20,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:   2%|▏         | 100/4671 [02:51<2:10:20,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   2%|▏         | 101/4671 [02:51<2:10:06,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   2%|▏         | 101/4671 [02:53<2:10:06,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   2%|▏         | 102/4671 [02:53<2:09:48,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   2%|▏         | 102/4671 [02:55<2:09:48,  1.70s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   2%|▏         | 103/4671 [02:55<2:09:59,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   2%|▏         | 103/4671 [02:56<2:09:59,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   2%|▏         | 104/4671 [02:56<2:10:29,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   2%|▏         | 104/4671 [02:58<2:10:29,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:   2%|▏         | 105/4671 [02:58<2:09:42,  1.70s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:   2%|▏         | 105/4671 [03:00<2:09:42,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   2%|▏         | 106/4671 [03:00<2:10:05,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   2%|▏         | 106/4671 [03:02<2:10:05,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:   2%|▏         | 107/4671 [03:02<2:09:31,  1.70s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:   2%|▏         | 107/4671 [03:03<2:09:31,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:   2%|▏         | 108/4671 [03:03<2:11:00,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:   2%|▏         | 108/4671 [03:05<2:11:00,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   2%|▏         | 109/4671 [03:05<2:09:15,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   2%|▏         | 109/4671 [03:07<2:09:15,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   2%|▏         | 110/4671 [03:07<2:08:45,  1.69s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   2%|▏         | 110/4671 [03:08<2:08:45,  1.69s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:   2%|▏         | 111/4671 [03:08<2:07:25,  1.68s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:   2%|▏         | 111/4671 [03:10<2:07:25,  1.68s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:   2%|▏         | 112/4671 [03:10<2:09:33,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:   2%|▏         | 112/4671 [03:12<2:09:33,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   2%|▏         | 113/4671 [03:12<2:08:52,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   2%|▏         | 113/4671 [03:13<2:08:52,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:   2%|▏         | 114/4671 [03:13<2:08:29,  1.69s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:   2%|▏         | 114/4671 [03:15<2:08:29,  1.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   2%|▏         | 115/4671 [03:15<2:08:57,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   2%|▏         | 115/4671 [03:17<2:08:57,  1.70s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:   2%|▏         | 116/4671 [03:17<2:09:09,  1.70s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:   2%|▏         | 116/4671 [03:19<2:09:09,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   3%|▎         | 117/4671 [03:19<2:09:04,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   3%|▎         | 117/4671 [03:20<2:09:04,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   3%|▎         | 118/4671 [03:20<2:08:57,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   3%|▎         | 118/4671 [03:22<2:08:57,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:   3%|▎         | 119/4671 [03:22<2:09:06,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:   3%|▎         | 119/4671 [03:24<2:09:06,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   3%|▎         | 120/4671 [03:24<2:09:04,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   3%|▎         | 120/4671 [03:25<2:09:04,  1.70s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:   3%|▎         | 121/4671 [03:25<2:09:49,  1.71s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:   3%|▎         | 121/4671 [03:27<2:09:49,  1.71s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:   3%|▎         | 122/4671 [03:27<2:08:56,  1.70s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:   3%|▎         | 122/4671 [03:29<2:08:56,  1.70s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:   3%|▎         | 123/4671 [03:29<2:09:08,  1.70s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:   3%|▎         | 123/4671 [03:30<2:09:08,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   3%|▎         | 124/4671 [03:30<2:09:34,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   3%|▎         | 124/4671 [03:32<2:09:34,  1.71s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:   3%|▎         | 125/4671 [03:32<2:08:35,  1.70s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:   3%|▎         | 125/4671 [03:34<2:08:35,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   3%|▎         | 126/4671 [03:34<2:09:15,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   3%|▎         | 126/4671 [03:36<2:09:15,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:   3%|▎         | 127/4671 [03:36<2:08:58,  1.70s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:   3%|▎         | 127/4671 [03:37<2:08:58,  1.70s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:   3%|▎         | 128/4671 [03:37<2:09:42,  1.71s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:   3%|▎         | 128/4671 [03:39<2:09:42,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:   3%|▎         | 129/4671 [03:39<2:10:39,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:   3%|▎         | 129/4671 [03:41<2:10:39,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   3%|▎         | 130/4671 [03:41<2:09:53,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   3%|▎         | 130/4671 [03:42<2:09:53,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:   3%|▎         | 131/4671 [03:42<2:09:59,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:   3%|▎         | 131/4671 [03:44<2:09:59,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   3%|▎         | 132/4671 [03:44<2:08:20,  1.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   3%|▎         | 132/4671 [03:46<2:08:20,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:   3%|▎         | 133/4671 [03:46<2:09:10,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:   3%|▎         | 133/4671 [03:48<2:09:10,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   3%|▎         | 134/4671 [03:48<2:09:24,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   3%|▎         | 134/4671 [03:49<2:09:24,  1.71s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:   3%|▎         | 135/4671 [03:49<2:09:12,  1.71s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:   3%|▎         | 135/4671 [03:51<2:09:12,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   3%|▎         | 136/4671 [03:51<2:09:38,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   3%|▎         | 136/4671 [03:53<2:09:38,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   3%|▎         | 137/4671 [03:53<2:08:19,  1.70s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   3%|▎         | 137/4671 [03:54<2:08:19,  1.70s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:   3%|▎         | 138/4671 [03:54<2:09:40,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:   3%|▎         | 138/4671 [03:56<2:09:40,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   3%|▎         | 139/4671 [03:56<2:08:49,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   3%|▎         | 139/4671 [03:58<2:08:49,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:   3%|▎         | 140/4671 [03:58<2:09:01,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:   3%|▎         | 140/4671 [03:59<2:09:01,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   3%|▎         | 141/4671 [03:59<2:08:12,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   3%|▎         | 141/4671 [04:01<2:08:12,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:   3%|▎         | 142/4671 [04:01<2:08:49,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:   3%|▎         | 142/4671 [04:03<2:08:49,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   3%|▎         | 143/4671 [04:03<2:08:33,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   3%|▎         | 143/4671 [04:05<2:08:33,  1.70s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:   3%|▎         | 144/4671 [04:05<2:08:25,  1.70s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:   3%|▎         | 144/4671 [04:06<2:08:25,  1.70s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   3%|▎         | 145/4671 [04:06<2:08:35,  1.70s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   3%|▎         | 145/4671 [04:08<2:08:35,  1.70s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   3%|▎         | 146/4671 [04:08<2:07:38,  1.69s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   3%|▎         | 146/4671 [04:10<2:07:38,  1.69s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:   3%|▎         | 147/4671 [04:10<2:09:19,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:   3%|▎         | 147/4671 [04:11<2:09:19,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:   3%|▎         | 148/4671 [04:11<2:09:39,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:   3%|▎         | 148/4671 [04:13<2:09:39,  1.72s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:   3%|▎         | 149/4671 [04:13<2:09:22,  1.72s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:   3%|▎         | 149/4671 [04:15<2:09:22,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   3%|▎         | 150/4671 [04:15<2:08:58,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   3%|▎         | 150/4671 [04:17<2:08:58,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   3%|▎         | 151/4671 [04:17<2:08:31,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   3%|▎         | 151/4671 [04:18<2:08:31,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:   3%|▎         | 152/4671 [04:18<2:08:30,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:   3%|▎         | 152/4671 [04:20<2:08:30,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   3%|▎         | 153/4671 [04:20<2:08:43,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   3%|▎         | 153/4671 [04:22<2:08:43,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   3%|▎         | 154/4671 [04:22<2:08:04,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   3%|▎         | 154/4671 [04:23<2:08:04,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:   3%|▎         | 155/4671 [04:23<2:08:28,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:   3%|▎         | 155/4671 [04:25<2:08:28,  1.71s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:   3%|▎         | 156/4671 [04:25<2:08:35,  1.71s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:   3%|▎         | 156/4671 [04:27<2:08:35,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:   3%|▎         | 157/4671 [04:27<2:08:29,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:   3%|▎         | 157/4671 [04:29<2:08:29,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:   3%|▎         | 158/4671 [04:29<2:09:05,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:   3%|▎         | 158/4671 [04:30<2:09:05,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   3%|▎         | 159/4671 [04:30<2:09:02,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   3%|▎         | 159/4671 [04:32<2:09:02,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   3%|▎         | 160/4671 [04:32<2:08:30,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   3%|▎         | 160/4671 [04:34<2:08:30,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   3%|▎         | 161/4671 [04:34<2:07:45,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   3%|▎         | 161/4671 [04:35<2:07:45,  1.70s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   3%|▎         | 162/4671 [04:35<2:08:15,  1.71s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   3%|▎         | 162/4671 [04:37<2:08:15,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   3%|▎         | 163/4671 [04:37<2:08:02,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   3%|▎         | 163/4671 [04:39<2:08:02,  1.70s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:   4%|▎         | 164/4671 [04:39<2:06:59,  1.69s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:   4%|▎         | 164/4671 [04:40<2:06:59,  1.69s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   4%|▎         | 165/4671 [04:40<2:06:03,  1.68s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   4%|▎         | 165/4671 [04:42<2:06:03,  1.68s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   4%|▎         | 166/4671 [04:42<2:05:54,  1.68s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   4%|▎         | 166/4671 [04:44<2:05:54,  1.68s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:   4%|▎         | 167/4671 [04:44<2:06:13,  1.68s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:   4%|▎         | 167/4671 [04:45<2:06:13,  1.68s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   4%|▎         | 168/4671 [04:45<2:06:16,  1.68s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   4%|▎         | 168/4671 [04:47<2:06:16,  1.68s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   4%|▎         | 169/4671 [04:47<2:05:58,  1.68s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   4%|▎         | 169/4671 [04:49<2:05:58,  1.68s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:   4%|▎         | 170/4671 [04:49<2:06:04,  1.68s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:   4%|▎         | 170/4671 [04:50<2:06:04,  1.68s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:   4%|▎         | 171/4671 [04:50<2:06:44,  1.69s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:   4%|▎         | 171/4671 [04:52<2:06:44,  1.69s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:   4%|▎         | 172/4671 [04:52<2:08:06,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:   4%|▎         | 172/4671 [04:54<2:08:06,  1.71s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:   4%|▎         | 173/4671 [04:54<2:07:51,  1.71s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:   4%|▎         | 173/4671 [04:56<2:07:51,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   4%|▎         | 174/4671 [04:56<2:07:56,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   4%|▎         | 174/4671 [04:57<2:07:56,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   4%|▎         | 175/4671 [04:57<2:07:00,  1.69s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   4%|▎         | 175/4671 [04:59<2:07:00,  1.69s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   4%|▍         | 176/4671 [04:59<2:07:10,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   4%|▍         | 176/4671 [05:01<2:07:10,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:   4%|▍         | 177/4671 [05:01<2:06:56,  1.69s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:   4%|▍         | 177/4671 [05:02<2:06:56,  1.69s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   4%|▍         | 178/4671 [05:02<2:06:51,  1.69s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   4%|▍         | 178/4671 [05:04<2:06:51,  1.69s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   4%|▍         | 179/4671 [05:04<2:07:21,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   4%|▍         | 179/4671 [05:06<2:07:21,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   4%|▍         | 180/4671 [05:06<2:07:41,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   4%|▍         | 180/4671 [05:08<2:07:41,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:   4%|▍         | 181/4671 [05:08<2:09:53,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:   4%|▍         | 181/4671 [05:09<2:09:53,  1.74s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   4%|▍         | 182/4671 [05:09<2:10:54,  1.75s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   4%|▍         | 182/4671 [05:11<2:10:54,  1.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:   4%|▍         | 183/4671 [05:11<2:12:56,  1.78s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:   4%|▍         | 183/4671 [05:13<2:12:56,  1.78s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:   4%|▍         | 184/4671 [05:13<2:12:39,  1.77s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:   4%|▍         | 184/4671 [05:15<2:12:39,  1.77s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:   4%|▍         | 185/4671 [05:15<2:11:40,  1.76s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:   4%|▍         | 185/4671 [05:17<2:11:40,  1.76s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   4%|▍         | 186/4671 [05:17<2:12:57,  1.78s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   4%|▍         | 186/4671 [05:18<2:12:57,  1.78s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   4%|▍         | 187/4671 [05:18<2:12:34,  1.77s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   4%|▍         | 187/4671 [05:20<2:12:34,  1.77s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   4%|▍         | 188/4671 [05:20<2:11:03,  1.75s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   4%|▍         | 188/4671 [05:22<2:11:03,  1.75s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   4%|▍         | 189/4671 [05:22<2:10:44,  1.75s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   4%|▍         | 189/4671 [05:23<2:10:44,  1.75s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:   4%|▍         | 190/4671 [05:23<2:09:13,  1.73s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:   4%|▍         | 190/4671 [05:25<2:09:13,  1.73s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:   4%|▍         | 191/4671 [05:25<2:08:24,  1.72s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:   4%|▍         | 191/4671 [05:27<2:08:24,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   4%|▍         | 192/4671 [05:27<2:08:32,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   4%|▍         | 192/4671 [05:29<2:08:32,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:   4%|▍         | 193/4671 [05:29<2:07:25,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:   4%|▍         | 193/4671 [05:30<2:07:25,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   4%|▍         | 194/4671 [05:30<2:07:48,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   4%|▍         | 194/4671 [05:32<2:07:48,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:   4%|▍         | 195/4671 [05:32<2:06:57,  1.70s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:   4%|▍         | 195/4671 [05:34<2:06:57,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   4%|▍         | 196/4671 [05:34<2:07:34,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   4%|▍         | 196/4671 [05:35<2:07:34,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:   4%|▍         | 197/4671 [05:35<2:06:53,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:   4%|▍         | 197/4671 [05:37<2:06:53,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   4%|▍         | 198/4671 [05:37<2:07:55,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   4%|▍         | 198/4671 [05:39<2:07:55,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:   4%|▍         | 199/4671 [05:39<2:06:51,  1.70s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:   4%|▍         | 199/4671 [05:41<2:06:51,  1.70s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:   4%|▍         | 200/4671 [05:41<2:08:27,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:   4%|▍         | 200/4671 [05:42<2:08:27,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   4%|▍         | 201/4671 [05:42<2:08:34,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   4%|▍         | 201/4671 [05:44<2:08:34,  1.73s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   4%|▍         | 202/4671 [05:44<2:08:24,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   4%|▍         | 202/4671 [05:46<2:08:24,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   4%|▍         | 203/4671 [05:46<2:07:48,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   4%|▍         | 203/4671 [05:47<2:07:48,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   4%|▍         | 204/4671 [05:47<2:06:48,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   4%|▍         | 204/4671 [05:49<2:06:48,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:   4%|▍         | 205/4671 [05:49<2:05:48,  1.69s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:   4%|▍         | 205/4671 [05:51<2:05:48,  1.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   4%|▍         | 206/4671 [05:51<2:05:52,  1.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   4%|▍         | 206/4671 [05:52<2:05:52,  1.69s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:   4%|▍         | 207/4671 [05:52<2:05:13,  1.68s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:   4%|▍         | 207/4671 [05:54<2:05:13,  1.68s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   4%|▍         | 208/4671 [05:54<2:05:37,  1.69s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   4%|▍         | 208/4671 [05:56<2:05:37,  1.69s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   4%|▍         | 209/4671 [05:56<2:06:23,  1.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   4%|▍         | 209/4671 [05:58<2:06:23,  1.70s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:   4%|▍         | 210/4671 [05:58<2:06:35,  1.70s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:   4%|▍         | 210/4671 [05:59<2:06:35,  1.70s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:   5%|▍         | 211/4671 [05:59<2:06:12,  1.70s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:   5%|▍         | 211/4671 [06:01<2:06:12,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   5%|▍         | 212/4671 [06:01<2:07:11,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   5%|▍         | 212/4671 [06:03<2:07:11,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   5%|▍         | 213/4671 [06:03<2:06:17,  1.70s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   5%|▍         | 213/4671 [06:04<2:06:17,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   5%|▍         | 214/4671 [06:04<2:05:35,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   5%|▍         | 214/4671 [06:06<2:05:35,  1.69s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   5%|▍         | 215/4671 [06:06<2:05:01,  1.68s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   5%|▍         | 215/4671 [06:08<2:05:01,  1.68s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:   5%|▍         | 216/4671 [06:08<2:06:16,  1.70s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:   5%|▍         | 216/4671 [06:09<2:06:16,  1.70s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:   5%|▍         | 217/4671 [06:09<2:06:34,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:   5%|▍         | 217/4671 [06:11<2:06:34,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   5%|▍         | 218/4671 [06:11<2:07:16,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   5%|▍         | 218/4671 [06:13<2:07:16,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:   5%|▍         | 219/4671 [06:13<2:05:49,  1.70s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:   5%|▍         | 219/4671 [06:15<2:05:49,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   5%|▍         | 220/4671 [06:15<2:26:05,  1.97s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   5%|▍         | 220/4671 [06:17<2:26:05,  1.97s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   5%|▍         | 221/4671 [06:17<2:23:39,  1.94s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   5%|▍         | 221/4671 [06:19<2:23:39,  1.94s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   5%|▍         | 222/4671 [06:19<2:20:46,  1.90s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   5%|▍         | 222/4671 [06:21<2:20:46,  1.90s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:   5%|▍         | 223/4671 [06:21<2:16:27,  1.84s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:   5%|▍         | 223/4671 [06:23<2:16:27,  1.84s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:   5%|▍         | 224/4671 [06:23<2:12:54,  1.79s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:   5%|▍         | 224/4671 [06:24<2:12:54,  1.79s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   5%|▍         | 225/4671 [06:24<2:10:24,  1.76s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   5%|▍         | 225/4671 [06:26<2:10:24,  1.76s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:   5%|▍         | 226/4671 [06:26<2:08:43,  1.74s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:   5%|▍         | 226/4671 [06:28<2:08:43,  1.74s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:   5%|▍         | 227/4671 [06:28<2:08:08,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:   5%|▍         | 227/4671 [06:29<2:08:08,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:   5%|▍         | 228/4671 [06:29<2:07:54,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:   5%|▍         | 228/4671 [06:31<2:07:54,  1.73s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   5%|▍         | 229/4671 [06:31<2:07:58,  1.73s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   5%|▍         | 229/4671 [06:33<2:07:58,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:   5%|▍         | 230/4671 [06:33<2:06:37,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:   5%|▍         | 230/4671 [06:34<2:06:37,  1.71s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:   5%|▍         | 231/4671 [06:34<2:05:53,  1.70s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:   5%|▍         | 231/4671 [06:36<2:05:53,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:   5%|▍         | 232/4671 [06:36<2:06:25,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:   5%|▍         | 232/4671 [06:38<2:06:25,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:   5%|▍         | 233/4671 [06:38<2:06:16,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:   5%|▍         | 233/4671 [06:40<2:06:16,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:   5%|▌         | 234/4671 [06:40<2:06:12,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:   5%|▌         | 234/4671 [06:41<2:06:12,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:   5%|▌         | 235/4671 [06:41<2:05:09,  1.69s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:   5%|▌         | 235/4671 [06:43<2:05:09,  1.69s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   5%|▌         | 236/4671 [06:43<2:05:46,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   5%|▌         | 236/4671 [06:45<2:05:46,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   5%|▌         | 237/4671 [06:45<2:05:56,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   5%|▌         | 237/4671 [06:46<2:05:56,  1.70s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:   5%|▌         | 238/4671 [06:46<2:06:15,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:   5%|▌         | 238/4671 [06:48<2:06:15,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:   5%|▌         | 239/4671 [06:48<2:06:28,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:   5%|▌         | 239/4671 [06:50<2:06:28,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   5%|▌         | 240/4671 [06:50<2:07:17,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   5%|▌         | 240/4671 [06:52<2:07:17,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:   5%|▌         | 241/4671 [06:52<2:07:46,  1.73s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:   5%|▌         | 241/4671 [06:53<2:07:46,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   5%|▌         | 242/4671 [06:53<2:06:32,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   5%|▌         | 242/4671 [06:55<2:06:32,  1.71s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   5%|▌         | 243/4671 [06:55<2:06:37,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   5%|▌         | 243/4671 [06:57<2:06:37,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:   5%|▌         | 244/4671 [06:57<2:06:38,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:   5%|▌         | 244/4671 [06:58<2:06:38,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   5%|▌         | 245/4671 [06:58<2:06:38,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   5%|▌         | 245/4671 [07:00<2:06:38,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:   5%|▌         | 246/4671 [07:00<2:06:46,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:   5%|▌         | 246/4671 [07:02<2:06:46,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:   5%|▌         | 247/4671 [07:02<2:07:00,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:   5%|▌         | 247/4671 [07:04<2:07:00,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:   5%|▌         | 248/4671 [07:04<2:06:16,  1.71s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:   5%|▌         | 248/4671 [07:05<2:06:16,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:   5%|▌         | 249/4671 [07:05<2:05:56,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:   5%|▌         | 249/4671 [07:07<2:05:56,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:   5%|▌         | 250/4671 [07:07<2:05:53,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:   5%|▌         | 250/4671 [07:09<2:05:53,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   5%|▌         | 251/4671 [07:09<2:04:33,  1.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   5%|▌         | 251/4671 [07:10<2:04:33,  1.69s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:   5%|▌         | 252/4671 [07:10<2:05:13,  1.70s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:   5%|▌         | 252/4671 [07:12<2:05:13,  1.70s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:   5%|▌         | 253/4671 [07:12<2:04:57,  1.70s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:   5%|▌         | 253/4671 [07:14<2:04:57,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:   5%|▌         | 254/4671 [07:14<2:04:59,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:   5%|▌         | 254/4671 [07:15<2:04:59,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:   5%|▌         | 255/4671 [07:15<2:05:46,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:   5%|▌         | 255/4671 [07:17<2:05:46,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:   5%|▌         | 256/4671 [07:17<2:04:29,  1.69s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:   5%|▌         | 256/4671 [07:19<2:04:29,  1.69s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:   6%|▌         | 257/4671 [07:19<2:05:04,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:   6%|▌         | 257/4671 [07:21<2:05:04,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:   6%|▌         | 258/4671 [07:21<2:05:16,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:   6%|▌         | 258/4671 [07:22<2:05:16,  1.70s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:   6%|▌         | 259/4671 [07:22<2:06:22,  1.72s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:   6%|▌         | 259/4671 [07:24<2:06:22,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   6%|▌         | 260/4671 [07:24<2:04:50,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   6%|▌         | 260/4671 [07:26<2:04:50,  1.70s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   6%|▌         | 261/4671 [07:26<2:04:19,  1.69s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   6%|▌         | 261/4671 [07:27<2:04:19,  1.69s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:   6%|▌         | 262/4671 [07:27<2:05:11,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:   6%|▌         | 262/4671 [07:29<2:05:11,  1.70s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:   6%|▌         | 263/4671 [07:29<2:05:17,  1.71s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:   6%|▌         | 263/4671 [07:31<2:05:17,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:   6%|▌         | 264/4671 [07:31<2:05:37,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:   6%|▌         | 264/4671 [07:32<2:05:37,  1.71s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   6%|▌         | 265/4671 [07:32<2:05:58,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   6%|▌         | 265/4671 [07:34<2:05:58,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   6%|▌         | 266/4671 [07:34<2:05:29,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   6%|▌         | 266/4671 [07:36<2:05:29,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:   6%|▌         | 267/4671 [07:36<2:05:06,  1.70s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:   6%|▌         | 267/4671 [07:38<2:05:06,  1.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:   6%|▌         | 268/4671 [07:38<2:05:29,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:   6%|▌         | 268/4671 [07:39<2:05:29,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   6%|▌         | 269/4671 [07:39<2:06:26,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   6%|▌         | 269/4671 [07:41<2:06:26,  1.72s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   6%|▌         | 270/4671 [07:41<2:05:46,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   6%|▌         | 270/4671 [07:43<2:05:46,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   6%|▌         | 271/4671 [07:43<2:05:29,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   6%|▌         | 271/4671 [07:44<2:05:29,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   6%|▌         | 272/4671 [07:44<2:04:31,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   6%|▌         | 272/4671 [07:46<2:04:31,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:   6%|▌         | 273/4671 [07:46<2:05:15,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:   6%|▌         | 273/4671 [07:48<2:05:15,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:   6%|▌         | 274/4671 [07:48<2:04:49,  1.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:   6%|▌         | 274/4671 [07:50<2:04:49,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   6%|▌         | 275/4671 [07:50<2:04:51,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   6%|▌         | 275/4671 [07:51<2:04:51,  1.70s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:   6%|▌         | 276/4671 [07:51<2:04:48,  1.70s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:   6%|▌         | 276/4671 [07:53<2:04:48,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:   6%|▌         | 277/4671 [07:53<2:04:18,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:   6%|▌         | 277/4671 [07:55<2:04:18,  1.70s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:   6%|▌         | 278/4671 [07:55<2:04:56,  1.71s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:   6%|▌         | 278/4671 [07:56<2:04:56,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:   6%|▌         | 279/4671 [07:56<2:04:24,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:   6%|▌         | 279/4671 [07:58<2:04:24,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   6%|▌         | 280/4671 [07:58<2:04:44,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   6%|▌         | 280/4671 [08:00<2:04:44,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   6%|▌         | 281/4671 [08:00<2:04:53,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   6%|▌         | 281/4671 [08:01<2:04:53,  1.71s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:   6%|▌         | 282/4671 [08:01<2:04:27,  1.70s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:   6%|▌         | 282/4671 [08:03<2:04:27,  1.70s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   6%|▌         | 283/4671 [08:03<2:03:17,  1.69s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   6%|▌         | 283/4671 [08:05<2:03:17,  1.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   6%|▌         | 284/4671 [08:05<2:03:48,  1.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:   6%|▌         | 284/4671 [08:07<2:03:48,  1.69s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:   6%|▌         | 285/4671 [08:07<2:04:17,  1.70s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:   6%|▌         | 285/4671 [08:08<2:04:17,  1.70s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:   6%|▌         | 286/4671 [08:08<2:05:07,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:   6%|▌         | 286/4671 [08:10<2:05:07,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:   6%|▌         | 287/4671 [08:10<2:04:54,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:   6%|▌         | 287/4671 [08:12<2:04:54,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   6%|▌         | 288/4671 [08:12<2:04:33,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:   6%|▌         | 288/4671 [08:13<2:04:33,  1.71s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:   6%|▌         | 289/4671 [08:13<2:05:20,  1.72s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:   6%|▌         | 289/4671 [08:15<2:05:20,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:   6%|▌         | 290/4671 [08:15<2:03:51,  1.70s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:   6%|▌         | 290/4671 [08:17<2:03:51,  1.70s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:   6%|▌         | 291/4671 [08:17<2:03:38,  1.69s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:   6%|▌         | 291/4671 [08:18<2:03:38,  1.69s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   6%|▋         | 292/4671 [08:18<2:03:58,  1.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   6%|▋         | 292/4671 [08:20<2:03:58,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   6%|▋         | 293/4671 [08:20<2:04:12,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   6%|▋         | 293/4671 [08:22<2:04:12,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:   6%|▋         | 294/4671 [08:22<2:03:58,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:   6%|▋         | 294/4671 [08:24<2:03:58,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:   6%|▋         | 295/4671 [08:24<2:03:51,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:   6%|▋         | 295/4671 [08:25<2:03:51,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   6%|▋         | 296/4671 [08:25<2:03:27,  1.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   6%|▋         | 296/4671 [08:27<2:03:27,  1.69s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:   6%|▋         | 297/4671 [08:27<2:02:06,  1.67s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:   6%|▋         | 297/4671 [08:29<2:02:06,  1.67s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:   6%|▋         | 298/4671 [08:29<2:02:15,  1.68s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:   6%|▋         | 298/4671 [08:30<2:02:15,  1.68s/it, training_loss=0.193]\u001B[A\n",
      "Epoch 1:   6%|▋         | 299/4671 [08:30<2:03:25,  1.69s/it, training_loss=0.193]\u001B[A\n",
      "Epoch 1:   6%|▋         | 299/4671 [08:32<2:03:25,  1.69s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:   6%|▋         | 300/4671 [08:32<2:03:45,  1.70s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:   6%|▋         | 300/4671 [08:34<2:03:45,  1.70s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:   6%|▋         | 301/4671 [08:34<2:03:13,  1.69s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:   6%|▋         | 301/4671 [08:35<2:03:13,  1.69s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:   6%|▋         | 302/4671 [08:35<2:02:10,  1.68s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:   6%|▋         | 302/4671 [08:37<2:02:10,  1.68s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:   6%|▋         | 303/4671 [08:37<2:02:34,  1.68s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:   6%|▋         | 303/4671 [08:39<2:02:34,  1.68s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:   7%|▋         | 304/4671 [08:39<2:03:38,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:   7%|▋         | 304/4671 [08:40<2:03:38,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:   7%|▋         | 305/4671 [08:40<2:04:07,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:   7%|▋         | 305/4671 [08:42<2:04:07,  1.71s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   7%|▋         | 306/4671 [08:42<2:03:00,  1.69s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   7%|▋         | 306/4671 [08:44<2:03:00,  1.69s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:   7%|▋         | 307/4671 [08:44<2:01:52,  1.68s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:   7%|▋         | 307/4671 [08:45<2:01:52,  1.68s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:   7%|▋         | 308/4671 [08:45<2:02:52,  1.69s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:   7%|▋         | 308/4671 [08:47<2:02:52,  1.69s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   7%|▋         | 309/4671 [08:47<2:03:29,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   7%|▋         | 309/4671 [08:49<2:03:29,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   7%|▋         | 310/4671 [08:49<2:04:08,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   7%|▋         | 310/4671 [08:51<2:04:08,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   7%|▋         | 311/4671 [08:51<2:04:34,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   7%|▋         | 311/4671 [08:52<2:04:34,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   7%|▋         | 312/4671 [08:52<2:03:23,  1.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   7%|▋         | 312/4671 [08:54<2:03:23,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   7%|▋         | 313/4671 [08:54<2:04:18,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   7%|▋         | 313/4671 [08:56<2:04:18,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   7%|▋         | 314/4671 [08:56<2:03:50,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:   7%|▋         | 314/4671 [08:58<2:03:50,  1.71s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:   7%|▋         | 315/4671 [08:58<2:04:34,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:   7%|▋         | 315/4671 [08:59<2:04:34,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:   7%|▋         | 316/4671 [08:59<2:04:06,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:   7%|▋         | 316/4671 [09:01<2:04:06,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   7%|▋         | 317/4671 [09:01<2:05:17,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   7%|▋         | 317/4671 [09:03<2:05:17,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:   7%|▋         | 318/4671 [09:03<2:04:14,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:   7%|▋         | 318/4671 [09:04<2:04:14,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:   7%|▋         | 319/4671 [09:04<2:03:30,  1.70s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:   7%|▋         | 319/4671 [09:06<2:03:30,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   7%|▋         | 320/4671 [09:06<2:03:22,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   7%|▋         | 320/4671 [09:08<2:03:22,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   7%|▋         | 321/4671 [09:08<2:02:49,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   7%|▋         | 321/4671 [09:09<2:02:49,  1.69s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:   7%|▋         | 322/4671 [09:09<2:03:23,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:   7%|▋         | 322/4671 [09:11<2:03:23,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:   7%|▋         | 323/4671 [09:11<2:03:20,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:   7%|▋         | 323/4671 [09:13<2:03:20,  1.70s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:   7%|▋         | 324/4671 [09:13<2:04:04,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:   7%|▋         | 324/4671 [09:15<2:04:04,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:   7%|▋         | 325/4671 [09:15<2:03:45,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:   7%|▋         | 325/4671 [09:16<2:03:45,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   7%|▋         | 326/4671 [09:16<2:04:08,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   7%|▋         | 326/4671 [09:18<2:04:08,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   7%|▋         | 327/4671 [09:18<2:03:31,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   7%|▋         | 327/4671 [09:20<2:03:31,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:   7%|▋         | 328/4671 [09:20<2:03:50,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:   7%|▋         | 328/4671 [09:21<2:03:50,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:   7%|▋         | 329/4671 [09:21<2:04:12,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:   7%|▋         | 329/4671 [09:23<2:04:12,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:   7%|▋         | 330/4671 [09:23<2:03:38,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:   7%|▋         | 330/4671 [09:25<2:03:38,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   7%|▋         | 331/4671 [09:25<2:01:44,  1.68s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   7%|▋         | 331/4671 [09:26<2:01:44,  1.68s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   7%|▋         | 332/4671 [09:26<2:00:17,  1.66s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   7%|▋         | 332/4671 [09:28<2:00:17,  1.66s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   7%|▋         | 333/4671 [09:28<2:01:44,  1.68s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   7%|▋         | 333/4671 [09:30<2:01:44,  1.68s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   7%|▋         | 334/4671 [09:30<2:02:40,  1.70s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   7%|▋         | 334/4671 [09:32<2:02:40,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:   7%|▋         | 335/4671 [09:32<2:03:16,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:   7%|▋         | 335/4671 [09:33<2:03:16,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   7%|▋         | 336/4671 [09:33<2:03:40,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   7%|▋         | 336/4671 [09:35<2:03:40,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   7%|▋         | 337/4671 [09:35<2:02:33,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   7%|▋         | 337/4671 [09:37<2:02:33,  1.70s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:   7%|▋         | 338/4671 [09:37<2:02:44,  1.70s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:   7%|▋         | 338/4671 [09:38<2:02:44,  1.70s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   7%|▋         | 339/4671 [09:38<2:03:18,  1.71s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   7%|▋         | 339/4671 [09:40<2:03:18,  1.71s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:   7%|▋         | 340/4671 [09:40<2:02:19,  1.69s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:   7%|▋         | 340/4671 [09:42<2:02:19,  1.69s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:   7%|▋         | 341/4671 [09:42<2:01:39,  1.69s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:   7%|▋         | 341/4671 [09:43<2:01:39,  1.69s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   7%|▋         | 342/4671 [09:43<2:02:16,  1.69s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   7%|▋         | 342/4671 [09:45<2:02:16,  1.69s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:   7%|▋         | 343/4671 [09:45<2:01:58,  1.69s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:   7%|▋         | 343/4671 [09:47<2:01:58,  1.69s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:   7%|▋         | 344/4671 [09:47<2:01:50,  1.69s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:   7%|▋         | 344/4671 [09:48<2:01:50,  1.69s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   7%|▋         | 345/4671 [09:48<2:01:27,  1.68s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   7%|▋         | 345/4671 [09:50<2:01:27,  1.68s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:   7%|▋         | 346/4671 [09:50<2:01:53,  1.69s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:   7%|▋         | 346/4671 [09:52<2:01:53,  1.69s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:   7%|▋         | 347/4671 [09:52<2:02:49,  1.70s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:   7%|▋         | 347/4671 [09:54<2:02:49,  1.70s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:   7%|▋         | 348/4671 [09:54<2:02:50,  1.70s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:   7%|▋         | 348/4671 [09:55<2:02:50,  1.70s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:   7%|▋         | 349/4671 [09:55<2:02:50,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:   7%|▋         | 349/4671 [09:57<2:02:50,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   7%|▋         | 350/4671 [09:57<2:00:40,  1.68s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   7%|▋         | 350/4671 [09:59<2:00:40,  1.68s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   8%|▊         | 351/4671 [09:59<2:00:54,  1.68s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   8%|▊         | 351/4671 [10:00<2:00:54,  1.68s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   8%|▊         | 352/4671 [10:00<2:00:32,  1.67s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:   8%|▊         | 352/4671 [10:02<2:00:32,  1.67s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:   8%|▊         | 353/4671 [10:02<2:00:59,  1.68s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:   8%|▊         | 353/4671 [10:04<2:00:59,  1.68s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:   8%|▊         | 354/4671 [10:04<2:01:42,  1.69s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:   8%|▊         | 354/4671 [10:05<2:01:42,  1.69s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   8%|▊         | 355/4671 [10:05<2:02:23,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   8%|▊         | 355/4671 [10:07<2:02:23,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   8%|▊         | 356/4671 [10:07<2:03:17,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   8%|▊         | 356/4671 [10:09<2:03:17,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:   8%|▊         | 357/4671 [10:09<2:03:43,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:   8%|▊         | 357/4671 [10:11<2:03:43,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   8%|▊         | 358/4671 [10:11<2:02:33,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   8%|▊         | 358/4671 [10:12<2:02:33,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   8%|▊         | 359/4671 [10:12<2:02:43,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   8%|▊         | 359/4671 [10:14<2:02:43,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   8%|▊         | 360/4671 [10:14<2:02:02,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   8%|▊         | 360/4671 [10:16<2:02:02,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:   8%|▊         | 361/4671 [10:16<2:02:06,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:   8%|▊         | 361/4671 [10:17<2:02:06,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   8%|▊         | 362/4671 [10:17<2:01:16,  1.69s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:   8%|▊         | 362/4671 [10:19<2:01:16,  1.69s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   8%|▊         | 363/4671 [10:19<2:00:54,  1.68s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   8%|▊         | 363/4671 [10:21<2:00:54,  1.68s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:   8%|▊         | 364/4671 [10:21<2:01:35,  1.69s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:   8%|▊         | 364/4671 [10:22<2:01:35,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   8%|▊         | 365/4671 [10:22<2:01:48,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   8%|▊         | 365/4671 [10:24<2:01:48,  1.70s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:   8%|▊         | 366/4671 [10:24<2:01:05,  1.69s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:   8%|▊         | 366/4671 [10:26<2:01:05,  1.69s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:   8%|▊         | 367/4671 [10:26<2:01:49,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:   8%|▊         | 367/4671 [10:28<2:01:49,  1.70s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:   8%|▊         | 368/4671 [10:28<2:02:35,  1.71s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:   8%|▊         | 368/4671 [10:29<2:02:35,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:   8%|▊         | 369/4671 [10:29<2:02:44,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:   8%|▊         | 369/4671 [10:31<2:02:44,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   8%|▊         | 370/4671 [10:31<2:03:41,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   8%|▊         | 370/4671 [10:33<2:03:41,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:   8%|▊         | 371/4671 [10:33<2:03:28,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:   8%|▊         | 371/4671 [10:34<2:03:28,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   8%|▊         | 372/4671 [10:34<2:02:52,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   8%|▊         | 372/4671 [10:36<2:02:52,  1.71s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:   8%|▊         | 373/4671 [10:36<2:02:53,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:   8%|▊         | 373/4671 [10:38<2:02:53,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:   8%|▊         | 374/4671 [10:38<2:03:34,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:   8%|▊         | 374/4671 [10:40<2:03:34,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:   8%|▊         | 375/4671 [10:40<2:02:57,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:   8%|▊         | 375/4671 [10:41<2:02:57,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   8%|▊         | 376/4671 [10:41<2:01:20,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   8%|▊         | 376/4671 [10:43<2:01:20,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:   8%|▊         | 377/4671 [10:43<2:02:19,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:   8%|▊         | 377/4671 [10:45<2:02:19,  1.71s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:   8%|▊         | 378/4671 [10:45<2:01:11,  1.69s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:   8%|▊         | 378/4671 [10:46<2:01:11,  1.69s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   8%|▊         | 379/4671 [10:46<2:01:59,  1.71s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   8%|▊         | 379/4671 [10:48<2:01:59,  1.71s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:   8%|▊         | 380/4671 [10:48<2:02:27,  1.71s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:   8%|▊         | 380/4671 [10:50<2:02:27,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:   8%|▊         | 381/4671 [10:50<2:02:36,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:   8%|▊         | 381/4671 [10:52<2:02:36,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   8%|▊         | 382/4671 [10:52<2:02:35,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:   8%|▊         | 382/4671 [10:53<2:02:35,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   8%|▊         | 383/4671 [10:53<2:02:25,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:   8%|▊         | 383/4671 [10:55<2:02:25,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:   8%|▊         | 384/4671 [10:55<2:01:18,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:   8%|▊         | 384/4671 [10:57<2:01:18,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:   8%|▊         | 385/4671 [10:57<2:01:16,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:   8%|▊         | 385/4671 [10:58<2:01:16,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:   8%|▊         | 386/4671 [10:58<2:02:49,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:   8%|▊         | 386/4671 [11:00<2:02:49,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:   8%|▊         | 387/4671 [11:00<2:01:31,  1.70s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:   8%|▊         | 387/4671 [11:02<2:01:31,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   8%|▊         | 388/4671 [11:02<2:01:30,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:   8%|▊         | 388/4671 [11:03<2:01:30,  1.70s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:   8%|▊         | 389/4671 [11:03<2:00:45,  1.69s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:   8%|▊         | 389/4671 [11:05<2:00:45,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:   8%|▊         | 390/4671 [11:05<2:02:06,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:   8%|▊         | 390/4671 [11:07<2:02:06,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   8%|▊         | 391/4671 [11:07<2:01:30,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:   8%|▊         | 391/4671 [11:09<2:01:30,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:   8%|▊         | 392/4671 [11:09<2:01:28,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:   8%|▊         | 392/4671 [11:10<2:01:28,  1.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:   8%|▊         | 393/4671 [11:10<2:00:14,  1.69s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:   8%|▊         | 393/4671 [11:12<2:00:14,  1.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   8%|▊         | 394/4671 [11:12<2:00:48,  1.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   8%|▊         | 394/4671 [11:14<2:00:48,  1.69s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   8%|▊         | 395/4671 [11:14<2:01:08,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   8%|▊         | 395/4671 [11:15<2:01:08,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:   8%|▊         | 396/4671 [11:15<2:00:53,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:   8%|▊         | 396/4671 [11:17<2:00:53,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:   8%|▊         | 397/4671 [11:17<2:00:31,  1.69s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:   8%|▊         | 397/4671 [11:19<2:00:31,  1.69s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   9%|▊         | 398/4671 [11:19<2:00:22,  1.69s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   9%|▊         | 398/4671 [11:20<2:00:22,  1.69s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:   9%|▊         | 399/4671 [11:20<2:01:11,  1.70s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:   9%|▊         | 399/4671 [11:22<2:01:11,  1.70s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   9%|▊         | 400/4671 [11:22<2:00:17,  1.69s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   9%|▊         | 400/4671 [11:24<2:00:17,  1.69s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:   9%|▊         | 401/4671 [11:24<2:01:06,  1.70s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:   9%|▊         | 401/4671 [11:25<2:01:06,  1.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:   9%|▊         | 402/4671 [11:25<2:00:50,  1.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:   9%|▊         | 402/4671 [11:27<2:00:50,  1.70s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:   9%|▊         | 403/4671 [11:27<2:01:27,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:   9%|▊         | 403/4671 [11:29<2:01:27,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   9%|▊         | 404/4671 [11:29<2:00:24,  1.69s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   9%|▊         | 404/4671 [11:31<2:00:24,  1.69s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:   9%|▊         | 405/4671 [11:31<2:00:07,  1.69s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:   9%|▊         | 405/4671 [11:32<2:00:07,  1.69s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:   9%|▊         | 406/4671 [11:32<1:59:54,  1.69s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:   9%|▊         | 406/4671 [11:34<1:59:54,  1.69s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:   9%|▊         | 407/4671 [11:34<2:00:05,  1.69s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:   9%|▊         | 407/4671 [11:36<2:00:05,  1.69s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:   9%|▊         | 408/4671 [11:36<2:00:13,  1.69s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:   9%|▊         | 408/4671 [11:37<2:00:13,  1.69s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   9%|▉         | 409/4671 [11:37<2:01:11,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:   9%|▉         | 409/4671 [11:39<2:01:11,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:   9%|▉         | 410/4671 [11:39<2:01:08,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:   9%|▉         | 410/4671 [11:41<2:01:08,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   9%|▉         | 411/4671 [11:41<2:01:39,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   9%|▉         | 411/4671 [11:42<2:01:39,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   9%|▉         | 412/4671 [11:42<2:01:04,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:   9%|▉         | 412/4671 [11:44<2:01:04,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   9%|▉         | 413/4671 [11:44<2:01:42,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:   9%|▉         | 413/4671 [11:46<2:01:42,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   9%|▉         | 414/4671 [11:46<2:01:18,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:   9%|▉         | 414/4671 [11:48<2:01:18,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:   9%|▉         | 415/4671 [11:48<1:59:54,  1.69s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:   9%|▉         | 415/4671 [11:49<1:59:54,  1.69s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:   9%|▉         | 416/4671 [11:49<1:59:01,  1.68s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:   9%|▉         | 416/4671 [11:51<1:59:01,  1.68s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:   9%|▉         | 417/4671 [11:51<1:59:05,  1.68s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:   9%|▉         | 417/4671 [11:53<1:59:05,  1.68s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:   9%|▉         | 418/4671 [11:53<2:00:08,  1.69s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:   9%|▉         | 418/4671 [11:54<2:00:08,  1.69s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:   9%|▉         | 419/4671 [11:54<2:00:17,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:   9%|▉         | 419/4671 [11:56<2:00:17,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:   9%|▉         | 420/4671 [11:56<2:00:00,  1.69s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:   9%|▉         | 420/4671 [11:58<2:00:00,  1.69s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:   9%|▉         | 421/4671 [11:58<1:59:48,  1.69s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:   9%|▉         | 421/4671 [11:59<1:59:48,  1.69s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:   9%|▉         | 422/4671 [11:59<2:00:41,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:   9%|▉         | 422/4671 [12:01<2:00:41,  1.70s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:   9%|▉         | 423/4671 [12:01<2:01:18,  1.71s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:   9%|▉         | 423/4671 [12:03<2:01:18,  1.71s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:   9%|▉         | 424/4671 [12:03<2:01:06,  1.71s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:   9%|▉         | 424/4671 [12:05<2:01:06,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:   9%|▉         | 425/4671 [12:05<2:00:50,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:   9%|▉         | 425/4671 [12:06<2:00:50,  1.71s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:   9%|▉         | 426/4671 [12:06<1:59:20,  1.69s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:   9%|▉         | 426/4671 [12:08<1:59:20,  1.69s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:   9%|▉         | 427/4671 [12:08<1:59:53,  1.69s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:   9%|▉         | 427/4671 [12:10<1:59:53,  1.69s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:   9%|▉         | 428/4671 [12:10<2:00:12,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:   9%|▉         | 428/4671 [12:11<2:00:12,  1.70s/it, training_loss=0.188]\u001B[A\n",
      "Epoch 1:   9%|▉         | 429/4671 [12:11<1:59:14,  1.69s/it, training_loss=0.188]\u001B[A\n",
      "Epoch 1:   9%|▉         | 429/4671 [12:13<1:59:14,  1.69s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:   9%|▉         | 430/4671 [12:13<1:59:39,  1.69s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:   9%|▉         | 430/4671 [12:15<1:59:39,  1.69s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   9%|▉         | 431/4671 [12:15<2:00:39,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   9%|▉         | 431/4671 [12:16<2:00:39,  1.71s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:   9%|▉         | 432/4671 [12:16<2:00:41,  1.71s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:   9%|▉         | 432/4671 [12:18<2:00:41,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:   9%|▉         | 433/4671 [12:18<1:59:32,  1.69s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:   9%|▉         | 433/4671 [12:20<1:59:32,  1.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   9%|▉         | 434/4671 [12:20<1:59:33,  1.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:   9%|▉         | 434/4671 [12:22<1:59:33,  1.69s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:   9%|▉         | 435/4671 [12:22<2:00:17,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:   9%|▉         | 435/4671 [12:23<2:00:17,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   9%|▉         | 436/4671 [12:23<2:00:10,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:   9%|▉         | 436/4671 [12:25<2:00:10,  1.70s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:   9%|▉         | 437/4671 [12:25<2:00:03,  1.70s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:   9%|▉         | 437/4671 [12:27<2:00:03,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:   9%|▉         | 438/4671 [12:27<2:00:24,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:   9%|▉         | 438/4671 [12:28<2:00:24,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:   9%|▉         | 439/4671 [12:28<2:00:41,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:   9%|▉         | 439/4671 [12:30<2:00:41,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   9%|▉         | 440/4671 [12:30<2:01:42,  1.73s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:   9%|▉         | 440/4671 [12:32<2:01:42,  1.73s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:   9%|▉         | 441/4671 [12:32<2:01:16,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:   9%|▉         | 441/4671 [12:34<2:01:16,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:   9%|▉         | 442/4671 [12:34<2:00:35,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:   9%|▉         | 442/4671 [12:35<2:00:35,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   9%|▉         | 443/4671 [12:35<2:01:16,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:   9%|▉         | 443/4671 [12:37<2:01:16,  1.72s/it, training_loss=0.192]\u001B[A\n",
      "Epoch 1:  10%|▉         | 444/4671 [12:37<2:00:57,  1.72s/it, training_loss=0.192]\u001B[A\n",
      "Epoch 1:  10%|▉         | 444/4671 [12:39<2:00:57,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  10%|▉         | 445/4671 [12:39<2:01:25,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  10%|▉         | 445/4671 [12:40<2:01:25,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  10%|▉         | 446/4671 [12:40<2:00:49,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  10%|▉         | 446/4671 [12:42<2:00:49,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  10%|▉         | 447/4671 [12:42<2:00:36,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  10%|▉         | 447/4671 [12:44<2:00:36,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  10%|▉         | 448/4671 [12:44<1:59:45,  1.70s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  10%|▉         | 448/4671 [12:46<1:59:45,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  10%|▉         | 449/4671 [12:46<1:59:53,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  10%|▉         | 449/4671 [12:47<1:59:53,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  10%|▉         | 450/4671 [12:47<2:00:03,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  10%|▉         | 450/4671 [12:49<2:00:03,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  10%|▉         | 451/4671 [12:49<2:00:34,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  10%|▉         | 451/4671 [12:51<2:00:34,  1.71s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  10%|▉         | 452/4671 [12:51<2:00:03,  1.71s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  10%|▉         | 452/4671 [12:52<2:00:03,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  10%|▉         | 453/4671 [12:52<1:59:58,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  10%|▉         | 453/4671 [12:54<1:59:58,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  10%|▉         | 454/4671 [12:54<2:00:03,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  10%|▉         | 454/4671 [12:56<2:00:03,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  10%|▉         | 455/4671 [12:56<1:59:51,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  10%|▉         | 455/4671 [12:57<1:59:51,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  10%|▉         | 456/4671 [12:57<1:59:31,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  10%|▉         | 456/4671 [12:59<1:59:31,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  10%|▉         | 457/4671 [12:59<1:59:46,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  10%|▉         | 457/4671 [13:01<1:59:46,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  10%|▉         | 458/4671 [13:01<1:59:02,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  10%|▉         | 458/4671 [13:03<1:59:02,  1.70s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  10%|▉         | 459/4671 [13:03<1:59:52,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  10%|▉         | 459/4671 [13:04<1:59:52,  1.71s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  10%|▉         | 460/4671 [13:04<1:58:52,  1.69s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  10%|▉         | 460/4671 [13:06<1:58:52,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  10%|▉         | 461/4671 [13:06<1:58:10,  1.68s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  10%|▉         | 461/4671 [13:08<1:58:10,  1.68s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  10%|▉         | 462/4671 [13:08<1:58:31,  1.69s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  10%|▉         | 462/4671 [13:09<1:58:31,  1.69s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  10%|▉         | 463/4671 [13:09<1:59:09,  1.70s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  10%|▉         | 463/4671 [13:11<1:59:09,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  10%|▉         | 464/4671 [13:11<1:57:57,  1.68s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  10%|▉         | 464/4671 [13:13<1:57:57,  1.68s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  10%|▉         | 465/4671 [13:13<1:58:28,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  10%|▉         | 465/4671 [13:14<1:58:28,  1.69s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  10%|▉         | 466/4671 [13:14<1:58:41,  1.69s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  10%|▉         | 466/4671 [13:16<1:58:41,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  10%|▉         | 467/4671 [13:16<1:59:29,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  10%|▉         | 467/4671 [13:18<1:59:29,  1.71s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  10%|█         | 468/4671 [13:18<1:58:47,  1.70s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  10%|█         | 468/4671 [13:19<1:58:47,  1.70s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  10%|█         | 469/4671 [13:19<1:59:07,  1.70s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  10%|█         | 469/4671 [13:21<1:59:07,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  10%|█         | 470/4671 [13:21<1:58:51,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  10%|█         | 470/4671 [13:23<1:58:51,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  10%|█         | 471/4671 [13:23<1:59:20,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  10%|█         | 471/4671 [13:25<1:59:20,  1.70s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  10%|█         | 472/4671 [13:25<1:59:33,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  10%|█         | 472/4671 [13:26<1:59:33,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  10%|█         | 473/4671 [13:26<1:59:29,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  10%|█         | 473/4671 [13:28<1:59:29,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  10%|█         | 474/4671 [13:28<1:59:37,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  10%|█         | 474/4671 [13:30<1:59:37,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  10%|█         | 475/4671 [13:30<1:59:32,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  10%|█         | 475/4671 [13:31<1:59:32,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  10%|█         | 476/4671 [13:31<1:59:22,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  10%|█         | 476/4671 [13:33<1:59:22,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  10%|█         | 477/4671 [13:33<1:58:29,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  10%|█         | 477/4671 [13:35<1:58:29,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  10%|█         | 478/4671 [13:35<1:57:38,  1.68s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  10%|█         | 478/4671 [13:36<1:57:38,  1.68s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  10%|█         | 479/4671 [13:36<1:57:23,  1.68s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  10%|█         | 479/4671 [13:38<1:57:23,  1.68s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  10%|█         | 480/4671 [13:38<1:59:27,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  10%|█         | 480/4671 [13:40<1:59:27,  1.71s/it, training_loss=0.183]\u001B[A\n",
      "Epoch 1:  10%|█         | 481/4671 [13:40<1:58:00,  1.69s/it, training_loss=0.183]\u001B[A\n",
      "Epoch 1:  10%|█         | 481/4671 [13:42<1:58:00,  1.69s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  10%|█         | 482/4671 [13:42<1:58:23,  1.70s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  10%|█         | 482/4671 [13:43<1:58:23,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  10%|█         | 483/4671 [13:43<1:59:30,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  10%|█         | 483/4671 [13:45<1:59:30,  1.71s/it, training_loss=0.194]\u001B[A\n",
      "Epoch 1:  10%|█         | 484/4671 [13:45<1:59:28,  1.71s/it, training_loss=0.194]\u001B[A\n",
      "Epoch 1:  10%|█         | 484/4671 [13:47<1:59:28,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  10%|█         | 485/4671 [13:47<2:04:02,  1.78s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  10%|█         | 485/4671 [13:49<2:04:02,  1.78s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  10%|█         | 486/4671 [13:49<2:07:04,  1.82s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  10%|█         | 486/4671 [13:51<2:07:04,  1.82s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  10%|█         | 487/4671 [13:51<2:07:00,  1.82s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  10%|█         | 487/4671 [13:53<2:07:00,  1.82s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  10%|█         | 488/4671 [13:53<2:06:26,  1.81s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  10%|█         | 488/4671 [13:54<2:06:26,  1.81s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  10%|█         | 489/4671 [13:54<2:05:54,  1.81s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  10%|█         | 489/4671 [13:56<2:05:54,  1.81s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  10%|█         | 490/4671 [13:56<2:05:05,  1.80s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  10%|█         | 490/4671 [13:58<2:05:05,  1.80s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  11%|█         | 491/4671 [13:58<2:04:22,  1.79s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  11%|█         | 491/4671 [14:00<2:04:22,  1.79s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  11%|█         | 492/4671 [14:00<2:02:30,  1.76s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  11%|█         | 492/4671 [14:01<2:02:30,  1.76s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  11%|█         | 493/4671 [14:01<2:02:23,  1.76s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  11%|█         | 493/4671 [14:03<2:02:23,  1.76s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  11%|█         | 494/4671 [14:03<2:01:44,  1.75s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  11%|█         | 494/4671 [14:05<2:01:44,  1.75s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  11%|█         | 495/4671 [14:05<2:02:07,  1.75s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  11%|█         | 495/4671 [14:07<2:02:07,  1.75s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  11%|█         | 496/4671 [14:07<2:01:22,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  11%|█         | 496/4671 [14:08<2:01:22,  1.74s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  11%|█         | 497/4671 [14:08<2:01:36,  1.75s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  11%|█         | 497/4671 [14:10<2:01:36,  1.75s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  11%|█         | 498/4671 [14:10<2:00:40,  1.73s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  11%|█         | 498/4671 [14:12<2:00:40,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  11%|█         | 499/4671 [14:12<1:59:20,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  11%|█         | 499/4671 [14:13<1:59:20,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  11%|█         | 500/4671 [14:13<1:59:42,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  11%|█         | 500/4671 [14:15<1:59:42,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  11%|█         | 501/4671 [14:15<1:59:12,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  11%|█         | 501/4671 [14:17<1:59:12,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  11%|█         | 502/4671 [14:17<1:57:51,  1.70s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  11%|█         | 502/4671 [14:18<1:57:51,  1.70s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  11%|█         | 503/4671 [14:18<1:58:40,  1.71s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  11%|█         | 503/4671 [14:20<1:58:40,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  11%|█         | 504/4671 [14:20<1:58:59,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  11%|█         | 504/4671 [14:22<1:58:59,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  11%|█         | 505/4671 [14:22<1:58:42,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  11%|█         | 505/4671 [14:24<1:58:42,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  11%|█         | 506/4671 [14:24<1:58:57,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  11%|█         | 506/4671 [14:25<1:58:57,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  11%|█         | 507/4671 [14:25<1:58:35,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  11%|█         | 507/4671 [14:27<1:58:35,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  11%|█         | 508/4671 [14:27<1:57:53,  1.70s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  11%|█         | 508/4671 [14:29<1:57:53,  1.70s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  11%|█         | 509/4671 [14:29<1:57:58,  1.70s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  11%|█         | 509/4671 [14:30<1:57:58,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  11%|█         | 510/4671 [14:30<1:57:34,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  11%|█         | 510/4671 [14:32<1:57:34,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  11%|█         | 511/4671 [14:32<1:58:32,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  11%|█         | 511/4671 [14:34<1:58:32,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  11%|█         | 512/4671 [14:34<1:58:46,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  11%|█         | 512/4671 [14:36<1:58:46,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  11%|█         | 513/4671 [14:36<1:58:45,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  11%|█         | 513/4671 [14:37<1:58:45,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  11%|█         | 514/4671 [14:37<1:58:49,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  11%|█         | 514/4671 [14:39<1:58:49,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  11%|█         | 515/4671 [14:39<1:59:18,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  11%|█         | 515/4671 [14:41<1:59:18,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  11%|█         | 516/4671 [14:41<1:58:54,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  11%|█         | 516/4671 [14:42<1:58:54,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  11%|█         | 517/4671 [14:42<1:59:14,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  11%|█         | 517/4671 [14:44<1:59:14,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  11%|█         | 518/4671 [14:44<1:59:48,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  11%|█         | 518/4671 [14:46<1:59:48,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  11%|█         | 519/4671 [14:46<1:59:25,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  11%|█         | 519/4671 [14:48<1:59:25,  1.73s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  11%|█         | 520/4671 [14:48<1:58:20,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  11%|█         | 520/4671 [14:49<1:58:20,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  11%|█         | 521/4671 [14:49<1:58:38,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  11%|█         | 521/4671 [14:51<1:58:38,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  11%|█         | 522/4671 [14:51<1:58:59,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  11%|█         | 522/4671 [14:53<1:58:59,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  11%|█         | 523/4671 [14:53<1:58:01,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  11%|█         | 523/4671 [14:54<1:58:01,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  11%|█         | 524/4671 [14:54<1:58:55,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  11%|█         | 524/4671 [14:56<1:58:55,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  11%|█         | 525/4671 [14:56<2:00:49,  1.75s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  11%|█         | 525/4671 [14:58<2:00:49,  1.75s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 526/4671 [14:58<2:03:52,  1.79s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 526/4671 [15:00<2:03:52,  1.79s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 527/4671 [15:00<2:04:12,  1.80s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 527/4671 [15:02<2:04:12,  1.80s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 528/4671 [15:02<2:03:04,  1.78s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 528/4671 [15:04<2:03:04,  1.78s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 529/4671 [15:04<2:03:03,  1.78s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 529/4671 [15:05<2:03:03,  1.78s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 530/4671 [15:05<2:02:21,  1.77s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 530/4671 [15:07<2:02:21,  1.77s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 531/4671 [15:07<2:02:02,  1.77s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 531/4671 [15:09<2:02:02,  1.77s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 532/4671 [15:09<2:01:29,  1.76s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 532/4671 [15:11<2:01:29,  1.76s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 533/4671 [15:11<2:00:44,  1.75s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 533/4671 [15:12<2:00:44,  1.75s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 534/4671 [15:12<1:59:55,  1.74s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 534/4671 [15:14<1:59:55,  1.74s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 535/4671 [15:14<1:59:14,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 535/4671 [15:16<1:59:14,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 536/4671 [15:16<1:59:13,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 536/4671 [15:17<1:59:13,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 537/4671 [15:17<1:58:41,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 537/4671 [15:19<1:58:41,  1.72s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 538/4671 [15:19<1:58:16,  1.72s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 538/4671 [15:21<1:58:16,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 539/4671 [15:21<1:57:47,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 539/4671 [15:23<1:57:47,  1.71s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 540/4671 [15:23<1:59:24,  1.73s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 540/4671 [15:24<1:59:24,  1.73s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 541/4671 [15:24<2:02:49,  1.78s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 541/4671 [15:26<2:02:49,  1.78s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 542/4671 [15:26<2:05:03,  1.82s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 542/4671 [15:28<2:05:03,  1.82s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 543/4671 [15:28<2:07:33,  1.85s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 543/4671 [15:30<2:07:33,  1.85s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 544/4671 [15:30<2:07:29,  1.85s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 544/4671 [15:32<2:07:29,  1.85s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 545/4671 [15:32<2:08:42,  1.87s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 545/4671 [15:34<2:08:42,  1.87s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 546/4671 [15:34<2:09:42,  1.89s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 546/4671 [15:36<2:09:42,  1.89s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 547/4671 [15:36<2:07:48,  1.86s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 547/4671 [15:38<2:07:48,  1.86s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 548/4671 [15:38<2:05:44,  1.83s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 548/4671 [15:39<2:05:44,  1.83s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 549/4671 [15:39<2:02:53,  1.79s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 549/4671 [15:41<2:02:53,  1.79s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 550/4671 [15:41<2:02:35,  1.78s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 550/4671 [15:43<2:02:35,  1.78s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 551/4671 [15:43<2:01:36,  1.77s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 551/4671 [15:44<2:01:36,  1.77s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 552/4671 [15:44<2:00:48,  1.76s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 552/4671 [15:46<2:00:48,  1.76s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 553/4671 [15:46<2:00:08,  1.75s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 553/4671 [15:48<2:00:08,  1.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 554/4671 [15:48<2:00:05,  1.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 554/4671 [15:50<2:00:05,  1.75s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 555/4671 [15:50<1:58:54,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 555/4671 [15:51<1:58:54,  1.73s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 556/4671 [15:51<1:59:32,  1.74s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 556/4671 [15:53<1:59:32,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 557/4671 [15:53<1:58:08,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 557/4671 [15:55<1:58:08,  1.72s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 558/4671 [15:55<1:56:46,  1.70s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 558/4671 [15:57<1:56:46,  1.70s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 559/4671 [15:57<1:57:57,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 559/4671 [15:58<1:57:57,  1.72s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 560/4671 [15:58<1:58:36,  1.73s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 560/4671 [16:00<1:58:36,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 561/4671 [16:00<1:58:42,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 561/4671 [16:02<1:58:42,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 562/4671 [16:02<1:57:55,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 562/4671 [16:03<1:57:55,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 563/4671 [16:03<1:58:13,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 563/4671 [16:05<1:58:13,  1.73s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 564/4671 [16:05<1:58:25,  1.73s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 564/4671 [16:07<1:58:25,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 565/4671 [16:07<1:58:34,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 565/4671 [16:09<1:58:34,  1.73s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 566/4671 [16:09<1:57:30,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 566/4671 [16:10<1:57:30,  1.72s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 567/4671 [16:10<1:57:08,  1.71s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 567/4671 [16:12<1:57:08,  1.71s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 568/4671 [16:12<1:57:42,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 568/4671 [16:14<1:57:42,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 569/4671 [16:14<1:57:40,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 569/4671 [16:15<1:57:40,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 570/4671 [16:15<1:57:46,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 570/4671 [16:17<1:57:46,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 571/4671 [16:17<1:57:08,  1.71s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 571/4671 [16:19<1:57:08,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 572/4671 [16:19<1:57:14,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 572/4671 [16:21<1:57:14,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 573/4671 [16:21<1:57:13,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 573/4671 [16:22<1:57:13,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 574/4671 [16:22<1:56:58,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 574/4671 [16:24<1:56:58,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 575/4671 [16:24<1:55:48,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 575/4671 [16:26<1:55:48,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 576/4671 [16:26<1:56:28,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 576/4671 [16:27<1:56:28,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 577/4671 [16:27<1:56:36,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 577/4671 [16:29<1:56:36,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 578/4671 [16:29<1:55:34,  1.69s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 578/4671 [16:31<1:55:34,  1.69s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 579/4671 [16:31<1:55:55,  1.70s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 579/4671 [16:32<1:55:55,  1.70s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 580/4671 [16:32<1:55:54,  1.70s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 580/4671 [16:34<1:55:54,  1.70s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 581/4671 [16:34<1:55:52,  1.70s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 581/4671 [16:36<1:55:52,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 582/4671 [16:36<1:56:35,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 582/4671 [16:38<1:56:35,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 583/4671 [16:38<1:56:23,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 583/4671 [16:39<1:56:23,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 584/4671 [16:39<1:56:59,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 584/4671 [16:41<1:56:59,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 585/4671 [16:41<1:56:48,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 585/4671 [16:43<1:56:48,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 586/4671 [16:43<1:56:54,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 586/4671 [16:44<1:56:54,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 587/4671 [16:44<1:55:54,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 587/4671 [16:46<1:55:54,  1.70s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 588/4671 [16:46<1:56:05,  1.71s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 588/4671 [16:48<1:56:05,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 589/4671 [16:48<1:55:36,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 589/4671 [16:50<1:55:36,  1.70s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 590/4671 [16:50<1:55:33,  1.70s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 590/4671 [16:51<1:55:33,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 591/4671 [16:51<1:55:15,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 591/4671 [16:53<1:55:15,  1.70s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 592/4671 [16:53<1:54:31,  1.68s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 592/4671 [16:55<1:54:31,  1.68s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 593/4671 [16:55<1:54:21,  1.68s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 593/4671 [16:56<1:54:21,  1.68s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 594/4671 [16:56<1:54:19,  1.68s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 594/4671 [16:58<1:54:19,  1.68s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 595/4671 [16:58<1:55:15,  1.70s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 595/4671 [17:00<1:55:15,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 596/4671 [17:00<1:55:46,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 596/4671 [17:01<1:55:46,  1.70s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 597/4671 [17:01<1:55:38,  1.70s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 597/4671 [17:03<1:55:38,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 598/4671 [17:03<1:55:29,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 598/4671 [17:05<1:55:29,  1.70s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 599/4671 [17:05<1:55:28,  1.70s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 599/4671 [17:07<1:55:28,  1.70s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 600/4671 [17:07<1:55:10,  1.70s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 600/4671 [17:08<1:55:10,  1.70s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 601/4671 [17:08<1:55:42,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 601/4671 [17:10<1:55:42,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 602/4671 [17:10<1:55:30,  1.70s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 602/4671 [17:12<1:55:30,  1.70s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 603/4671 [17:12<1:55:51,  1.71s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 603/4671 [17:13<1:55:51,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 604/4671 [17:13<1:55:41,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 604/4671 [17:15<1:55:41,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 605/4671 [17:15<1:55:15,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 605/4671 [17:17<1:55:15,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 606/4671 [17:17<1:55:09,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 606/4671 [17:19<1:55:09,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 607/4671 [17:19<1:56:20,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 607/4671 [17:20<1:56:20,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 608/4671 [17:20<1:55:46,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 608/4671 [17:22<1:55:46,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 609/4671 [17:22<1:55:38,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 609/4671 [17:24<1:55:38,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 610/4671 [17:24<1:55:43,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 610/4671 [17:25<1:55:43,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 611/4671 [17:25<1:55:33,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 611/4671 [17:27<1:55:33,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 612/4671 [17:27<1:55:33,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 612/4671 [17:29<1:55:33,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 613/4671 [17:29<1:54:27,  1.69s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 613/4671 [17:30<1:54:27,  1.69s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 614/4671 [17:30<1:54:44,  1.70s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 614/4671 [17:32<1:54:44,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 615/4671 [17:32<1:55:12,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 615/4671 [17:34<1:55:12,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 616/4671 [17:34<1:55:07,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 616/4671 [17:36<1:55:07,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 617/4671 [17:36<1:56:00,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 617/4671 [17:37<1:56:00,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 618/4671 [17:37<1:55:37,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 618/4671 [17:39<1:55:37,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 619/4671 [17:39<1:55:46,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 619/4671 [17:41<1:55:46,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 620/4671 [17:41<1:55:52,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 620/4671 [17:42<1:55:52,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 621/4671 [17:42<1:55:49,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 621/4671 [17:44<1:55:49,  1.72s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 622/4671 [17:44<1:55:30,  1.71s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 622/4671 [17:46<1:55:30,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 623/4671 [17:46<1:56:02,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 623/4671 [17:48<1:56:02,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 624/4671 [17:48<1:54:47,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 624/4671 [17:49<1:54:47,  1.70s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 625/4671 [17:49<1:54:40,  1.70s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 625/4671 [17:51<1:54:40,  1.70s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 626/4671 [17:51<1:54:26,  1.70s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 626/4671 [17:53<1:54:26,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 627/4671 [17:53<1:54:15,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 627/4671 [17:54<1:54:15,  1.70s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 628/4671 [17:54<1:53:58,  1.69s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 628/4671 [17:56<1:53:58,  1.69s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 629/4671 [17:56<1:53:51,  1.69s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 629/4671 [17:58<1:53:51,  1.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 630/4671 [17:58<1:55:37,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 630/4671 [17:59<1:55:37,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 631/4671 [17:59<1:55:02,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 631/4671 [18:01<1:55:02,  1.71s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 632/4671 [18:01<1:54:19,  1.70s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 632/4671 [18:03<1:54:19,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 633/4671 [18:03<1:56:05,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 633/4671 [18:05<1:56:05,  1.72s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 634/4671 [18:05<1:56:39,  1.73s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 634/4671 [18:06<1:56:39,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 635/4671 [18:06<1:55:08,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 635/4671 [18:08<1:55:08,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 636/4671 [18:08<1:55:35,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 636/4671 [18:10<1:55:35,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 637/4671 [18:10<1:56:04,  1.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 637/4671 [18:12<1:56:04,  1.73s/it, training_loss=0.183]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 638/4671 [18:12<1:56:46,  1.74s/it, training_loss=0.183]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 638/4671 [18:13<1:56:46,  1.74s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 639/4671 [18:13<1:55:27,  1.72s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 639/4671 [18:15<1:55:27,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 640/4671 [18:15<1:54:56,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 640/4671 [18:17<1:54:56,  1.71s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 641/4671 [18:17<1:55:24,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 641/4671 [18:18<1:55:24,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 642/4671 [18:18<1:54:56,  1.71s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 642/4671 [18:20<1:54:56,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 643/4671 [18:20<1:53:45,  1.69s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 643/4671 [18:22<1:53:45,  1.69s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 644/4671 [18:22<1:52:45,  1.68s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 644/4671 [18:23<1:52:45,  1.68s/it, training_loss=0.078]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 645/4671 [18:23<1:52:44,  1.68s/it, training_loss=0.078]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 645/4671 [18:25<1:52:44,  1.68s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 646/4671 [18:25<1:52:51,  1.68s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 646/4671 [18:27<1:52:51,  1.68s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 647/4671 [18:27<1:52:45,  1.68s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 647/4671 [18:28<1:52:45,  1.68s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 648/4671 [18:28<1:53:03,  1.69s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 648/4671 [18:30<1:53:03,  1.69s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 649/4671 [18:30<1:52:21,  1.68s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 649/4671 [18:32<1:52:21,  1.68s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 650/4671 [18:32<1:53:40,  1.70s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 650/4671 [18:33<1:53:40,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 651/4671 [18:33<1:53:38,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 651/4671 [18:35<1:53:38,  1.70s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 652/4671 [18:35<1:52:01,  1.67s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 652/4671 [18:37<1:52:01,  1.67s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 653/4671 [18:37<1:53:46,  1.70s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 653/4671 [18:39<1:53:46,  1.70s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 654/4671 [18:39<1:52:56,  1.69s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 654/4671 [18:40<1:52:56,  1.69s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 655/4671 [18:40<1:53:51,  1.70s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 655/4671 [18:42<1:53:51,  1.70s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 656/4671 [18:42<1:53:07,  1.69s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 656/4671 [18:44<1:53:07,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 657/4671 [18:44<1:53:37,  1.70s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 657/4671 [18:45<1:53:37,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 658/4671 [18:45<1:54:02,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 658/4671 [18:47<1:54:02,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 659/4671 [18:47<1:53:22,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 659/4671 [18:49<1:53:22,  1.70s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 660/4671 [18:49<1:53:18,  1.69s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 660/4671 [18:50<1:53:18,  1.69s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 661/4671 [18:50<1:53:19,  1.70s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 661/4671 [18:52<1:53:19,  1.70s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 662/4671 [18:52<1:53:13,  1.69s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 662/4671 [18:54<1:53:13,  1.69s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 663/4671 [18:54<1:52:48,  1.69s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 663/4671 [18:55<1:52:48,  1.69s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 664/4671 [18:55<1:51:47,  1.67s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 664/4671 [18:57<1:51:47,  1.67s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 665/4671 [18:57<1:53:18,  1.70s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 665/4671 [18:59<1:53:18,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 666/4671 [18:59<1:56:55,  1.75s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 666/4671 [19:01<1:56:55,  1.75s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 667/4671 [19:01<1:58:37,  1.78s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 667/4671 [19:03<1:58:37,  1.78s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 668/4671 [19:03<2:00:20,  1.80s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 668/4671 [19:04<2:00:20,  1.80s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 669/4671 [19:04<1:58:47,  1.78s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 669/4671 [19:06<1:58:47,  1.78s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 670/4671 [19:06<1:57:48,  1.77s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 670/4671 [19:08<1:57:48,  1.77s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 671/4671 [19:08<1:57:10,  1.76s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 671/4671 [19:10<1:57:10,  1.76s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 672/4671 [19:10<1:56:18,  1.75s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 672/4671 [19:11<1:56:18,  1.75s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 673/4671 [19:11<1:55:59,  1.74s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 673/4671 [19:13<1:55:59,  1.74s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 674/4671 [19:13<1:53:57,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 674/4671 [19:15<1:53:57,  1.71s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 675/4671 [19:15<1:53:32,  1.70s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 675/4671 [19:16<1:53:32,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 676/4671 [19:16<1:53:27,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 676/4671 [19:18<1:53:27,  1.70s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 677/4671 [19:18<1:52:40,  1.69s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 677/4671 [19:20<1:52:40,  1.69s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 678/4671 [19:20<1:52:32,  1.69s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 678/4671 [19:21<1:52:32,  1.69s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 679/4671 [19:21<1:51:57,  1.68s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 679/4671 [19:23<1:51:57,  1.68s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 680/4671 [19:23<1:52:48,  1.70s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 680/4671 [19:25<1:52:48,  1.70s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 681/4671 [19:25<1:53:19,  1.70s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 681/4671 [19:27<1:53:19,  1.70s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 682/4671 [19:27<1:53:50,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 682/4671 [19:28<1:53:50,  1.71s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 683/4671 [19:28<1:53:30,  1.71s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 683/4671 [19:30<1:53:30,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 684/4671 [19:30<1:53:17,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 684/4671 [19:32<1:53:17,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 685/4671 [19:32<1:53:57,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 685/4671 [19:33<1:53:57,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 686/4671 [19:33<1:52:48,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 686/4671 [19:35<1:52:48,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 687/4671 [19:35<1:53:21,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 687/4671 [19:37<1:53:21,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 688/4671 [19:37<1:54:58,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 688/4671 [19:39<1:54:58,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 689/4671 [19:39<1:53:29,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 689/4671 [19:40<1:53:29,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 690/4671 [19:40<1:54:03,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 690/4671 [19:42<1:54:03,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 691/4671 [19:42<1:53:28,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 691/4671 [19:44<1:53:28,  1.71s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 692/4671 [19:44<1:53:43,  1.71s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 692/4671 [19:45<1:53:43,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 693/4671 [19:45<1:53:15,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 693/4671 [19:47<1:53:15,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 694/4671 [19:47<1:52:41,  1.70s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 694/4671 [19:49<1:52:41,  1.70s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 695/4671 [19:49<1:52:41,  1.70s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 695/4671 [19:51<1:52:41,  1.70s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 696/4671 [19:51<1:52:00,  1.69s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 696/4671 [19:52<1:52:00,  1.69s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 697/4671 [19:52<1:51:21,  1.68s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 697/4671 [19:54<1:51:21,  1.68s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 698/4671 [19:54<1:51:38,  1.69s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 698/4671 [19:56<1:51:38,  1.69s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 699/4671 [19:56<1:51:59,  1.69s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 699/4671 [19:57<1:51:59,  1.69s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 700/4671 [19:57<1:52:06,  1.69s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 700/4671 [19:59<1:52:06,  1.69s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 701/4671 [19:59<1:51:40,  1.69s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 701/4671 [20:01<1:51:40,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 702/4671 [20:01<1:52:04,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 702/4671 [20:02<1:52:04,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 703/4671 [20:02<1:51:53,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 703/4671 [20:04<1:51:53,  1.69s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 704/4671 [20:04<1:51:10,  1.68s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 704/4671 [20:06<1:51:10,  1.68s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 705/4671 [20:06<1:52:11,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 705/4671 [20:07<1:52:11,  1.70s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 706/4671 [20:07<1:52:32,  1.70s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 706/4671 [20:09<1:52:32,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 707/4671 [20:09<1:52:59,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 707/4671 [20:11<1:52:59,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 708/4671 [20:11<1:52:58,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 708/4671 [20:13<1:52:58,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 709/4671 [20:13<1:53:20,  1.72s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 709/4671 [20:14<1:53:20,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 710/4671 [20:14<1:53:14,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 710/4671 [20:16<1:53:14,  1.72s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 711/4671 [20:16<1:52:33,  1.71s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 711/4671 [20:18<1:52:33,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 712/4671 [20:18<1:51:51,  1.70s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 712/4671 [20:19<1:51:51,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 713/4671 [20:19<1:52:41,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 713/4671 [20:21<1:52:41,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 714/4671 [20:21<1:53:27,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 714/4671 [20:23<1:53:27,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 715/4671 [20:23<1:52:52,  1.71s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 715/4671 [20:25<1:52:52,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 716/4671 [20:25<1:52:20,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 716/4671 [20:26<1:52:20,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 717/4671 [20:26<1:52:21,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 717/4671 [20:28<1:52:21,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 718/4671 [20:28<1:53:03,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 718/4671 [20:30<1:53:03,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 719/4671 [20:30<1:53:33,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 719/4671 [20:31<1:53:33,  1.72s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 720/4671 [20:31<1:53:29,  1.72s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 720/4671 [20:33<1:53:29,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 721/4671 [20:33<1:53:01,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 721/4671 [20:35<1:53:01,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 722/4671 [20:35<1:52:20,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 722/4671 [20:37<1:52:20,  1.71s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 723/4671 [20:37<1:51:42,  1.70s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 723/4671 [20:38<1:51:42,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 724/4671 [20:38<1:50:54,  1.69s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 724/4671 [20:40<1:50:54,  1.69s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 725/4671 [20:40<1:51:22,  1.69s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 725/4671 [20:42<1:51:22,  1.69s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 726/4671 [20:42<1:51:30,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 726/4671 [20:43<1:51:30,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 727/4671 [20:43<1:51:47,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 727/4671 [20:45<1:51:47,  1.70s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 728/4671 [20:45<1:50:39,  1.68s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 728/4671 [20:47<1:50:39,  1.68s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 729/4671 [20:47<1:51:04,  1.69s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 729/4671 [20:48<1:51:04,  1.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 730/4671 [20:48<1:51:33,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 730/4671 [20:50<1:51:33,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 731/4671 [20:50<1:52:38,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 731/4671 [20:52<1:52:38,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 732/4671 [20:52<1:52:40,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 732/4671 [20:54<1:52:40,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 733/4671 [20:54<1:52:07,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 733/4671 [20:55<1:52:07,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 734/4671 [20:55<1:51:03,  1.69s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 734/4671 [20:57<1:51:03,  1.69s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 735/4671 [20:57<1:51:12,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 735/4671 [20:59<1:51:12,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 736/4671 [20:59<1:50:14,  1.68s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 736/4671 [21:00<1:50:14,  1.68s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 737/4671 [21:00<1:49:36,  1.67s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 737/4671 [21:02<1:49:36,  1.67s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 738/4671 [21:02<1:50:27,  1.69s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 738/4671 [21:04<1:50:27,  1.69s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 739/4671 [21:04<1:51:31,  1.70s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 739/4671 [21:05<1:51:31,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 740/4671 [21:05<1:50:51,  1.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 740/4671 [21:07<1:50:51,  1.69s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 741/4671 [21:07<1:50:45,  1.69s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 741/4671 [21:09<1:50:45,  1.69s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 742/4671 [21:09<1:50:11,  1.68s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 742/4671 [21:10<1:50:11,  1.68s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 743/4671 [21:10<1:50:16,  1.68s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 743/4671 [21:12<1:50:16,  1.68s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 744/4671 [21:12<1:50:36,  1.69s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 744/4671 [21:14<1:50:36,  1.69s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 745/4671 [21:14<1:51:11,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 745/4671 [21:16<1:51:11,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 746/4671 [21:16<1:51:51,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 746/4671 [21:17<1:51:51,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 747/4671 [21:17<1:51:14,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 747/4671 [21:19<1:51:14,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 748/4671 [21:19<1:51:12,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 748/4671 [21:21<1:51:12,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 749/4671 [21:21<2:06:13,  1.93s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 749/4671 [21:23<2:06:13,  1.93s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 750/4671 [21:23<2:04:47,  1.91s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 750/4671 [21:25<2:04:47,  1.91s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 751/4671 [21:25<2:02:59,  1.88s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 751/4671 [21:27<2:02:59,  1.88s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 752/4671 [21:27<1:58:52,  1.82s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 752/4671 [21:28<1:58:52,  1.82s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 753/4671 [21:28<1:55:57,  1.78s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 753/4671 [21:30<1:55:57,  1.78s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 754/4671 [21:30<1:54:58,  1.76s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 754/4671 [21:32<1:54:58,  1.76s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 755/4671 [21:32<1:54:38,  1.76s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 755/4671 [21:34<1:54:38,  1.76s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 756/4671 [21:34<1:54:04,  1.75s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 756/4671 [21:35<1:54:04,  1.75s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 757/4671 [21:35<1:52:52,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 757/4671 [21:37<1:52:52,  1.73s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 758/4671 [21:37<1:52:39,  1.73s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 758/4671 [21:39<1:52:39,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 759/4671 [21:39<1:52:18,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 759/4671 [21:40<1:52:18,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 760/4671 [21:40<1:52:01,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 760/4671 [21:42<1:52:01,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 761/4671 [21:42<1:51:58,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 761/4671 [21:44<1:51:58,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 762/4671 [21:44<1:51:23,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 762/4671 [21:46<1:51:23,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 763/4671 [21:46<1:51:02,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 763/4671 [21:47<1:51:02,  1.70s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 764/4671 [21:47<1:50:12,  1.69s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 764/4671 [21:49<1:50:12,  1.69s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 765/4671 [21:49<1:50:27,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 765/4671 [21:51<1:50:27,  1.70s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 766/4671 [21:51<1:50:57,  1.70s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 766/4671 [21:52<1:50:57,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 767/4671 [21:52<1:51:56,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 767/4671 [21:54<1:51:56,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 768/4671 [21:54<1:51:34,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 768/4671 [21:56<1:51:34,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 769/4671 [21:56<1:51:00,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 769/4671 [21:57<1:51:00,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 770/4671 [21:57<1:51:01,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 770/4671 [21:59<1:51:01,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 771/4671 [21:59<1:51:12,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 771/4671 [22:01<1:51:12,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 772/4671 [22:01<1:51:08,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 772/4671 [22:03<1:51:08,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 773/4671 [22:03<1:50:43,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 773/4671 [22:04<1:50:43,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 774/4671 [22:04<1:50:11,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 774/4671 [22:06<1:50:11,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 775/4671 [22:06<1:51:10,  1.71s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 775/4671 [22:08<1:51:10,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 776/4671 [22:08<1:51:03,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 776/4671 [22:09<1:51:03,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 777/4671 [22:09<1:51:42,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 777/4671 [22:11<1:51:42,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 778/4671 [22:11<1:50:36,  1.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 778/4671 [22:13<1:50:36,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 779/4671 [22:13<1:51:19,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 779/4671 [22:15<1:51:19,  1.72s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 780/4671 [22:15<1:50:38,  1.71s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 780/4671 [22:16<1:50:38,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 781/4671 [22:16<1:50:28,  1.70s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 781/4671 [22:18<1:50:28,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 782/4671 [22:18<1:49:24,  1.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 782/4671 [22:20<1:49:24,  1.69s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 783/4671 [22:20<1:49:55,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 783/4671 [22:21<1:49:55,  1.70s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 784/4671 [22:21<1:49:53,  1.70s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 784/4671 [22:23<1:49:53,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 785/4671 [22:23<1:48:10,  1.67s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 785/4671 [22:25<1:48:10,  1.67s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 786/4671 [22:25<1:49:20,  1.69s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 786/4671 [22:26<1:49:20,  1.69s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 787/4671 [22:26<1:48:37,  1.68s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 787/4671 [22:28<1:48:37,  1.68s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 788/4671 [22:28<1:49:04,  1.69s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 788/4671 [22:30<1:49:04,  1.69s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 789/4671 [22:30<1:49:04,  1.69s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 789/4671 [22:31<1:49:04,  1.69s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 790/4671 [22:31<1:49:51,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 790/4671 [22:33<1:49:51,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 791/4671 [22:33<1:50:21,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 791/4671 [22:35<1:50:21,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 792/4671 [22:35<1:51:06,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 792/4671 [22:37<1:51:06,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 793/4671 [22:37<1:51:16,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 793/4671 [22:38<1:51:16,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 794/4671 [22:38<1:51:02,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 794/4671 [22:40<1:51:02,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 795/4671 [22:40<1:51:21,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 795/4671 [22:42<1:51:21,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 796/4671 [22:42<1:50:30,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 796/4671 [22:43<1:50:30,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 797/4671 [22:43<1:49:57,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 797/4671 [22:45<1:49:57,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 798/4671 [22:45<1:49:32,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 798/4671 [22:47<1:49:32,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 799/4671 [22:47<1:49:24,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 799/4671 [22:49<1:49:24,  1.70s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 800/4671 [22:49<1:50:14,  1.71s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 800/4671 [22:50<1:50:14,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 801/4671 [22:50<1:50:07,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 801/4671 [22:52<1:50:07,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 802/4671 [22:52<1:50:37,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 802/4671 [22:54<1:50:37,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 803/4671 [22:54<1:49:38,  1.70s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 803/4671 [22:55<1:49:38,  1.70s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 804/4671 [22:55<1:50:27,  1.71s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 804/4671 [22:57<1:50:27,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 805/4671 [22:57<1:51:07,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 805/4671 [22:59<1:51:07,  1.72s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 806/4671 [22:59<1:50:05,  1.71s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 806/4671 [23:01<1:50:05,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 807/4671 [23:01<1:49:06,  1.69s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 807/4671 [23:02<1:49:06,  1.69s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 808/4671 [23:02<1:48:41,  1.69s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 808/4671 [23:04<1:48:41,  1.69s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 809/4671 [23:04<1:48:28,  1.69s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 809/4671 [23:06<1:48:28,  1.69s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 810/4671 [23:06<1:48:33,  1.69s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 810/4671 [23:07<1:48:33,  1.69s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 811/4671 [23:07<1:48:36,  1.69s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 811/4671 [23:09<1:48:36,  1.69s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 812/4671 [23:09<1:48:08,  1.68s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 812/4671 [23:11<1:48:08,  1.68s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 813/4671 [23:11<1:47:39,  1.67s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 813/4671 [23:12<1:47:39,  1.67s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 814/4671 [23:12<1:47:41,  1.68s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 814/4671 [23:14<1:47:41,  1.68s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 815/4671 [23:14<1:48:20,  1.69s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 815/4671 [23:16<1:48:20,  1.69s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 816/4671 [23:16<1:48:35,  1.69s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 816/4671 [23:17<1:48:35,  1.69s/it, training_loss=0.193]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 817/4671 [23:17<1:47:47,  1.68s/it, training_loss=0.193]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 817/4671 [23:19<1:47:47,  1.68s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 818/4671 [23:19<1:47:05,  1.67s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 818/4671 [23:21<1:47:05,  1.67s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 819/4671 [23:21<1:47:44,  1.68s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 819/4671 [23:22<1:47:44,  1.68s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 820/4671 [23:22<1:48:17,  1.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 820/4671 [23:24<1:48:17,  1.69s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 821/4671 [23:24<1:48:04,  1.68s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 821/4671 [23:26<1:48:04,  1.68s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 822/4671 [23:26<1:49:01,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 822/4671 [23:27<1:49:01,  1.70s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 823/4671 [23:27<1:48:57,  1.70s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 823/4671 [23:29<1:48:57,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 824/4671 [23:29<1:48:26,  1.69s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 824/4671 [23:31<1:48:26,  1.69s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 825/4671 [23:31<1:48:27,  1.69s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 825/4671 [23:33<1:48:27,  1.69s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 826/4671 [23:33<1:48:03,  1.69s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 826/4671 [23:34<1:48:03,  1.69s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 827/4671 [23:34<1:47:49,  1.68s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 827/4671 [23:36<1:47:49,  1.68s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 828/4671 [23:36<1:48:14,  1.69s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 828/4671 [23:38<1:48:14,  1.69s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 829/4671 [23:38<1:48:50,  1.70s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 829/4671 [23:39<1:48:50,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 830/4671 [23:39<1:48:52,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 830/4671 [23:41<1:48:52,  1.70s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 831/4671 [23:41<1:49:47,  1.72s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 831/4671 [23:43<1:49:47,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 832/4671 [23:43<1:49:38,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 832/4671 [23:44<1:49:38,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 833/4671 [23:44<1:48:22,  1.69s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 833/4671 [23:46<1:48:22,  1.69s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 834/4671 [23:46<1:47:51,  1.69s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 834/4671 [23:48<1:47:51,  1.69s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 835/4671 [23:48<1:48:32,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 835/4671 [23:50<1:48:32,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 836/4671 [23:50<1:48:46,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 836/4671 [23:51<1:48:46,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 837/4671 [23:51<1:48:33,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 837/4671 [23:53<1:48:33,  1.70s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 838/4671 [23:53<1:48:58,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 838/4671 [23:55<1:48:58,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 839/4671 [23:55<1:49:15,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 839/4671 [23:56<1:49:15,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 840/4671 [23:56<1:49:38,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 840/4671 [23:58<1:49:38,  1.72s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 841/4671 [23:58<1:50:15,  1.73s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 841/4671 [24:00<1:50:15,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 842/4671 [24:00<1:49:26,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 842/4671 [24:02<1:49:26,  1.72s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 843/4671 [24:02<1:49:54,  1.72s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 843/4671 [24:03<1:49:54,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 844/4671 [24:03<1:49:27,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 844/4671 [24:05<1:49:27,  1.72s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 845/4671 [24:05<1:49:26,  1.72s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 845/4671 [24:07<1:49:26,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 846/4671 [24:07<1:49:28,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 846/4671 [24:08<1:49:28,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 847/4671 [24:08<1:49:55,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 847/4671 [24:10<1:49:55,  1.72s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 848/4671 [24:10<1:48:52,  1.71s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 848/4671 [24:12<1:48:52,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 849/4671 [24:12<1:49:06,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 849/4671 [24:14<1:49:06,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 850/4671 [24:14<1:48:36,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 850/4671 [24:15<1:48:36,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 851/4671 [24:15<1:48:43,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 851/4671 [24:17<1:48:43,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 852/4671 [24:17<1:48:46,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 852/4671 [24:19<1:48:46,  1.71s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 853/4671 [24:19<1:49:01,  1.71s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 853/4671 [24:20<1:49:01,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 854/4671 [24:20<1:48:34,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 854/4671 [24:22<1:48:34,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 855/4671 [24:22<1:48:46,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 855/4671 [24:24<1:48:46,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 856/4671 [24:24<1:49:34,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 856/4671 [24:26<1:49:34,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 857/4671 [24:26<1:48:23,  1.71s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 857/4671 [24:27<1:48:23,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 858/4671 [24:27<1:47:39,  1.69s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 858/4671 [24:29<1:47:39,  1.69s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 859/4671 [24:29<1:47:26,  1.69s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 859/4671 [24:31<1:47:26,  1.69s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 860/4671 [24:31<1:47:27,  1.69s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 860/4671 [24:32<1:47:27,  1.69s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 861/4671 [24:32<1:47:49,  1.70s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 861/4671 [24:34<1:47:49,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 862/4671 [24:34<1:47:16,  1.69s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 862/4671 [24:36<1:47:16,  1.69s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 863/4671 [24:36<1:47:30,  1.69s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 863/4671 [24:37<1:47:30,  1.69s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 864/4671 [24:37<1:47:47,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 864/4671 [24:39<1:47:47,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 865/4671 [24:39<1:47:44,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 865/4671 [24:41<1:47:44,  1.70s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 866/4671 [24:41<1:47:47,  1.70s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 866/4671 [24:42<1:47:47,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 867/4671 [24:42<1:46:47,  1.68s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 867/4671 [24:44<1:46:47,  1.68s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 868/4671 [24:44<1:47:00,  1.69s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 868/4671 [24:46<1:47:00,  1.69s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 869/4671 [24:46<1:47:38,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 869/4671 [24:48<1:47:38,  1.70s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 870/4671 [24:48<1:48:38,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 870/4671 [24:49<1:48:38,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 871/4671 [24:49<1:49:06,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 871/4671 [24:51<1:49:06,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 872/4671 [24:51<1:47:19,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 872/4671 [24:53<1:47:19,  1.70s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 873/4671 [24:53<1:47:58,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 873/4671 [24:54<1:47:58,  1.71s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 874/4671 [24:54<1:46:45,  1.69s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 874/4671 [24:56<1:46:45,  1.69s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 875/4671 [24:56<1:46:42,  1.69s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 875/4671 [24:58<1:46:42,  1.69s/it, training_loss=0.076]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 876/4671 [24:58<1:47:06,  1.69s/it, training_loss=0.076]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 876/4671 [24:59<1:47:06,  1.69s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 877/4671 [24:59<1:47:14,  1.70s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 877/4671 [25:01<1:47:14,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 878/4671 [25:01<1:47:19,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 878/4671 [25:03<1:47:19,  1.70s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 879/4671 [25:03<1:48:21,  1.71s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 879/4671 [25:05<1:48:21,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 880/4671 [25:05<1:48:22,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 880/4671 [25:06<1:48:22,  1.72s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 881/4671 [25:06<1:48:19,  1.71s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 881/4671 [25:08<1:48:19,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 882/4671 [25:08<1:48:18,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 882/4671 [25:10<1:48:18,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 883/4671 [25:10<1:48:27,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 883/4671 [25:11<1:48:27,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 884/4671 [25:11<1:47:04,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 884/4671 [25:13<1:47:04,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 885/4671 [25:13<1:47:19,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 885/4671 [25:15<1:47:19,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 886/4671 [25:15<1:48:29,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 886/4671 [25:17<1:48:29,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 887/4671 [25:17<1:48:01,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 887/4671 [25:18<1:48:01,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 888/4671 [25:18<1:47:59,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 888/4671 [25:20<1:47:59,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 889/4671 [25:20<1:47:35,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 889/4671 [25:22<1:47:35,  1.71s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 890/4671 [25:22<1:46:43,  1.69s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 890/4671 [25:23<1:46:43,  1.69s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 891/4671 [25:23<1:47:05,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 891/4671 [25:25<1:47:05,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 892/4671 [25:25<1:47:58,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 892/4671 [25:27<1:47:58,  1.71s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 893/4671 [25:27<1:48:33,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 893/4671 [25:29<1:48:33,  1.72s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 894/4671 [25:29<1:47:27,  1.71s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 894/4671 [25:30<1:47:27,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 895/4671 [25:30<1:47:35,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 895/4671 [25:32<1:47:35,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 896/4671 [25:32<1:47:39,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 896/4671 [25:34<1:47:39,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 897/4671 [25:34<1:46:56,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 897/4671 [25:35<1:46:56,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 898/4671 [25:35<1:46:53,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 898/4671 [25:37<1:46:53,  1.70s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 899/4671 [25:37<1:47:37,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 899/4671 [25:39<1:47:37,  1.71s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 900/4671 [25:39<1:48:26,  1.73s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 900/4671 [25:41<1:48:26,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 901/4671 [25:41<1:47:58,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 901/4671 [25:42<1:47:58,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 902/4671 [25:42<1:47:30,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 902/4671 [25:44<1:47:30,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 903/4671 [25:44<1:47:32,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 903/4671 [25:46<1:47:32,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 904/4671 [25:46<1:46:40,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 904/4671 [25:47<1:46:40,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 905/4671 [25:47<1:46:31,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 905/4671 [25:49<1:46:31,  1.70s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 906/4671 [25:49<1:46:28,  1.70s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 906/4671 [25:51<1:46:28,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 907/4671 [25:51<1:46:21,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 907/4671 [25:52<1:46:21,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 908/4671 [25:52<1:46:32,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 908/4671 [25:54<1:46:32,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 909/4671 [25:54<1:46:28,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 909/4671 [25:56<1:46:28,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 910/4671 [25:56<1:46:24,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 910/4671 [25:57<1:46:24,  1.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 911/4671 [25:57<1:45:44,  1.69s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 911/4671 [25:59<1:45:44,  1.69s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 912/4671 [25:59<1:45:47,  1.69s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 912/4671 [26:01<1:45:47,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 913/4671 [26:01<1:46:05,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 913/4671 [26:03<1:46:05,  1.69s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 914/4671 [26:03<1:45:53,  1.69s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 914/4671 [26:04<1:45:53,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 915/4671 [26:04<1:45:35,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 915/4671 [26:06<1:45:35,  1.69s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 916/4671 [26:06<1:45:27,  1.69s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 916/4671 [26:08<1:45:27,  1.69s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 917/4671 [26:08<1:45:51,  1.69s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 917/4671 [26:09<1:45:51,  1.69s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 918/4671 [26:09<1:45:04,  1.68s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 918/4671 [26:11<1:45:04,  1.68s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 919/4671 [26:11<1:44:10,  1.67s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 919/4671 [26:13<1:44:10,  1.67s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 920/4671 [26:13<1:45:10,  1.68s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 920/4671 [26:14<1:45:10,  1.68s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 921/4671 [26:14<1:46:22,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 921/4671 [26:16<1:46:22,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 922/4671 [26:16<1:45:57,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 922/4671 [26:18<1:45:57,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 923/4671 [26:18<1:46:25,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 923/4671 [26:19<1:46:25,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 924/4671 [26:19<1:46:54,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 924/4671 [26:21<1:46:54,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 925/4671 [26:21<1:47:10,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 925/4671 [26:23<1:47:10,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 926/4671 [26:23<1:46:35,  1.71s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 926/4671 [26:25<1:46:35,  1.71s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 927/4671 [26:25<1:46:28,  1.71s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 927/4671 [26:26<1:46:28,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 928/4671 [26:26<1:46:31,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 928/4671 [26:28<1:46:31,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 929/4671 [26:28<1:46:57,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 929/4671 [26:30<1:46:57,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 930/4671 [26:30<1:46:41,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 930/4671 [26:31<1:46:41,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 931/4671 [26:31<1:46:14,  1.70s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 931/4671 [26:33<1:46:14,  1.70s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 932/4671 [26:33<1:45:21,  1.69s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 932/4671 [26:35<1:45:21,  1.69s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 933/4671 [26:35<1:45:37,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 933/4671 [26:36<1:45:37,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 934/4671 [26:36<1:45:40,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 934/4671 [26:38<1:45:40,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  20%|██        | 935/4671 [26:38<1:46:25,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  20%|██        | 935/4671 [26:40<1:46:25,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  20%|██        | 936/4671 [26:40<1:46:38,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  20%|██        | 936/4671 [26:42<1:46:38,  1.71s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  20%|██        | 937/4671 [26:42<1:46:27,  1.71s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  20%|██        | 937/4671 [26:43<1:46:27,  1.71s/it, training_loss=0.216]\u001B[A\n",
      "Epoch 1:  20%|██        | 938/4671 [26:43<1:45:44,  1.70s/it, training_loss=0.216]\u001B[A\n",
      "Epoch 1:  20%|██        | 938/4671 [26:45<1:45:44,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  20%|██        | 939/4671 [26:45<1:44:59,  1.69s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  20%|██        | 939/4671 [26:47<1:44:59,  1.69s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  20%|██        | 940/4671 [26:47<1:44:58,  1.69s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  20%|██        | 940/4671 [26:48<1:44:58,  1.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  20%|██        | 941/4671 [26:48<1:45:03,  1.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  20%|██        | 941/4671 [26:50<1:45:03,  1.69s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  20%|██        | 942/4671 [26:50<1:45:49,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  20%|██        | 942/4671 [26:52<1:45:49,  1.70s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  20%|██        | 943/4671 [26:52<1:46:01,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  20%|██        | 943/4671 [26:54<1:46:01,  1.71s/it, training_loss=0.192]\u001B[A\n",
      "Epoch 1:  20%|██        | 944/4671 [26:54<1:46:03,  1.71s/it, training_loss=0.192]\u001B[A\n",
      "Epoch 1:  20%|██        | 944/4671 [26:55<1:46:03,  1.71s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  20%|██        | 945/4671 [26:55<1:44:14,  1.68s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  20%|██        | 945/4671 [26:57<1:44:14,  1.68s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  20%|██        | 946/4671 [26:57<1:44:17,  1.68s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  20%|██        | 946/4671 [26:59<1:44:17,  1.68s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  20%|██        | 947/4671 [26:59<1:44:34,  1.68s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  20%|██        | 947/4671 [27:00<1:44:34,  1.68s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  20%|██        | 948/4671 [27:00<1:45:39,  1.70s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  20%|██        | 948/4671 [27:02<1:45:39,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  20%|██        | 949/4671 [27:02<1:45:09,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  20%|██        | 949/4671 [27:04<1:45:09,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  20%|██        | 950/4671 [27:04<1:45:19,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  20%|██        | 950/4671 [27:05<1:45:19,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  20%|██        | 951/4671 [27:05<1:45:13,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  20%|██        | 951/4671 [27:07<1:45:13,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  20%|██        | 952/4671 [27:07<1:45:01,  1.69s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  20%|██        | 952/4671 [27:09<1:45:01,  1.69s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  20%|██        | 953/4671 [27:09<1:45:48,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  20%|██        | 953/4671 [27:10<1:45:48,  1.71s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  20%|██        | 954/4671 [27:10<1:45:15,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  20%|██        | 954/4671 [27:12<1:45:15,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  20%|██        | 955/4671 [27:12<1:45:05,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  20%|██        | 955/4671 [27:14<1:45:05,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  20%|██        | 956/4671 [27:14<1:44:30,  1.69s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  20%|██        | 956/4671 [27:16<1:44:30,  1.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  20%|██        | 957/4671 [27:16<1:45:06,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  20%|██        | 957/4671 [27:17<1:45:06,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  21%|██        | 958/4671 [27:17<1:46:54,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  21%|██        | 958/4671 [27:19<1:46:54,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  21%|██        | 959/4671 [27:19<1:46:37,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  21%|██        | 959/4671 [27:21<1:46:37,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  21%|██        | 960/4671 [27:21<1:45:35,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  21%|██        | 960/4671 [27:22<1:45:35,  1.71s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  21%|██        | 961/4671 [27:22<1:46:06,  1.72s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  21%|██        | 961/4671 [27:24<1:46:06,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  21%|██        | 962/4671 [27:24<1:46:27,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  21%|██        | 962/4671 [27:26<1:46:27,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  21%|██        | 963/4671 [27:26<1:45:36,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  21%|██        | 963/4671 [27:28<1:45:36,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  21%|██        | 964/4671 [27:28<1:45:33,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  21%|██        | 964/4671 [27:29<1:45:33,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  21%|██        | 965/4671 [27:29<1:44:28,  1.69s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  21%|██        | 965/4671 [27:31<1:44:28,  1.69s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  21%|██        | 966/4671 [27:31<1:44:01,  1.68s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  21%|██        | 966/4671 [27:33<1:44:01,  1.68s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  21%|██        | 967/4671 [27:33<1:44:31,  1.69s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  21%|██        | 967/4671 [27:34<1:44:31,  1.69s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  21%|██        | 968/4671 [27:34<1:44:41,  1.70s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  21%|██        | 968/4671 [27:36<1:44:41,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  21%|██        | 969/4671 [27:36<1:45:23,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  21%|██        | 969/4671 [27:38<1:45:23,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  21%|██        | 970/4671 [27:38<1:45:05,  1.70s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  21%|██        | 970/4671 [27:39<1:45:05,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  21%|██        | 971/4671 [27:39<1:44:35,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  21%|██        | 971/4671 [27:41<1:44:35,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  21%|██        | 972/4671 [27:41<1:44:54,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  21%|██        | 972/4671 [27:43<1:44:54,  1.70s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  21%|██        | 973/4671 [27:43<1:44:30,  1.70s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  21%|██        | 973/4671 [27:45<1:44:30,  1.70s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  21%|██        | 974/4671 [27:45<1:45:13,  1.71s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  21%|██        | 974/4671 [27:46<1:45:13,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  21%|██        | 975/4671 [27:46<1:45:08,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  21%|██        | 975/4671 [27:48<1:45:08,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  21%|██        | 976/4671 [27:48<1:44:50,  1.70s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  21%|██        | 976/4671 [27:50<1:44:50,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  21%|██        | 977/4671 [27:50<1:44:40,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  21%|██        | 977/4671 [27:51<1:44:40,  1.70s/it, training_loss=0.075]\u001B[A\n",
      "Epoch 1:  21%|██        | 978/4671 [27:51<1:44:35,  1.70s/it, training_loss=0.075]\u001B[A\n",
      "Epoch 1:  21%|██        | 978/4671 [27:53<1:44:35,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  21%|██        | 979/4671 [27:53<1:44:46,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  21%|██        | 979/4671 [27:55<1:44:46,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  21%|██        | 980/4671 [27:55<1:43:53,  1.69s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  21%|██        | 980/4671 [27:56<1:43:53,  1.69s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  21%|██        | 981/4671 [27:56<1:43:37,  1.68s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  21%|██        | 981/4671 [27:58<1:43:37,  1.68s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  21%|██        | 982/4671 [27:58<1:43:46,  1.69s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  21%|██        | 982/4671 [28:00<1:43:46,  1.69s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  21%|██        | 983/4671 [28:00<1:43:39,  1.69s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  21%|██        | 983/4671 [28:01<1:43:39,  1.69s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  21%|██        | 984/4671 [28:01<1:44:06,  1.69s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  21%|██        | 984/4671 [28:03<1:44:06,  1.69s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  21%|██        | 985/4671 [28:03<1:44:20,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  21%|██        | 985/4671 [28:05<1:44:20,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  21%|██        | 986/4671 [28:05<1:44:24,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  21%|██        | 986/4671 [28:07<1:44:24,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  21%|██        | 987/4671 [28:07<1:44:31,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  21%|██        | 987/4671 [28:08<1:44:31,  1.70s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  21%|██        | 988/4671 [28:08<1:44:30,  1.70s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  21%|██        | 988/4671 [28:10<1:44:30,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  21%|██        | 989/4671 [28:10<1:43:49,  1.69s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  21%|██        | 989/4671 [28:12<1:43:49,  1.69s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  21%|██        | 990/4671 [28:12<1:43:52,  1.69s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  21%|██        | 990/4671 [28:13<1:43:52,  1.69s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  21%|██        | 991/4671 [28:13<1:43:21,  1.69s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  21%|██        | 991/4671 [28:15<1:43:21,  1.69s/it, training_loss=0.192]\u001B[A\n",
      "Epoch 1:  21%|██        | 992/4671 [28:15<1:44:11,  1.70s/it, training_loss=0.192]\u001B[A\n",
      "Epoch 1:  21%|██        | 992/4671 [28:17<1:44:11,  1.70s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 993/4671 [28:17<1:44:18,  1.70s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 993/4671 [28:18<1:44:18,  1.70s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 994/4671 [28:18<1:43:41,  1.69s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 994/4671 [28:20<1:43:41,  1.69s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 995/4671 [28:20<1:43:53,  1.70s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 995/4671 [28:22<1:43:53,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 996/4671 [28:22<1:43:36,  1.69s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 996/4671 [28:23<1:43:36,  1.69s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 997/4671 [28:23<1:43:15,  1.69s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 997/4671 [28:25<1:43:15,  1.69s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 998/4671 [28:25<1:43:37,  1.69s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 998/4671 [28:27<1:43:37,  1.69s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 999/4671 [28:27<1:44:14,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 999/4671 [28:29<1:44:14,  1.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 1000/4671 [28:29<1:44:06,  1.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 1000/4671 [28:30<1:44:06,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 1001/4671 [28:30<1:43:40,  1.69s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 1001/4671 [28:32<1:43:40,  1.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 1002/4671 [28:32<1:44:12,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 1002/4671 [28:34<1:44:12,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 1003/4671 [28:34<1:44:00,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 1003/4671 [28:35<1:44:00,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 1004/4671 [28:35<1:43:41,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 1004/4671 [28:37<1:43:41,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1005/4671 [28:37<1:44:21,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1005/4671 [28:39<1:44:21,  1.71s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1006/4671 [28:39<1:44:15,  1.71s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1006/4671 [28:41<1:44:15,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1007/4671 [28:41<1:44:23,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1007/4671 [28:42<1:44:23,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1008/4671 [28:42<1:44:00,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1008/4671 [28:44<1:44:00,  1.70s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1009/4671 [28:44<1:43:35,  1.70s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1009/4671 [28:46<1:43:35,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1010/4671 [28:46<1:43:58,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1010/4671 [28:47<1:43:58,  1.70s/it, training_loss=0.185]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1011/4671 [28:47<1:44:01,  1.71s/it, training_loss=0.185]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1011/4671 [28:49<1:44:01,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1012/4671 [28:49<1:43:17,  1.69s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1012/4671 [28:51<1:43:17,  1.69s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1013/4671 [28:51<1:42:28,  1.68s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1013/4671 [28:52<1:42:28,  1.68s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1014/4671 [28:52<1:42:39,  1.68s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1014/4671 [28:54<1:42:39,  1.68s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1015/4671 [28:54<1:42:39,  1.68s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1015/4671 [28:56<1:42:39,  1.68s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1016/4671 [28:56<1:42:52,  1.69s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1016/4671 [28:57<1:42:52,  1.69s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1017/4671 [28:57<1:43:27,  1.70s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1017/4671 [28:59<1:43:27,  1.70s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1018/4671 [28:59<1:43:35,  1.70s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1018/4671 [29:01<1:43:35,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1019/4671 [29:01<1:43:06,  1.69s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1019/4671 [29:03<1:43:06,  1.69s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1020/4671 [29:03<1:42:50,  1.69s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1020/4671 [29:04<1:42:50,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1021/4671 [29:04<1:43:02,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1021/4671 [29:06<1:43:02,  1.69s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1022/4671 [29:06<1:42:54,  1.69s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1022/4671 [29:08<1:42:54,  1.69s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1023/4671 [29:08<1:43:18,  1.70s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1023/4671 [29:09<1:43:18,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1024/4671 [29:09<1:42:56,  1.69s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1024/4671 [29:11<1:42:56,  1.69s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1025/4671 [29:11<1:43:12,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1025/4671 [29:13<1:43:12,  1.70s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1026/4671 [29:13<1:43:14,  1.70s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1026/4671 [29:14<1:43:14,  1.70s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1027/4671 [29:14<1:43:02,  1.70s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1027/4671 [29:16<1:43:02,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1028/4671 [29:16<1:42:48,  1.69s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1028/4671 [29:18<1:42:48,  1.69s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1029/4671 [29:18<1:43:12,  1.70s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1029/4671 [29:19<1:43:12,  1.70s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1030/4671 [29:19<1:42:43,  1.69s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1030/4671 [29:21<1:42:43,  1.69s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1031/4671 [29:21<1:43:03,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1031/4671 [29:23<1:43:03,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1032/4671 [29:23<1:44:07,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1032/4671 [29:25<1:44:07,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1033/4671 [29:25<1:43:35,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1033/4671 [29:26<1:43:35,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1034/4671 [29:26<1:43:07,  1.70s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1034/4671 [29:28<1:43:07,  1.70s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1035/4671 [29:28<1:42:58,  1.70s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1035/4671 [29:30<1:42:58,  1.70s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1036/4671 [29:30<1:42:33,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1036/4671 [29:31<1:42:33,  1.69s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1037/4671 [29:31<1:41:32,  1.68s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1037/4671 [29:33<1:41:32,  1.68s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1038/4671 [29:33<1:42:05,  1.69s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1038/4671 [29:35<1:42:05,  1.69s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1039/4671 [29:35<1:42:55,  1.70s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1039/4671 [29:36<1:42:55,  1.70s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1040/4671 [29:36<1:41:47,  1.68s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1040/4671 [29:38<1:41:47,  1.68s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1041/4671 [29:38<1:43:00,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1041/4671 [29:40<1:43:00,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1042/4671 [29:40<1:42:54,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1042/4671 [29:42<1:42:54,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1043/4671 [29:42<1:43:55,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1043/4671 [29:43<1:43:55,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1044/4671 [29:43<1:43:35,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1044/4671 [29:45<1:43:35,  1.71s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1045/4671 [29:45<1:43:40,  1.72s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1045/4671 [29:47<1:43:40,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1046/4671 [29:47<1:43:38,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1046/4671 [29:49<1:43:38,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1047/4671 [29:49<1:43:43,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1047/4671 [29:50<1:43:43,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1048/4671 [29:50<1:43:23,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1048/4671 [29:52<1:43:23,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1049/4671 [29:52<1:43:34,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1049/4671 [29:54<1:43:34,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1050/4671 [29:54<1:42:35,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 1050/4671 [29:55<1:42:35,  1.70s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1051/4671 [29:55<1:42:24,  1.70s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1051/4671 [29:57<1:42:24,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1052/4671 [29:57<1:43:03,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1052/4671 [29:59<1:43:03,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1053/4671 [29:59<1:42:56,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1053/4671 [30:00<1:42:56,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1054/4671 [30:00<1:43:37,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1054/4671 [30:02<1:43:37,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1055/4671 [30:02<1:43:41,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1055/4671 [30:04<1:43:41,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1056/4671 [30:04<1:43:02,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1056/4671 [30:06<1:43:02,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1057/4671 [30:06<1:42:10,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1057/4671 [30:07<1:42:10,  1.70s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1058/4671 [30:07<1:41:33,  1.69s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1058/4671 [30:09<1:41:33,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1059/4671 [30:09<1:42:21,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1059/4671 [30:11<1:42:21,  1.70s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1060/4671 [30:11<1:41:19,  1.68s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1060/4671 [30:12<1:41:19,  1.68s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1061/4671 [30:12<1:42:33,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1061/4671 [30:14<1:42:33,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1062/4671 [30:14<1:43:07,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1062/4671 [30:16<1:43:07,  1.71s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1063/4671 [30:16<1:42:44,  1.71s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1063/4671 [30:17<1:42:44,  1.71s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1064/4671 [30:17<1:42:59,  1.71s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1064/4671 [30:19<1:42:59,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1065/4671 [30:19<1:42:43,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1065/4671 [30:21<1:42:43,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1066/4671 [30:21<1:42:23,  1.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1066/4671 [30:23<1:42:23,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1067/4671 [30:23<1:42:49,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1067/4671 [30:24<1:42:49,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1068/4671 [30:24<1:43:03,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1068/4671 [30:26<1:43:03,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1069/4671 [30:26<1:42:55,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1069/4671 [30:28<1:42:55,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1070/4671 [30:28<1:42:55,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1070/4671 [30:29<1:42:55,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1071/4671 [30:29<1:42:58,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1071/4671 [30:31<1:42:58,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1072/4671 [30:31<1:42:31,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1072/4671 [30:33<1:42:31,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1073/4671 [30:33<1:42:11,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1073/4671 [30:35<1:42:11,  1.70s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1074/4671 [30:35<1:41:59,  1.70s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1074/4671 [30:36<1:41:59,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1075/4671 [30:36<1:41:21,  1.69s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1075/4671 [30:38<1:41:21,  1.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1076/4671 [30:38<1:41:51,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1076/4671 [30:40<1:41:51,  1.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1077/4671 [30:40<1:42:27,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1077/4671 [30:41<1:42:27,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1078/4671 [30:41<1:42:46,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1078/4671 [30:43<1:42:46,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1079/4671 [30:43<1:42:13,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1079/4671 [30:45<1:42:13,  1.71s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1080/4671 [30:45<1:42:03,  1.71s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1080/4671 [30:46<1:42:03,  1.71s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1081/4671 [30:46<1:41:43,  1.70s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1081/4671 [30:48<1:41:43,  1.70s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1082/4671 [30:48<1:41:17,  1.69s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1082/4671 [30:50<1:41:17,  1.69s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1083/4671 [30:50<1:42:24,  1.71s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1083/4671 [30:52<1:42:24,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1084/4671 [30:52<1:42:53,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1084/4671 [30:53<1:42:53,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1085/4671 [30:53<1:42:50,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1085/4671 [30:55<1:42:50,  1.72s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1086/4671 [30:55<1:41:55,  1.71s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1086/4671 [30:57<1:41:55,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1087/4671 [30:57<1:41:49,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1087/4671 [30:58<1:41:49,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1088/4671 [30:58<1:41:35,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1088/4671 [31:00<1:41:35,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1089/4671 [31:00<1:42:07,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1089/4671 [31:02<1:42:07,  1.71s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1090/4671 [31:02<1:41:38,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1090/4671 [31:04<1:41:38,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1091/4671 [31:04<1:41:15,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1091/4671 [31:05<1:41:15,  1.70s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1092/4671 [31:05<1:40:43,  1.69s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1092/4671 [31:07<1:40:43,  1.69s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1093/4671 [31:07<1:40:33,  1.69s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1093/4671 [31:09<1:40:33,  1.69s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1094/4671 [31:09<1:40:57,  1.69s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1094/4671 [31:10<1:40:57,  1.69s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1095/4671 [31:10<1:41:03,  1.70s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1095/4671 [31:12<1:41:03,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1096/4671 [31:12<1:40:59,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1096/4671 [31:14<1:40:59,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1097/4671 [31:14<1:40:52,  1.69s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 1097/4671 [31:15<1:40:52,  1.69s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1098/4671 [31:15<1:40:37,  1.69s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1098/4671 [31:17<1:40:37,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1099/4671 [31:17<1:40:48,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1099/4671 [31:19<1:40:48,  1.69s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1100/4671 [31:19<1:41:35,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1100/4671 [31:21<1:41:35,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1101/4671 [31:21<1:42:08,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1101/4671 [31:22<1:42:08,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1102/4671 [31:22<1:40:29,  1.69s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1102/4671 [31:24<1:40:29,  1.69s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1103/4671 [31:24<1:40:32,  1.69s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1103/4671 [31:26<1:40:32,  1.69s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1104/4671 [31:26<1:40:59,  1.70s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1104/4671 [31:27<1:40:59,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1105/4671 [31:27<1:40:37,  1.69s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1105/4671 [31:29<1:40:37,  1.69s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1106/4671 [31:29<1:40:14,  1.69s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1106/4671 [31:31<1:40:14,  1.69s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1107/4671 [31:31<1:41:28,  1.71s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1107/4671 [31:32<1:41:28,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1108/4671 [31:32<1:40:41,  1.70s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1108/4671 [31:34<1:40:41,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1109/4671 [31:34<1:41:33,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 1109/4671 [31:36<1:41:33,  1.71s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1110/4671 [31:36<1:41:17,  1.71s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1110/4671 [31:38<1:41:17,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1111/4671 [31:38<1:40:54,  1.70s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1111/4671 [31:39<1:40:54,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1112/4671 [31:39<1:40:15,  1.69s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1112/4671 [31:41<1:40:15,  1.69s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1113/4671 [31:41<1:40:05,  1.69s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1113/4671 [31:43<1:40:05,  1.69s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1114/4671 [31:43<1:40:11,  1.69s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1114/4671 [31:44<1:40:11,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1115/4671 [31:44<1:38:53,  1.67s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1115/4671 [31:46<1:38:53,  1.67s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1116/4671 [31:46<1:38:54,  1.67s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1116/4671 [31:48<1:38:54,  1.67s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1117/4671 [31:48<1:39:41,  1.68s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1117/4671 [31:49<1:39:41,  1.68s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1118/4671 [31:49<1:39:50,  1.69s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1118/4671 [31:51<1:39:50,  1.69s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1119/4671 [31:51<1:40:36,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1119/4671 [31:53<1:40:36,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1120/4671 [31:53<1:40:39,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1120/4671 [31:54<1:40:39,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1121/4671 [31:54<1:40:36,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1121/4671 [31:56<1:40:36,  1.70s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1122/4671 [31:56<1:39:11,  1.68s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1122/4671 [31:58<1:39:11,  1.68s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1123/4671 [31:58<1:39:12,  1.68s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1123/4671 [31:59<1:39:12,  1.68s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1124/4671 [31:59<1:38:34,  1.67s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1124/4671 [32:01<1:38:34,  1.67s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1125/4671 [32:01<1:40:14,  1.70s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1125/4671 [32:03<1:40:14,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1126/4671 [32:03<1:40:31,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1126/4671 [32:05<1:40:31,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1127/4671 [32:05<1:40:30,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1127/4671 [32:06<1:40:30,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1128/4671 [32:06<1:40:33,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1128/4671 [32:08<1:40:33,  1.70s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1129/4671 [32:08<1:40:55,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1129/4671 [32:10<1:40:55,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1130/4671 [32:10<1:41:05,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1130/4671 [32:11<1:41:05,  1.71s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1131/4671 [32:11<1:40:26,  1.70s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1131/4671 [32:13<1:40:26,  1.70s/it, training_loss=0.211]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1132/4671 [32:13<1:42:12,  1.73s/it, training_loss=0.211]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1132/4671 [32:15<1:42:12,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1133/4671 [32:15<1:41:24,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1133/4671 [32:16<1:41:24,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1134/4671 [32:16<1:40:29,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1134/4671 [32:18<1:40:29,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1135/4671 [32:18<1:40:01,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1135/4671 [32:20<1:40:01,  1.70s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1136/4671 [32:20<1:39:31,  1.69s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1136/4671 [32:22<1:39:31,  1.69s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1137/4671 [32:22<1:39:45,  1.69s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1137/4671 [32:23<1:39:45,  1.69s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1138/4671 [32:23<1:39:15,  1.69s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1138/4671 [32:25<1:39:15,  1.69s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1139/4671 [32:25<1:40:04,  1.70s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1139/4671 [32:27<1:40:04,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1140/4671 [32:27<1:40:00,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1140/4671 [32:28<1:40:00,  1.70s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1141/4671 [32:28<1:40:25,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1141/4671 [32:30<1:40:25,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1142/4671 [32:30<1:40:42,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1142/4671 [32:32<1:40:42,  1.71s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1143/4671 [32:32<1:39:33,  1.69s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1143/4671 [32:33<1:39:33,  1.69s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1144/4671 [32:33<1:39:48,  1.70s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 1144/4671 [32:35<1:39:48,  1.70s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1145/4671 [32:35<1:39:25,  1.69s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1145/4671 [32:37<1:39:25,  1.69s/it, training_loss=0.256]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1146/4671 [32:37<1:40:06,  1.70s/it, training_loss=0.256]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1146/4671 [32:39<1:40:06,  1.70s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1147/4671 [32:39<1:40:32,  1.71s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1147/4671 [32:40<1:40:32,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1148/4671 [32:40<1:39:41,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1148/4671 [32:42<1:39:41,  1.70s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1149/4671 [32:42<1:39:06,  1.69s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1149/4671 [32:44<1:39:06,  1.69s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1150/4671 [32:44<1:39:23,  1.69s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1150/4671 [32:45<1:39:23,  1.69s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1151/4671 [32:45<1:39:29,  1.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1151/4671 [32:47<1:39:29,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1152/4671 [32:47<1:39:01,  1.69s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1152/4671 [32:49<1:39:01,  1.69s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1153/4671 [32:49<1:38:31,  1.68s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1153/4671 [32:50<1:38:31,  1.68s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1154/4671 [32:50<1:38:27,  1.68s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1154/4671 [32:52<1:38:27,  1.68s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1155/4671 [32:52<1:38:19,  1.68s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1155/4671 [32:54<1:38:19,  1.68s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1156/4671 [32:54<1:38:43,  1.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1156/4671 [32:55<1:38:43,  1.69s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1157/4671 [32:55<1:38:07,  1.68s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1157/4671 [32:57<1:38:07,  1.68s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1158/4671 [32:57<1:37:53,  1.67s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1158/4671 [32:59<1:37:53,  1.67s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1159/4671 [32:59<1:38:04,  1.68s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1159/4671 [33:00<1:38:04,  1.68s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1160/4671 [33:00<1:38:28,  1.68s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1160/4671 [33:02<1:38:28,  1.68s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1161/4671 [33:02<1:38:52,  1.69s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1161/4671 [33:04<1:38:52,  1.69s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1162/4671 [33:04<1:38:57,  1.69s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1162/4671 [33:06<1:38:57,  1.69s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1163/4671 [33:06<1:39:34,  1.70s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1163/4671 [33:07<1:39:34,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1164/4671 [33:07<1:40:14,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1164/4671 [33:09<1:40:14,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1165/4671 [33:09<1:40:12,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1165/4671 [33:11<1:40:12,  1.71s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1166/4671 [33:11<1:39:49,  1.71s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1166/4671 [33:12<1:39:49,  1.71s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1167/4671 [33:12<1:39:06,  1.70s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 1167/4671 [33:14<1:39:06,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1168/4671 [33:14<1:38:14,  1.68s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1168/4671 [33:16<1:38:14,  1.68s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1169/4671 [33:16<1:38:06,  1.68s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1169/4671 [33:17<1:38:06,  1.68s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1170/4671 [33:17<1:37:51,  1.68s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1170/4671 [33:19<1:37:51,  1.68s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1171/4671 [33:19<1:38:28,  1.69s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1171/4671 [33:21<1:38:28,  1.69s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1172/4671 [33:21<1:38:34,  1.69s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1172/4671 [33:22<1:38:34,  1.69s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1173/4671 [33:22<1:37:39,  1.68s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1173/4671 [33:24<1:37:39,  1.68s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1174/4671 [33:24<1:38:09,  1.68s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1174/4671 [33:26<1:38:09,  1.68s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1175/4671 [33:26<1:39:05,  1.70s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1175/4671 [33:28<1:39:05,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1176/4671 [33:28<1:39:00,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1176/4671 [33:29<1:39:00,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1177/4671 [33:29<1:39:23,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1177/4671 [33:31<1:39:23,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1178/4671 [33:31<1:39:54,  1.72s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1178/4671 [33:33<1:39:54,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1179/4671 [33:33<1:38:48,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1179/4671 [33:34<1:38:48,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1180/4671 [33:34<1:39:16,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1180/4671 [33:36<1:39:16,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1181/4671 [33:36<1:37:51,  1.68s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1181/4671 [33:38<1:37:51,  1.68s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1182/4671 [33:38<1:38:29,  1.69s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1182/4671 [33:39<1:38:29,  1.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1183/4671 [33:39<1:38:16,  1.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1183/4671 [33:41<1:38:16,  1.69s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1184/4671 [33:41<1:37:27,  1.68s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1184/4671 [33:43<1:37:27,  1.68s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1185/4671 [33:43<1:37:42,  1.68s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1185/4671 [33:45<1:37:42,  1.68s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1186/4671 [33:45<1:38:34,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1186/4671 [33:46<1:38:34,  1.70s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1187/4671 [33:46<1:37:47,  1.68s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1187/4671 [33:48<1:37:47,  1.68s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1188/4671 [33:48<1:37:49,  1.69s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1188/4671 [33:50<1:37:49,  1.69s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1189/4671 [33:50<1:38:46,  1.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1189/4671 [33:51<1:38:46,  1.70s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1190/4671 [33:51<1:37:55,  1.69s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1190/4671 [33:53<1:37:55,  1.69s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1191/4671 [33:53<1:38:27,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 1191/4671 [33:55<1:38:27,  1.70s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1192/4671 [33:55<1:37:36,  1.68s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1192/4671 [33:56<1:37:36,  1.68s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1193/4671 [33:56<1:38:18,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1193/4671 [33:58<1:38:18,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1194/4671 [33:58<1:38:11,  1.69s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1194/4671 [34:00<1:38:11,  1.69s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1195/4671 [34:00<1:37:53,  1.69s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1195/4671 [34:01<1:37:53,  1.69s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1196/4671 [34:01<1:38:34,  1.70s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1196/4671 [34:03<1:38:34,  1.70s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1197/4671 [34:03<1:38:17,  1.70s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1197/4671 [34:05<1:38:17,  1.70s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1198/4671 [34:05<1:40:27,  1.74s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1198/4671 [34:07<1:40:27,  1.74s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1199/4671 [34:07<1:42:18,  1.77s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1199/4671 [34:09<1:42:18,  1.77s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1200/4671 [34:09<1:42:51,  1.78s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1200/4671 [34:10<1:42:51,  1.78s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1201/4671 [34:10<1:42:00,  1.76s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1201/4671 [34:12<1:42:00,  1.76s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1202/4671 [34:12<1:40:04,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1202/4671 [34:14<1:40:04,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1203/4671 [34:14<1:39:47,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1203/4671 [34:15<1:39:47,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1204/4671 [34:15<1:37:55,  1.69s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1204/4671 [34:17<1:37:55,  1.69s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1205/4671 [34:17<1:37:17,  1.68s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1205/4671 [34:19<1:37:17,  1.68s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1206/4671 [34:19<1:37:36,  1.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1206/4671 [34:20<1:37:36,  1.69s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1207/4671 [34:20<1:38:16,  1.70s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1207/4671 [34:22<1:38:16,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1208/4671 [34:22<1:38:36,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1208/4671 [34:24<1:38:36,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1209/4671 [34:24<1:37:39,  1.69s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1209/4671 [34:25<1:37:39,  1.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1210/4671 [34:25<1:37:45,  1.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1210/4671 [34:27<1:37:45,  1.69s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1211/4671 [34:27<1:37:04,  1.68s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1211/4671 [34:29<1:37:04,  1.68s/it, training_loss=0.079]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1212/4671 [34:29<1:37:18,  1.69s/it, training_loss=0.079]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1212/4671 [34:31<1:37:18,  1.69s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1213/4671 [34:31<1:37:25,  1.69s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1213/4671 [34:32<1:37:25,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1214/4671 [34:32<1:37:34,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1214/4671 [34:34<1:37:34,  1.69s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1215/4671 [34:34<1:38:07,  1.70s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1215/4671 [34:36<1:38:07,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1216/4671 [34:36<1:38:23,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1216/4671 [34:37<1:38:23,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1217/4671 [34:37<1:37:58,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1217/4671 [34:39<1:37:58,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1218/4671 [34:39<1:39:01,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1218/4671 [34:41<1:39:01,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1219/4671 [34:41<1:39:21,  1.73s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1219/4671 [34:43<1:39:21,  1.73s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1220/4671 [34:43<1:38:21,  1.71s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1220/4671 [34:44<1:38:21,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1221/4671 [34:44<1:37:59,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1221/4671 [34:46<1:37:59,  1.70s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1222/4671 [34:46<1:38:33,  1.71s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1222/4671 [34:48<1:38:33,  1.71s/it, training_loss=0.077]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1223/4671 [34:48<1:38:43,  1.72s/it, training_loss=0.077]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1223/4671 [34:49<1:38:43,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1224/4671 [34:49<1:38:25,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1224/4671 [34:51<1:38:25,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1225/4671 [34:51<1:38:07,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1225/4671 [34:53<1:38:07,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1226/4671 [34:53<1:36:56,  1.69s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 1226/4671 [34:54<1:36:56,  1.69s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1227/4671 [34:54<1:36:58,  1.69s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1227/4671 [34:56<1:36:58,  1.69s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1228/4671 [34:56<1:37:44,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1228/4671 [34:58<1:37:44,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1229/4671 [34:58<1:37:45,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1229/4671 [35:00<1:37:45,  1.70s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1230/4671 [35:00<1:37:50,  1.71s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1230/4671 [35:01<1:37:50,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1231/4671 [35:01<1:37:51,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1231/4671 [35:03<1:37:51,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1232/4671 [35:03<1:38:07,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1232/4671 [35:05<1:38:07,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1233/4671 [35:05<1:37:22,  1.70s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1233/4671 [35:06<1:37:22,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1234/4671 [35:06<1:37:48,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1234/4671 [35:08<1:37:48,  1.71s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1235/4671 [35:08<1:37:45,  1.71s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1235/4671 [35:10<1:37:45,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1236/4671 [35:10<1:37:55,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1236/4671 [35:12<1:37:55,  1.71s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1237/4671 [35:12<1:37:33,  1.70s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 1237/4671 [35:13<1:37:33,  1.70s/it, training_loss=0.078]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1238/4671 [35:13<1:36:44,  1.69s/it, training_loss=0.078]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1238/4671 [35:15<1:36:44,  1.69s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1239/4671 [35:15<1:36:33,  1.69s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1239/4671 [35:17<1:36:33,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1240/4671 [35:17<1:36:39,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1240/4671 [35:18<1:36:39,  1.69s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1241/4671 [35:18<1:37:45,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1241/4671 [35:20<1:37:45,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1242/4671 [35:20<1:38:24,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1242/4671 [35:22<1:38:24,  1.72s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1243/4671 [35:22<1:39:05,  1.73s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1243/4671 [35:24<1:39:05,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1244/4671 [35:24<1:41:16,  1.77s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1244/4671 [35:26<1:41:16,  1.77s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1245/4671 [35:26<1:44:00,  1.82s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1245/4671 [35:28<1:44:00,  1.82s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1246/4671 [35:28<1:45:40,  1.85s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1246/4671 [35:29<1:45:40,  1.85s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1247/4671 [35:29<1:45:31,  1.85s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1247/4671 [35:31<1:45:31,  1.85s/it, training_loss=0.197]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1248/4671 [35:31<1:46:16,  1.86s/it, training_loss=0.197]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1248/4671 [35:33<1:46:16,  1.86s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1249/4671 [35:33<1:44:17,  1.83s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1249/4671 [35:35<1:44:17,  1.83s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1250/4671 [35:35<1:41:31,  1.78s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1250/4671 [35:36<1:41:31,  1.78s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1251/4671 [35:36<1:39:32,  1.75s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1251/4671 [35:38<1:39:32,  1.75s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1252/4671 [35:38<1:39:29,  1.75s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1252/4671 [35:40<1:39:29,  1.75s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1253/4671 [35:40<1:39:28,  1.75s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1253/4671 [35:42<1:39:28,  1.75s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1254/4671 [35:42<1:38:43,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1254/4671 [35:43<1:38:43,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1255/4671 [35:43<1:38:03,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1255/4671 [35:45<1:38:03,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1256/4671 [35:45<1:38:25,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1256/4671 [35:47<1:38:25,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1257/4671 [35:47<1:38:13,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1257/4671 [35:48<1:38:13,  1.73s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1258/4671 [35:48<1:38:40,  1.73s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1258/4671 [35:50<1:38:40,  1.73s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1259/4671 [35:50<1:37:55,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1259/4671 [35:52<1:37:55,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1260/4671 [35:52<1:36:27,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1260/4671 [35:54<1:36:27,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1261/4671 [35:54<1:36:09,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1261/4671 [35:55<1:36:09,  1.69s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1262/4671 [35:55<1:35:31,  1.68s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1262/4671 [35:57<1:35:31,  1.68s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1263/4671 [35:57<1:36:00,  1.69s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1263/4671 [35:59<1:36:00,  1.69s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1264/4671 [35:59<1:36:18,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1264/4671 [36:00<1:36:18,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1265/4671 [36:00<1:35:42,  1.69s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1265/4671 [36:02<1:35:42,  1.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1266/4671 [36:02<1:36:45,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1266/4671 [36:04<1:36:45,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1267/4671 [36:04<1:36:17,  1.70s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1267/4671 [36:05<1:36:17,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1268/4671 [36:05<1:36:21,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1268/4671 [36:07<1:36:21,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1269/4671 [36:07<1:37:22,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1269/4671 [36:09<1:37:22,  1.72s/it, training_loss=0.205]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1270/4671 [36:09<1:37:29,  1.72s/it, training_loss=0.205]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1270/4671 [36:11<1:37:29,  1.72s/it, training_loss=0.212]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1271/4671 [36:11<1:37:03,  1.71s/it, training_loss=0.212]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1271/4671 [36:12<1:37:03,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1272/4671 [36:12<1:37:05,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1272/4671 [36:14<1:37:05,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1273/4671 [36:14<1:36:57,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1273/4671 [36:16<1:36:57,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1274/4671 [36:16<1:36:38,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1274/4671 [36:17<1:36:38,  1.71s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1275/4671 [36:17<1:36:01,  1.70s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1275/4671 [36:19<1:36:01,  1.70s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1276/4671 [36:19<1:35:40,  1.69s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1276/4671 [36:21<1:35:40,  1.69s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1277/4671 [36:21<1:36:14,  1.70s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1277/4671 [36:22<1:36:14,  1.70s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1278/4671 [36:22<1:36:26,  1.71s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1278/4671 [36:24<1:36:26,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1279/4671 [36:24<1:40:47,  1.78s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1279/4671 [36:26<1:40:47,  1.78s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1280/4671 [36:26<1:43:38,  1.83s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1280/4671 [36:29<1:43:38,  1.83s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1281/4671 [36:29<1:59:37,  2.12s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1281/4671 [36:31<1:59:37,  2.12s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1282/4671 [36:31<1:56:33,  2.06s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1282/4671 [36:33<1:56:33,  2.06s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1283/4671 [36:33<1:54:06,  2.02s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1283/4671 [36:35<1:54:06,  2.02s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1284/4671 [36:35<1:49:24,  1.94s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 1284/4671 [36:37<1:49:24,  1.94s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1285/4671 [36:37<1:47:30,  1.90s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1285/4671 [36:38<1:47:30,  1.90s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1286/4671 [36:38<1:44:41,  1.86s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1286/4671 [36:40<1:44:41,  1.86s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1287/4671 [36:40<1:42:41,  1.82s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1287/4671 [36:42<1:42:41,  1.82s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1288/4671 [36:42<1:41:54,  1.81s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1288/4671 [36:44<1:41:54,  1.81s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1289/4671 [36:44<1:39:50,  1.77s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1289/4671 [36:45<1:39:50,  1.77s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1290/4671 [36:45<1:39:20,  1.76s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1290/4671 [36:47<1:39:20,  1.76s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1291/4671 [36:47<1:38:41,  1.75s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1291/4671 [36:49<1:38:41,  1.75s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1292/4671 [36:49<1:38:38,  1.75s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1292/4671 [36:50<1:38:38,  1.75s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1293/4671 [36:50<1:38:19,  1.75s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1293/4671 [36:52<1:38:19,  1.75s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1294/4671 [36:52<1:40:05,  1.78s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1294/4671 [36:54<1:40:05,  1.78s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1295/4671 [36:54<1:42:24,  1.82s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1295/4671 [36:56<1:42:24,  1.82s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1296/4671 [36:56<1:42:29,  1.82s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1296/4671 [36:58<1:42:29,  1.82s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1297/4671 [36:58<1:42:08,  1.82s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1297/4671 [37:00<1:42:08,  1.82s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1298/4671 [37:00<1:40:38,  1.79s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1298/4671 [37:01<1:40:38,  1.79s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1299/4671 [37:01<1:40:12,  1.78s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1299/4671 [37:03<1:40:12,  1.78s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1300/4671 [37:03<1:41:40,  1.81s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1300/4671 [37:05<1:41:40,  1.81s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1301/4671 [37:05<1:41:59,  1.82s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1301/4671 [37:07<1:41:59,  1.82s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1302/4671 [37:07<1:40:58,  1.80s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1302/4671 [37:09<1:40:58,  1.80s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1303/4671 [37:09<1:40:07,  1.78s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1303/4671 [37:10<1:40:07,  1.78s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1304/4671 [37:10<1:40:56,  1.80s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1304/4671 [37:12<1:40:56,  1.80s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1305/4671 [37:12<1:40:00,  1.78s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1305/4671 [37:14<1:40:00,  1.78s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1306/4671 [37:14<1:39:30,  1.77s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1306/4671 [37:16<1:39:30,  1.77s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1307/4671 [37:16<1:38:16,  1.75s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1307/4671 [37:17<1:38:16,  1.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1308/4671 [37:17<1:39:49,  1.78s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1308/4671 [37:19<1:39:49,  1.78s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1309/4671 [37:19<1:40:39,  1.80s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1309/4671 [37:21<1:40:39,  1.80s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1310/4671 [37:21<1:40:52,  1.80s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1310/4671 [37:23<1:40:52,  1.80s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1311/4671 [37:23<1:40:45,  1.80s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1311/4671 [37:25<1:40:45,  1.80s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1312/4671 [37:25<1:41:25,  1.81s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1312/4671 [37:27<1:41:25,  1.81s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1313/4671 [37:27<1:41:52,  1.82s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1313/4671 [37:28<1:41:52,  1.82s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1314/4671 [37:28<1:40:49,  1.80s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1314/4671 [37:30<1:40:49,  1.80s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1315/4671 [37:30<1:40:37,  1.80s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1315/4671 [37:32<1:40:37,  1.80s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1316/4671 [37:32<1:39:00,  1.77s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1316/4671 [37:34<1:39:00,  1.77s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1317/4671 [37:34<1:38:22,  1.76s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1317/4671 [37:35<1:38:22,  1.76s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1318/4671 [37:35<1:38:11,  1.76s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1318/4671 [37:37<1:38:11,  1.76s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1319/4671 [37:37<1:37:51,  1.75s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1319/4671 [37:39<1:37:51,  1.75s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1320/4671 [37:39<1:37:30,  1.75s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1320/4671 [37:41<1:37:30,  1.75s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1321/4671 [37:41<1:37:46,  1.75s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1321/4671 [37:42<1:37:46,  1.75s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1322/4671 [37:42<1:36:35,  1.73s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1322/4671 [37:44<1:36:35,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1323/4671 [37:44<1:35:47,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1323/4671 [37:46<1:35:47,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1324/4671 [37:46<1:36:03,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1324/4671 [37:47<1:36:03,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1325/4671 [37:47<1:36:14,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1325/4671 [37:49<1:36:14,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1326/4671 [37:49<1:35:46,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1326/4671 [37:51<1:35:46,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1327/4671 [37:51<1:36:41,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1327/4671 [37:53<1:36:41,  1.73s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1328/4671 [37:53<1:37:33,  1.75s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1328/4671 [37:54<1:37:33,  1.75s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1329/4671 [37:54<1:37:11,  1.74s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1329/4671 [37:56<1:37:11,  1.74s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1330/4671 [37:56<1:36:42,  1.74s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1330/4671 [37:58<1:36:42,  1.74s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1331/4671 [37:58<1:36:58,  1.74s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 1331/4671 [38:00<1:36:58,  1.74s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1332/4671 [38:00<1:36:07,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1332/4671 [38:01<1:36:07,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1333/4671 [38:01<1:35:38,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1333/4671 [38:03<1:35:38,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1334/4671 [38:03<1:37:03,  1.75s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1334/4671 [38:05<1:37:03,  1.75s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1335/4671 [38:05<1:37:06,  1.75s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1335/4671 [38:07<1:37:06,  1.75s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1336/4671 [38:07<1:37:09,  1.75s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1336/4671 [38:08<1:37:09,  1.75s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1337/4671 [38:08<1:36:19,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1337/4671 [38:10<1:36:19,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1338/4671 [38:10<1:36:37,  1.74s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1338/4671 [38:12<1:36:37,  1.74s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1339/4671 [38:12<1:36:16,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1339/4671 [38:13<1:36:16,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1340/4671 [38:13<1:36:21,  1.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1340/4671 [38:15<1:36:21,  1.74s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1341/4671 [38:15<1:36:30,  1.74s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1341/4671 [38:17<1:36:30,  1.74s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1342/4671 [38:17<1:36:29,  1.74s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 1342/4671 [38:19<1:36:29,  1.74s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1343/4671 [38:19<1:35:52,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1343/4671 [38:20<1:35:52,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1344/4671 [38:20<1:35:20,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1344/4671 [38:22<1:35:20,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1345/4671 [38:22<1:35:03,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1345/4671 [38:24<1:35:03,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1346/4671 [38:24<1:34:58,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1346/4671 [38:26<1:34:58,  1.71s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1347/4671 [38:26<1:35:25,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1347/4671 [38:27<1:35:25,  1.72s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1348/4671 [38:27<1:34:57,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1348/4671 [38:29<1:34:57,  1.71s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1349/4671 [38:29<1:35:17,  1.72s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1349/4671 [38:31<1:35:17,  1.72s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1350/4671 [38:31<1:35:51,  1.73s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1350/4671 [38:32<1:35:51,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1351/4671 [38:32<1:35:37,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1351/4671 [38:34<1:35:37,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1352/4671 [38:34<1:36:08,  1.74s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1352/4671 [38:36<1:36:08,  1.74s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1353/4671 [38:36<1:36:05,  1.74s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1353/4671 [38:38<1:36:05,  1.74s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1354/4671 [38:38<1:35:38,  1.73s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1354/4671 [38:39<1:35:38,  1.73s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1355/4671 [38:39<1:35:01,  1.72s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1355/4671 [38:41<1:35:01,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1356/4671 [38:41<1:35:27,  1.73s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1356/4671 [38:43<1:35:27,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1357/4671 [38:43<1:36:36,  1.75s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1357/4671 [38:45<1:36:36,  1.75s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1358/4671 [38:45<1:36:24,  1.75s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1358/4671 [38:46<1:36:24,  1.75s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1359/4671 [38:46<1:35:53,  1.74s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1359/4671 [38:48<1:35:53,  1.74s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1360/4671 [38:48<1:35:18,  1.73s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1360/4671 [38:50<1:35:18,  1.73s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1361/4671 [38:50<1:35:11,  1.73s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1361/4671 [38:51<1:35:11,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1362/4671 [38:51<1:34:24,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1362/4671 [38:53<1:34:24,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1363/4671 [38:53<1:34:44,  1.72s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1363/4671 [38:55<1:34:44,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1364/4671 [38:55<1:35:01,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1364/4671 [38:57<1:35:01,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1365/4671 [38:57<1:35:07,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1365/4671 [38:58<1:35:07,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1366/4671 [38:58<1:35:56,  1.74s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1366/4671 [39:00<1:35:56,  1.74s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1367/4671 [39:00<1:35:24,  1.73s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1367/4671 [39:02<1:35:24,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1368/4671 [39:02<1:34:56,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1368/4671 [39:04<1:34:56,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1369/4671 [39:04<1:34:17,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1369/4671 [39:05<1:34:17,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1370/4671 [39:05<1:34:53,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1370/4671 [39:07<1:34:53,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1371/4671 [39:07<1:34:35,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1371/4671 [39:09<1:34:35,  1.72s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1372/4671 [39:09<1:35:22,  1.73s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1372/4671 [39:10<1:35:22,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1373/4671 [39:10<1:34:34,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1373/4671 [39:12<1:34:34,  1.72s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1374/4671 [39:12<1:34:06,  1.71s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1374/4671 [39:14<1:34:06,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1375/4671 [39:14<1:34:38,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1375/4671 [39:16<1:34:38,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1376/4671 [39:16<1:34:05,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1376/4671 [39:17<1:34:05,  1.71s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1377/4671 [39:17<1:34:06,  1.71s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 1377/4671 [39:19<1:34:06,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1378/4671 [39:19<1:34:30,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1378/4671 [39:21<1:34:30,  1.72s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1379/4671 [39:21<1:34:28,  1.72s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1379/4671 [39:23<1:34:28,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1380/4671 [39:23<1:36:11,  1.75s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1380/4671 [39:24<1:36:11,  1.75s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1381/4671 [39:24<1:36:36,  1.76s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1381/4671 [39:26<1:36:36,  1.76s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1382/4671 [39:26<1:36:34,  1.76s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1382/4671 [39:28<1:36:34,  1.76s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1383/4671 [39:28<1:36:02,  1.75s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1383/4671 [39:30<1:36:02,  1.75s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1384/4671 [39:30<1:36:04,  1.75s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1384/4671 [39:31<1:36:04,  1.75s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1385/4671 [39:31<1:35:44,  1.75s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1385/4671 [39:33<1:35:44,  1.75s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1386/4671 [39:33<1:35:41,  1.75s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1386/4671 [39:35<1:35:41,  1.75s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1387/4671 [39:35<1:34:21,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1387/4671 [39:37<1:34:21,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1388/4671 [39:37<1:35:08,  1.74s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1388/4671 [39:38<1:35:08,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1389/4671 [39:38<1:37:24,  1.78s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1389/4671 [39:40<1:37:24,  1.78s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1390/4671 [39:40<1:36:38,  1.77s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1390/4671 [39:42<1:36:38,  1.77s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1391/4671 [39:42<1:36:24,  1.76s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1391/4671 [39:44<1:36:24,  1.76s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1392/4671 [39:44<1:35:50,  1.75s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1392/4671 [39:45<1:35:50,  1.75s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1393/4671 [39:45<1:34:41,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1393/4671 [39:47<1:34:41,  1.73s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1394/4671 [39:47<1:34:53,  1.74s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1394/4671 [39:49<1:34:53,  1.74s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1395/4671 [39:49<1:34:31,  1.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1395/4671 [39:51<1:34:31,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1396/4671 [39:51<1:34:24,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1396/4671 [39:52<1:34:24,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1397/4671 [39:52<1:34:05,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1397/4671 [39:54<1:34:05,  1.72s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1398/4671 [39:54<1:33:34,  1.72s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1398/4671 [39:56<1:33:34,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1399/4671 [39:56<1:33:34,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1399/4671 [39:57<1:33:34,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1400/4671 [39:57<1:33:55,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1400/4671 [39:59<1:33:55,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1401/4671 [39:59<1:34:38,  1.74s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 1401/4671 [40:01<1:34:38,  1.74s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  30%|███       | 1402/4671 [40:01<1:34:26,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  30%|███       | 1402/4671 [40:03<1:34:26,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  30%|███       | 1403/4671 [40:03<1:35:00,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  30%|███       | 1403/4671 [40:04<1:35:00,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  30%|███       | 1404/4671 [40:04<1:34:38,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  30%|███       | 1404/4671 [40:06<1:34:38,  1.74s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  30%|███       | 1405/4671 [40:06<1:34:40,  1.74s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  30%|███       | 1405/4671 [40:08<1:34:40,  1.74s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  30%|███       | 1406/4671 [40:08<1:33:52,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  30%|███       | 1406/4671 [40:10<1:33:52,  1.73s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  30%|███       | 1407/4671 [40:10<1:33:45,  1.72s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  30%|███       | 1407/4671 [40:11<1:33:45,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  30%|███       | 1408/4671 [40:11<1:34:51,  1.74s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  30%|███       | 1408/4671 [40:13<1:34:51,  1.74s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  30%|███       | 1409/4671 [40:13<1:35:02,  1.75s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  30%|███       | 1409/4671 [40:15<1:35:02,  1.75s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  30%|███       | 1410/4671 [40:15<1:35:19,  1.75s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  30%|███       | 1410/4671 [40:17<1:35:19,  1.75s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  30%|███       | 1411/4671 [40:17<1:34:50,  1.75s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  30%|███       | 1411/4671 [40:18<1:34:50,  1.75s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  30%|███       | 1412/4671 [40:18<1:35:14,  1.75s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  30%|███       | 1412/4671 [40:20<1:35:14,  1.75s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  30%|███       | 1413/4671 [40:20<1:34:38,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  30%|███       | 1413/4671 [40:22<1:34:38,  1.74s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  30%|███       | 1414/4671 [40:22<1:34:58,  1.75s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  30%|███       | 1414/4671 [40:24<1:34:58,  1.75s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  30%|███       | 1415/4671 [40:24<1:34:38,  1.74s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  30%|███       | 1415/4671 [40:25<1:34:38,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  30%|███       | 1416/4671 [40:25<1:34:15,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  30%|███       | 1416/4671 [40:27<1:34:15,  1.74s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  30%|███       | 1417/4671 [40:27<1:34:16,  1.74s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  30%|███       | 1417/4671 [40:29<1:34:16,  1.74s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  30%|███       | 1418/4671 [40:29<1:34:04,  1.74s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  30%|███       | 1418/4671 [40:30<1:34:04,  1.74s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  30%|███       | 1419/4671 [40:30<1:33:38,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  30%|███       | 1419/4671 [40:32<1:33:38,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  30%|███       | 1420/4671 [40:32<1:33:40,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  30%|███       | 1420/4671 [40:34<1:33:40,  1.73s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  30%|███       | 1421/4671 [40:34<1:34:26,  1.74s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  30%|███       | 1421/4671 [40:36<1:34:26,  1.74s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  30%|███       | 1422/4671 [40:36<1:34:19,  1.74s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  30%|███       | 1422/4671 [40:37<1:34:19,  1.74s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  30%|███       | 1423/4671 [40:37<1:34:23,  1.74s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  30%|███       | 1423/4671 [40:39<1:34:23,  1.74s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  30%|███       | 1424/4671 [40:39<1:33:03,  1.72s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  30%|███       | 1424/4671 [40:41<1:33:03,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  31%|███       | 1425/4671 [40:41<1:32:46,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  31%|███       | 1425/4671 [40:43<1:32:46,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  31%|███       | 1426/4671 [40:43<1:33:15,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  31%|███       | 1426/4671 [40:44<1:33:15,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  31%|███       | 1427/4671 [40:44<1:33:28,  1.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  31%|███       | 1427/4671 [40:46<1:33:28,  1.73s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  31%|███       | 1428/4671 [40:46<1:33:40,  1.73s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  31%|███       | 1428/4671 [40:48<1:33:40,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  31%|███       | 1429/4671 [40:48<1:33:13,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  31%|███       | 1429/4671 [40:50<1:33:13,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  31%|███       | 1430/4671 [40:50<1:33:34,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  31%|███       | 1430/4671 [40:51<1:33:34,  1.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  31%|███       | 1431/4671 [40:51<1:33:46,  1.74s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  31%|███       | 1431/4671 [40:53<1:33:46,  1.74s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  31%|███       | 1432/4671 [40:53<1:33:21,  1.73s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  31%|███       | 1432/4671 [40:55<1:33:21,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  31%|███       | 1433/4671 [40:55<1:32:56,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  31%|███       | 1433/4671 [40:56<1:32:56,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  31%|███       | 1434/4671 [40:56<1:33:03,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  31%|███       | 1434/4671 [40:58<1:33:03,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  31%|███       | 1435/4671 [40:58<1:33:51,  1.74s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  31%|███       | 1435/4671 [41:00<1:33:51,  1.74s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  31%|███       | 1436/4671 [41:00<1:34:12,  1.75s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  31%|███       | 1436/4671 [41:02<1:34:12,  1.75s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  31%|███       | 1437/4671 [41:02<1:34:09,  1.75s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  31%|███       | 1437/4671 [41:03<1:34:09,  1.75s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  31%|███       | 1438/4671 [41:03<1:32:18,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  31%|███       | 1438/4671 [41:05<1:32:18,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  31%|███       | 1439/4671 [41:05<1:32:52,  1.72s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  31%|███       | 1439/4671 [41:07<1:32:52,  1.72s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  31%|███       | 1440/4671 [41:07<1:32:51,  1.72s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  31%|███       | 1440/4671 [41:09<1:32:51,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  31%|███       | 1441/4671 [41:09<1:33:15,  1.73s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  31%|███       | 1441/4671 [41:10<1:33:15,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  31%|███       | 1442/4671 [41:10<1:33:25,  1.74s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  31%|███       | 1442/4671 [41:12<1:33:25,  1.74s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  31%|███       | 1443/4671 [41:12<1:32:47,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  31%|███       | 1443/4671 [41:14<1:32:47,  1.72s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  31%|███       | 1444/4671 [41:14<1:32:45,  1.72s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  31%|███       | 1444/4671 [41:15<1:32:45,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  31%|███       | 1445/4671 [41:15<1:32:56,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  31%|███       | 1445/4671 [41:17<1:32:56,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  31%|███       | 1446/4671 [41:17<1:32:41,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  31%|███       | 1446/4671 [41:19<1:32:41,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  31%|███       | 1447/4671 [41:19<1:33:06,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  31%|███       | 1447/4671 [41:21<1:33:06,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  31%|███       | 1448/4671 [41:21<1:33:17,  1.74s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  31%|███       | 1448/4671 [41:22<1:33:17,  1.74s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  31%|███       | 1449/4671 [41:22<1:32:48,  1.73s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  31%|███       | 1449/4671 [41:24<1:32:48,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  31%|███       | 1450/4671 [41:24<1:32:36,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  31%|███       | 1450/4671 [41:26<1:32:36,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  31%|███       | 1451/4671 [41:26<1:32:56,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  31%|███       | 1451/4671 [41:28<1:32:56,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  31%|███       | 1452/4671 [41:28<1:33:05,  1.74s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  31%|███       | 1452/4671 [41:29<1:33:05,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  31%|███       | 1453/4671 [41:29<1:32:50,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  31%|███       | 1453/4671 [41:31<1:32:50,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  31%|███       | 1454/4671 [41:31<1:32:55,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  31%|███       | 1454/4671 [41:33<1:32:55,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  31%|███       | 1455/4671 [41:33<1:33:03,  1.74s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  31%|███       | 1455/4671 [41:35<1:33:03,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  31%|███       | 1456/4671 [41:35<1:32:51,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  31%|███       | 1456/4671 [41:36<1:32:51,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  31%|███       | 1457/4671 [41:36<1:32:03,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  31%|███       | 1457/4671 [41:38<1:32:03,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  31%|███       | 1458/4671 [41:38<1:32:04,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  31%|███       | 1458/4671 [41:40<1:32:04,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  31%|███       | 1459/4671 [41:40<1:32:04,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  31%|███       | 1459/4671 [41:41<1:32:04,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1460/4671 [41:41<1:32:03,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1460/4671 [41:43<1:32:03,  1.72s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1461/4671 [41:43<1:32:10,  1.72s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1461/4671 [41:45<1:32:10,  1.72s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1462/4671 [41:45<1:32:31,  1.73s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1462/4671 [41:47<1:32:31,  1.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1463/4671 [41:47<1:32:16,  1.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1463/4671 [41:48<1:32:16,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1464/4671 [41:48<1:32:02,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1464/4671 [41:50<1:32:02,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1465/4671 [41:50<1:32:02,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1465/4671 [41:52<1:32:02,  1.72s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1466/4671 [41:52<1:32:37,  1.73s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1466/4671 [41:54<1:32:37,  1.73s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1467/4671 [41:54<1:32:56,  1.74s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1467/4671 [41:55<1:32:56,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1468/4671 [41:55<1:31:58,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1468/4671 [41:57<1:31:58,  1.72s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1469/4671 [41:57<1:31:15,  1.71s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1469/4671 [41:59<1:31:15,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1470/4671 [41:59<1:31:27,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1470/4671 [42:00<1:31:27,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1471/4671 [42:00<1:31:33,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 1471/4671 [42:02<1:31:33,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1472/4671 [42:02<1:31:33,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1472/4671 [42:04<1:31:33,  1.72s/it, training_loss=0.199]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1473/4671 [42:04<1:32:01,  1.73s/it, training_loss=0.199]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1473/4671 [42:06<1:32:01,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1474/4671 [42:06<1:32:47,  1.74s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1474/4671 [42:07<1:32:47,  1.74s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1475/4671 [42:07<1:32:21,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1475/4671 [42:09<1:32:21,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1476/4671 [42:09<1:32:59,  1.75s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1476/4671 [42:11<1:32:59,  1.75s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1477/4671 [42:11<1:32:21,  1.74s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1477/4671 [42:12<1:32:21,  1.74s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1478/4671 [42:12<1:31:22,  1.72s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1478/4671 [42:14<1:31:22,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1479/4671 [42:14<1:31:01,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1479/4671 [42:16<1:31:01,  1.71s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1480/4671 [42:16<1:30:14,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1480/4671 [42:18<1:30:14,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1481/4671 [42:18<1:30:25,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1481/4671 [42:19<1:30:25,  1.70s/it, training_loss=0.077]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1482/4671 [42:19<1:30:36,  1.70s/it, training_loss=0.077]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1482/4671 [42:21<1:30:36,  1.70s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1483/4671 [42:21<1:31:06,  1.71s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1483/4671 [42:23<1:31:06,  1.71s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1484/4671 [42:23<1:31:06,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1484/4671 [42:24<1:31:06,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1485/4671 [42:24<1:30:36,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1485/4671 [42:26<1:30:36,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1486/4671 [42:26<1:30:23,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1486/4671 [42:28<1:30:23,  1.70s/it, training_loss=0.183]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1487/4671 [42:28<1:30:18,  1.70s/it, training_loss=0.183]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1487/4671 [42:29<1:30:18,  1.70s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1488/4671 [42:29<1:30:48,  1.71s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1488/4671 [42:31<1:30:48,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1489/4671 [42:31<1:30:54,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1489/4671 [42:33<1:30:54,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1490/4671 [42:33<1:31:09,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1490/4671 [42:35<1:31:09,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1491/4671 [42:35<1:31:11,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1491/4671 [42:36<1:31:11,  1.72s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1492/4671 [42:36<1:31:09,  1.72s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1492/4671 [42:38<1:31:09,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1493/4671 [42:38<1:31:01,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1493/4671 [42:40<1:31:01,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1494/4671 [42:40<1:30:51,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1494/4671 [42:42<1:30:51,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1495/4671 [42:42<1:30:45,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1495/4671 [42:43<1:30:45,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1496/4671 [42:43<1:31:34,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1496/4671 [42:45<1:31:34,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1497/4671 [42:45<1:31:36,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1497/4671 [42:47<1:31:36,  1.73s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1498/4671 [42:47<1:30:59,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1498/4671 [42:48<1:30:59,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1499/4671 [42:48<1:30:55,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1499/4671 [42:50<1:30:55,  1.72s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1500/4671 [42:50<1:30:51,  1.72s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1500/4671 [42:52<1:30:51,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1501/4671 [42:52<1:31:18,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1501/4671 [42:54<1:31:18,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1502/4671 [42:54<1:31:03,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1502/4671 [42:55<1:31:03,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1503/4671 [42:55<1:30:38,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1503/4671 [42:57<1:30:38,  1.72s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1504/4671 [42:57<1:30:56,  1.72s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1504/4671 [42:59<1:30:56,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1505/4671 [42:59<1:30:55,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1505/4671 [43:00<1:30:55,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1506/4671 [43:01<1:30:56,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1506/4671 [43:02<1:30:56,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1507/4671 [43:02<1:30:20,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1507/4671 [43:04<1:30:20,  1.71s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1508/4671 [43:04<1:30:43,  1.72s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1508/4671 [43:06<1:30:43,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1509/4671 [43:06<1:30:35,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1509/4671 [43:07<1:30:35,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1510/4671 [43:07<1:30:40,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1510/4671 [43:09<1:30:40,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1511/4671 [43:09<1:30:44,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1511/4671 [43:11<1:30:44,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1512/4671 [43:11<1:30:45,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1512/4671 [43:13<1:30:45,  1.72s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1513/4671 [43:13<1:30:49,  1.73s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1513/4671 [43:14<1:30:49,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1514/4671 [43:14<1:30:19,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1514/4671 [43:16<1:30:19,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1515/4671 [43:16<1:30:09,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1515/4671 [43:18<1:30:09,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1516/4671 [43:18<1:30:49,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1516/4671 [43:19<1:30:49,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1517/4671 [43:19<1:31:13,  1.74s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1517/4671 [43:21<1:31:13,  1.74s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1518/4671 [43:21<1:31:03,  1.73s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 1518/4671 [43:23<1:31:03,  1.73s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1519/4671 [43:23<1:30:58,  1.73s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1519/4671 [43:25<1:30:58,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1520/4671 [43:25<1:30:35,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1520/4671 [43:26<1:30:35,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1521/4671 [43:26<1:30:59,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1521/4671 [43:28<1:30:59,  1.73s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1522/4671 [43:28<1:30:55,  1.73s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1522/4671 [43:30<1:30:55,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1523/4671 [43:30<1:30:42,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1523/4671 [43:32<1:30:42,  1.73s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1524/4671 [43:32<1:30:55,  1.73s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1524/4671 [43:33<1:30:55,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1525/4671 [43:33<1:30:31,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1525/4671 [43:35<1:30:31,  1.73s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1526/4671 [43:35<1:29:41,  1.71s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1526/4671 [43:37<1:29:41,  1.71s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1527/4671 [43:37<1:29:28,  1.71s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1527/4671 [43:38<1:29:28,  1.71s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1528/4671 [43:38<1:29:27,  1.71s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1528/4671 [43:40<1:29:27,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1529/4671 [43:40<1:28:45,  1.69s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1529/4671 [43:42<1:28:45,  1.69s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1530/4671 [43:42<1:29:56,  1.72s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1530/4671 [43:44<1:29:56,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1531/4671 [43:44<1:30:14,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1531/4671 [43:45<1:30:14,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1532/4671 [43:45<1:30:01,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1532/4671 [43:47<1:30:01,  1.72s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1533/4671 [43:47<1:29:54,  1.72s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1533/4671 [43:49<1:29:54,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1534/4671 [43:49<1:29:50,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1534/4671 [43:50<1:29:50,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1535/4671 [43:50<1:29:47,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1535/4671 [43:52<1:29:47,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1536/4671 [43:52<1:29:45,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1536/4671 [43:54<1:29:45,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1537/4671 [43:54<1:29:55,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1537/4671 [43:56<1:29:55,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1538/4671 [43:56<1:29:55,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1538/4671 [43:57<1:29:55,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1539/4671 [43:57<1:30:09,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1539/4671 [43:59<1:30:09,  1.73s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1540/4671 [43:59<1:29:30,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1540/4671 [44:01<1:29:30,  1.72s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1541/4671 [44:01<1:29:40,  1.72s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1541/4671 [44:02<1:29:40,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1542/4671 [44:02<1:29:52,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1542/4671 [44:04<1:29:52,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1543/4671 [44:04<1:29:48,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1543/4671 [44:06<1:29:48,  1.72s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1544/4671 [44:06<1:30:37,  1.74s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1544/4671 [44:08<1:30:37,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1545/4671 [44:08<1:29:57,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1545/4671 [44:09<1:29:57,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1546/4671 [44:09<1:29:56,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1546/4671 [44:11<1:29:56,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1547/4671 [44:11<1:30:20,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1547/4671 [44:13<1:30:20,  1.74s/it, training_loss=0.190]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1548/4671 [44:13<1:30:06,  1.73s/it, training_loss=0.190]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1548/4671 [44:15<1:30:06,  1.73s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1549/4671 [44:15<1:29:42,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1549/4671 [44:16<1:29:42,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1550/4671 [44:16<1:29:18,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1550/4671 [44:18<1:29:18,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1551/4671 [44:18<1:30:06,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1551/4671 [44:20<1:30:06,  1.73s/it, training_loss=0.194]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1552/4671 [44:20<1:29:35,  1.72s/it, training_loss=0.194]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1552/4671 [44:21<1:29:35,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1553/4671 [44:21<1:29:15,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1553/4671 [44:23<1:29:15,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1554/4671 [44:23<1:28:45,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1554/4671 [44:25<1:28:45,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1555/4671 [44:25<1:28:58,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1555/4671 [44:27<1:28:58,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1556/4671 [44:27<1:28:43,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1556/4671 [44:28<1:28:43,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1557/4671 [44:28<1:28:50,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1557/4671 [44:30<1:28:50,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1558/4671 [44:30<1:29:16,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1558/4671 [44:32<1:29:16,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1559/4671 [44:32<1:29:19,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1559/4671 [44:33<1:29:19,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1560/4671 [44:33<1:29:08,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1560/4671 [44:35<1:29:08,  1.72s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1561/4671 [44:35<1:28:50,  1.71s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1561/4671 [44:37<1:28:50,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1562/4671 [44:37<1:28:21,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1562/4671 [44:39<1:28:21,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1563/4671 [44:39<1:28:55,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1563/4671 [44:40<1:28:55,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1564/4671 [44:40<1:29:04,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 1564/4671 [44:42<1:29:04,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1565/4671 [44:42<1:29:08,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1565/4671 [44:44<1:29:08,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1566/4671 [44:44<1:29:46,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1566/4671 [44:46<1:29:46,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1567/4671 [44:46<1:29:35,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1567/4671 [44:47<1:29:35,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1568/4671 [44:47<1:29:05,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1568/4671 [44:49<1:29:05,  1.72s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1569/4671 [44:49<1:27:30,  1.69s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1569/4671 [44:51<1:27:30,  1.69s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1570/4671 [44:51<1:27:51,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1570/4671 [44:52<1:27:51,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1571/4671 [44:52<1:28:32,  1.71s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1571/4671 [44:54<1:28:32,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1572/4671 [44:54<1:28:16,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1572/4671 [44:56<1:28:16,  1.71s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1573/4671 [44:56<1:28:18,  1.71s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1573/4671 [44:57<1:28:18,  1.71s/it, training_loss=0.195]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1574/4671 [44:57<1:27:55,  1.70s/it, training_loss=0.195]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1574/4671 [44:59<1:27:55,  1.70s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1575/4671 [44:59<1:27:57,  1.70s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1575/4671 [45:01<1:27:57,  1.70s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1576/4671 [45:01<1:27:43,  1.70s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 1576/4671 [45:02<1:27:43,  1.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1577/4671 [45:02<1:27:14,  1.69s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1577/4671 [45:04<1:27:14,  1.69s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1578/4671 [45:04<1:28:02,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1578/4671 [45:06<1:28:02,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1579/4671 [45:06<1:27:36,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1579/4671 [45:08<1:27:36,  1.70s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1580/4671 [45:08<1:27:55,  1.71s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1580/4671 [45:09<1:27:55,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1581/4671 [45:09<1:28:20,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1581/4671 [45:11<1:28:20,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1582/4671 [45:11<1:28:20,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1582/4671 [45:13<1:28:20,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1583/4671 [45:13<1:28:51,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1583/4671 [45:15<1:28:51,  1.73s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1584/4671 [45:15<1:29:26,  1.74s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1584/4671 [45:16<1:29:26,  1.74s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1585/4671 [45:16<1:29:13,  1.73s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1585/4671 [45:18<1:29:13,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1586/4671 [45:18<1:29:11,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1586/4671 [45:20<1:29:11,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1587/4671 [45:20<1:29:05,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1587/4671 [45:22<1:29:05,  1.73s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1588/4671 [45:22<1:29:10,  1.74s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1588/4671 [45:23<1:29:10,  1.74s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1589/4671 [45:23<1:28:28,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1589/4671 [45:25<1:28:28,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1590/4671 [45:25<1:28:07,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1590/4671 [45:27<1:28:07,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1591/4671 [45:27<1:28:03,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1591/4671 [45:28<1:28:03,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1592/4671 [45:28<1:28:16,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1592/4671 [45:30<1:28:16,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1593/4671 [45:30<1:28:31,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1593/4671 [45:32<1:28:31,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1594/4671 [45:32<1:27:18,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1594/4671 [45:34<1:27:18,  1.70s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1595/4671 [45:34<1:27:51,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1595/4671 [45:35<1:27:51,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1596/4671 [45:35<1:28:29,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1596/4671 [45:37<1:28:29,  1.73s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1597/4671 [45:37<1:28:19,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1597/4671 [45:39<1:28:19,  1.72s/it, training_loss=0.080]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1598/4671 [45:39<1:28:43,  1.73s/it, training_loss=0.080]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1598/4671 [45:40<1:28:43,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1599/4671 [45:40<1:28:04,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1599/4671 [45:42<1:28:04,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1600/4671 [45:42<1:28:04,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1600/4671 [45:44<1:28:04,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1601/4671 [45:44<1:28:21,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1601/4671 [45:46<1:28:21,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1602/4671 [45:46<1:27:20,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1602/4671 [45:47<1:27:20,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1603/4671 [45:47<1:27:23,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1603/4671 [45:49<1:27:23,  1.71s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1604/4671 [45:49<1:27:42,  1.72s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1604/4671 [45:51<1:27:42,  1.72s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1605/4671 [45:51<1:27:35,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1605/4671 [45:52<1:27:35,  1.71s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1606/4671 [45:52<1:27:22,  1.71s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1606/4671 [45:54<1:27:22,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1607/4671 [45:54<1:27:31,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1607/4671 [45:56<1:27:31,  1.71s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1608/4671 [45:56<1:27:33,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1608/4671 [45:58<1:27:33,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1609/4671 [45:58<1:27:46,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1609/4671 [45:59<1:27:46,  1.72s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1610/4671 [45:59<1:28:18,  1.73s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1610/4671 [46:01<1:28:18,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1611/4671 [46:01<1:28:24,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 1611/4671 [46:03<1:28:24,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1612/4671 [46:03<1:28:07,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1612/4671 [46:05<1:28:07,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1613/4671 [46:05<1:28:11,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1613/4671 [46:06<1:28:11,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1614/4671 [46:06<1:27:54,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1614/4671 [46:08<1:27:54,  1.73s/it, training_loss=0.192]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1615/4671 [46:08<1:28:03,  1.73s/it, training_loss=0.192]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1615/4671 [46:10<1:28:03,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1616/4671 [46:10<1:27:39,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1616/4671 [46:11<1:27:39,  1.72s/it, training_loss=0.073]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1617/4671 [46:11<1:27:04,  1.71s/it, training_loss=0.073]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1617/4671 [46:13<1:27:04,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1618/4671 [46:13<1:27:05,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1618/4671 [46:15<1:27:05,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1619/4671 [46:15<1:27:17,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1619/4671 [46:17<1:27:17,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1620/4671 [46:17<1:27:02,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1620/4671 [46:18<1:27:02,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1621/4671 [46:18<1:27:06,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1621/4671 [46:20<1:27:06,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1622/4671 [46:20<1:26:14,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1622/4671 [46:22<1:26:14,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1623/4671 [46:22<1:26:07,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1623/4671 [46:23<1:26:07,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1624/4671 [46:23<1:26:01,  1.69s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1624/4671 [46:25<1:26:01,  1.69s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1625/4671 [46:25<1:26:45,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1625/4671 [46:27<1:26:45,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1626/4671 [46:27<1:26:52,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1626/4671 [46:28<1:26:52,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1627/4671 [46:28<1:27:23,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1627/4671 [46:30<1:27:23,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1628/4671 [46:30<1:26:40,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1628/4671 [46:32<1:26:40,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1629/4671 [46:32<1:26:50,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1629/4671 [46:34<1:26:50,  1.71s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1630/4671 [46:34<1:27:00,  1.72s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1630/4671 [46:35<1:27:00,  1.72s/it, training_loss=0.217]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1631/4671 [46:35<1:25:49,  1.69s/it, training_loss=0.217]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1631/4671 [46:37<1:25:49,  1.69s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1632/4671 [46:37<1:27:00,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1632/4671 [46:39<1:27:00,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1633/4671 [46:39<1:27:01,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1633/4671 [46:40<1:27:01,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1634/4671 [46:40<1:26:47,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 1634/4671 [46:42<1:26:47,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1635/4671 [46:42<1:27:05,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1635/4671 [46:44<1:27:05,  1.72s/it, training_loss=0.183]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1636/4671 [46:44<1:27:23,  1.73s/it, training_loss=0.183]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1636/4671 [46:46<1:27:23,  1.73s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1637/4671 [46:46<1:27:26,  1.73s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1637/4671 [46:47<1:27:26,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1638/4671 [46:47<1:27:12,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1638/4671 [46:49<1:27:12,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1639/4671 [46:49<1:26:57,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1639/4671 [46:51<1:26:57,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1640/4671 [46:51<1:26:59,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1640/4671 [46:53<1:26:59,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1641/4671 [46:53<1:27:02,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1641/4671 [46:54<1:27:02,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1642/4671 [46:54<1:26:49,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1642/4671 [46:56<1:26:49,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1643/4671 [46:56<1:26:25,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1643/4671 [46:58<1:26:25,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1644/4671 [46:58<1:25:56,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1644/4671 [46:59<1:25:56,  1.70s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1645/4671 [46:59<1:26:15,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1645/4671 [47:01<1:26:15,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1646/4671 [47:01<1:25:56,  1.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1646/4671 [47:03<1:25:56,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1647/4671 [47:03<1:25:12,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1647/4671 [47:04<1:25:12,  1.69s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1648/4671 [47:04<1:25:23,  1.69s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1648/4671 [47:06<1:25:23,  1.69s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1649/4671 [47:06<1:25:32,  1.70s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1649/4671 [47:08<1:25:32,  1.70s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1650/4671 [47:08<1:25:43,  1.70s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1650/4671 [47:10<1:25:43,  1.70s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1651/4671 [47:10<1:26:06,  1.71s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1651/4671 [47:11<1:26:06,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1652/4671 [47:11<1:25:21,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1652/4671 [47:13<1:25:21,  1.70s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1653/4671 [47:13<1:25:31,  1.70s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1653/4671 [47:15<1:25:31,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1654/4671 [47:15<1:26:06,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1654/4671 [47:16<1:26:06,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1655/4671 [47:16<1:26:17,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1655/4671 [47:18<1:26:17,  1.72s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1656/4671 [47:18<1:25:25,  1.70s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1656/4671 [47:20<1:25:25,  1.70s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1657/4671 [47:20<1:25:53,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1657/4671 [47:21<1:25:53,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1658/4671 [47:21<1:25:50,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 1658/4671 [47:23<1:25:50,  1.71s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1659/4671 [47:23<1:25:31,  1.70s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1659/4671 [47:25<1:25:31,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1660/4671 [47:25<1:26:01,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1660/4671 [47:27<1:26:01,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1661/4671 [47:27<1:25:59,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1661/4671 [47:28<1:25:59,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1662/4671 [47:28<1:26:28,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1662/4671 [47:30<1:26:28,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1663/4671 [47:30<1:26:14,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1663/4671 [47:32<1:26:14,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1664/4671 [47:32<1:26:23,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1664/4671 [47:33<1:26:23,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1665/4671 [47:33<1:25:33,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1665/4671 [47:35<1:25:33,  1.71s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1666/4671 [47:35<1:26:05,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1666/4671 [47:37<1:26:05,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1667/4671 [47:37<1:26:44,  1.73s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1667/4671 [47:39<1:26:44,  1.73s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1668/4671 [47:39<1:26:41,  1.73s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1668/4671 [47:40<1:26:41,  1.73s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1669/4671 [47:40<1:26:50,  1.74s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1669/4671 [47:42<1:26:50,  1.74s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1670/4671 [47:42<1:26:47,  1.74s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1670/4671 [47:44<1:26:47,  1.74s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1671/4671 [47:44<1:26:35,  1.73s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1671/4671 [47:46<1:26:35,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1672/4671 [47:46<1:25:36,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1672/4671 [47:47<1:25:36,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1673/4671 [47:47<1:26:10,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1673/4671 [47:49<1:26:10,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1674/4671 [47:49<1:25:31,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1674/4671 [47:51<1:25:31,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1675/4671 [47:51<1:25:15,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1675/4671 [47:52<1:25:15,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1676/4671 [47:52<1:25:43,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1676/4671 [47:54<1:25:43,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1677/4671 [47:54<1:24:53,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1677/4671 [47:56<1:24:53,  1.70s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1678/4671 [47:56<1:24:44,  1.70s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1678/4671 [47:58<1:24:44,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1679/4671 [47:58<1:25:02,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1679/4671 [47:59<1:25:02,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1680/4671 [47:59<1:25:21,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1680/4671 [48:01<1:25:21,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1681/4671 [48:01<1:24:46,  1.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1681/4671 [48:03<1:24:46,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1682/4671 [48:03<1:24:49,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1682/4671 [48:04<1:24:49,  1.70s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1683/4671 [48:04<1:26:01,  1.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1683/4671 [48:06<1:26:01,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1684/4671 [48:06<1:25:56,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1684/4671 [48:08<1:25:56,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1685/4671 [48:08<1:25:57,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1685/4671 [48:10<1:25:57,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1686/4671 [48:10<1:25:48,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1686/4671 [48:11<1:25:48,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1687/4671 [48:11<1:25:42,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1687/4671 [48:13<1:25:42,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1688/4671 [48:13<1:25:26,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1688/4671 [48:15<1:25:26,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1689/4671 [48:15<1:25:37,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1689/4671 [48:17<1:25:37,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1690/4671 [48:17<1:25:50,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1690/4671 [48:18<1:25:50,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1691/4671 [48:18<1:25:44,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1691/4671 [48:20<1:25:44,  1.73s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1692/4671 [48:20<1:25:11,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1692/4671 [48:22<1:25:11,  1.72s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1693/4671 [48:22<1:25:12,  1.72s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 1693/4671 [48:23<1:25:12,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1694/4671 [48:23<1:24:42,  1.71s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1694/4671 [48:25<1:24:42,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1695/4671 [48:25<1:24:56,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1695/4671 [48:27<1:24:56,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1696/4671 [48:27<1:24:51,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1696/4671 [48:28<1:24:51,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1697/4671 [48:28<1:24:45,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1697/4671 [48:30<1:24:45,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1698/4671 [48:30<1:24:27,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1698/4671 [48:32<1:24:27,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1699/4671 [48:32<1:25:02,  1.72s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1699/4671 [48:34<1:25:02,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1700/4671 [48:34<1:24:55,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1700/4671 [48:35<1:24:55,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1701/4671 [48:35<1:25:05,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1701/4671 [48:37<1:25:05,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1702/4671 [48:37<1:25:03,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1702/4671 [48:39<1:25:03,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1703/4671 [48:39<1:24:46,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1703/4671 [48:41<1:24:46,  1.71s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1704/4671 [48:41<1:25:07,  1.72s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 1704/4671 [48:42<1:25:07,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1705/4671 [48:42<1:25:15,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1705/4671 [48:44<1:25:15,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1706/4671 [48:44<1:26:09,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1706/4671 [48:46<1:26:09,  1.74s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1707/4671 [48:46<1:25:39,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1707/4671 [48:47<1:25:39,  1.73s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1708/4671 [48:47<1:25:31,  1.73s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1708/4671 [48:49<1:25:31,  1.73s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1709/4671 [48:49<1:24:52,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1709/4671 [48:51<1:24:52,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1710/4671 [48:51<1:24:58,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1710/4671 [48:53<1:24:58,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1711/4671 [48:53<1:24:23,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1711/4671 [48:54<1:24:23,  1.71s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1712/4671 [48:54<1:23:32,  1.69s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1712/4671 [48:56<1:23:32,  1.69s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1713/4671 [48:56<1:24:21,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1713/4671 [48:58<1:24:21,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1714/4671 [48:58<1:24:14,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1714/4671 [48:59<1:24:14,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1715/4671 [48:59<1:23:35,  1.70s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1715/4671 [49:01<1:23:35,  1.70s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1716/4671 [49:01<1:23:58,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1716/4671 [49:03<1:23:58,  1.71s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1717/4671 [49:03<1:23:28,  1.70s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1717/4671 [49:04<1:23:28,  1.70s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1718/4671 [49:04<1:23:19,  1.69s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1718/4671 [49:06<1:23:19,  1.69s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1719/4671 [49:06<1:23:57,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1719/4671 [49:08<1:23:57,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1720/4671 [49:08<1:24:18,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1720/4671 [49:10<1:24:18,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1721/4671 [49:10<1:26:15,  1.75s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1721/4671 [49:12<1:26:15,  1.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1722/4671 [49:12<1:27:43,  1.78s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1722/4671 [49:13<1:27:43,  1.78s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1723/4671 [49:13<1:27:42,  1.78s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1723/4671 [49:15<1:27:42,  1.78s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1724/4671 [49:15<1:26:18,  1.76s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1724/4671 [49:17<1:26:18,  1.76s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1725/4671 [49:17<1:25:55,  1.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1725/4671 [49:19<1:25:55,  1.75s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1726/4671 [49:19<1:26:04,  1.75s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1726/4671 [49:20<1:26:04,  1.75s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1727/4671 [49:20<1:25:06,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1727/4671 [49:22<1:25:06,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1728/4671 [49:22<1:25:04,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1728/4671 [49:24<1:25:04,  1.73s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1729/4671 [49:24<1:25:07,  1.74s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1729/4671 [49:25<1:25:07,  1.74s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1730/4671 [49:25<1:25:02,  1.74s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1730/4671 [49:27<1:25:02,  1.74s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1731/4671 [49:27<1:24:44,  1.73s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1731/4671 [49:29<1:24:44,  1.73s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1732/4671 [49:29<1:24:08,  1.72s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1732/4671 [49:31<1:24:08,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1733/4671 [49:31<1:24:25,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1733/4671 [49:32<1:24:25,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1734/4671 [49:32<1:24:27,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1734/4671 [49:34<1:24:27,  1.73s/it, training_loss=0.206]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1735/4671 [49:34<1:24:27,  1.73s/it, training_loss=0.206]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1735/4671 [49:36<1:24:27,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1736/4671 [49:36<1:24:26,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1736/4671 [49:38<1:24:26,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1737/4671 [49:38<1:24:13,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1737/4671 [49:39<1:24:13,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1738/4671 [49:39<1:24:03,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1738/4671 [49:41<1:24:03,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1739/4671 [49:41<1:23:41,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1739/4671 [49:43<1:23:41,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1740/4671 [49:43<1:23:09,  1.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1740/4671 [49:44<1:23:09,  1.70s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1741/4671 [49:44<1:23:15,  1.70s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1741/4671 [49:46<1:23:15,  1.70s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1742/4671 [49:46<1:23:55,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1742/4671 [49:48<1:23:55,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1743/4671 [49:48<1:24:10,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1743/4671 [49:50<1:24:10,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1744/4671 [49:50<1:23:47,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1744/4671 [49:51<1:23:47,  1.72s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1745/4671 [49:51<1:24:42,  1.74s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1745/4671 [49:53<1:24:42,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1746/4671 [49:53<1:24:22,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1746/4671 [49:55<1:24:22,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1747/4671 [49:55<1:24:53,  1.74s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1747/4671 [49:56<1:24:53,  1.74s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1748/4671 [49:56<1:24:26,  1.73s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1748/4671 [49:58<1:24:26,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1749/4671 [49:58<1:24:38,  1.74s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1749/4671 [50:00<1:24:38,  1.74s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1750/4671 [50:00<1:23:47,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1750/4671 [50:02<1:23:47,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1751/4671 [50:02<1:23:21,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 1751/4671 [50:03<1:23:21,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1752/4671 [50:03<1:23:31,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1752/4671 [50:05<1:23:31,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1753/4671 [50:05<1:23:43,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1753/4671 [50:07<1:23:43,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1754/4671 [50:07<1:23:44,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1754/4671 [50:09<1:23:44,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1755/4671 [50:09<1:23:43,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1755/4671 [50:10<1:23:43,  1.72s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1756/4671 [50:10<1:23:45,  1.72s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1756/4671 [50:12<1:23:45,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1757/4671 [50:12<1:23:24,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1757/4671 [50:14<1:23:24,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1758/4671 [50:14<1:22:44,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1758/4671 [50:15<1:22:44,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1759/4671 [50:15<1:22:44,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1759/4671 [50:17<1:22:44,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1760/4671 [50:17<1:22:34,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1760/4671 [50:19<1:22:34,  1.70s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1761/4671 [50:19<1:22:50,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1761/4671 [50:20<1:22:50,  1.71s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1762/4671 [50:20<1:22:53,  1.71s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1762/4671 [50:22<1:22:53,  1.71s/it, training_loss=0.072]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1763/4671 [50:22<1:22:55,  1.71s/it, training_loss=0.072]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1763/4671 [50:24<1:22:55,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1764/4671 [50:24<1:22:53,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1764/4671 [50:26<1:22:53,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1765/4671 [50:26<1:23:00,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1765/4671 [50:27<1:23:00,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1766/4671 [50:27<1:23:01,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1766/4671 [50:29<1:23:01,  1.71s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1767/4671 [50:29<1:23:34,  1.73s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1767/4671 [50:31<1:23:34,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1768/4671 [50:31<1:23:58,  1.74s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1768/4671 [50:33<1:23:58,  1.74s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1769/4671 [50:33<1:23:43,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1769/4671 [50:34<1:23:43,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1770/4671 [50:34<1:23:06,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1770/4671 [50:36<1:23:06,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1771/4671 [50:36<1:22:32,  1.71s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1771/4671 [50:38<1:22:32,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1772/4671 [50:38<1:23:11,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1772/4671 [50:39<1:23:11,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1773/4671 [50:39<1:22:26,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1773/4671 [50:41<1:22:26,  1.71s/it, training_loss=0.077]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1774/4671 [50:41<1:23:10,  1.72s/it, training_loss=0.077]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1774/4671 [50:43<1:23:10,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1775/4671 [50:43<1:22:50,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1775/4671 [50:45<1:22:50,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1776/4671 [50:45<1:23:05,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1776/4671 [50:46<1:23:05,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1777/4671 [50:46<1:22:57,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1777/4671 [50:48<1:22:57,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1778/4671 [50:48<1:23:16,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1778/4671 [50:50<1:23:16,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1779/4671 [50:50<1:22:50,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1779/4671 [50:51<1:22:50,  1.72s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1780/4671 [50:51<1:21:59,  1.70s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1780/4671 [50:53<1:21:59,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1781/4671 [50:53<1:22:05,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1781/4671 [50:55<1:22:05,  1.70s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1782/4671 [50:55<1:21:25,  1.69s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1782/4671 [50:56<1:21:25,  1.69s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1783/4671 [50:56<1:21:52,  1.70s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1783/4671 [50:58<1:21:52,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1784/4671 [50:58<1:21:28,  1.69s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1784/4671 [51:00<1:21:28,  1.69s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1785/4671 [51:00<1:21:57,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1785/4671 [51:02<1:21:57,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1786/4671 [51:02<1:22:30,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1786/4671 [51:03<1:22:30,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1787/4671 [51:03<1:22:35,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1787/4671 [51:05<1:22:35,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1788/4671 [51:05<1:22:11,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1788/4671 [51:07<1:22:11,  1.71s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1789/4671 [51:07<1:22:44,  1.72s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1789/4671 [51:08<1:22:44,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1790/4671 [51:08<1:22:25,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1790/4671 [51:10<1:22:25,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1791/4671 [51:10<1:22:21,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1791/4671 [51:12<1:22:21,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1792/4671 [51:12<1:22:53,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1792/4671 [51:14<1:22:53,  1.73s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1793/4671 [51:14<1:22:50,  1.73s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1793/4671 [51:15<1:22:50,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1794/4671 [51:15<1:22:30,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1794/4671 [51:17<1:22:30,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1795/4671 [51:17<1:22:29,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1795/4671 [51:19<1:22:29,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1796/4671 [51:19<1:21:58,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1796/4671 [51:20<1:21:58,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1797/4671 [51:20<1:21:33,  1.70s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1797/4671 [51:22<1:21:33,  1.70s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1798/4671 [51:22<1:21:31,  1.70s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 1798/4671 [51:24<1:21:31,  1.70s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1799/4671 [51:24<1:21:07,  1.69s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1799/4671 [51:26<1:21:07,  1.69s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1800/4671 [51:26<1:21:45,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1800/4671 [51:27<1:21:45,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1801/4671 [51:27<1:22:19,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1801/4671 [51:29<1:22:19,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1802/4671 [51:29<1:21:35,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1802/4671 [51:31<1:21:35,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1803/4671 [51:31<1:22:18,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1803/4671 [51:33<1:22:18,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1804/4671 [51:33<1:22:38,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1804/4671 [51:35<1:22:38,  1.73s/it, training_loss=0.072]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1805/4671 [51:35<1:36:05,  2.01s/it, training_loss=0.072]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1805/4671 [51:37<1:36:05,  2.01s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1806/4671 [51:37<1:33:26,  1.96s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1806/4671 [51:39<1:33:26,  1.96s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1807/4671 [51:39<1:30:24,  1.89s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1807/4671 [51:40<1:30:24,  1.89s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1808/4671 [51:40<1:27:24,  1.83s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1808/4671 [51:42<1:27:24,  1.83s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1809/4671 [51:42<1:25:41,  1.80s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1809/4671 [51:44<1:25:41,  1.80s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1810/4671 [51:44<1:24:38,  1.78s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 1810/4671 [51:46<1:24:38,  1.78s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1811/4671 [51:46<1:23:30,  1.75s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1811/4671 [51:47<1:23:30,  1.75s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1812/4671 [51:47<1:22:54,  1.74s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1812/4671 [51:49<1:22:54,  1.74s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1813/4671 [51:49<1:22:38,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1813/4671 [51:51<1:22:38,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1814/4671 [51:51<1:22:11,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1814/4671 [51:52<1:22:11,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1815/4671 [51:52<1:21:55,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1815/4671 [51:54<1:21:55,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1816/4671 [51:54<1:21:52,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1816/4671 [51:56<1:21:52,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1817/4671 [51:56<1:21:33,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1817/4671 [51:58<1:21:33,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1818/4671 [51:58<1:20:39,  1.70s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1818/4671 [51:59<1:20:39,  1.70s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1819/4671 [51:59<1:21:28,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1819/4671 [52:01<1:21:28,  1.71s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1820/4671 [52:01<1:21:25,  1.71s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1820/4671 [52:03<1:21:25,  1.71s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1821/4671 [52:03<1:21:20,  1.71s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1821/4671 [52:04<1:21:20,  1.71s/it, training_loss=0.190]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1822/4671 [52:04<1:20:31,  1.70s/it, training_loss=0.190]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1822/4671 [52:06<1:20:31,  1.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1823/4671 [52:06<1:20:45,  1.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1823/4671 [52:08<1:20:45,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1824/4671 [52:08<1:20:45,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1824/4671 [52:09<1:20:45,  1.70s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1825/4671 [52:10<1:21:00,  1.71s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1825/4671 [52:11<1:21:00,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1826/4671 [52:11<1:21:41,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1826/4671 [52:13<1:21:41,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1827/4671 [52:13<1:21:33,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1827/4671 [52:15<1:21:33,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1828/4671 [52:15<1:21:58,  1.73s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1828/4671 [52:16<1:21:58,  1.73s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1829/4671 [52:16<1:21:54,  1.73s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1829/4671 [52:18<1:21:54,  1.73s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1830/4671 [52:18<1:22:17,  1.74s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1830/4671 [52:20<1:22:17,  1.74s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1831/4671 [52:20<1:21:52,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1831/4671 [52:22<1:21:52,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1832/4671 [52:22<1:22:22,  1.74s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1832/4671 [52:23<1:22:22,  1.74s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1833/4671 [52:23<1:21:39,  1.73s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1833/4671 [52:25<1:21:39,  1.73s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1834/4671 [52:25<1:21:37,  1.73s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1834/4671 [52:27<1:21:37,  1.73s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1835/4671 [52:27<1:20:56,  1.71s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1835/4671 [52:29<1:20:56,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1836/4671 [52:29<1:21:00,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1836/4671 [52:30<1:21:00,  1.71s/it, training_loss=0.195]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1837/4671 [52:30<1:21:02,  1.72s/it, training_loss=0.195]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1837/4671 [52:32<1:21:02,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1838/4671 [52:32<1:20:53,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1838/4671 [52:34<1:20:53,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1839/4671 [52:34<1:20:42,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1839/4671 [52:35<1:20:42,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1840/4671 [52:35<1:20:37,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1840/4671 [52:37<1:20:37,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1841/4671 [52:37<1:21:03,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1841/4671 [52:39<1:21:03,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1842/4671 [52:39<1:21:02,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1842/4671 [52:41<1:21:02,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1843/4671 [52:41<1:21:07,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1843/4671 [52:42<1:21:07,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1844/4671 [52:42<1:20:53,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1844/4671 [52:44<1:20:53,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1845/4671 [52:44<1:20:16,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 1845/4671 [52:46<1:20:16,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1846/4671 [52:46<1:19:43,  1.69s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1846/4671 [52:47<1:19:43,  1.69s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1847/4671 [52:47<1:20:22,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1847/4671 [52:49<1:20:22,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1848/4671 [52:49<1:19:58,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1848/4671 [52:51<1:19:58,  1.70s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1849/4671 [52:51<1:20:15,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1849/4671 [52:52<1:20:15,  1.71s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1850/4671 [52:52<1:20:03,  1.70s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1850/4671 [52:54<1:20:03,  1.70s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1851/4671 [52:54<1:20:01,  1.70s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1851/4671 [52:56<1:20:01,  1.70s/it, training_loss=0.070]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1852/4671 [52:56<1:19:19,  1.69s/it, training_loss=0.070]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1852/4671 [52:57<1:19:19,  1.69s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1853/4671 [52:57<1:19:22,  1.69s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1853/4671 [52:59<1:19:22,  1.69s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1854/4671 [52:59<1:20:05,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1854/4671 [53:01<1:20:05,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1855/4671 [53:01<1:19:50,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1855/4671 [53:03<1:19:50,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1856/4671 [53:03<1:19:39,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1856/4671 [53:04<1:19:39,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1857/4671 [53:04<1:19:53,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1857/4671 [53:06<1:19:53,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1858/4671 [53:06<1:19:26,  1.69s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1858/4671 [53:08<1:19:26,  1.69s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1859/4671 [53:08<1:19:29,  1.70s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1859/4671 [53:09<1:19:29,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1860/4671 [53:09<1:19:51,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1860/4671 [53:11<1:19:51,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1861/4671 [53:11<1:20:30,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1861/4671 [53:13<1:20:30,  1.72s/it, training_loss=0.206]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1862/4671 [53:13<1:19:55,  1.71s/it, training_loss=0.206]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1862/4671 [53:15<1:19:55,  1.71s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1863/4671 [53:15<1:19:24,  1.70s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1863/4671 [53:16<1:19:24,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1864/4671 [53:16<1:19:50,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1864/4671 [53:18<1:19:50,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1865/4671 [53:18<1:20:21,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1865/4671 [53:20<1:20:21,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1866/4671 [53:20<1:20:41,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1866/4671 [53:21<1:20:41,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1867/4671 [53:21<1:19:59,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1867/4671 [53:23<1:19:59,  1.71s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1868/4671 [53:23<1:20:27,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 1868/4671 [53:25<1:20:27,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  40%|████      | 1869/4671 [53:25<1:20:17,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  40%|████      | 1869/4671 [53:27<1:20:17,  1.72s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  40%|████      | 1870/4671 [53:27<1:19:51,  1.71s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  40%|████      | 1870/4671 [53:28<1:19:51,  1.71s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  40%|████      | 1871/4671 [53:28<1:19:35,  1.71s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  40%|████      | 1871/4671 [53:30<1:19:35,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  40%|████      | 1872/4671 [53:30<1:19:53,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  40%|████      | 1872/4671 [53:32<1:19:53,  1.71s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  40%|████      | 1873/4671 [53:32<1:20:28,  1.73s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  40%|████      | 1873/4671 [53:33<1:20:28,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  40%|████      | 1874/4671 [53:33<1:20:21,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  40%|████      | 1874/4671 [53:35<1:20:21,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  40%|████      | 1875/4671 [53:35<1:19:40,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  40%|████      | 1875/4671 [53:37<1:19:40,  1.71s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  40%|████      | 1876/4671 [53:37<1:19:49,  1.71s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  40%|████      | 1876/4671 [53:39<1:19:49,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  40%|████      | 1877/4671 [53:39<1:20:07,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  40%|████      | 1877/4671 [53:40<1:20:07,  1.72s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  40%|████      | 1878/4671 [53:40<1:20:08,  1.72s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  40%|████      | 1878/4671 [53:42<1:20:08,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  40%|████      | 1879/4671 [53:42<1:19:26,  1.71s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  40%|████      | 1879/4671 [53:44<1:19:26,  1.71s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  40%|████      | 1880/4671 [53:44<1:19:27,  1.71s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  40%|████      | 1880/4671 [53:45<1:19:27,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  40%|████      | 1881/4671 [53:45<1:19:10,  1.70s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  40%|████      | 1881/4671 [53:47<1:19:10,  1.70s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  40%|████      | 1882/4671 [53:47<1:19:51,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  40%|████      | 1882/4671 [53:49<1:19:51,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  40%|████      | 1883/4671 [53:49<1:19:42,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  40%|████      | 1883/4671 [53:51<1:19:42,  1.72s/it, training_loss=0.217]\u001B[A\n",
      "Epoch 1:  40%|████      | 1884/4671 [53:51<1:19:14,  1.71s/it, training_loss=0.217]\u001B[A\n",
      "Epoch 1:  40%|████      | 1884/4671 [53:52<1:19:14,  1.71s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  40%|████      | 1885/4671 [53:52<1:18:59,  1.70s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  40%|████      | 1885/4671 [53:54<1:18:59,  1.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  40%|████      | 1886/4671 [53:54<1:19:02,  1.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  40%|████      | 1886/4671 [53:56<1:19:02,  1.70s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  40%|████      | 1887/4671 [53:56<1:19:44,  1.72s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  40%|████      | 1887/4671 [53:57<1:19:44,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  40%|████      | 1888/4671 [53:57<1:19:53,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  40%|████      | 1888/4671 [53:59<1:19:53,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  40%|████      | 1889/4671 [53:59<1:20:15,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  40%|████      | 1889/4671 [54:01<1:20:15,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  40%|████      | 1890/4671 [54:01<1:20:21,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  40%|████      | 1890/4671 [54:03<1:20:21,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  40%|████      | 1891/4671 [54:03<1:19:47,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  40%|████      | 1891/4671 [54:04<1:19:47,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  41%|████      | 1892/4671 [54:04<1:19:31,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  41%|████      | 1892/4671 [54:06<1:19:31,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  41%|████      | 1893/4671 [54:06<1:18:49,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  41%|████      | 1893/4671 [54:08<1:18:49,  1.70s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  41%|████      | 1894/4671 [54:08<1:18:58,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  41%|████      | 1894/4671 [54:09<1:18:58,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  41%|████      | 1895/4671 [54:09<1:19:38,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  41%|████      | 1895/4671 [54:11<1:19:38,  1.72s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  41%|████      | 1896/4671 [54:11<1:19:18,  1.71s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  41%|████      | 1896/4671 [54:13<1:19:18,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  41%|████      | 1897/4671 [54:13<1:19:36,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  41%|████      | 1897/4671 [54:15<1:19:36,  1.72s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  41%|████      | 1898/4671 [54:15<1:19:48,  1.73s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  41%|████      | 1898/4671 [54:16<1:19:48,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  41%|████      | 1899/4671 [54:16<1:19:59,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  41%|████      | 1899/4671 [54:18<1:19:59,  1.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  41%|████      | 1900/4671 [54:18<1:19:24,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  41%|████      | 1900/4671 [54:20<1:19:24,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  41%|████      | 1901/4671 [54:20<1:19:29,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  41%|████      | 1901/4671 [54:21<1:19:29,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  41%|████      | 1902/4671 [54:21<1:18:27,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  41%|████      | 1902/4671 [54:23<1:18:27,  1.70s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  41%|████      | 1903/4671 [54:23<1:19:04,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  41%|████      | 1903/4671 [54:25<1:19:04,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  41%|████      | 1904/4671 [54:25<1:18:52,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  41%|████      | 1904/4671 [54:27<1:18:52,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  41%|████      | 1905/4671 [54:27<1:19:00,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  41%|████      | 1905/4671 [54:28<1:19:00,  1.71s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  41%|████      | 1906/4671 [54:28<1:18:51,  1.71s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  41%|████      | 1906/4671 [54:30<1:18:51,  1.71s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  41%|████      | 1907/4671 [54:30<1:18:31,  1.70s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  41%|████      | 1907/4671 [54:32<1:18:31,  1.70s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  41%|████      | 1908/4671 [54:32<1:18:39,  1.71s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  41%|████      | 1908/4671 [54:33<1:18:39,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  41%|████      | 1909/4671 [54:33<1:18:53,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  41%|████      | 1909/4671 [54:35<1:18:53,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  41%|████      | 1910/4671 [54:35<1:19:27,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  41%|████      | 1910/4671 [54:37<1:19:27,  1.73s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  41%|████      | 1911/4671 [54:37<1:20:02,  1.74s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  41%|████      | 1911/4671 [54:39<1:20:02,  1.74s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  41%|████      | 1912/4671 [54:39<1:19:48,  1.74s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  41%|████      | 1912/4671 [54:40<1:19:48,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  41%|████      | 1913/4671 [54:40<1:19:47,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  41%|████      | 1913/4671 [54:42<1:19:47,  1.74s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  41%|████      | 1914/4671 [54:42<1:19:37,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  41%|████      | 1914/4671 [54:44<1:19:37,  1.73s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  41%|████      | 1915/4671 [54:44<1:19:30,  1.73s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  41%|████      | 1915/4671 [54:46<1:19:30,  1.73s/it, training_loss=0.080]\u001B[A\n",
      "Epoch 1:  41%|████      | 1916/4671 [54:46<1:18:54,  1.72s/it, training_loss=0.080]\u001B[A\n",
      "Epoch 1:  41%|████      | 1916/4671 [54:47<1:18:54,  1.72s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  41%|████      | 1917/4671 [54:47<1:19:22,  1.73s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  41%|████      | 1917/4671 [54:49<1:19:22,  1.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  41%|████      | 1918/4671 [54:49<1:19:19,  1.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  41%|████      | 1918/4671 [54:51<1:19:19,  1.73s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  41%|████      | 1919/4671 [54:51<1:19:06,  1.72s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  41%|████      | 1919/4671 [54:52<1:19:06,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  41%|████      | 1920/4671 [54:52<1:18:51,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  41%|████      | 1920/4671 [54:54<1:18:51,  1.72s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  41%|████      | 1921/4671 [54:54<1:18:38,  1.72s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  41%|████      | 1921/4671 [54:56<1:18:38,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  41%|████      | 1922/4671 [54:56<1:18:08,  1.71s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  41%|████      | 1922/4671 [54:58<1:18:08,  1.71s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  41%|████      | 1923/4671 [54:58<1:18:05,  1.71s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  41%|████      | 1923/4671 [54:59<1:18:05,  1.71s/it, training_loss=0.214]\u001B[A\n",
      "Epoch 1:  41%|████      | 1924/4671 [54:59<1:18:15,  1.71s/it, training_loss=0.214]\u001B[A\n",
      "Epoch 1:  41%|████      | 1924/4671 [55:01<1:18:15,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  41%|████      | 1925/4671 [55:01<1:18:45,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  41%|████      | 1925/4671 [55:03<1:18:45,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  41%|████      | 1926/4671 [55:03<1:18:11,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  41%|████      | 1926/4671 [55:04<1:18:11,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1927/4671 [55:04<1:17:50,  1.70s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1927/4671 [55:06<1:17:50,  1.70s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1928/4671 [55:06<1:18:23,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1928/4671 [55:08<1:18:23,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1929/4671 [55:08<1:18:31,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1929/4671 [55:10<1:18:31,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1930/4671 [55:10<1:18:25,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1930/4671 [55:11<1:18:25,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1931/4671 [55:11<1:18:44,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1931/4671 [55:13<1:18:44,  1.72s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1932/4671 [55:13<1:18:40,  1.72s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1932/4671 [55:15<1:18:40,  1.72s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1933/4671 [55:15<1:18:51,  1.73s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1933/4671 [55:17<1:18:51,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1934/4671 [55:17<1:18:46,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1934/4671 [55:18<1:18:46,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1935/4671 [55:18<1:19:01,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1935/4671 [55:20<1:19:01,  1.73s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1936/4671 [55:20<1:18:43,  1.73s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1936/4671 [55:22<1:18:43,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1937/4671 [55:22<1:18:21,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1937/4671 [55:23<1:18:21,  1.72s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1938/4671 [55:23<1:18:36,  1.73s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 1938/4671 [55:25<1:18:36,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1939/4671 [55:25<1:18:38,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1939/4671 [55:27<1:18:38,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1940/4671 [55:27<1:18:05,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1940/4671 [55:29<1:18:05,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1941/4671 [55:29<1:18:05,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1941/4671 [55:30<1:18:05,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1942/4671 [55:30<1:18:49,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1942/4671 [55:32<1:18:49,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1943/4671 [55:32<1:18:29,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1943/4671 [55:34<1:18:29,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1944/4671 [55:34<1:17:26,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1944/4671 [55:35<1:17:26,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1945/4671 [55:35<1:17:09,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1945/4671 [55:37<1:17:09,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1946/4671 [55:37<1:17:27,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1946/4671 [55:39<1:17:27,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1947/4671 [55:39<1:18:16,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1947/4671 [55:41<1:18:16,  1.72s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1948/4671 [55:41<1:18:36,  1.73s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1948/4671 [55:42<1:18:36,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1949/4671 [55:42<1:18:32,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1949/4671 [55:44<1:18:32,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1950/4671 [55:44<1:18:52,  1.74s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1950/4671 [55:46<1:18:52,  1.74s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1951/4671 [55:46<1:18:15,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1951/4671 [55:48<1:18:15,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1952/4671 [55:48<1:18:05,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1952/4671 [55:49<1:18:05,  1.72s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1953/4671 [55:49<1:17:38,  1.71s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1953/4671 [55:51<1:17:38,  1.71s/it, training_loss=0.209]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1954/4671 [55:51<1:17:17,  1.71s/it, training_loss=0.209]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1954/4671 [55:53<1:17:17,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1955/4671 [55:53<1:17:30,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1955/4671 [55:54<1:17:30,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1956/4671 [55:54<1:17:02,  1.70s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1956/4671 [55:56<1:17:02,  1.70s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1957/4671 [55:56<1:17:09,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1957/4671 [55:58<1:17:09,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1958/4671 [55:58<1:17:50,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1958/4671 [56:00<1:17:50,  1.72s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1959/4671 [56:00<1:18:23,  1.73s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1959/4671 [56:01<1:18:23,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1960/4671 [56:01<1:18:13,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1960/4671 [56:03<1:18:13,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1961/4671 [56:03<1:17:47,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1961/4671 [56:05<1:17:47,  1.72s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1962/4671 [56:05<1:17:36,  1.72s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1962/4671 [56:06<1:17:36,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1963/4671 [56:06<1:17:34,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1963/4671 [56:08<1:17:34,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1964/4671 [56:08<1:17:59,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1964/4671 [56:10<1:17:59,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1965/4671 [56:10<1:17:33,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1965/4671 [56:12<1:17:33,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1966/4671 [56:12<1:17:42,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1966/4671 [56:13<1:17:42,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1967/4671 [56:13<1:17:14,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1967/4671 [56:15<1:17:14,  1.71s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1968/4671 [56:15<1:17:25,  1.72s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1968/4671 [56:17<1:17:25,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1969/4671 [56:17<1:17:53,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1969/4671 [56:18<1:17:53,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1970/4671 [56:18<1:17:48,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1970/4671 [56:20<1:17:48,  1.73s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1971/4671 [56:20<1:17:09,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1971/4671 [56:22<1:17:09,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1972/4671 [56:22<1:17:14,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1972/4671 [56:24<1:17:14,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1973/4671 [56:24<1:17:41,  1.73s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1973/4671 [56:25<1:17:41,  1.73s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1974/4671 [56:25<1:17:17,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1974/4671 [56:27<1:17:17,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1975/4671 [56:27<1:16:41,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1975/4671 [56:29<1:16:41,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1976/4671 [56:29<1:16:30,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1976/4671 [56:30<1:16:30,  1.70s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1977/4671 [56:30<1:16:27,  1.70s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1977/4671 [56:32<1:16:27,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1978/4671 [56:32<1:16:14,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1978/4671 [56:34<1:16:14,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1979/4671 [56:34<1:15:45,  1.69s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1979/4671 [56:35<1:15:45,  1.69s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1980/4671 [56:35<1:16:10,  1.70s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1980/4671 [56:37<1:16:10,  1.70s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1981/4671 [56:37<1:15:40,  1.69s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1981/4671 [56:39<1:15:40,  1.69s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1982/4671 [56:39<1:16:10,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1982/4671 [56:41<1:16:10,  1.70s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1983/4671 [56:41<1:16:28,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1983/4671 [56:42<1:16:28,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1984/4671 [56:42<1:16:45,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1984/4671 [56:44<1:16:45,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1985/4671 [56:44<1:16:53,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 1985/4671 [56:46<1:16:53,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1986/4671 [56:46<1:17:05,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1986/4671 [56:48<1:17:05,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1987/4671 [56:48<1:17:07,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1987/4671 [56:49<1:17:07,  1.72s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1988/4671 [56:49<1:16:28,  1.71s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1988/4671 [56:51<1:16:28,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1989/4671 [56:51<1:16:28,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1989/4671 [56:53<1:16:28,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1990/4671 [56:53<1:16:28,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1990/4671 [56:54<1:16:28,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1991/4671 [56:54<1:16:38,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1991/4671 [56:56<1:16:38,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1992/4671 [56:56<1:16:46,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1992/4671 [56:58<1:16:46,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1993/4671 [56:58<1:16:36,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1993/4671 [56:59<1:16:36,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1994/4671 [56:59<1:16:19,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1994/4671 [57:01<1:16:19,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1995/4671 [57:01<1:16:32,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1995/4671 [57:03<1:16:32,  1.72s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1996/4671 [57:03<1:16:34,  1.72s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1996/4671 [57:05<1:16:34,  1.72s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1997/4671 [57:05<1:16:25,  1.71s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1997/4671 [57:06<1:16:25,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1998/4671 [57:06<1:16:23,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1998/4671 [57:08<1:16:23,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1999/4671 [57:08<1:16:33,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 1999/4671 [57:10<1:16:33,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2000/4671 [57:10<1:16:19,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2000/4671 [57:12<1:16:19,  1.71s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2001/4671 [57:12<1:16:26,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2001/4671 [57:13<1:16:26,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2002/4671 [57:13<1:15:42,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2002/4671 [57:15<1:15:42,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2003/4671 [57:15<1:16:24,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2003/4671 [57:17<1:16:24,  1.72s/it, training_loss=0.066]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2004/4671 [57:17<1:16:46,  1.73s/it, training_loss=0.066]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2004/4671 [57:18<1:16:46,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2005/4671 [57:18<1:16:36,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2005/4671 [57:20<1:16:36,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2006/4671 [57:20<1:16:08,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2006/4671 [57:22<1:16:08,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2007/4671 [57:22<1:15:30,  1.70s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2007/4671 [57:24<1:15:30,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2008/4671 [57:24<1:16:00,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2008/4671 [57:25<1:16:00,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2009/4671 [57:25<1:16:12,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2009/4671 [57:27<1:16:12,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2010/4671 [57:27<1:16:14,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2010/4671 [57:29<1:16:14,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2011/4671 [57:29<1:16:22,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2011/4671 [57:30<1:16:22,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2012/4671 [57:30<1:15:48,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2012/4671 [57:32<1:15:48,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2013/4671 [57:32<1:15:37,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2013/4671 [57:34<1:15:37,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2014/4671 [57:34<1:15:10,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2014/4671 [57:36<1:15:10,  1.70s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2015/4671 [57:36<1:15:56,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2015/4671 [57:37<1:15:56,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2016/4671 [57:37<1:15:37,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2016/4671 [57:39<1:15:37,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2017/4671 [57:39<1:15:57,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2017/4671 [57:41<1:15:57,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2018/4671 [57:41<1:16:32,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2018/4671 [57:42<1:16:32,  1.73s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2019/4671 [57:42<1:16:38,  1.73s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2019/4671 [57:44<1:16:38,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2020/4671 [57:44<1:16:03,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2020/4671 [57:46<1:16:03,  1.72s/it, training_loss=0.080]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2021/4671 [57:46<1:16:13,  1.73s/it, training_loss=0.080]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2021/4671 [57:48<1:16:13,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2022/4671 [57:48<1:15:32,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2022/4671 [57:49<1:15:32,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2023/4671 [57:49<1:15:46,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2023/4671 [57:51<1:15:46,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2024/4671 [57:51<1:15:51,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2024/4671 [57:53<1:15:51,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2025/4671 [57:53<1:15:40,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2025/4671 [57:54<1:15:40,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2026/4671 [57:54<1:15:09,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2026/4671 [57:56<1:15:09,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2027/4671 [57:56<1:15:24,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2027/4671 [57:58<1:15:24,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2028/4671 [57:58<1:14:41,  1.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2028/4671 [58:00<1:14:41,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2029/4671 [58:00<1:15:32,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2029/4671 [58:01<1:15:32,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2030/4671 [58:01<1:14:56,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2030/4671 [58:03<1:14:56,  1.70s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2031/4671 [58:03<1:15:25,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 2031/4671 [58:05<1:15:25,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2032/4671 [58:05<1:14:48,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2032/4671 [58:06<1:14:48,  1.70s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2033/4671 [58:06<1:15:00,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2033/4671 [58:08<1:15:00,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2034/4671 [58:08<1:15:10,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2034/4671 [58:10<1:15:10,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2035/4671 [58:10<1:15:14,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2035/4671 [58:12<1:15:14,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2036/4671 [58:12<1:15:33,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2036/4671 [58:13<1:15:33,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2037/4671 [58:13<1:15:21,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2037/4671 [58:15<1:15:21,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2038/4671 [58:15<1:15:06,  1.71s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2038/4671 [58:17<1:15:06,  1.71s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2039/4671 [58:17<1:14:55,  1.71s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2039/4671 [58:18<1:14:55,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2040/4671 [58:18<1:15:13,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2040/4671 [58:20<1:15:13,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2041/4671 [58:20<1:15:31,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2041/4671 [58:22<1:15:31,  1.72s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2042/4671 [58:22<1:15:24,  1.72s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2042/4671 [58:24<1:15:24,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2043/4671 [58:24<1:15:43,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 2043/4671 [58:25<1:15:43,  1.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2044/4671 [58:25<1:15:31,  1.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2044/4671 [58:27<1:15:31,  1.73s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2045/4671 [58:27<1:14:54,  1.71s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2045/4671 [58:29<1:14:54,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2046/4671 [58:29<1:14:50,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2046/4671 [58:30<1:14:50,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2047/4671 [58:30<1:15:10,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2047/4671 [58:32<1:15:10,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2048/4671 [58:32<1:14:54,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2048/4671 [58:34<1:14:54,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2049/4671 [58:34<1:14:24,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2049/4671 [58:36<1:14:24,  1.70s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2050/4671 [58:36<1:14:53,  1.71s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2050/4671 [58:37<1:14:53,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2051/4671 [58:37<1:14:25,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2051/4671 [58:39<1:14:25,  1.70s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2052/4671 [58:39<1:14:22,  1.70s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2052/4671 [58:41<1:14:22,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2053/4671 [58:41<1:14:09,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2053/4671 [58:42<1:14:09,  1.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2054/4671 [58:42<1:14:10,  1.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2054/4671 [58:44<1:14:10,  1.70s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2055/4671 [58:44<1:14:34,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2055/4671 [58:46<1:14:34,  1.71s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2056/4671 [58:46<1:14:43,  1.71s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2056/4671 [58:47<1:14:43,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2057/4671 [58:47<1:14:27,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2057/4671 [58:49<1:14:27,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2058/4671 [58:49<1:14:24,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2058/4671 [58:51<1:14:24,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2059/4671 [58:51<1:13:26,  1.69s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2059/4671 [58:52<1:13:26,  1.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2060/4671 [58:52<1:13:31,  1.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2060/4671 [58:54<1:13:31,  1.69s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2061/4671 [58:54<1:13:50,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2061/4671 [58:56<1:13:50,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2062/4671 [58:56<1:13:51,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2062/4671 [58:58<1:13:51,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2063/4671 [58:58<1:14:27,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2063/4671 [58:59<1:14:27,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2064/4671 [58:59<1:14:31,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2064/4671 [59:01<1:14:31,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2065/4671 [59:01<1:14:12,  1.71s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2065/4671 [59:03<1:14:12,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2066/4671 [59:03<1:13:58,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2066/4671 [59:04<1:13:58,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2067/4671 [59:04<1:13:12,  1.69s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2067/4671 [59:06<1:13:12,  1.69s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2068/4671 [59:06<1:13:39,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2068/4671 [59:08<1:13:39,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2069/4671 [59:08<1:13:53,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2069/4671 [59:10<1:13:53,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2070/4671 [59:10<1:13:55,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2070/4671 [59:11<1:13:55,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2071/4671 [59:11<1:14:23,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2071/4671 [59:13<1:14:23,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2072/4671 [59:13<1:14:16,  1.71s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2072/4671 [59:15<1:14:16,  1.71s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2073/4671 [59:15<1:14:04,  1.71s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2073/4671 [59:16<1:14:04,  1.71s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2074/4671 [59:16<1:14:11,  1.71s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2074/4671 [59:18<1:14:11,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2075/4671 [59:18<1:13:58,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2075/4671 [59:20<1:13:58,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2076/4671 [59:20<1:14:18,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2076/4671 [59:22<1:14:18,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2077/4671 [59:22<1:13:43,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2077/4671 [59:23<1:13:43,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2078/4671 [59:23<1:12:58,  1.69s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 2078/4671 [59:25<1:12:58,  1.69s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2079/4671 [59:25<1:13:13,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2079/4671 [59:27<1:13:13,  1.70s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2080/4671 [59:27<1:13:31,  1.70s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2080/4671 [59:28<1:13:31,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2081/4671 [59:28<1:13:25,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2081/4671 [59:30<1:13:25,  1.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2082/4671 [59:30<1:14:41,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2082/4671 [59:32<1:14:41,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2083/4671 [59:32<1:15:03,  1.74s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2083/4671 [59:34<1:15:03,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2084/4671 [59:34<1:14:52,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2084/4671 [59:35<1:14:52,  1.74s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2085/4671 [59:35<1:14:36,  1.73s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2085/4671 [59:37<1:14:36,  1.73s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2086/4671 [59:37<1:14:32,  1.73s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2086/4671 [59:39<1:14:32,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2087/4671 [59:39<1:14:36,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2087/4671 [59:40<1:14:36,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2088/4671 [59:40<1:13:53,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2088/4671 [59:42<1:13:53,  1.72s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2089/4671 [59:42<1:14:34,  1.73s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2089/4671 [59:44<1:14:34,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2090/4671 [59:44<1:14:30,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2090/4671 [59:46<1:14:30,  1.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2091/4671 [59:46<1:14:14,  1.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2091/4671 [59:47<1:14:14,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2092/4671 [59:47<1:13:55,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2092/4671 [59:49<1:13:55,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2093/4671 [59:49<1:14:38,  1.74s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2093/4671 [59:51<1:14:38,  1.74s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2094/4671 [59:51<1:15:01,  1.75s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2094/4671 [59:53<1:15:01,  1.75s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2095/4671 [59:53<1:14:36,  1.74s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2095/4671 [59:54<1:14:36,  1.74s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2096/4671 [59:54<1:15:04,  1.75s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2096/4671 [59:56<1:15:04,  1.75s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2097/4671 [59:56<1:15:03,  1.75s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2097/4671 [59:58<1:15:03,  1.75s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2098/4671 [59:58<1:14:18,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2098/4671 [1:00:00<1:14:18,  1.73s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2099/4671 [1:00:00<1:14:54,  1.75s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2099/4671 [1:00:01<1:14:54,  1.75s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2100/4671 [1:00:01<1:14:14,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2100/4671 [1:00:03<1:14:14,  1.73s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2101/4671 [1:00:03<1:14:21,  1.74s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 2101/4671 [1:00:05<1:14:21,  1.74s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2102/4671 [1:00:05<1:14:39,  1.74s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2102/4671 [1:00:07<1:14:39,  1.74s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2103/4671 [1:00:07<1:14:17,  1.74s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2103/4671 [1:00:08<1:14:17,  1.74s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2104/4671 [1:00:08<1:14:14,  1.74s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2104/4671 [1:00:10<1:14:14,  1.74s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2105/4671 [1:00:10<1:14:17,  1.74s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2105/4671 [1:00:12<1:14:17,  1.74s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2106/4671 [1:00:12<1:13:39,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2106/4671 [1:00:13<1:13:39,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2107/4671 [1:00:13<1:13:25,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2107/4671 [1:00:15<1:13:25,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2108/4671 [1:00:15<1:13:22,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2108/4671 [1:00:17<1:13:22,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2109/4671 [1:00:17<1:13:56,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2109/4671 [1:00:19<1:13:56,  1.73s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2110/4671 [1:00:19<1:14:12,  1.74s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2110/4671 [1:00:20<1:14:12,  1.74s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2111/4671 [1:00:20<1:14:36,  1.75s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2111/4671 [1:00:22<1:14:36,  1.75s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2112/4671 [1:00:22<1:14:41,  1.75s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2112/4671 [1:00:24<1:14:41,  1.75s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2113/4671 [1:00:24<1:14:28,  1.75s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2113/4671 [1:00:26<1:14:28,  1.75s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2114/4671 [1:00:26<1:14:01,  1.74s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2114/4671 [1:00:27<1:14:01,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2115/4671 [1:00:27<1:13:45,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2115/4671 [1:00:29<1:13:45,  1.73s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2116/4671 [1:00:29<1:13:40,  1.73s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2116/4671 [1:00:31<1:13:40,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2117/4671 [1:00:31<1:13:33,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2117/4671 [1:00:33<1:13:33,  1.73s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2118/4671 [1:00:33<1:13:55,  1.74s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2118/4671 [1:00:34<1:13:55,  1.74s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2119/4671 [1:00:34<1:13:05,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2119/4671 [1:00:36<1:13:05,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2120/4671 [1:00:36<1:12:41,  1.71s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2120/4671 [1:00:38<1:12:41,  1.71s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2121/4671 [1:00:38<1:13:27,  1.73s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2121/4671 [1:00:40<1:13:27,  1.73s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2122/4671 [1:00:40<1:14:01,  1.74s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2122/4671 [1:00:41<1:14:01,  1.74s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2123/4671 [1:00:41<1:13:46,  1.74s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2123/4671 [1:00:43<1:13:46,  1.74s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2124/4671 [1:00:43<1:13:29,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2124/4671 [1:00:45<1:13:29,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2125/4671 [1:00:45<1:13:10,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 2125/4671 [1:00:46<1:13:10,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2126/4671 [1:00:46<1:12:23,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2126/4671 [1:00:48<1:12:23,  1.71s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2127/4671 [1:00:48<1:12:59,  1.72s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2127/4671 [1:00:50<1:12:59,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2128/4671 [1:00:50<1:13:13,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2128/4671 [1:00:52<1:13:13,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2129/4671 [1:00:52<1:13:08,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2129/4671 [1:00:53<1:13:08,  1.73s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2130/4671 [1:00:53<1:12:27,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2130/4671 [1:00:55<1:12:27,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2131/4671 [1:00:55<1:12:27,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2131/4671 [1:00:57<1:12:27,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2132/4671 [1:00:57<1:11:49,  1.70s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2132/4671 [1:00:58<1:11:49,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2133/4671 [1:00:58<1:12:08,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2133/4671 [1:01:00<1:12:08,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2134/4671 [1:01:00<1:12:46,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2134/4671 [1:01:02<1:12:46,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2135/4671 [1:01:02<1:12:37,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2135/4671 [1:01:04<1:12:37,  1.72s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2136/4671 [1:01:04<1:12:29,  1.72s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2136/4671 [1:01:05<1:12:29,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2137/4671 [1:01:05<1:12:35,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2137/4671 [1:01:07<1:12:35,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2138/4671 [1:01:07<1:12:22,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2138/4671 [1:01:09<1:12:22,  1.71s/it, training_loss=0.204]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2139/4671 [1:01:09<1:12:25,  1.72s/it, training_loss=0.204]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2139/4671 [1:01:10<1:12:25,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2140/4671 [1:01:10<1:12:36,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2140/4671 [1:01:12<1:12:36,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2141/4671 [1:01:12<1:13:16,  1.74s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2141/4671 [1:01:14<1:13:16,  1.74s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2142/4671 [1:01:14<1:12:39,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2142/4671 [1:01:16<1:12:39,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2143/4671 [1:01:16<1:13:06,  1.74s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2143/4671 [1:01:17<1:13:06,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2144/4671 [1:01:17<1:12:43,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2144/4671 [1:01:19<1:12:43,  1.73s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2145/4671 [1:01:19<1:12:29,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2145/4671 [1:01:21<1:12:29,  1.72s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2146/4671 [1:01:21<1:12:45,  1.73s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2146/4671 [1:01:23<1:12:45,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2147/4671 [1:01:23<1:13:11,  1.74s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2147/4671 [1:01:24<1:13:11,  1.74s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2148/4671 [1:01:24<1:13:13,  1.74s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2148/4671 [1:01:26<1:13:13,  1.74s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2149/4671 [1:01:26<1:12:40,  1.73s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2149/4671 [1:01:28<1:12:40,  1.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2150/4671 [1:01:28<1:12:50,  1.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2150/4671 [1:01:29<1:12:50,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2151/4671 [1:01:29<1:12:29,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2151/4671 [1:01:31<1:12:29,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2152/4671 [1:01:31<1:12:15,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2152/4671 [1:01:33<1:12:15,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2153/4671 [1:01:33<1:12:20,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2153/4671 [1:01:35<1:12:20,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2154/4671 [1:01:35<1:11:59,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2154/4671 [1:01:36<1:11:59,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2155/4671 [1:01:36<1:11:42,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2155/4671 [1:01:38<1:11:42,  1.71s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2156/4671 [1:01:38<1:12:09,  1.72s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2156/4671 [1:01:40<1:12:09,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2157/4671 [1:01:40<1:11:38,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2157/4671 [1:01:41<1:11:38,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2158/4671 [1:01:41<1:11:48,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2158/4671 [1:01:43<1:11:48,  1.71s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2159/4671 [1:01:43<1:12:18,  1.73s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2159/4671 [1:01:45<1:12:18,  1.73s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2160/4671 [1:01:45<1:11:31,  1.71s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 2160/4671 [1:01:47<1:11:31,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2161/4671 [1:01:47<1:11:27,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2161/4671 [1:01:48<1:11:27,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2162/4671 [1:01:48<1:11:36,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2162/4671 [1:01:50<1:11:36,  1.71s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2163/4671 [1:01:50<1:11:46,  1.72s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2163/4671 [1:01:52<1:11:46,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2164/4671 [1:01:52<1:10:54,  1.70s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2164/4671 [1:01:53<1:10:54,  1.70s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2165/4671 [1:01:53<1:11:41,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2165/4671 [1:01:55<1:11:41,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2166/4671 [1:01:55<1:11:13,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2166/4671 [1:01:57<1:11:13,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2167/4671 [1:01:57<1:11:08,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2167/4671 [1:01:59<1:11:08,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2168/4671 [1:01:59<1:11:09,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2168/4671 [1:02:00<1:11:09,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2169/4671 [1:02:00<1:11:05,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2169/4671 [1:02:02<1:11:05,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2170/4671 [1:02:02<1:12:13,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2170/4671 [1:02:04<1:12:13,  1.73s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2171/4671 [1:02:04<1:12:14,  1.73s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2171/4671 [1:02:05<1:12:14,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2172/4671 [1:02:05<1:11:56,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 2172/4671 [1:02:07<1:11:56,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2173/4671 [1:02:07<1:11:55,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2173/4671 [1:02:09<1:11:55,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2174/4671 [1:02:09<1:11:22,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2174/4671 [1:02:11<1:11:22,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2175/4671 [1:02:11<1:11:34,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2175/4671 [1:02:12<1:11:34,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2176/4671 [1:02:12<1:11:17,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2176/4671 [1:02:14<1:11:17,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2177/4671 [1:02:14<1:10:49,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2177/4671 [1:02:16<1:10:49,  1.70s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2178/4671 [1:02:16<1:10:56,  1.71s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2178/4671 [1:02:17<1:10:56,  1.71s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2179/4671 [1:02:17<1:10:41,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2179/4671 [1:02:19<1:10:41,  1.70s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2180/4671 [1:02:19<1:10:44,  1.70s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2180/4671 [1:02:21<1:10:44,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2181/4671 [1:02:21<1:11:14,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2181/4671 [1:02:23<1:11:14,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2182/4671 [1:02:23<1:11:46,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2182/4671 [1:02:24<1:11:46,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2183/4671 [1:02:24<1:11:23,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2183/4671 [1:02:26<1:11:23,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2184/4671 [1:02:26<1:11:13,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2184/4671 [1:02:28<1:11:13,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2185/4671 [1:02:28<1:11:16,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2185/4671 [1:02:29<1:11:16,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2186/4671 [1:02:29<1:11:07,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2186/4671 [1:02:31<1:11:07,  1.72s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2187/4671 [1:02:31<1:10:48,  1.71s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2187/4671 [1:02:33<1:10:48,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2188/4671 [1:02:33<1:10:46,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2188/4671 [1:02:35<1:10:46,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2189/4671 [1:02:35<1:10:52,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2189/4671 [1:02:36<1:10:52,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2190/4671 [1:02:36<1:10:50,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2190/4671 [1:02:38<1:10:50,  1.71s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2191/4671 [1:02:38<1:11:06,  1.72s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2191/4671 [1:02:40<1:11:06,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2192/4671 [1:02:40<1:10:36,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2192/4671 [1:02:41<1:10:36,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2193/4671 [1:02:41<1:10:16,  1.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2193/4671 [1:02:43<1:10:16,  1.70s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2194/4671 [1:02:43<1:10:19,  1.70s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2194/4671 [1:02:45<1:10:19,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2195/4671 [1:02:45<1:10:24,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2195/4671 [1:02:46<1:10:24,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2196/4671 [1:02:46<1:10:03,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2196/4671 [1:02:48<1:10:03,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2197/4671 [1:02:48<1:10:17,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2197/4671 [1:02:50<1:10:17,  1.70s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2198/4671 [1:02:50<1:10:27,  1.71s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2198/4671 [1:02:52<1:10:27,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2199/4671 [1:02:52<1:10:53,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2199/4671 [1:02:53<1:10:53,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2200/4671 [1:02:53<1:11:08,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2200/4671 [1:02:55<1:11:08,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2201/4671 [1:02:55<1:10:48,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2201/4671 [1:02:57<1:10:48,  1.72s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2202/4671 [1:02:57<1:10:37,  1.72s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2202/4671 [1:02:59<1:10:37,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2203/4671 [1:02:59<1:10:18,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2203/4671 [1:03:00<1:10:18,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2204/4671 [1:03:00<1:10:20,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2204/4671 [1:03:02<1:10:20,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2205/4671 [1:03:02<1:10:44,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2205/4671 [1:03:04<1:10:44,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2206/4671 [1:03:04<1:10:32,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2206/4671 [1:03:05<1:10:32,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2207/4671 [1:03:05<1:10:48,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2207/4671 [1:03:07<1:10:48,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2208/4671 [1:03:07<1:10:38,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2208/4671 [1:03:09<1:10:38,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2209/4671 [1:03:09<1:10:25,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2209/4671 [1:03:11<1:10:25,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2210/4671 [1:03:11<1:10:36,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2210/4671 [1:03:12<1:10:36,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2211/4671 [1:03:12<1:10:51,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2211/4671 [1:03:14<1:10:51,  1.73s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2212/4671 [1:03:14<1:10:39,  1.72s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2212/4671 [1:03:16<1:10:39,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2213/4671 [1:03:16<1:10:32,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2213/4671 [1:03:17<1:10:32,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2214/4671 [1:03:17<1:10:33,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2214/4671 [1:03:19<1:10:33,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2215/4671 [1:03:19<1:10:14,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2215/4671 [1:03:21<1:10:14,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2216/4671 [1:03:21<1:09:56,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2216/4671 [1:03:23<1:09:56,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2217/4671 [1:03:23<1:10:03,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2217/4671 [1:03:24<1:10:03,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2218/4671 [1:03:24<1:10:11,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 2218/4671 [1:03:26<1:10:11,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2219/4671 [1:03:26<1:10:26,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2219/4671 [1:03:28<1:10:26,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2220/4671 [1:03:28<1:10:48,  1.73s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2220/4671 [1:03:30<1:10:48,  1.73s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2221/4671 [1:03:30<1:10:20,  1.72s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2221/4671 [1:03:31<1:10:20,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2222/4671 [1:03:31<1:09:55,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2222/4671 [1:03:33<1:09:55,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2223/4671 [1:03:33<1:10:03,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2223/4671 [1:03:35<1:10:03,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2224/4671 [1:03:35<1:09:34,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2224/4671 [1:03:36<1:09:34,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2225/4671 [1:03:36<1:09:57,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2225/4671 [1:03:38<1:09:57,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2226/4671 [1:03:38<1:10:17,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2226/4671 [1:03:40<1:10:17,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2227/4671 [1:03:40<1:10:02,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2227/4671 [1:03:42<1:10:02,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2228/4671 [1:03:42<1:09:56,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2228/4671 [1:03:43<1:09:56,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2229/4671 [1:03:43<1:10:07,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2229/4671 [1:03:45<1:10:07,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2230/4671 [1:03:45<1:10:09,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2230/4671 [1:03:47<1:10:09,  1.72s/it, training_loss=0.188]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2231/4671 [1:03:47<1:10:09,  1.73s/it, training_loss=0.188]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2231/4671 [1:03:48<1:10:09,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2232/4671 [1:03:48<1:10:14,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2232/4671 [1:03:50<1:10:14,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2233/4671 [1:03:50<1:10:01,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2233/4671 [1:03:52<1:10:01,  1.72s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2234/4671 [1:03:52<1:09:27,  1.71s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2234/4671 [1:03:54<1:09:27,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2235/4671 [1:03:54<1:09:21,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2235/4671 [1:03:55<1:09:21,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2236/4671 [1:03:55<1:09:44,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2236/4671 [1:03:57<1:09:44,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2237/4671 [1:03:57<1:09:57,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2237/4671 [1:03:59<1:09:57,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2238/4671 [1:03:59<1:10:16,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2238/4671 [1:04:00<1:10:16,  1.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2239/4671 [1:04:00<1:09:47,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2239/4671 [1:04:02<1:09:47,  1.72s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2240/4671 [1:04:02<1:10:09,  1.73s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2240/4671 [1:04:04<1:10:09,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2241/4671 [1:04:04<1:09:33,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2241/4671 [1:04:06<1:09:33,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2242/4671 [1:04:06<1:09:49,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2242/4671 [1:04:07<1:09:49,  1.72s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2243/4671 [1:04:07<1:09:04,  1.71s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2243/4671 [1:04:09<1:09:04,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2244/4671 [1:04:09<1:09:00,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2244/4671 [1:04:11<1:09:00,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2245/4671 [1:04:11<1:08:40,  1.70s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2245/4671 [1:04:12<1:08:40,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2246/4671 [1:04:12<1:09:41,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2246/4671 [1:04:14<1:09:41,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2247/4671 [1:04:14<1:11:29,  1.77s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2247/4671 [1:04:16<1:11:29,  1.77s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2248/4671 [1:04:16<1:12:29,  1.80s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2248/4671 [1:04:18<1:12:29,  1.80s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2249/4671 [1:04:18<1:11:27,  1.77s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2249/4671 [1:04:20<1:11:27,  1.77s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2250/4671 [1:04:20<1:10:51,  1.76s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2250/4671 [1:04:21<1:10:51,  1.76s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2251/4671 [1:04:21<1:10:21,  1.74s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2251/4671 [1:04:23<1:10:21,  1.74s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2252/4671 [1:04:23<1:10:01,  1.74s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2252/4671 [1:04:25<1:10:01,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2253/4671 [1:04:25<1:08:40,  1.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2253/4671 [1:04:26<1:08:40,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2254/4671 [1:04:26<1:09:12,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2254/4671 [1:04:28<1:09:12,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2255/4671 [1:04:28<1:08:45,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2255/4671 [1:04:30<1:08:45,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2256/4671 [1:04:30<1:08:20,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2256/4671 [1:04:32<1:08:20,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2257/4671 [1:04:32<1:08:47,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2257/4671 [1:04:33<1:08:47,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2258/4671 [1:04:33<1:08:23,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2258/4671 [1:04:35<1:08:23,  1.70s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2259/4671 [1:04:35<1:08:27,  1.70s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2259/4671 [1:04:37<1:08:27,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2260/4671 [1:04:37<1:09:00,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2260/4671 [1:04:38<1:09:00,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2261/4671 [1:04:38<1:08:47,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2261/4671 [1:04:40<1:08:47,  1.71s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2262/4671 [1:04:40<1:08:58,  1.72s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2262/4671 [1:04:42<1:08:58,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2263/4671 [1:04:42<1:08:33,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2263/4671 [1:04:44<1:08:33,  1.71s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2264/4671 [1:04:44<1:08:35,  1.71s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2264/4671 [1:04:45<1:08:35,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2265/4671 [1:04:45<1:08:44,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 2265/4671 [1:04:47<1:08:44,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2266/4671 [1:04:47<1:08:22,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2266/4671 [1:04:49<1:08:22,  1.71s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2267/4671 [1:04:49<1:09:06,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2267/4671 [1:04:50<1:09:06,  1.72s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2268/4671 [1:04:50<1:09:19,  1.73s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2268/4671 [1:04:52<1:09:19,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2269/4671 [1:04:52<1:09:00,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2269/4671 [1:04:54<1:09:00,  1.72s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2270/4671 [1:04:54<1:09:34,  1.74s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2270/4671 [1:04:56<1:09:34,  1.74s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2271/4671 [1:04:56<1:09:01,  1.73s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2271/4671 [1:04:57<1:09:01,  1.73s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2272/4671 [1:04:57<1:08:27,  1.71s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2272/4671 [1:04:59<1:08:27,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2273/4671 [1:04:59<1:08:45,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2273/4671 [1:05:01<1:08:45,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2274/4671 [1:05:01<1:08:49,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2274/4671 [1:05:02<1:08:49,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2275/4671 [1:05:02<1:08:19,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2275/4671 [1:05:04<1:08:19,  1.71s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2276/4671 [1:05:04<1:07:39,  1.69s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2276/4671 [1:05:06<1:07:39,  1.69s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2277/4671 [1:05:06<1:07:44,  1.70s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 2277/4671 [1:05:08<1:07:44,  1.70s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2278/4671 [1:05:08<1:08:35,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2278/4671 [1:05:09<1:08:35,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2279/4671 [1:05:09<1:08:19,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2279/4671 [1:05:11<1:08:19,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2280/4671 [1:05:11<1:08:22,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2280/4671 [1:05:13<1:08:22,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2281/4671 [1:05:13<1:08:34,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2281/4671 [1:05:15<1:08:34,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2282/4671 [1:05:15<1:08:55,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2282/4671 [1:05:16<1:08:55,  1.73s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2283/4671 [1:05:16<1:08:25,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2283/4671 [1:05:18<1:08:25,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2284/4671 [1:05:18<1:08:31,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2284/4671 [1:05:20<1:08:31,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2285/4671 [1:05:20<1:08:32,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2285/4671 [1:05:21<1:08:32,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2286/4671 [1:05:21<1:08:02,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2286/4671 [1:05:23<1:08:02,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2287/4671 [1:05:23<1:07:39,  1.70s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2287/4671 [1:05:25<1:07:39,  1.70s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2288/4671 [1:05:25<1:07:10,  1.69s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2288/4671 [1:05:26<1:07:10,  1.69s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2289/4671 [1:05:26<1:07:16,  1.69s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2289/4671 [1:05:28<1:07:16,  1.69s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2290/4671 [1:05:28<1:07:30,  1.70s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2290/4671 [1:05:30<1:07:30,  1.70s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2291/4671 [1:05:30<1:07:47,  1.71s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2291/4671 [1:05:32<1:07:47,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2292/4671 [1:05:32<1:07:45,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2292/4671 [1:05:33<1:07:45,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2293/4671 [1:05:33<1:08:09,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2293/4671 [1:05:35<1:08:09,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2294/4671 [1:05:35<1:08:05,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2294/4671 [1:05:37<1:08:05,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2295/4671 [1:05:37<1:08:21,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2295/4671 [1:05:38<1:08:21,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2296/4671 [1:05:38<1:08:20,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2296/4671 [1:05:40<1:08:20,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2297/4671 [1:05:40<1:08:32,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2297/4671 [1:05:42<1:08:32,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2298/4671 [1:05:42<1:08:33,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2298/4671 [1:05:44<1:08:33,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2299/4671 [1:05:44<1:08:48,  1.74s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2299/4671 [1:05:45<1:08:48,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2300/4671 [1:05:45<1:08:26,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2300/4671 [1:05:47<1:08:26,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2301/4671 [1:05:47<1:08:27,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2301/4671 [1:05:49<1:08:27,  1.73s/it, training_loss=0.183]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2302/4671 [1:05:49<1:08:18,  1.73s/it, training_loss=0.183]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2302/4671 [1:05:51<1:08:18,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2303/4671 [1:05:51<1:08:14,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2303/4671 [1:05:52<1:08:14,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2304/4671 [1:05:52<1:08:02,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2304/4671 [1:05:54<1:08:02,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2305/4671 [1:05:54<1:08:02,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2305/4671 [1:05:56<1:08:02,  1.73s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2306/4671 [1:05:56<1:07:20,  1.71s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2306/4671 [1:05:58<1:07:20,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2307/4671 [1:05:58<1:08:05,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2307/4671 [1:05:59<1:08:05,  1.73s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2308/4671 [1:05:59<1:07:44,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2308/4671 [1:06:01<1:07:44,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2309/4671 [1:06:01<1:08:05,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2309/4671 [1:06:03<1:08:05,  1.73s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2310/4671 [1:06:03<1:08:01,  1.73s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2310/4671 [1:06:04<1:08:01,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2311/4671 [1:06:04<1:07:58,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2311/4671 [1:06:06<1:07:58,  1.73s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2312/4671 [1:06:06<1:07:43,  1.72s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 2312/4671 [1:06:08<1:07:43,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2313/4671 [1:06:08<1:07:37,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2313/4671 [1:06:10<1:07:37,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2314/4671 [1:06:10<1:07:19,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2314/4671 [1:06:11<1:07:19,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2315/4671 [1:06:11<1:07:27,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2315/4671 [1:06:13<1:07:27,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2316/4671 [1:06:13<1:07:09,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2316/4671 [1:06:15<1:07:09,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2317/4671 [1:06:15<1:07:25,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2317/4671 [1:06:16<1:07:25,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2318/4671 [1:06:16<1:07:37,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2318/4671 [1:06:18<1:07:37,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2319/4671 [1:06:18<1:07:37,  1.73s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2319/4671 [1:06:20<1:07:37,  1.73s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2320/4671 [1:06:20<1:07:25,  1.72s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2320/4671 [1:06:22<1:07:25,  1.72s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2321/4671 [1:06:22<1:08:00,  1.74s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2321/4671 [1:06:23<1:08:00,  1.74s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2322/4671 [1:06:23<1:07:48,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2322/4671 [1:06:25<1:07:48,  1.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2323/4671 [1:06:25<1:07:44,  1.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2323/4671 [1:06:27<1:07:44,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2324/4671 [1:06:27<1:07:23,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2324/4671 [1:06:28<1:07:23,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2325/4671 [1:06:28<1:06:40,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2325/4671 [1:06:30<1:06:40,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2326/4671 [1:06:30<1:07:08,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2326/4671 [1:06:32<1:07:08,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2327/4671 [1:06:32<1:07:25,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2327/4671 [1:06:34<1:07:25,  1.73s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2328/4671 [1:06:34<1:07:52,  1.74s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2328/4671 [1:06:35<1:07:52,  1.74s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2329/4671 [1:06:35<1:06:55,  1.71s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2329/4671 [1:06:37<1:06:55,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2330/4671 [1:06:37<1:07:23,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2330/4671 [1:06:39<1:07:23,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2331/4671 [1:06:39<1:07:02,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2331/4671 [1:06:41<1:07:02,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2332/4671 [1:06:41<1:17:59,  2.00s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2332/4671 [1:06:43<1:17:59,  2.00s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2333/4671 [1:06:43<1:17:23,  1.99s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2333/4671 [1:06:45<1:17:23,  1.99s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2334/4671 [1:06:45<1:15:32,  1.94s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2334/4671 [1:06:47<1:15:32,  1.94s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2335/4671 [1:06:47<1:12:50,  1.87s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 2335/4671 [1:06:49<1:12:50,  1.87s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2336/4671 [1:06:49<1:11:31,  1.84s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2336/4671 [1:06:50<1:11:31,  1.84s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2337/4671 [1:06:50<1:10:03,  1.80s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2337/4671 [1:06:52<1:10:03,  1.80s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2338/4671 [1:06:52<1:09:29,  1.79s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2338/4671 [1:06:54<1:09:29,  1.79s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2339/4671 [1:06:54<1:08:41,  1.77s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2339/4671 [1:06:56<1:08:41,  1.77s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2340/4671 [1:06:56<1:07:51,  1.75s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2340/4671 [1:06:57<1:07:51,  1.75s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2341/4671 [1:06:57<1:07:33,  1.74s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2341/4671 [1:06:59<1:07:33,  1.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2342/4671 [1:06:59<1:07:00,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2342/4671 [1:07:01<1:07:00,  1.73s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2343/4671 [1:07:01<1:07:13,  1.73s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2343/4671 [1:07:03<1:07:13,  1.73s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2344/4671 [1:07:03<1:07:09,  1.73s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2344/4671 [1:07:04<1:07:09,  1.73s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2345/4671 [1:07:04<1:07:27,  1.74s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2345/4671 [1:07:06<1:07:27,  1.74s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2346/4671 [1:07:06<1:06:15,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2346/4671 [1:07:08<1:06:15,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2347/4671 [1:07:08<1:06:32,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2347/4671 [1:07:09<1:06:32,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2348/4671 [1:07:09<1:06:30,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2348/4671 [1:07:11<1:06:30,  1.72s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2349/4671 [1:07:11<1:06:39,  1.72s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2349/4671 [1:07:13<1:06:39,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2350/4671 [1:07:13<1:06:33,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2350/4671 [1:07:15<1:06:33,  1.72s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2351/4671 [1:07:15<1:06:22,  1.72s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2351/4671 [1:07:16<1:06:22,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2352/4671 [1:07:16<1:06:32,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2352/4671 [1:07:18<1:06:32,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2353/4671 [1:07:18<1:06:37,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2353/4671 [1:07:20<1:06:37,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2354/4671 [1:07:20<1:06:07,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2354/4671 [1:07:21<1:06:07,  1.71s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2355/4671 [1:07:21<1:06:23,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2355/4671 [1:07:23<1:06:23,  1.72s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2356/4671 [1:07:23<1:06:34,  1.73s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2356/4671 [1:07:25<1:06:34,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2357/4671 [1:07:25<1:06:04,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2357/4671 [1:07:27<1:06:04,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2358/4671 [1:07:27<1:05:38,  1.70s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  50%|█████     | 2358/4671 [1:07:28<1:05:38,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2359/4671 [1:07:28<1:05:32,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2359/4671 [1:07:30<1:05:32,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2360/4671 [1:07:30<1:06:03,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2360/4671 [1:07:32<1:06:03,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2361/4671 [1:07:32<1:06:08,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2361/4671 [1:07:33<1:06:08,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2362/4671 [1:07:33<1:05:51,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2362/4671 [1:07:35<1:05:51,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2363/4671 [1:07:35<1:05:32,  1.70s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2363/4671 [1:07:37<1:05:32,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2364/4671 [1:07:37<1:05:39,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2364/4671 [1:07:39<1:05:39,  1.71s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2365/4671 [1:07:39<1:05:58,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2365/4671 [1:07:40<1:05:58,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2366/4671 [1:07:40<1:06:06,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2366/4671 [1:07:42<1:06:06,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2367/4671 [1:07:42<1:06:03,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2367/4671 [1:07:44<1:06:03,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2368/4671 [1:07:44<1:06:05,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2368/4671 [1:07:45<1:06:05,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2369/4671 [1:07:45<1:06:22,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2369/4671 [1:07:47<1:06:22,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2370/4671 [1:07:47<1:05:58,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2370/4671 [1:07:49<1:05:58,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2371/4671 [1:07:49<1:05:53,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2371/4671 [1:07:51<1:05:53,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2372/4671 [1:07:51<1:05:38,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2372/4671 [1:07:52<1:05:38,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2373/4671 [1:07:52<1:05:12,  1.70s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2373/4671 [1:07:54<1:05:12,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2374/4671 [1:07:54<1:05:41,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2374/4671 [1:07:56<1:05:41,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2375/4671 [1:07:56<1:05:26,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2375/4671 [1:07:57<1:05:26,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2376/4671 [1:07:57<1:05:37,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2376/4671 [1:07:59<1:05:37,  1.72s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2377/4671 [1:07:59<1:05:45,  1.72s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2377/4671 [1:08:01<1:05:45,  1.72s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2378/4671 [1:08:01<1:05:51,  1.72s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2378/4671 [1:08:03<1:05:51,  1.72s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2379/4671 [1:08:03<1:05:35,  1.72s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2379/4671 [1:08:04<1:05:35,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2380/4671 [1:08:04<1:05:40,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2380/4671 [1:08:06<1:05:40,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2381/4671 [1:08:06<1:05:49,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2381/4671 [1:08:08<1:05:49,  1.72s/it, training_loss=0.072]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2382/4671 [1:08:08<1:05:46,  1.72s/it, training_loss=0.072]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2382/4671 [1:08:09<1:05:46,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2383/4671 [1:08:09<1:05:48,  1.73s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2383/4671 [1:08:11<1:05:48,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2384/4671 [1:08:11<1:05:41,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2384/4671 [1:08:13<1:05:41,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2385/4671 [1:08:13<1:05:32,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2385/4671 [1:08:15<1:05:32,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2386/4671 [1:08:15<1:05:58,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2386/4671 [1:08:16<1:05:58,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2387/4671 [1:08:16<1:06:11,  1.74s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2387/4671 [1:08:18<1:06:11,  1.74s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2388/4671 [1:08:18<1:06:12,  1.74s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2388/4671 [1:08:20<1:06:12,  1.74s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2389/4671 [1:08:20<1:05:47,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2389/4671 [1:08:22<1:05:47,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2390/4671 [1:08:22<1:05:30,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2390/4671 [1:08:23<1:05:30,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2391/4671 [1:08:23<1:05:10,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2391/4671 [1:08:25<1:05:10,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2392/4671 [1:08:25<1:04:35,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2392/4671 [1:08:27<1:04:35,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2393/4671 [1:08:27<1:05:38,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  51%|█████     | 2393/4671 [1:08:28<1:05:38,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2394/4671 [1:08:28<1:05:21,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2394/4671 [1:08:30<1:05:21,  1.72s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2395/4671 [1:08:30<1:05:12,  1.72s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2395/4671 [1:08:32<1:05:12,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2396/4671 [1:08:32<1:04:36,  1.70s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2396/4671 [1:08:34<1:04:36,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2397/4671 [1:08:34<1:04:34,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2397/4671 [1:08:35<1:04:34,  1.70s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2398/4671 [1:08:35<1:05:07,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2398/4671 [1:08:37<1:05:07,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2399/4671 [1:08:37<1:05:13,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2399/4671 [1:08:39<1:05:13,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2400/4671 [1:08:39<1:04:38,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2400/4671 [1:08:40<1:04:38,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2401/4671 [1:08:40<1:05:09,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2401/4671 [1:08:42<1:05:09,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2402/4671 [1:08:42<1:05:56,  1.74s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2402/4671 [1:08:44<1:05:56,  1.74s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2403/4671 [1:08:44<1:05:44,  1.74s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2403/4671 [1:08:46<1:05:44,  1.74s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2404/4671 [1:08:46<1:05:26,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2404/4671 [1:08:47<1:05:26,  1.73s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2405/4671 [1:08:47<1:05:09,  1.73s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 2405/4671 [1:08:49<1:05:09,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2406/4671 [1:08:49<1:04:53,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2406/4671 [1:08:51<1:04:53,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2407/4671 [1:08:51<1:04:51,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2407/4671 [1:08:52<1:04:51,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2408/4671 [1:08:53<1:04:14,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2408/4671 [1:08:54<1:04:14,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2409/4671 [1:08:54<1:04:35,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2409/4671 [1:08:56<1:04:35,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2410/4671 [1:08:56<1:04:17,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2410/4671 [1:08:58<1:04:17,  1.71s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2411/4671 [1:08:58<1:04:15,  1.71s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2411/4671 [1:08:59<1:04:15,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2412/4671 [1:08:59<1:04:35,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2412/4671 [1:09:01<1:04:35,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2413/4671 [1:09:01<1:04:25,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2413/4671 [1:09:03<1:04:25,  1.71s/it, training_loss=0.198]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2414/4671 [1:09:03<1:04:08,  1.70s/it, training_loss=0.198]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2414/4671 [1:09:05<1:04:08,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2415/4671 [1:09:05<1:04:32,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2415/4671 [1:09:06<1:04:32,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2416/4671 [1:09:06<1:04:27,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2416/4671 [1:09:08<1:04:27,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2417/4671 [1:09:08<1:04:40,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2417/4671 [1:09:10<1:04:40,  1.72s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2418/4671 [1:09:10<1:04:47,  1.73s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2418/4671 [1:09:11<1:04:47,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2419/4671 [1:09:11<1:04:42,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2419/4671 [1:09:13<1:04:42,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2420/4671 [1:09:13<1:04:55,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2420/4671 [1:09:15<1:04:55,  1.73s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2421/4671 [1:09:15<1:04:30,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2421/4671 [1:09:17<1:04:30,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2422/4671 [1:09:17<1:04:25,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2422/4671 [1:09:18<1:04:25,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2423/4671 [1:09:18<1:04:06,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2423/4671 [1:09:20<1:04:06,  1.71s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2424/4671 [1:09:20<1:04:24,  1.72s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2424/4671 [1:09:22<1:04:24,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2425/4671 [1:09:22<1:04:38,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2425/4671 [1:09:23<1:04:38,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2426/4671 [1:09:23<1:04:33,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2426/4671 [1:09:25<1:04:33,  1.73s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2427/4671 [1:09:25<1:04:11,  1.72s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2427/4671 [1:09:27<1:04:11,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2428/4671 [1:09:27<1:04:46,  1.73s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2428/4671 [1:09:29<1:04:46,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2429/4671 [1:09:29<1:03:50,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2429/4671 [1:09:30<1:03:50,  1.71s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2430/4671 [1:09:30<1:04:20,  1.72s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2430/4671 [1:09:32<1:04:20,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2431/4671 [1:09:32<1:05:01,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2431/4671 [1:09:34<1:05:01,  1.74s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2432/4671 [1:09:34<1:04:23,  1.73s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2432/4671 [1:09:36<1:04:23,  1.73s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2433/4671 [1:09:36<1:04:12,  1.72s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2433/4671 [1:09:37<1:04:12,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2434/4671 [1:09:37<1:04:26,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2434/4671 [1:09:39<1:04:26,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2435/4671 [1:09:39<1:04:25,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2435/4671 [1:09:41<1:04:25,  1.73s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2436/4671 [1:09:41<1:04:20,  1.73s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2436/4671 [1:09:42<1:04:20,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2437/4671 [1:09:42<1:04:38,  1.74s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2437/4671 [1:09:44<1:04:38,  1.74s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2438/4671 [1:09:44<1:04:02,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2438/4671 [1:09:46<1:04:02,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2439/4671 [1:09:46<1:03:56,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2439/4671 [1:09:48<1:03:56,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2440/4671 [1:09:48<1:02:58,  1.69s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2440/4671 [1:09:49<1:02:58,  1.69s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2441/4671 [1:09:49<1:03:22,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2441/4671 [1:09:51<1:03:22,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2442/4671 [1:09:51<1:03:40,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2442/4671 [1:09:53<1:03:40,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2443/4671 [1:09:53<1:03:39,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2443/4671 [1:09:54<1:03:39,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2444/4671 [1:09:54<1:04:02,  1.73s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2444/4671 [1:09:56<1:04:02,  1.73s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2445/4671 [1:09:56<1:03:55,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2445/4671 [1:09:58<1:03:55,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2446/4671 [1:09:58<1:03:18,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2446/4671 [1:10:00<1:03:18,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2447/4671 [1:10:00<1:03:09,  1.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2447/4671 [1:10:01<1:03:09,  1.70s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2448/4671 [1:10:01<1:03:21,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2448/4671 [1:10:03<1:03:21,  1.71s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2449/4671 [1:10:03<1:03:22,  1.71s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2449/4671 [1:10:05<1:03:22,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2450/4671 [1:10:05<1:02:47,  1.70s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2450/4671 [1:10:06<1:02:47,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2451/4671 [1:10:06<1:03:16,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2451/4671 [1:10:08<1:03:16,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2452/4671 [1:10:08<1:03:30,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 2452/4671 [1:10:10<1:03:30,  1.72s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2453/4671 [1:10:10<1:04:03,  1.73s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2453/4671 [1:10:12<1:04:03,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2454/4671 [1:10:12<1:03:58,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2454/4671 [1:10:13<1:03:58,  1.73s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2455/4671 [1:10:13<1:04:03,  1.73s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2455/4671 [1:10:15<1:04:03,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2456/4671 [1:10:15<1:04:16,  1.74s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2456/4671 [1:10:17<1:04:16,  1.74s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2457/4671 [1:10:17<1:04:09,  1.74s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2457/4671 [1:10:19<1:04:09,  1.74s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2458/4671 [1:10:19<1:04:18,  1.74s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2458/4671 [1:10:20<1:04:18,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2459/4671 [1:10:20<1:04:05,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2459/4671 [1:10:22<1:04:05,  1.74s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2460/4671 [1:10:22<1:04:12,  1.74s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2460/4671 [1:10:24<1:04:12,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2461/4671 [1:10:24<1:04:27,  1.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2461/4671 [1:10:26<1:04:27,  1.75s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2462/4671 [1:10:26<1:04:16,  1.75s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2462/4671 [1:10:27<1:04:16,  1.75s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2463/4671 [1:10:27<1:03:27,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2463/4671 [1:10:29<1:03:27,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2464/4671 [1:10:29<1:03:01,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2464/4671 [1:10:31<1:03:01,  1.71s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2465/4671 [1:10:31<1:03:15,  1.72s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2465/4671 [1:10:32<1:03:15,  1.72s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2466/4671 [1:10:32<1:03:48,  1.74s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2466/4671 [1:10:34<1:03:48,  1.74s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2467/4671 [1:10:34<1:03:38,  1.73s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2467/4671 [1:10:36<1:03:38,  1.73s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2468/4671 [1:10:36<1:03:42,  1.74s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2468/4671 [1:10:38<1:03:42,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2469/4671 [1:10:38<1:03:44,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2469/4671 [1:10:39<1:03:44,  1.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2470/4671 [1:10:39<1:03:22,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2470/4671 [1:10:41<1:03:22,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2471/4671 [1:10:41<1:03:31,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2471/4671 [1:10:43<1:03:31,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2472/4671 [1:10:43<1:03:33,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2472/4671 [1:10:45<1:03:33,  1.73s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2473/4671 [1:10:45<1:03:15,  1.73s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2473/4671 [1:10:46<1:03:15,  1.73s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2474/4671 [1:10:46<1:03:10,  1.73s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2474/4671 [1:10:48<1:03:10,  1.73s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2475/4671 [1:10:48<1:02:51,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2475/4671 [1:10:50<1:02:51,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2476/4671 [1:10:50<1:02:46,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2476/4671 [1:10:51<1:02:46,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2477/4671 [1:10:51<1:02:29,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2477/4671 [1:10:53<1:02:29,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2478/4671 [1:10:53<1:02:55,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2478/4671 [1:10:55<1:02:55,  1.72s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2479/4671 [1:10:55<1:02:35,  1.71s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2479/4671 [1:10:57<1:02:35,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2480/4671 [1:10:57<1:02:30,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2480/4671 [1:10:58<1:02:30,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2481/4671 [1:10:58<1:02:32,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2481/4671 [1:11:00<1:02:32,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2482/4671 [1:11:00<1:02:31,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2482/4671 [1:11:02<1:02:31,  1.71s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2483/4671 [1:11:02<1:02:46,  1.72s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2483/4671 [1:11:03<1:02:46,  1.72s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2484/4671 [1:11:03<1:03:04,  1.73s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2484/4671 [1:11:05<1:03:04,  1.73s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2485/4671 [1:11:05<1:02:36,  1.72s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2485/4671 [1:11:07<1:02:36,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2486/4671 [1:11:07<1:02:45,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2486/4671 [1:11:09<1:02:45,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2487/4671 [1:11:09<1:02:51,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2487/4671 [1:11:10<1:02:51,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2488/4671 [1:11:10<1:03:12,  1.74s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2488/4671 [1:11:12<1:03:12,  1.74s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2489/4671 [1:11:12<1:02:50,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2489/4671 [1:11:14<1:02:50,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2490/4671 [1:11:14<1:02:26,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2490/4671 [1:11:15<1:02:26,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2491/4671 [1:11:15<1:02:26,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2491/4671 [1:11:17<1:02:26,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2492/4671 [1:11:17<1:02:20,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2492/4671 [1:11:19<1:02:20,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2493/4671 [1:11:19<1:02:36,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2493/4671 [1:11:21<1:02:36,  1.72s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2494/4671 [1:11:21<1:03:03,  1.74s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2494/4671 [1:11:22<1:03:03,  1.74s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2495/4671 [1:11:22<1:02:51,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2495/4671 [1:11:24<1:02:51,  1.73s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2496/4671 [1:11:24<1:02:30,  1.72s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2496/4671 [1:11:26<1:02:30,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2497/4671 [1:11:26<1:02:50,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2497/4671 [1:11:28<1:02:50,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2498/4671 [1:11:28<1:02:40,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 2498/4671 [1:11:29<1:02:40,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2499/4671 [1:11:29<1:02:10,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2499/4671 [1:11:31<1:02:10,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2500/4671 [1:11:31<1:02:12,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2500/4671 [1:11:33<1:02:12,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2501/4671 [1:11:33<1:01:58,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2501/4671 [1:11:34<1:01:58,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2502/4671 [1:11:34<1:02:17,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2502/4671 [1:11:36<1:02:17,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2503/4671 [1:11:36<1:01:33,  1.70s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2503/4671 [1:11:38<1:01:33,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2504/4671 [1:11:38<1:01:44,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2504/4671 [1:11:40<1:01:44,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2505/4671 [1:11:40<1:02:11,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2505/4671 [1:11:41<1:02:11,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2506/4671 [1:11:41<1:01:47,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2506/4671 [1:11:43<1:01:47,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2507/4671 [1:11:43<1:01:40,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2507/4671 [1:11:45<1:01:40,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2508/4671 [1:11:45<1:01:17,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2508/4671 [1:11:46<1:01:17,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2509/4671 [1:11:46<1:01:31,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2509/4671 [1:11:48<1:01:31,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2510/4671 [1:11:48<1:01:15,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 2510/4671 [1:11:50<1:01:15,  1.70s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2511/4671 [1:11:50<1:01:50,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2511/4671 [1:11:52<1:01:50,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2512/4671 [1:11:52<1:02:05,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2512/4671 [1:11:53<1:02:05,  1.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2513/4671 [1:11:53<1:02:04,  1.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2513/4671 [1:11:55<1:02:04,  1.73s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2514/4671 [1:11:55<1:02:12,  1.73s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2514/4671 [1:11:57<1:02:12,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2515/4671 [1:11:57<1:00:58,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2515/4671 [1:11:58<1:00:58,  1.70s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2516/4671 [1:11:58<1:01:40,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2516/4671 [1:12:00<1:01:40,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2517/4671 [1:12:00<1:01:58,  1.73s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2517/4671 [1:12:02<1:01:58,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2518/4671 [1:12:02<1:01:54,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2518/4671 [1:12:04<1:01:54,  1.73s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2519/4671 [1:12:04<1:02:06,  1.73s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2519/4671 [1:12:05<1:02:06,  1.73s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2520/4671 [1:12:05<1:01:21,  1.71s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2520/4671 [1:12:07<1:01:21,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2521/4671 [1:12:07<1:01:02,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2521/4671 [1:12:09<1:01:02,  1.70s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2522/4671 [1:12:09<1:00:57,  1.70s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2522/4671 [1:12:10<1:00:57,  1.70s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2523/4671 [1:12:10<1:01:12,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2523/4671 [1:12:12<1:01:12,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2524/4671 [1:12:12<1:01:07,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2524/4671 [1:12:14<1:01:07,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2525/4671 [1:12:14<1:01:15,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2525/4671 [1:12:16<1:01:15,  1.71s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2526/4671 [1:12:16<1:01:11,  1.71s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2526/4671 [1:12:17<1:01:11,  1.71s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2527/4671 [1:12:17<1:00:43,  1.70s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2527/4671 [1:12:19<1:00:43,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2528/4671 [1:12:19<1:01:08,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2528/4671 [1:12:21<1:01:08,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2529/4671 [1:12:21<1:01:25,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2529/4671 [1:12:22<1:01:25,  1.72s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2530/4671 [1:12:22<1:01:16,  1.72s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2530/4671 [1:12:24<1:01:16,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2531/4671 [1:12:24<1:01:24,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2531/4671 [1:12:26<1:01:24,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2532/4671 [1:12:26<1:01:30,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2532/4671 [1:12:28<1:01:30,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2533/4671 [1:12:28<1:01:42,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2533/4671 [1:12:29<1:01:42,  1.73s/it, training_loss=0.079]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2534/4671 [1:12:29<1:01:35,  1.73s/it, training_loss=0.079]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2534/4671 [1:12:31<1:01:35,  1.73s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2535/4671 [1:12:31<1:01:29,  1.73s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2535/4671 [1:12:33<1:01:29,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2536/4671 [1:12:33<1:01:20,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2536/4671 [1:12:35<1:01:20,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2537/4671 [1:12:35<1:01:08,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2537/4671 [1:12:36<1:01:08,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2538/4671 [1:12:36<1:00:28,  1.70s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2538/4671 [1:12:38<1:00:28,  1.70s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2539/4671 [1:12:38<1:00:30,  1.70s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2539/4671 [1:12:40<1:00:30,  1.70s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2540/4671 [1:12:40<1:00:28,  1.70s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2540/4671 [1:12:41<1:00:28,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2541/4671 [1:12:41<1:00:10,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2541/4671 [1:12:43<1:00:10,  1.70s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2542/4671 [1:12:43<1:00:53,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2542/4671 [1:12:45<1:00:53,  1.72s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2543/4671 [1:12:45<1:00:40,  1.71s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2543/4671 [1:12:46<1:00:40,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2544/4671 [1:12:46<1:00:47,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2544/4671 [1:12:48<1:00:47,  1.71s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2545/4671 [1:12:48<1:01:15,  1.73s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 2545/4671 [1:12:50<1:01:15,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2546/4671 [1:12:50<1:01:06,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2546/4671 [1:12:52<1:01:06,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2547/4671 [1:12:52<1:01:12,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2547/4671 [1:12:53<1:01:12,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2548/4671 [1:12:53<1:01:18,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2548/4671 [1:12:55<1:01:18,  1.73s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2549/4671 [1:12:55<1:01:03,  1.73s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2549/4671 [1:12:57<1:01:03,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2550/4671 [1:12:57<1:00:45,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2550/4671 [1:12:58<1:00:45,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2551/4671 [1:12:58<1:00:07,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2551/4671 [1:13:00<1:00:07,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2552/4671 [1:13:00<1:00:20,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2552/4671 [1:13:02<1:00:20,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2553/4671 [1:13:02<1:00:14,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2553/4671 [1:13:04<1:00:14,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2554/4671 [1:13:04<1:00:08,  1.70s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2554/4671 [1:13:05<1:00:08,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2555/4671 [1:13:05<59:46,  1.69s/it, training_loss=0.124]  \u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2555/4671 [1:13:07<59:46,  1.69s/it, training_loss=0.069]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2556/4671 [1:13:07<59:55,  1.70s/it, training_loss=0.069]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2556/4671 [1:13:09<59:55,  1.70s/it, training_loss=0.066]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2557/4671 [1:13:09<59:43,  1.70s/it, training_loss=0.066]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2557/4671 [1:13:10<59:43,  1.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2558/4671 [1:13:10<59:30,  1.69s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2558/4671 [1:13:12<59:30,  1.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2559/4671 [1:13:12<59:28,  1.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2559/4671 [1:13:14<59:28,  1.69s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2560/4671 [1:13:14<1:00:16,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2560/4671 [1:13:16<1:00:16,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2561/4671 [1:13:16<1:00:34,  1.72s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2561/4671 [1:13:17<1:00:34,  1.72s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2562/4671 [1:13:17<1:00:30,  1.72s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2562/4671 [1:13:19<1:00:30,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2563/4671 [1:13:19<1:00:12,  1.71s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2563/4671 [1:13:21<1:00:12,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2564/4671 [1:13:21<59:48,  1.70s/it, training_loss=0.152]  \u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2564/4671 [1:13:22<59:48,  1.70s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2565/4671 [1:13:22<1:00:01,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2565/4671 [1:13:24<1:00:01,  1.71s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2566/4671 [1:13:24<1:00:10,  1.72s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2566/4671 [1:13:26<1:00:10,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2567/4671 [1:13:26<1:00:09,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2567/4671 [1:13:28<1:00:09,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2568/4671 [1:13:28<1:00:12,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2568/4671 [1:13:29<1:00:12,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2569/4671 [1:13:29<59:35,  1.70s/it, training_loss=0.126]  \u001B[A\n",
      "Epoch 1:  55%|█████▍    | 2569/4671 [1:13:31<59:35,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2570/4671 [1:13:31<58:59,  1.68s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2570/4671 [1:13:33<58:59,  1.68s/it, training_loss=0.209]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2571/4671 [1:13:33<59:17,  1.69s/it, training_loss=0.209]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2571/4671 [1:13:34<59:17,  1.69s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2572/4671 [1:13:34<59:35,  1.70s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2572/4671 [1:13:36<59:35,  1.70s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2573/4671 [1:13:36<59:43,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2573/4671 [1:13:38<59:43,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2574/4671 [1:13:38<59:55,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2574/4671 [1:13:39<59:55,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2575/4671 [1:13:39<59:41,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2575/4671 [1:13:41<59:41,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2576/4671 [1:13:41<59:43,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2576/4671 [1:13:43<59:43,  1.71s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2577/4671 [1:13:43<59:56,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2577/4671 [1:13:45<59:56,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2578/4671 [1:13:45<59:36,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2578/4671 [1:13:46<59:36,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2579/4671 [1:13:46<59:39,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2579/4671 [1:13:48<59:39,  1.71s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2580/4671 [1:13:48<59:26,  1.71s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2580/4671 [1:13:50<59:26,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2581/4671 [1:13:50<59:55,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2581/4671 [1:13:51<59:55,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2582/4671 [1:13:51<59:52,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2582/4671 [1:13:53<59:52,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2583/4671 [1:13:53<59:21,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2583/4671 [1:13:55<59:21,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2584/4671 [1:13:55<59:50,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2584/4671 [1:13:57<59:50,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2585/4671 [1:13:57<1:00:08,  1.73s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2585/4671 [1:13:58<1:00:08,  1.73s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2586/4671 [1:13:58<59:58,  1.73s/it, training_loss=0.141]  \u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2586/4671 [1:14:00<59:58,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2587/4671 [1:14:00<59:43,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2587/4671 [1:14:02<59:43,  1.72s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2588/4671 [1:14:02<59:20,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2588/4671 [1:14:03<59:20,  1.71s/it, training_loss=0.193]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2589/4671 [1:14:03<59:21,  1.71s/it, training_loss=0.193]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2589/4671 [1:14:05<59:21,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2590/4671 [1:14:05<59:19,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2590/4671 [1:14:07<59:19,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2591/4671 [1:14:07<59:12,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2591/4671 [1:14:09<59:12,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2592/4671 [1:14:09<1:00:04,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 2592/4671 [1:14:10<1:00:04,  1.73s/it, training_loss=0.068]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2593/4671 [1:14:10<59:51,  1.73s/it, training_loss=0.068]  \u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2593/4671 [1:14:12<59:51,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2594/4671 [1:14:12<1:00:04,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2594/4671 [1:14:14<1:00:04,  1.74s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2595/4671 [1:14:14<1:00:10,  1.74s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2595/4671 [1:14:16<1:00:10,  1.74s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2596/4671 [1:14:16<59:21,  1.72s/it, training_loss=0.118]  \u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2596/4671 [1:14:17<59:21,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2597/4671 [1:14:17<59:25,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2597/4671 [1:14:19<59:25,  1.72s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2598/4671 [1:14:19<59:13,  1.71s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2598/4671 [1:14:21<59:13,  1.71s/it, training_loss=0.215]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2599/4671 [1:14:21<58:52,  1.70s/it, training_loss=0.215]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2599/4671 [1:14:22<58:52,  1.70s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2600/4671 [1:14:22<59:21,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2600/4671 [1:14:24<59:21,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2601/4671 [1:14:24<59:38,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2601/4671 [1:14:26<59:38,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2602/4671 [1:14:26<59:37,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2602/4671 [1:14:28<59:37,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2603/4671 [1:14:28<59:07,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2603/4671 [1:14:29<59:07,  1.72s/it, training_loss=0.076]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2604/4671 [1:14:29<59:00,  1.71s/it, training_loss=0.076]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2604/4671 [1:14:31<59:00,  1.71s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2605/4671 [1:14:31<59:18,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2605/4671 [1:14:33<59:18,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2606/4671 [1:14:33<59:11,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2606/4671 [1:14:34<59:11,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2607/4671 [1:14:34<59:13,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2607/4671 [1:14:36<59:13,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2608/4671 [1:14:36<59:17,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2608/4671 [1:14:38<59:17,  1.72s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2609/4671 [1:14:38<59:04,  1.72s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2609/4671 [1:14:40<59:04,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2610/4671 [1:14:40<58:30,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2610/4671 [1:14:41<58:30,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2611/4671 [1:14:41<58:16,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2611/4671 [1:14:43<58:16,  1.70s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2612/4671 [1:14:43<57:56,  1.69s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2612/4671 [1:14:45<57:56,  1.69s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2613/4671 [1:14:45<58:20,  1.70s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2613/4671 [1:14:46<58:20,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2614/4671 [1:14:46<58:33,  1.71s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2614/4671 [1:14:48<58:33,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2615/4671 [1:14:48<58:06,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2615/4671 [1:14:50<58:06,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2616/4671 [1:14:50<58:12,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2616/4671 [1:14:51<58:12,  1.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2617/4671 [1:14:51<57:55,  1.69s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2617/4671 [1:14:53<57:55,  1.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2618/4671 [1:14:53<57:43,  1.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2618/4671 [1:14:55<57:43,  1.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2619/4671 [1:14:55<58:02,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2619/4671 [1:14:57<58:02,  1.70s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2620/4671 [1:14:57<58:14,  1.70s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2620/4671 [1:14:58<58:14,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2621/4671 [1:14:58<58:05,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2621/4671 [1:15:00<58:05,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2622/4671 [1:15:00<58:10,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2622/4671 [1:15:02<58:10,  1.70s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2623/4671 [1:15:02<58:01,  1.70s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2623/4671 [1:15:03<58:01,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2624/4671 [1:15:03<57:59,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2624/4671 [1:15:05<57:59,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2625/4671 [1:15:05<58:03,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2625/4671 [1:15:07<58:03,  1.70s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2626/4671 [1:15:07<58:31,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2626/4671 [1:15:09<58:31,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2627/4671 [1:15:09<58:41,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 2627/4671 [1:15:10<58:41,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2628/4671 [1:15:10<58:32,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2628/4671 [1:15:12<58:32,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2629/4671 [1:15:12<58:42,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2629/4671 [1:15:14<58:42,  1.73s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2630/4671 [1:15:14<59:08,  1.74s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2630/4671 [1:15:15<59:08,  1.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2631/4671 [1:15:15<58:51,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2631/4671 [1:15:17<58:51,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2632/4671 [1:15:17<58:18,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2632/4671 [1:15:19<58:18,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2633/4671 [1:15:19<58:32,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2633/4671 [1:15:21<58:32,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2634/4671 [1:15:21<58:44,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2634/4671 [1:15:22<58:44,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2635/4671 [1:15:22<58:36,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2635/4671 [1:15:24<58:36,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2636/4671 [1:15:24<58:31,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2636/4671 [1:15:26<58:31,  1.73s/it, training_loss=0.190]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2637/4671 [1:15:26<58:31,  1.73s/it, training_loss=0.190]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2637/4671 [1:15:28<58:31,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2638/4671 [1:15:28<58:36,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2638/4671 [1:15:29<58:36,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2639/4671 [1:15:29<58:41,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 2639/4671 [1:15:31<58:41,  1.73s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2640/4671 [1:15:31<58:46,  1.74s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2640/4671 [1:15:33<58:46,  1.74s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2641/4671 [1:15:33<58:26,  1.73s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2641/4671 [1:15:34<58:26,  1.73s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2642/4671 [1:15:34<58:19,  1.72s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2642/4671 [1:15:36<58:19,  1.72s/it, training_loss=0.080]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2643/4671 [1:15:36<58:18,  1.73s/it, training_loss=0.080]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2643/4671 [1:15:38<58:18,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2644/4671 [1:15:38<58:29,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2644/4671 [1:15:40<58:29,  1.73s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2645/4671 [1:15:40<58:10,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2645/4671 [1:15:41<58:10,  1.72s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2646/4671 [1:15:41<58:27,  1.73s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2646/4671 [1:15:43<58:27,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2647/4671 [1:15:43<58:33,  1.74s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2647/4671 [1:15:45<58:33,  1.74s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2648/4671 [1:15:45<58:01,  1.72s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2648/4671 [1:15:47<58:01,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2649/4671 [1:15:47<57:54,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2649/4671 [1:15:48<57:54,  1.72s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2650/4671 [1:15:48<58:17,  1.73s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2650/4671 [1:15:50<58:17,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2651/4671 [1:15:50<58:32,  1.74s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2651/4671 [1:15:52<58:32,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2652/4671 [1:15:52<58:28,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2652/4671 [1:15:54<58:28,  1.74s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2653/4671 [1:15:54<58:46,  1.75s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2653/4671 [1:15:55<58:46,  1.75s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2654/4671 [1:15:55<59:04,  1.76s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2654/4671 [1:15:57<59:04,  1.76s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2655/4671 [1:15:57<58:28,  1.74s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2655/4671 [1:15:59<58:28,  1.74s/it, training_loss=0.188]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2656/4671 [1:15:59<58:06,  1.73s/it, training_loss=0.188]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2656/4671 [1:16:00<58:06,  1.73s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2657/4671 [1:16:00<57:45,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2657/4671 [1:16:02<57:45,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2658/4671 [1:16:02<58:04,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2658/4671 [1:16:04<58:04,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2659/4671 [1:16:04<57:31,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2659/4671 [1:16:06<57:31,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2660/4671 [1:16:06<58:06,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2660/4671 [1:16:07<58:06,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2661/4671 [1:16:07<57:54,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2661/4671 [1:16:09<57:54,  1.73s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2662/4671 [1:16:09<58:01,  1.73s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2662/4671 [1:16:11<58:01,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2663/4671 [1:16:11<57:54,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2663/4671 [1:16:13<57:54,  1.73s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2664/4671 [1:16:13<57:54,  1.73s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2664/4671 [1:16:14<57:54,  1.73s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2665/4671 [1:16:14<57:35,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2665/4671 [1:16:16<57:35,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2666/4671 [1:16:16<57:41,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2666/4671 [1:16:18<57:41,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2667/4671 [1:16:18<57:13,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2667/4671 [1:16:19<57:13,  1.71s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2668/4671 [1:16:19<57:31,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2668/4671 [1:16:21<57:31,  1.72s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2669/4671 [1:16:21<57:27,  1.72s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2669/4671 [1:16:23<57:27,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2670/4671 [1:16:23<57:14,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2670/4671 [1:16:25<57:14,  1.72s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2671/4671 [1:16:25<57:06,  1.71s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2671/4671 [1:16:26<57:06,  1.71s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2672/4671 [1:16:26<56:39,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2672/4671 [1:16:28<56:39,  1.70s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2673/4671 [1:16:28<56:29,  1.70s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2673/4671 [1:16:30<56:29,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2674/4671 [1:16:30<56:32,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2674/4671 [1:16:31<56:32,  1.70s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2675/4671 [1:16:31<56:12,  1.69s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2675/4671 [1:16:33<56:12,  1.69s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2676/4671 [1:16:33<56:18,  1.69s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2676/4671 [1:16:35<56:18,  1.69s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2677/4671 [1:16:35<56:18,  1.69s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2677/4671 [1:16:36<56:18,  1.69s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2678/4671 [1:16:36<56:29,  1.70s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2678/4671 [1:16:38<56:29,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2679/4671 [1:16:38<56:51,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2679/4671 [1:16:40<56:51,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2680/4671 [1:16:40<56:42,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2680/4671 [1:16:42<56:42,  1.71s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2681/4671 [1:16:42<56:28,  1.70s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2681/4671 [1:16:43<56:28,  1.70s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2682/4671 [1:16:43<56:48,  1.71s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2682/4671 [1:16:45<56:48,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2683/4671 [1:16:45<56:43,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2683/4671 [1:16:47<56:43,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2684/4671 [1:16:47<56:39,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2684/4671 [1:16:48<56:39,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2685/4671 [1:16:48<56:44,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 2685/4671 [1:16:50<56:44,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2686/4671 [1:16:50<57:00,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2686/4671 [1:16:52<57:00,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2687/4671 [1:16:52<56:58,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2687/4671 [1:16:54<56:58,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2688/4671 [1:16:54<56:56,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2688/4671 [1:16:55<56:56,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2689/4671 [1:16:55<56:40,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2689/4671 [1:16:57<56:40,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2690/4671 [1:16:57<56:48,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2690/4671 [1:16:59<56:48,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2691/4671 [1:16:59<56:46,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2691/4671 [1:17:00<56:46,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2692/4671 [1:17:00<56:29,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2692/4671 [1:17:02<56:29,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2693/4671 [1:17:02<56:40,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2693/4671 [1:17:04<56:40,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2694/4671 [1:17:04<56:58,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2694/4671 [1:17:06<56:58,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2695/4671 [1:17:06<57:10,  1.74s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2695/4671 [1:17:07<57:10,  1.74s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2696/4671 [1:17:07<57:09,  1.74s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2696/4671 [1:17:09<57:09,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2697/4671 [1:17:09<57:17,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2697/4671 [1:17:11<57:17,  1.74s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2698/4671 [1:17:11<56:45,  1.73s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2698/4671 [1:17:13<56:45,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2699/4671 [1:17:13<56:21,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2699/4671 [1:17:14<56:21,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2700/4671 [1:17:14<56:15,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2700/4671 [1:17:16<56:15,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2701/4671 [1:17:16<56:27,  1.72s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2701/4671 [1:17:18<56:27,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2702/4671 [1:17:18<56:40,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2702/4671 [1:17:19<56:40,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2703/4671 [1:17:19<56:34,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2703/4671 [1:17:21<56:34,  1.72s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2704/4671 [1:17:21<56:16,  1.72s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2704/4671 [1:17:23<56:16,  1.72s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2705/4671 [1:17:23<55:58,  1.71s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2705/4671 [1:17:25<55:58,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2706/4671 [1:17:25<56:11,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2706/4671 [1:17:26<56:11,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2707/4671 [1:17:26<55:51,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2707/4671 [1:17:28<55:51,  1.71s/it, training_loss=0.080]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2708/4671 [1:17:28<56:09,  1.72s/it, training_loss=0.080]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2708/4671 [1:17:30<56:09,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2709/4671 [1:17:30<56:40,  1.73s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2709/4671 [1:17:31<56:40,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2710/4671 [1:17:31<56:10,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2710/4671 [1:17:33<56:10,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2711/4671 [1:17:33<56:08,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2711/4671 [1:17:35<56:08,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2712/4671 [1:17:35<56:09,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2712/4671 [1:17:37<56:09,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2713/4671 [1:17:37<56:25,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2713/4671 [1:17:38<56:25,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2714/4671 [1:17:38<56:02,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2714/4671 [1:17:40<56:02,  1.72s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2715/4671 [1:17:40<56:23,  1.73s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2715/4671 [1:17:42<56:23,  1.73s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2716/4671 [1:17:42<55:56,  1.72s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2716/4671 [1:17:44<55:56,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2717/4671 [1:17:44<56:19,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2717/4671 [1:17:45<56:19,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2718/4671 [1:17:45<56:24,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2718/4671 [1:17:47<56:24,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2719/4671 [1:17:47<56:11,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2719/4671 [1:17:49<56:11,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2720/4671 [1:17:49<56:03,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2720/4671 [1:17:50<56:03,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2721/4671 [1:17:50<55:55,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2721/4671 [1:17:52<55:55,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2722/4671 [1:17:52<55:52,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2722/4671 [1:17:54<55:52,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2723/4671 [1:17:54<55:46,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2723/4671 [1:17:56<55:46,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2724/4671 [1:17:56<55:56,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2724/4671 [1:17:57<55:56,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2725/4671 [1:17:57<55:43,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2725/4671 [1:17:59<55:43,  1.72s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2726/4671 [1:17:59<55:35,  1.71s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2726/4671 [1:18:01<55:35,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2727/4671 [1:18:01<55:44,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2727/4671 [1:18:02<55:44,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2728/4671 [1:18:02<55:49,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2728/4671 [1:18:04<55:49,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2729/4671 [1:18:04<56:00,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2729/4671 [1:18:06<56:00,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2730/4671 [1:18:06<55:53,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2730/4671 [1:18:08<55:53,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2731/4671 [1:18:08<55:14,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2731/4671 [1:18:09<55:14,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2732/4671 [1:18:09<55:38,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 2732/4671 [1:18:11<55:38,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2733/4671 [1:18:11<55:38,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2733/4671 [1:18:13<55:38,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2734/4671 [1:18:13<55:41,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2734/4671 [1:18:15<55:41,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2735/4671 [1:18:15<55:31,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2735/4671 [1:18:16<55:31,  1.72s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2736/4671 [1:18:16<55:44,  1.73s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2736/4671 [1:18:18<55:44,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2737/4671 [1:18:18<55:23,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2737/4671 [1:18:20<55:23,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2738/4671 [1:18:20<55:00,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2738/4671 [1:18:21<55:00,  1.71s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2739/4671 [1:18:21<55:05,  1.71s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2739/4671 [1:18:23<55:05,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2740/4671 [1:18:23<55:13,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2740/4671 [1:18:25<55:13,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2741/4671 [1:18:25<55:04,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2741/4671 [1:18:27<55:04,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2742/4671 [1:18:27<55:23,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2742/4671 [1:18:28<55:23,  1.72s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2743/4671 [1:18:28<54:54,  1.71s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2743/4671 [1:18:30<54:54,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2744/4671 [1:18:30<55:33,  1.73s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 2744/4671 [1:18:32<55:33,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2745/4671 [1:18:32<55:46,  1.74s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2745/4671 [1:18:33<55:46,  1.74s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2746/4671 [1:18:33<55:20,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2746/4671 [1:18:35<55:20,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2747/4671 [1:18:35<55:18,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2747/4671 [1:18:37<55:18,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2748/4671 [1:18:37<55:23,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2748/4671 [1:18:39<55:23,  1.73s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2749/4671 [1:18:39<55:13,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2749/4671 [1:18:40<55:13,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2750/4671 [1:18:40<54:32,  1.70s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2750/4671 [1:18:42<54:32,  1.70s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2751/4671 [1:18:42<55:02,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2751/4671 [1:18:44<55:02,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2752/4671 [1:18:44<55:10,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2752/4671 [1:18:45<55:10,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2753/4671 [1:18:45<54:43,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2753/4671 [1:18:47<54:43,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2754/4671 [1:18:47<55:09,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2754/4671 [1:18:49<55:09,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2755/4671 [1:18:49<54:57,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2755/4671 [1:18:51<54:57,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2756/4671 [1:18:51<54:59,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2756/4671 [1:18:52<54:59,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2757/4671 [1:18:52<54:40,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2757/4671 [1:18:54<54:40,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2758/4671 [1:18:54<54:58,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2758/4671 [1:18:56<54:58,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2759/4671 [1:18:56<55:20,  1.74s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2759/4671 [1:18:58<55:20,  1.74s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2760/4671 [1:18:58<54:51,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2760/4671 [1:18:59<54:51,  1.72s/it, training_loss=0.204]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2761/4671 [1:18:59<54:44,  1.72s/it, training_loss=0.204]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2761/4671 [1:19:01<54:44,  1.72s/it, training_loss=0.067]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2762/4671 [1:19:01<54:28,  1.71s/it, training_loss=0.067]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2762/4671 [1:19:03<54:28,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2763/4671 [1:19:03<54:17,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2763/4671 [1:19:04<54:17,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2764/4671 [1:19:04<54:49,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2764/4671 [1:19:06<54:49,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2765/4671 [1:19:06<54:50,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2765/4671 [1:19:08<54:50,  1.73s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2766/4671 [1:19:08<54:32,  1.72s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2766/4671 [1:19:10<54:32,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2767/4671 [1:19:10<54:41,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2767/4671 [1:19:11<54:41,  1.72s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2768/4671 [1:19:11<54:43,  1.73s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2768/4671 [1:19:13<54:43,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2769/4671 [1:19:13<54:45,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2769/4671 [1:19:15<54:45,  1.73s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2770/4671 [1:19:15<54:29,  1.72s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2770/4671 [1:19:16<54:29,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2771/4671 [1:19:16<54:33,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2771/4671 [1:19:18<54:33,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2772/4671 [1:19:18<55:46,  1.76s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2772/4671 [1:19:20<55:46,  1.76s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2773/4671 [1:19:20<56:40,  1.79s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2773/4671 [1:19:22<56:40,  1.79s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2774/4671 [1:19:22<56:16,  1.78s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2774/4671 [1:19:24<56:16,  1.78s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2775/4671 [1:19:24<55:32,  1.76s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2775/4671 [1:19:25<55:32,  1.76s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2776/4671 [1:19:25<54:44,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2776/4671 [1:19:27<54:44,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2777/4671 [1:19:27<54:13,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2777/4671 [1:19:29<54:13,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2778/4671 [1:19:29<55:15,  1.75s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2778/4671 [1:19:31<55:15,  1.75s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2779/4671 [1:19:31<54:51,  1.74s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 2779/4671 [1:19:32<54:51,  1.74s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2780/4671 [1:19:32<54:27,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2780/4671 [1:19:34<54:27,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2781/4671 [1:19:34<54:35,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2781/4671 [1:19:36<54:35,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2782/4671 [1:19:36<54:32,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2782/4671 [1:19:37<54:32,  1.73s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2783/4671 [1:19:37<54:19,  1.73s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2783/4671 [1:19:39<54:19,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2784/4671 [1:19:39<54:12,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2784/4671 [1:19:41<54:12,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2785/4671 [1:19:41<53:49,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2785/4671 [1:19:43<53:49,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2786/4671 [1:19:43<53:30,  1.70s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2786/4671 [1:19:44<53:30,  1.70s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2787/4671 [1:19:44<53:27,  1.70s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2787/4671 [1:19:46<53:27,  1.70s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2788/4671 [1:19:46<53:42,  1.71s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2788/4671 [1:19:48<53:42,  1.71s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2789/4671 [1:19:48<53:40,  1.71s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2789/4671 [1:19:49<53:40,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2790/4671 [1:19:49<53:51,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2790/4671 [1:19:51<53:51,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2791/4671 [1:19:51<53:55,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2791/4671 [1:19:53<53:55,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2792/4671 [1:19:53<53:52,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2792/4671 [1:19:55<53:52,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2793/4671 [1:19:55<53:44,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2793/4671 [1:19:56<53:44,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2794/4671 [1:19:56<53:01,  1.69s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2794/4671 [1:19:58<53:01,  1.69s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2795/4671 [1:19:58<53:45,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2795/4671 [1:20:00<53:45,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2796/4671 [1:20:00<53:33,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2796/4671 [1:20:01<53:33,  1.71s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2797/4671 [1:20:01<53:26,  1.71s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2797/4671 [1:20:03<53:26,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2798/4671 [1:20:03<53:36,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2798/4671 [1:20:05<53:36,  1.72s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2799/4671 [1:20:05<53:45,  1.72s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2799/4671 [1:20:07<53:45,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2800/4671 [1:20:07<53:54,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2800/4671 [1:20:08<53:54,  1.73s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2801/4671 [1:20:08<53:49,  1.73s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2801/4671 [1:20:10<53:49,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2802/4671 [1:20:10<53:52,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 2802/4671 [1:20:12<53:52,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2803/4671 [1:20:12<53:49,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2803/4671 [1:20:13<53:49,  1.73s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2804/4671 [1:20:13<53:31,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2804/4671 [1:20:15<53:31,  1.72s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2805/4671 [1:20:15<53:34,  1.72s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2805/4671 [1:20:17<53:34,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2806/4671 [1:20:17<53:18,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2806/4671 [1:20:19<53:18,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2807/4671 [1:20:19<53:57,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2807/4671 [1:20:20<53:57,  1.74s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2808/4671 [1:20:20<54:17,  1.75s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2808/4671 [1:20:22<54:17,  1.75s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2809/4671 [1:20:22<54:38,  1.76s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2809/4671 [1:20:24<54:38,  1.76s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2810/4671 [1:20:24<54:25,  1.75s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2810/4671 [1:20:26<54:25,  1.75s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2811/4671 [1:20:26<54:17,  1.75s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2811/4671 [1:20:27<54:17,  1.75s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2812/4671 [1:20:27<54:04,  1.75s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2812/4671 [1:20:29<54:04,  1.75s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2813/4671 [1:20:29<53:53,  1.74s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2813/4671 [1:20:31<53:53,  1.74s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2814/4671 [1:20:31<53:27,  1.73s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2814/4671 [1:20:33<53:27,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2815/4671 [1:20:33<53:27,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2815/4671 [1:20:34<53:27,  1.73s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2816/4671 [1:20:34<53:32,  1.73s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2816/4671 [1:20:36<53:32,  1.73s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2817/4671 [1:20:36<53:18,  1.73s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2817/4671 [1:20:38<53:18,  1.73s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2818/4671 [1:20:38<53:30,  1.73s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2818/4671 [1:20:40<53:30,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2819/4671 [1:20:40<53:13,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2819/4671 [1:20:41<53:13,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2820/4671 [1:20:41<53:09,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2820/4671 [1:20:43<53:09,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2821/4671 [1:20:43<53:00,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2821/4671 [1:20:45<53:00,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2822/4671 [1:20:45<52:44,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2822/4671 [1:20:46<52:44,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2823/4671 [1:20:46<52:55,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2823/4671 [1:20:48<52:55,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2824/4671 [1:20:48<52:33,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2824/4671 [1:20:50<52:33,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2825/4671 [1:20:50<52:37,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  60%|██████    | 2825/4671 [1:20:52<52:37,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2826/4671 [1:20:52<52:40,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2826/4671 [1:20:53<52:40,  1.71s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2827/4671 [1:20:53<52:58,  1.72s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2827/4671 [1:20:55<52:58,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2828/4671 [1:20:55<52:53,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2828/4671 [1:20:57<52:53,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2829/4671 [1:20:57<52:54,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2829/4671 [1:20:58<52:54,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2830/4671 [1:20:58<53:12,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2830/4671 [1:21:00<53:12,  1.73s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2831/4671 [1:21:00<52:58,  1.73s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2831/4671 [1:21:02<52:58,  1.73s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2832/4671 [1:21:02<52:50,  1.72s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2832/4671 [1:21:04<52:50,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2833/4671 [1:21:04<52:30,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2833/4671 [1:21:05<52:30,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2834/4671 [1:21:05<52:37,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2834/4671 [1:21:07<52:37,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2835/4671 [1:21:07<52:49,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2835/4671 [1:21:09<52:49,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2836/4671 [1:21:09<53:05,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2836/4671 [1:21:11<53:05,  1.74s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2837/4671 [1:21:11<53:28,  1.75s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2837/4671 [1:21:12<53:28,  1.75s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2838/4671 [1:21:12<53:23,  1.75s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2838/4671 [1:21:14<53:23,  1.75s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2839/4671 [1:21:14<53:00,  1.74s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2839/4671 [1:21:16<53:00,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2840/4671 [1:21:16<52:54,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2840/4671 [1:21:17<52:54,  1.73s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2841/4671 [1:21:17<52:20,  1.72s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2841/4671 [1:21:19<52:20,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2842/4671 [1:21:19<52:16,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2842/4671 [1:21:21<52:16,  1.71s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2843/4671 [1:21:21<52:17,  1.72s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2843/4671 [1:21:23<52:17,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2844/4671 [1:21:23<52:18,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2844/4671 [1:21:24<52:18,  1.72s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2845/4671 [1:21:24<52:24,  1.72s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2845/4671 [1:21:26<52:24,  1.72s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2846/4671 [1:21:26<52:23,  1.72s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2846/4671 [1:21:28<52:23,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2847/4671 [1:21:28<51:48,  1.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2847/4671 [1:21:29<51:48,  1.70s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2848/4671 [1:21:29<51:44,  1.70s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2848/4671 [1:21:31<51:44,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2849/4671 [1:21:31<52:10,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2849/4671 [1:21:33<52:10,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2850/4671 [1:21:33<52:07,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2850/4671 [1:21:35<52:07,  1.72s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2851/4671 [1:21:35<51:43,  1.71s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2851/4671 [1:21:36<51:43,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2852/4671 [1:21:36<51:54,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2852/4671 [1:21:38<51:54,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2853/4671 [1:21:38<51:49,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2853/4671 [1:21:40<51:49,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2854/4671 [1:21:40<52:11,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2854/4671 [1:21:41<52:11,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2855/4671 [1:21:41<52:06,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2855/4671 [1:21:43<52:06,  1.72s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2856/4671 [1:21:43<51:39,  1.71s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2856/4671 [1:21:45<51:39,  1.71s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2857/4671 [1:21:45<51:40,  1.71s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2857/4671 [1:21:47<51:40,  1.71s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2858/4671 [1:21:47<56:12,  1.86s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2858/4671 [1:21:49<56:12,  1.86s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2859/4671 [1:21:49<58:46,  1.95s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2859/4671 [1:21:51<58:46,  1.95s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2860/4671 [1:21:51<57:46,  1.91s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  61%|██████    | 2860/4671 [1:21:53<57:46,  1.91s/it, training_loss=0.072]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2861/4671 [1:21:53<56:13,  1.86s/it, training_loss=0.072]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2861/4671 [1:21:55<56:13,  1.86s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2862/4671 [1:21:55<54:59,  1.82s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2862/4671 [1:21:56<54:59,  1.82s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2863/4671 [1:21:56<54:18,  1.80s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2863/4671 [1:21:58<54:18,  1.80s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2864/4671 [1:21:58<53:34,  1.78s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2864/4671 [1:22:00<53:34,  1.78s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2865/4671 [1:22:00<53:08,  1.77s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2865/4671 [1:22:01<53:08,  1.77s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2866/4671 [1:22:01<52:17,  1.74s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2866/4671 [1:22:03<52:17,  1.74s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2867/4671 [1:22:03<51:51,  1.73s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2867/4671 [1:22:05<51:51,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2868/4671 [1:22:05<51:45,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2868/4671 [1:22:07<51:45,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2869/4671 [1:22:07<52:03,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2869/4671 [1:22:08<52:03,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2870/4671 [1:22:08<52:12,  1.74s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2870/4671 [1:22:10<52:12,  1.74s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2871/4671 [1:22:10<52:14,  1.74s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2871/4671 [1:22:12<52:14,  1.74s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2872/4671 [1:22:12<52:24,  1.75s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 2872/4671 [1:22:14<52:24,  1.75s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2873/4671 [1:22:14<52:14,  1.74s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2873/4671 [1:22:15<52:14,  1.74s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2874/4671 [1:22:15<51:48,  1.73s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2874/4671 [1:22:17<51:48,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2875/4671 [1:22:17<51:53,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2875/4671 [1:22:19<51:53,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2876/4671 [1:22:19<52:08,  1.74s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2876/4671 [1:22:21<52:08,  1.74s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2877/4671 [1:22:21<52:32,  1.76s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2877/4671 [1:22:22<52:32,  1.76s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2878/4671 [1:22:22<52:53,  1.77s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2878/4671 [1:22:24<52:53,  1.77s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2879/4671 [1:22:24<52:16,  1.75s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2879/4671 [1:22:26<52:16,  1.75s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2880/4671 [1:22:26<52:29,  1.76s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2880/4671 [1:22:28<52:29,  1.76s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2881/4671 [1:22:28<52:09,  1.75s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2881/4671 [1:22:29<52:09,  1.75s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2882/4671 [1:22:29<52:19,  1.75s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2882/4671 [1:22:31<52:19,  1.75s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2883/4671 [1:22:31<52:10,  1.75s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2883/4671 [1:22:33<52:10,  1.75s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2884/4671 [1:22:33<52:06,  1.75s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2884/4671 [1:22:35<52:06,  1.75s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2885/4671 [1:22:35<51:50,  1.74s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2885/4671 [1:22:36<51:50,  1.74s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2886/4671 [1:22:36<51:50,  1.74s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2886/4671 [1:22:38<51:50,  1.74s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2887/4671 [1:22:38<51:25,  1.73s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2887/4671 [1:22:40<51:25,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2888/4671 [1:22:40<51:35,  1.74s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2888/4671 [1:22:42<51:35,  1.74s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2889/4671 [1:22:42<53:05,  1.79s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2889/4671 [1:22:43<53:05,  1.79s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2890/4671 [1:22:43<52:43,  1.78s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2890/4671 [1:22:45<52:43,  1.78s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2891/4671 [1:22:45<52:07,  1.76s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2891/4671 [1:22:47<52:07,  1.76s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2892/4671 [1:22:47<51:56,  1.75s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2892/4671 [1:22:49<51:56,  1.75s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2893/4671 [1:22:49<53:31,  1.81s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2893/4671 [1:22:51<53:31,  1.81s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2894/4671 [1:22:51<58:49,  1.99s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2894/4671 [1:22:54<58:49,  1.99s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2895/4671 [1:22:54<1:02:14,  2.10s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2895/4671 [1:22:56<1:02:14,  2.10s/it, training_loss=0.071]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2896/4671 [1:22:56<1:03:20,  2.14s/it, training_loss=0.071]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2896/4671 [1:22:58<1:03:20,  2.14s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2897/4671 [1:22:58<59:26,  2.01s/it, training_loss=0.111]  \u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2897/4671 [1:22:59<59:26,  2.01s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2898/4671 [1:22:59<57:38,  1.95s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2898/4671 [1:23:01<57:38,  1.95s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2899/4671 [1:23:01<55:17,  1.87s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2899/4671 [1:23:03<55:17,  1.87s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2900/4671 [1:23:03<53:31,  1.81s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2900/4671 [1:23:04<53:31,  1.81s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2901/4671 [1:23:04<52:30,  1.78s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2901/4671 [1:23:06<52:30,  1.78s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2902/4671 [1:23:06<52:18,  1.77s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2902/4671 [1:23:08<52:18,  1.77s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2903/4671 [1:23:08<52:11,  1.77s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2903/4671 [1:23:10<52:11,  1.77s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2904/4671 [1:23:10<51:52,  1.76s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2904/4671 [1:23:11<51:52,  1.76s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2905/4671 [1:23:11<51:33,  1.75s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2905/4671 [1:23:13<51:33,  1.75s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2906/4671 [1:23:13<51:03,  1.74s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2906/4671 [1:23:15<51:03,  1.74s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2907/4671 [1:23:15<50:43,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2907/4671 [1:23:17<50:43,  1.73s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2908/4671 [1:23:17<50:58,  1.74s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2908/4671 [1:23:18<50:58,  1.74s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2909/4671 [1:23:18<52:28,  1.79s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2909/4671 [1:23:20<52:28,  1.79s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2910/4671 [1:23:20<52:00,  1.77s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2910/4671 [1:23:22<52:00,  1.77s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2911/4671 [1:23:22<51:20,  1.75s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2911/4671 [1:23:24<51:20,  1.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2912/4671 [1:23:24<51:06,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2912/4671 [1:23:25<51:06,  1.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2913/4671 [1:23:25<50:30,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2913/4671 [1:23:27<50:30,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2914/4671 [1:23:27<50:33,  1.73s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2914/4671 [1:23:29<50:33,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2915/4671 [1:23:29<51:19,  1.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2915/4671 [1:23:31<51:19,  1.75s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2916/4671 [1:23:31<52:04,  1.78s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2916/4671 [1:23:32<52:04,  1.78s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2917/4671 [1:23:32<52:12,  1.79s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2917/4671 [1:23:34<52:12,  1.79s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2918/4671 [1:23:34<53:12,  1.82s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2918/4671 [1:23:36<53:12,  1.82s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2919/4671 [1:23:36<53:11,  1.82s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 2919/4671 [1:23:38<53:11,  1.82s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2920/4671 [1:23:38<52:22,  1.79s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2920/4671 [1:23:40<52:22,  1.79s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2921/4671 [1:23:40<52:11,  1.79s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2921/4671 [1:23:41<52:11,  1.79s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2922/4671 [1:23:41<51:14,  1.76s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2922/4671 [1:23:43<51:14,  1.76s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2923/4671 [1:23:43<51:30,  1.77s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2923/4671 [1:23:45<51:30,  1.77s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2924/4671 [1:23:45<51:14,  1.76s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2924/4671 [1:23:47<51:14,  1.76s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2925/4671 [1:23:47<50:45,  1.74s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2925/4671 [1:23:48<50:45,  1.74s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2926/4671 [1:23:48<50:40,  1.74s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2926/4671 [1:23:50<50:40,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2927/4671 [1:23:50<50:50,  1.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2927/4671 [1:23:52<50:50,  1.75s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2928/4671 [1:23:52<50:26,  1.74s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2928/4671 [1:23:54<50:26,  1.74s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2929/4671 [1:23:54<50:41,  1.75s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2929/4671 [1:23:55<50:41,  1.75s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2930/4671 [1:23:55<50:32,  1.74s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2930/4671 [1:23:57<50:32,  1.74s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2931/4671 [1:23:57<50:14,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2931/4671 [1:23:59<50:14,  1.73s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2932/4671 [1:23:59<49:57,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2932/4671 [1:24:00<49:57,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2933/4671 [1:24:00<49:42,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2933/4671 [1:24:02<49:42,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2934/4671 [1:24:02<49:50,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2934/4671 [1:24:04<49:50,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2935/4671 [1:24:04<49:56,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2935/4671 [1:24:06<49:56,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2936/4671 [1:24:06<50:01,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2936/4671 [1:24:07<50:01,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2937/4671 [1:24:07<49:48,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2937/4671 [1:24:09<49:48,  1.72s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2938/4671 [1:24:09<49:40,  1.72s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2938/4671 [1:24:11<49:40,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2939/4671 [1:24:11<49:46,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2939/4671 [1:24:13<49:46,  1.72s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2940/4671 [1:24:13<49:29,  1.72s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2940/4671 [1:24:14<49:29,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2941/4671 [1:24:14<49:41,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2941/4671 [1:24:16<49:41,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2942/4671 [1:24:16<49:51,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2942/4671 [1:24:18<49:51,  1.73s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2943/4671 [1:24:18<49:42,  1.73s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2943/4671 [1:24:19<49:42,  1.73s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2944/4671 [1:24:19<49:42,  1.73s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2944/4671 [1:24:21<49:42,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2945/4671 [1:24:21<49:47,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2945/4671 [1:24:23<49:47,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2946/4671 [1:24:23<49:51,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2946/4671 [1:24:25<49:51,  1.73s/it, training_loss=0.077]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2947/4671 [1:24:25<49:22,  1.72s/it, training_loss=0.077]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2947/4671 [1:24:26<49:22,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2948/4671 [1:24:26<50:20,  1.75s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2948/4671 [1:24:28<50:20,  1.75s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2949/4671 [1:24:28<51:32,  1.80s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2949/4671 [1:24:30<51:32,  1.80s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2950/4671 [1:24:30<51:21,  1.79s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2950/4671 [1:24:32<51:21,  1.79s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2951/4671 [1:24:32<51:06,  1.78s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2951/4671 [1:24:34<51:06,  1.78s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2952/4671 [1:24:34<50:30,  1.76s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2952/4671 [1:24:35<50:30,  1.76s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2953/4671 [1:24:35<49:56,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2953/4671 [1:24:37<49:56,  1.74s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2954/4671 [1:24:37<50:46,  1.77s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2954/4671 [1:24:39<50:46,  1.77s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2955/4671 [1:24:39<51:24,  1.80s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2955/4671 [1:24:41<51:24,  1.80s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2956/4671 [1:24:41<52:54,  1.85s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2956/4671 [1:24:43<52:54,  1.85s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2957/4671 [1:24:43<52:02,  1.82s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2957/4671 [1:24:44<52:02,  1.82s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2958/4671 [1:24:44<51:17,  1.80s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2958/4671 [1:24:46<51:17,  1.80s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2959/4671 [1:24:46<50:36,  1.77s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2959/4671 [1:24:48<50:36,  1.77s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2960/4671 [1:24:48<50:11,  1.76s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2960/4671 [1:24:50<50:11,  1.76s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2961/4671 [1:24:50<50:04,  1.76s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2961/4671 [1:24:51<50:04,  1.76s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2962/4671 [1:24:51<49:24,  1.73s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2962/4671 [1:24:53<49:24,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2963/4671 [1:24:53<49:10,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2963/4671 [1:24:55<49:10,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2964/4671 [1:24:55<50:06,  1.76s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2964/4671 [1:24:57<50:06,  1.76s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2965/4671 [1:24:57<50:04,  1.76s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2965/4671 [1:24:58<50:04,  1.76s/it, training_loss=0.188]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2966/4671 [1:24:58<49:49,  1.75s/it, training_loss=0.188]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 2966/4671 [1:25:00<49:49,  1.75s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2967/4671 [1:25:00<49:28,  1.74s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2967/4671 [1:25:02<49:28,  1.74s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2968/4671 [1:25:02<49:17,  1.74s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2968/4671 [1:25:04<49:17,  1.74s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2969/4671 [1:25:04<49:20,  1.74s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2969/4671 [1:25:05<49:20,  1.74s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2970/4671 [1:25:05<49:04,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2970/4671 [1:25:07<49:04,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2971/4671 [1:25:07<49:05,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2971/4671 [1:25:09<49:05,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2972/4671 [1:25:09<49:06,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2972/4671 [1:25:11<49:06,  1.73s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2973/4671 [1:25:11<49:16,  1.74s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2973/4671 [1:25:12<49:16,  1.74s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2974/4671 [1:25:12<49:12,  1.74s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2974/4671 [1:25:14<49:12,  1.74s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2975/4671 [1:25:14<49:13,  1.74s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2975/4671 [1:25:16<49:13,  1.74s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2976/4671 [1:25:16<49:27,  1.75s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2976/4671 [1:25:18<49:27,  1.75s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2977/4671 [1:25:18<49:14,  1.74s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 2977/4671 [1:25:19<49:14,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2978/4671 [1:25:19<49:25,  1.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2978/4671 [1:25:21<49:25,  1.75s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2979/4671 [1:25:21<49:33,  1.76s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2979/4671 [1:25:23<49:33,  1.76s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2980/4671 [1:25:23<49:25,  1.75s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2980/4671 [1:25:25<49:25,  1.75s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2981/4671 [1:25:25<48:59,  1.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2981/4671 [1:25:26<48:59,  1.74s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2982/4671 [1:25:26<49:08,  1.75s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2982/4671 [1:25:28<49:08,  1.75s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2983/4671 [1:25:28<49:06,  1.75s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2983/4671 [1:25:30<49:06,  1.75s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2984/4671 [1:25:30<48:59,  1.74s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2984/4671 [1:25:32<48:59,  1.74s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2985/4671 [1:25:32<48:57,  1.74s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2985/4671 [1:25:33<48:57,  1.74s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2986/4671 [1:25:33<49:15,  1.75s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2986/4671 [1:25:35<49:15,  1.75s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2987/4671 [1:25:35<49:11,  1.75s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2987/4671 [1:25:37<49:11,  1.75s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2988/4671 [1:25:37<49:17,  1.76s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2988/4671 [1:25:39<49:17,  1.76s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2989/4671 [1:25:39<48:49,  1.74s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2989/4671 [1:25:40<48:49,  1.74s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2990/4671 [1:25:40<48:45,  1.74s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2990/4671 [1:25:42<48:45,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2991/4671 [1:25:42<48:44,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2991/4671 [1:25:44<48:44,  1.74s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2992/4671 [1:25:44<48:25,  1.73s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2992/4671 [1:25:45<48:25,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2993/4671 [1:25:45<48:12,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2993/4671 [1:25:47<48:12,  1.72s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2994/4671 [1:25:47<48:18,  1.73s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2994/4671 [1:25:49<48:18,  1.73s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2995/4671 [1:25:49<48:08,  1.72s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2995/4671 [1:25:51<48:08,  1.72s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2996/4671 [1:25:51<48:15,  1.73s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2996/4671 [1:25:52<48:15,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2997/4671 [1:25:52<48:13,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2997/4671 [1:25:54<48:13,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2998/4671 [1:25:54<48:09,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2998/4671 [1:25:56<48:09,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2999/4671 [1:25:56<48:01,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 2999/4671 [1:25:57<48:01,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3000/4671 [1:25:57<47:48,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3000/4671 [1:25:59<47:48,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3001/4671 [1:25:59<48:05,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3001/4671 [1:26:01<48:05,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3002/4671 [1:26:01<48:32,  1.75s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3002/4671 [1:26:03<48:32,  1.75s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3003/4671 [1:26:03<48:09,  1.73s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3003/4671 [1:26:04<48:09,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3004/4671 [1:26:04<48:39,  1.75s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3004/4671 [1:26:06<48:39,  1.75s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3005/4671 [1:26:06<48:31,  1.75s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3005/4671 [1:26:08<48:31,  1.75s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3006/4671 [1:26:08<48:23,  1.74s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3006/4671 [1:26:10<48:23,  1.74s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3007/4671 [1:26:10<48:30,  1.75s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3007/4671 [1:26:11<48:30,  1.75s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3008/4671 [1:26:11<48:10,  1.74s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3008/4671 [1:26:13<48:10,  1.74s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3009/4671 [1:26:13<47:58,  1.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3009/4671 [1:26:15<47:58,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3010/4671 [1:26:15<47:39,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3010/4671 [1:26:17<47:39,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3011/4671 [1:26:17<47:28,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3011/4671 [1:26:18<47:28,  1.72s/it, training_loss=0.223]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3012/4671 [1:26:18<48:11,  1.74s/it, training_loss=0.223]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 3012/4671 [1:26:20<48:11,  1.74s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3013/4671 [1:26:20<48:01,  1.74s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3013/4671 [1:26:22<48:01,  1.74s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3014/4671 [1:26:22<47:51,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3014/4671 [1:26:24<47:51,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3015/4671 [1:26:24<47:57,  1.74s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3015/4671 [1:26:25<47:57,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3016/4671 [1:26:25<47:51,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3016/4671 [1:26:27<47:51,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3017/4671 [1:26:27<47:25,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3017/4671 [1:26:29<47:25,  1.72s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3018/4671 [1:26:29<47:42,  1.73s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3018/4671 [1:26:30<47:42,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3019/4671 [1:26:30<47:52,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3019/4671 [1:26:32<47:52,  1.74s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3020/4671 [1:26:32<47:38,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3020/4671 [1:26:34<47:38,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3021/4671 [1:26:34<47:37,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3021/4671 [1:26:36<47:37,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3022/4671 [1:26:36<47:32,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3022/4671 [1:26:37<47:32,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3023/4671 [1:26:37<47:51,  1.74s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3023/4671 [1:26:39<47:51,  1.74s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3024/4671 [1:26:39<47:12,  1.72s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3024/4671 [1:26:41<47:12,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3025/4671 [1:26:41<47:20,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3025/4671 [1:26:43<47:20,  1.73s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3026/4671 [1:26:43<47:18,  1.73s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3026/4671 [1:26:44<47:18,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3027/4671 [1:26:44<47:07,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3027/4671 [1:26:46<47:07,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3028/4671 [1:26:46<47:18,  1.73s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3028/4671 [1:26:48<47:18,  1.73s/it, training_loss=0.064]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3029/4671 [1:26:48<47:04,  1.72s/it, training_loss=0.064]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3029/4671 [1:26:49<47:04,  1.72s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3030/4671 [1:26:49<47:00,  1.72s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3030/4671 [1:26:51<47:00,  1.72s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3031/4671 [1:26:51<47:11,  1.73s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3031/4671 [1:26:53<47:11,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3032/4671 [1:26:53<47:07,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3032/4671 [1:26:55<47:07,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3033/4671 [1:26:55<47:11,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3033/4671 [1:26:56<47:11,  1.73s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3034/4671 [1:26:56<47:28,  1.74s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3034/4671 [1:26:58<47:28,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3035/4671 [1:26:58<47:14,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3035/4671 [1:27:00<47:14,  1.73s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3036/4671 [1:27:00<47:07,  1.73s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 3036/4671 [1:27:02<47:07,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3037/4671 [1:27:02<46:46,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3037/4671 [1:27:03<46:46,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3038/4671 [1:27:03<46:48,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3038/4671 [1:27:05<46:48,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3039/4671 [1:27:05<46:51,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3039/4671 [1:27:07<46:51,  1.72s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3040/4671 [1:27:07<46:48,  1.72s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3040/4671 [1:27:08<46:48,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3041/4671 [1:27:08<46:44,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3041/4671 [1:27:10<46:44,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3042/4671 [1:27:10<46:41,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3042/4671 [1:27:12<46:41,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3043/4671 [1:27:12<46:37,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3043/4671 [1:27:14<46:37,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3044/4671 [1:27:14<46:52,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3044/4671 [1:27:15<46:52,  1.73s/it, training_loss=0.199]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3045/4671 [1:27:15<46:39,  1.72s/it, training_loss=0.199]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3045/4671 [1:27:17<46:39,  1.72s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3046/4671 [1:27:17<46:34,  1.72s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3046/4671 [1:27:19<46:34,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3047/4671 [1:27:19<46:15,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3047/4671 [1:27:20<46:15,  1.71s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3048/4671 [1:27:20<46:39,  1.73s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3048/4671 [1:27:22<46:39,  1.73s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3049/4671 [1:27:22<46:23,  1.72s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3049/4671 [1:27:24<46:23,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3050/4671 [1:27:24<46:23,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3050/4671 [1:27:26<46:23,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3051/4671 [1:27:26<46:13,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3051/4671 [1:27:27<46:13,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3052/4671 [1:27:27<46:17,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3052/4671 [1:27:29<46:17,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3053/4671 [1:27:29<46:19,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3053/4671 [1:27:31<46:19,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3054/4671 [1:27:31<46:27,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3054/4671 [1:27:33<46:27,  1.72s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3055/4671 [1:27:33<46:30,  1.73s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3055/4671 [1:27:34<46:30,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3056/4671 [1:27:34<46:23,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3056/4671 [1:27:36<46:23,  1.72s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3057/4671 [1:27:36<46:33,  1.73s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3057/4671 [1:27:38<46:33,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3058/4671 [1:27:38<46:41,  1.74s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3058/4671 [1:27:39<46:41,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3059/4671 [1:27:39<46:45,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 3059/4671 [1:27:41<46:45,  1.74s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3060/4671 [1:27:41<46:48,  1.74s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3060/4671 [1:27:43<46:48,  1.74s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3061/4671 [1:27:43<46:43,  1.74s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3061/4671 [1:27:45<46:43,  1.74s/it, training_loss=0.077]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3062/4671 [1:27:45<46:19,  1.73s/it, training_loss=0.077]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3062/4671 [1:27:46<46:19,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3063/4671 [1:27:46<45:42,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3063/4671 [1:27:48<45:42,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3064/4671 [1:27:48<46:10,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3064/4671 [1:27:50<46:10,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3065/4671 [1:27:50<46:24,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3065/4671 [1:27:52<46:24,  1.73s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3066/4671 [1:27:52<46:32,  1.74s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3066/4671 [1:27:53<46:32,  1.74s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3067/4671 [1:27:53<46:43,  1.75s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3067/4671 [1:27:55<46:43,  1.75s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3068/4671 [1:27:55<46:51,  1.75s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3068/4671 [1:27:57<46:51,  1.75s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3069/4671 [1:27:57<46:36,  1.75s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3069/4671 [1:27:59<46:36,  1.75s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3070/4671 [1:27:59<46:32,  1.74s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3070/4671 [1:28:00<46:32,  1.74s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3071/4671 [1:28:00<47:42,  1.79s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3071/4671 [1:28:02<47:42,  1.79s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3072/4671 [1:28:02<47:31,  1.78s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3072/4671 [1:28:04<47:31,  1.78s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3073/4671 [1:28:04<46:48,  1.76s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3073/4671 [1:28:06<46:48,  1.76s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3074/4671 [1:28:06<51:13,  1.92s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3074/4671 [1:28:08<51:13,  1.92s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3075/4671 [1:28:08<50:22,  1.89s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3075/4671 [1:28:10<50:22,  1.89s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3076/4671 [1:28:10<48:50,  1.84s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3076/4671 [1:28:12<48:50,  1.84s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3077/4671 [1:28:12<48:07,  1.81s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3077/4671 [1:28:13<48:07,  1.81s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3078/4671 [1:28:13<47:43,  1.80s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3078/4671 [1:28:15<47:43,  1.80s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3079/4671 [1:28:15<47:07,  1.78s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3079/4671 [1:28:17<47:07,  1.78s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3080/4671 [1:28:17<46:55,  1.77s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3080/4671 [1:28:19<46:55,  1.77s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3081/4671 [1:28:19<46:38,  1.76s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3081/4671 [1:28:20<46:38,  1.76s/it, training_loss=0.193]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3082/4671 [1:28:20<46:07,  1.74s/it, training_loss=0.193]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3082/4671 [1:28:22<46:07,  1.74s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3083/4671 [1:28:22<46:03,  1.74s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3083/4671 [1:28:24<46:03,  1.74s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3084/4671 [1:28:24<46:02,  1.74s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3084/4671 [1:28:25<46:02,  1.74s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3085/4671 [1:28:25<45:55,  1.74s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3085/4671 [1:28:27<45:55,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3086/4671 [1:28:27<46:17,  1.75s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3086/4671 [1:28:29<46:17,  1.75s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3087/4671 [1:28:29<46:26,  1.76s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3087/4671 [1:28:31<46:26,  1.76s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3088/4671 [1:28:31<46:18,  1.76s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3088/4671 [1:28:33<46:18,  1.76s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3089/4671 [1:28:33<46:20,  1.76s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3089/4671 [1:28:34<46:20,  1.76s/it, training_loss=0.192]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3090/4671 [1:28:34<46:05,  1.75s/it, training_loss=0.192]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3090/4671 [1:28:36<46:05,  1.75s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3091/4671 [1:28:36<46:42,  1.77s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3091/4671 [1:28:38<46:42,  1.77s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3092/4671 [1:28:38<46:40,  1.77s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3092/4671 [1:28:40<46:40,  1.77s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3093/4671 [1:28:40<46:09,  1.75s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3093/4671 [1:28:41<46:09,  1.75s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3094/4671 [1:28:41<45:48,  1.74s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 3094/4671 [1:28:43<45:48,  1.74s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3095/4671 [1:28:43<45:58,  1.75s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3095/4671 [1:28:45<45:58,  1.75s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3096/4671 [1:28:45<45:48,  1.75s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3096/4671 [1:28:46<45:48,  1.75s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3097/4671 [1:28:46<45:26,  1.73s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3097/4671 [1:28:48<45:26,  1.73s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3098/4671 [1:28:48<45:32,  1.74s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3098/4671 [1:28:50<45:32,  1.74s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3099/4671 [1:28:50<45:26,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3099/4671 [1:28:52<45:26,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3100/4671 [1:28:52<45:32,  1.74s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3100/4671 [1:28:53<45:32,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3101/4671 [1:28:53<45:37,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3101/4671 [1:28:55<45:37,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3102/4671 [1:28:55<45:22,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3102/4671 [1:28:57<45:22,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3103/4671 [1:28:57<45:03,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3103/4671 [1:28:59<45:03,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3104/4671 [1:28:59<45:18,  1.73s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3104/4671 [1:29:00<45:18,  1.73s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3105/4671 [1:29:00<45:09,  1.73s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3105/4671 [1:29:02<45:09,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3106/4671 [1:29:02<45:06,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 3106/4671 [1:29:04<45:06,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3107/4671 [1:29:04<45:07,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3107/4671 [1:29:05<45:07,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3108/4671 [1:29:05<44:40,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3108/4671 [1:29:07<44:40,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3109/4671 [1:29:07<44:54,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3109/4671 [1:29:09<44:54,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3110/4671 [1:29:09<45:49,  1.76s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3110/4671 [1:29:11<45:49,  1.76s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3111/4671 [1:29:11<46:01,  1.77s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3111/4671 [1:29:13<46:01,  1.77s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3112/4671 [1:29:13<45:49,  1.76s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3112/4671 [1:29:14<45:49,  1.76s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3113/4671 [1:29:14<45:30,  1.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3113/4671 [1:29:16<45:30,  1.75s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3114/4671 [1:29:16<45:21,  1.75s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3114/4671 [1:29:18<45:21,  1.75s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3115/4671 [1:29:18<45:32,  1.76s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3115/4671 [1:29:20<45:32,  1.76s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3116/4671 [1:29:20<45:07,  1.74s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3116/4671 [1:29:21<45:07,  1.74s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3117/4671 [1:29:21<45:13,  1.75s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3117/4671 [1:29:23<45:13,  1.75s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3118/4671 [1:29:23<45:29,  1.76s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3118/4671 [1:29:25<45:29,  1.76s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3119/4671 [1:29:25<44:50,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3119/4671 [1:29:27<44:50,  1.73s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3120/4671 [1:29:27<44:40,  1.73s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3120/4671 [1:29:28<44:40,  1.73s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3121/4671 [1:29:28<44:44,  1.73s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3121/4671 [1:29:30<44:44,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3122/4671 [1:29:30<44:47,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3122/4671 [1:29:32<44:47,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3123/4671 [1:29:32<44:25,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3123/4671 [1:29:33<44:25,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3124/4671 [1:29:33<44:28,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3124/4671 [1:29:35<44:28,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3125/4671 [1:29:35<44:14,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3125/4671 [1:29:37<44:14,  1.72s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3126/4671 [1:29:37<44:30,  1.73s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3126/4671 [1:29:39<44:30,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3127/4671 [1:29:39<44:26,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3127/4671 [1:29:40<44:26,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3128/4671 [1:29:40<44:24,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3128/4671 [1:29:42<44:24,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3129/4671 [1:29:42<44:34,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3129/4671 [1:29:44<44:34,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3130/4671 [1:29:44<44:32,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3130/4671 [1:29:46<44:32,  1.73s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3131/4671 [1:29:46<44:35,  1.74s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3131/4671 [1:29:47<44:35,  1.74s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3132/4671 [1:29:47<44:42,  1.74s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3132/4671 [1:29:49<44:42,  1.74s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3133/4671 [1:29:49<44:30,  1.74s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3133/4671 [1:29:51<44:30,  1.74s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3134/4671 [1:29:51<44:47,  1.75s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3134/4671 [1:29:53<44:47,  1.75s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3135/4671 [1:29:53<44:39,  1.74s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3135/4671 [1:29:54<44:39,  1.74s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3136/4671 [1:29:54<44:17,  1.73s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3136/4671 [1:29:56<44:17,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3137/4671 [1:29:56<43:55,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3137/4671 [1:29:58<43:55,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3138/4671 [1:29:58<44:25,  1.74s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3138/4671 [1:29:59<44:25,  1.74s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3139/4671 [1:29:59<44:24,  1.74s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3139/4671 [1:30:01<44:24,  1.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3140/4671 [1:30:01<44:26,  1.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3140/4671 [1:30:03<44:26,  1.74s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3141/4671 [1:30:03<44:07,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3141/4671 [1:30:05<44:07,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3142/4671 [1:30:05<43:53,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3142/4671 [1:30:06<43:53,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3143/4671 [1:30:06<43:58,  1.73s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3143/4671 [1:30:08<43:58,  1.73s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3144/4671 [1:30:08<44:03,  1.73s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3144/4671 [1:30:10<44:03,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3145/4671 [1:30:10<44:04,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3145/4671 [1:30:12<44:04,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3146/4671 [1:30:12<43:51,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3146/4671 [1:30:13<43:51,  1.73s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3147/4671 [1:30:13<43:51,  1.73s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3147/4671 [1:30:15<43:51,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3148/4671 [1:30:15<43:57,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3148/4671 [1:30:17<43:57,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3149/4671 [1:30:17<43:42,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3149/4671 [1:30:18<43:42,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3150/4671 [1:30:18<43:58,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3150/4671 [1:30:20<43:58,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3151/4671 [1:30:20<44:12,  1.75s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3151/4671 [1:30:22<44:12,  1.75s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3152/4671 [1:30:22<44:07,  1.74s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 3152/4671 [1:30:24<44:07,  1.74s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3153/4671 [1:30:24<44:03,  1.74s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3153/4671 [1:30:25<44:03,  1.74s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3154/4671 [1:30:25<44:08,  1.75s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3154/4671 [1:30:27<44:08,  1.75s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3155/4671 [1:30:27<43:28,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3155/4671 [1:30:29<43:28,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3156/4671 [1:30:29<43:58,  1.74s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3156/4671 [1:30:31<43:58,  1.74s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3157/4671 [1:30:31<43:52,  1.74s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3157/4671 [1:30:32<43:52,  1.74s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3158/4671 [1:30:32<44:02,  1.75s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3158/4671 [1:30:34<44:02,  1.75s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3159/4671 [1:30:34<43:45,  1.74s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3159/4671 [1:30:36<43:45,  1.74s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3160/4671 [1:30:36<43:37,  1.73s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3160/4671 [1:30:38<43:37,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3161/4671 [1:30:38<43:34,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3161/4671 [1:30:39<43:34,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3162/4671 [1:30:39<43:43,  1.74s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3162/4671 [1:30:41<43:43,  1.74s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3163/4671 [1:30:41<43:35,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3163/4671 [1:30:43<43:35,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3164/4671 [1:30:43<43:40,  1.74s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3164/4671 [1:30:45<43:40,  1.74s/it, training_loss=0.060]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3165/4671 [1:30:45<43:48,  1.75s/it, training_loss=0.060]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3165/4671 [1:30:46<43:48,  1.75s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3166/4671 [1:30:46<43:43,  1.74s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3166/4671 [1:30:48<43:43,  1.74s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3167/4671 [1:30:48<43:59,  1.75s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3167/4671 [1:30:50<43:59,  1.75s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3168/4671 [1:30:50<43:31,  1.74s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3168/4671 [1:30:52<43:31,  1.74s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3169/4671 [1:30:52<43:40,  1.74s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3169/4671 [1:30:53<43:40,  1.74s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3170/4671 [1:30:53<43:54,  1.76s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3170/4671 [1:30:55<43:54,  1.76s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3171/4671 [1:30:55<43:52,  1.76s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3171/4671 [1:30:57<43:52,  1.76s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3172/4671 [1:30:57<43:27,  1.74s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3172/4671 [1:30:59<43:27,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3173/4671 [1:30:59<43:35,  1.75s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3173/4671 [1:31:00<43:35,  1.75s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3174/4671 [1:31:00<43:21,  1.74s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3174/4671 [1:31:02<43:21,  1.74s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3175/4671 [1:31:02<43:16,  1.74s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3175/4671 [1:31:04<43:16,  1.74s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3176/4671 [1:31:04<43:12,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3176/4671 [1:31:05<43:12,  1.73s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3177/4671 [1:31:05<43:00,  1.73s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3177/4671 [1:31:07<43:00,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3178/4671 [1:31:07<43:01,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3178/4671 [1:31:09<43:01,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3179/4671 [1:31:09<43:00,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3179/4671 [1:31:11<43:00,  1.73s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3180/4671 [1:31:11<43:03,  1.73s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3180/4671 [1:31:12<43:03,  1.73s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3181/4671 [1:31:12<43:09,  1.74s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3181/4671 [1:31:14<43:09,  1.74s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3182/4671 [1:31:14<43:18,  1.75s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3182/4671 [1:31:16<43:18,  1.75s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3183/4671 [1:31:16<42:56,  1.73s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3183/4671 [1:31:18<42:56,  1.73s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3184/4671 [1:31:18<42:22,  1.71s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3184/4671 [1:31:19<42:22,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3185/4671 [1:31:19<42:42,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3185/4671 [1:31:21<42:42,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3186/4671 [1:31:21<43:01,  1.74s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3186/4671 [1:31:23<43:01,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3187/4671 [1:31:23<43:06,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3187/4671 [1:31:25<43:06,  1.74s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3188/4671 [1:31:25<42:59,  1.74s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3188/4671 [1:31:26<42:59,  1.74s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3189/4671 [1:31:26<42:47,  1.73s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3189/4671 [1:31:28<42:47,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3190/4671 [1:31:28<42:50,  1.74s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3190/4671 [1:31:30<42:50,  1.74s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3191/4671 [1:31:30<42:43,  1.73s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3191/4671 [1:31:31<42:43,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3192/4671 [1:31:31<42:27,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3192/4671 [1:31:33<42:27,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3193/4671 [1:31:33<42:19,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3193/4671 [1:31:35<42:19,  1.72s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3194/4671 [1:31:35<42:15,  1.72s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3194/4671 [1:31:37<42:15,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3195/4671 [1:31:37<42:26,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3195/4671 [1:31:38<42:26,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3196/4671 [1:31:38<42:10,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3196/4671 [1:31:40<42:10,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3197/4671 [1:31:40<42:24,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3197/4671 [1:31:42<42:24,  1.73s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3198/4671 [1:31:42<42:29,  1.73s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3198/4671 [1:31:43<42:29,  1.73s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3199/4671 [1:31:43<42:23,  1.73s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 3199/4671 [1:31:45<42:23,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3200/4671 [1:31:45<42:33,  1.74s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3200/4671 [1:31:47<42:33,  1.74s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3201/4671 [1:31:47<42:08,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3201/4671 [1:31:49<42:08,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3202/4671 [1:31:49<42:15,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3202/4671 [1:31:50<42:15,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3203/4671 [1:31:50<41:54,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3203/4671 [1:31:52<41:54,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3204/4671 [1:31:52<41:55,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3204/4671 [1:31:54<41:55,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3205/4671 [1:31:54<42:21,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3205/4671 [1:31:56<42:21,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3206/4671 [1:31:56<42:12,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3206/4671 [1:31:57<42:12,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3207/4671 [1:31:57<42:16,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3207/4671 [1:31:59<42:16,  1.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3208/4671 [1:31:59<42:08,  1.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3208/4671 [1:32:01<42:08,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3209/4671 [1:32:01<41:40,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3209/4671 [1:32:02<41:40,  1.71s/it, training_loss=0.078]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3210/4671 [1:32:02<41:37,  1.71s/it, training_loss=0.078]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3210/4671 [1:32:04<41:37,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3211/4671 [1:32:04<41:57,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 3211/4671 [1:32:06<41:57,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3212/4671 [1:32:06<42:12,  1.74s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3212/4671 [1:32:08<42:12,  1.74s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3213/4671 [1:32:08<42:03,  1.73s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3213/4671 [1:32:09<42:03,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3214/4671 [1:32:09<42:29,  1.75s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3214/4671 [1:32:11<42:29,  1.75s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3215/4671 [1:32:11<42:15,  1.74s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3215/4671 [1:32:13<42:15,  1.74s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3216/4671 [1:32:13<42:17,  1.74s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3216/4671 [1:32:15<42:17,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3217/4671 [1:32:15<42:30,  1.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3217/4671 [1:32:16<42:30,  1.75s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3218/4671 [1:32:16<42:20,  1.75s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3218/4671 [1:32:18<42:20,  1.75s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3219/4671 [1:32:18<42:12,  1.74s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3219/4671 [1:32:20<42:12,  1.74s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3220/4671 [1:32:20<42:06,  1.74s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3220/4671 [1:32:22<42:06,  1.74s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3221/4671 [1:32:22<42:03,  1.74s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3221/4671 [1:32:23<42:03,  1.74s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3222/4671 [1:32:23<42:30,  1.76s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3222/4671 [1:32:25<42:30,  1.76s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3223/4671 [1:32:25<42:09,  1.75s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3223/4671 [1:32:27<42:09,  1.75s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3224/4671 [1:32:27<41:56,  1.74s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3224/4671 [1:32:29<41:56,  1.74s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3225/4671 [1:32:29<41:46,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3225/4671 [1:32:30<41:46,  1.73s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3226/4671 [1:32:30<41:26,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3226/4671 [1:32:32<41:26,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3227/4671 [1:32:32<41:31,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3227/4671 [1:32:34<41:31,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3228/4671 [1:32:34<41:27,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3228/4671 [1:32:35<41:27,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3229/4671 [1:32:35<41:27,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3229/4671 [1:32:37<41:27,  1.72s/it, training_loss=0.183]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3230/4671 [1:32:37<41:14,  1.72s/it, training_loss=0.183]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3230/4671 [1:32:39<41:14,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3231/4671 [1:32:39<41:05,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3231/4671 [1:32:41<41:05,  1.71s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3232/4671 [1:32:41<41:10,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3232/4671 [1:32:42<41:10,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3233/4671 [1:32:42<40:54,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3233/4671 [1:32:44<40:54,  1.71s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3234/4671 [1:32:44<41:04,  1.72s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3234/4671 [1:32:46<41:04,  1.72s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3235/4671 [1:32:46<41:13,  1.72s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3235/4671 [1:32:47<41:13,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3236/4671 [1:32:47<41:23,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3236/4671 [1:32:49<41:23,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3237/4671 [1:32:49<41:32,  1.74s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3237/4671 [1:32:51<41:32,  1.74s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3238/4671 [1:32:51<41:25,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3238/4671 [1:32:53<41:25,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3239/4671 [1:32:53<41:37,  1.74s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3239/4671 [1:32:54<41:37,  1.74s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3240/4671 [1:32:54<41:15,  1.73s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3240/4671 [1:32:56<41:15,  1.73s/it, training_loss=0.223]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3241/4671 [1:32:56<41:07,  1.73s/it, training_loss=0.223]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3241/4671 [1:32:58<41:07,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3242/4671 [1:32:58<41:35,  1.75s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3242/4671 [1:33:00<41:35,  1.75s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3243/4671 [1:33:00<41:32,  1.75s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3243/4671 [1:33:01<41:32,  1.75s/it, training_loss=0.188]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3244/4671 [1:33:01<41:31,  1.75s/it, training_loss=0.188]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3244/4671 [1:33:03<41:31,  1.75s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3245/4671 [1:33:03<41:34,  1.75s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3245/4671 [1:33:05<41:34,  1.75s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3246/4671 [1:33:05<41:25,  1.74s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 3246/4671 [1:33:07<41:25,  1.74s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3247/4671 [1:33:07<41:22,  1.74s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3247/4671 [1:33:08<41:22,  1.74s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3248/4671 [1:33:08<41:12,  1.74s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3248/4671 [1:33:10<41:12,  1.74s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3249/4671 [1:33:10<41:19,  1.74s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3249/4671 [1:33:12<41:19,  1.74s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3250/4671 [1:33:12<41:14,  1.74s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3250/4671 [1:33:14<41:14,  1.74s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3251/4671 [1:33:14<41:14,  1.74s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3251/4671 [1:33:15<41:14,  1.74s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3252/4671 [1:33:15<40:52,  1.73s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3252/4671 [1:33:17<40:52,  1.73s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3253/4671 [1:33:17<40:54,  1.73s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3253/4671 [1:33:19<40:54,  1.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3254/4671 [1:33:19<40:40,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3254/4671 [1:33:21<40:40,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3255/4671 [1:33:21<40:55,  1.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3255/4671 [1:33:22<40:55,  1.73s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3256/4671 [1:33:22<41:15,  1.75s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3256/4671 [1:33:24<41:15,  1.75s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3257/4671 [1:33:24<41:02,  1.74s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3257/4671 [1:33:26<41:02,  1.74s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3258/4671 [1:33:26<40:36,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3258/4671 [1:33:27<40:36,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3259/4671 [1:33:27<40:39,  1.73s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3259/4671 [1:33:29<40:39,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3260/4671 [1:33:29<40:10,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3260/4671 [1:33:31<40:10,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3261/4671 [1:33:31<40:20,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3261/4671 [1:33:33<40:20,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3262/4671 [1:33:33<40:20,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3262/4671 [1:33:34<40:20,  1.72s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3263/4671 [1:33:34<40:08,  1.71s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3263/4671 [1:33:36<40:08,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3264/4671 [1:33:36<40:14,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3264/4671 [1:33:38<40:14,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3265/4671 [1:33:38<40:16,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3265/4671 [1:33:39<40:16,  1.72s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3266/4671 [1:33:39<40:32,  1.73s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3266/4671 [1:33:41<40:32,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3267/4671 [1:33:41<40:30,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3267/4671 [1:33:43<40:30,  1.73s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3268/4671 [1:33:43<40:22,  1.73s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3268/4671 [1:33:45<40:22,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3269/4671 [1:33:45<40:30,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 3269/4671 [1:33:46<40:30,  1.73s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3270/4671 [1:33:46<40:38,  1.74s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3270/4671 [1:33:48<40:38,  1.74s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3271/4671 [1:33:48<40:12,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3271/4671 [1:33:50<40:12,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3272/4671 [1:33:50<40:07,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3272/4671 [1:33:52<40:07,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3273/4671 [1:33:52<39:55,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3273/4671 [1:33:53<39:55,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3274/4671 [1:33:53<40:01,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3274/4671 [1:33:55<40:01,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3275/4671 [1:33:55<40:10,  1.73s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3275/4671 [1:33:57<40:10,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3276/4671 [1:33:57<40:10,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3276/4671 [1:33:58<40:10,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3277/4671 [1:33:58<39:56,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3277/4671 [1:34:00<39:56,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3278/4671 [1:34:00<40:17,  1.74s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3278/4671 [1:34:02<40:17,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3279/4671 [1:34:02<40:08,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3279/4671 [1:34:04<40:08,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3280/4671 [1:34:04<40:15,  1.74s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3280/4671 [1:34:05<40:15,  1.74s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3281/4671 [1:34:05<39:40,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3281/4671 [1:34:07<39:40,  1.71s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3282/4671 [1:34:07<39:48,  1.72s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3282/4671 [1:34:09<39:48,  1.72s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3283/4671 [1:34:09<39:51,  1.72s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3283/4671 [1:34:10<39:51,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3284/4671 [1:34:10<39:35,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3284/4671 [1:34:12<39:35,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3285/4671 [1:34:12<39:38,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3285/4671 [1:34:14<39:38,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3286/4671 [1:34:14<39:43,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3286/4671 [1:34:16<39:43,  1.72s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3287/4671 [1:34:16<39:53,  1.73s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3287/4671 [1:34:17<39:53,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3288/4671 [1:34:17<39:53,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3288/4671 [1:34:19<39:53,  1.73s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3289/4671 [1:34:19<39:42,  1.72s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3289/4671 [1:34:21<39:42,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3290/4671 [1:34:21<40:09,  1.74s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3290/4671 [1:34:23<40:09,  1.74s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3291/4671 [1:34:23<40:53,  1.78s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3291/4671 [1:34:25<40:53,  1.78s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3292/4671 [1:34:25<41:12,  1.79s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3292/4671 [1:34:26<41:12,  1.79s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3293/4671 [1:34:26<40:42,  1.77s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  70%|███████   | 3293/4671 [1:34:28<40:42,  1.77s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3294/4671 [1:34:28<40:08,  1.75s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3294/4671 [1:34:30<40:08,  1.75s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3295/4671 [1:34:30<39:53,  1.74s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3295/4671 [1:34:31<39:53,  1.74s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3296/4671 [1:34:31<39:41,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3296/4671 [1:34:33<39:41,  1.73s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3297/4671 [1:34:33<39:48,  1.74s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3297/4671 [1:34:35<39:48,  1.74s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3298/4671 [1:34:35<39:42,  1.74s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3298/4671 [1:34:37<39:42,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3299/4671 [1:34:37<39:41,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3299/4671 [1:34:38<39:41,  1.74s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3300/4671 [1:34:38<39:46,  1.74s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3300/4671 [1:34:40<39:46,  1.74s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3301/4671 [1:34:40<39:17,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3301/4671 [1:34:42<39:17,  1.72s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3302/4671 [1:34:42<38:43,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3302/4671 [1:34:43<38:43,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3303/4671 [1:34:43<38:46,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3303/4671 [1:34:45<38:46,  1.70s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3304/4671 [1:34:45<38:39,  1.70s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3304/4671 [1:34:47<38:39,  1.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3305/4671 [1:34:47<38:50,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3305/4671 [1:34:49<38:50,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3306/4671 [1:34:49<39:00,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3306/4671 [1:34:50<39:00,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3307/4671 [1:34:50<38:56,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3307/4671 [1:34:52<38:56,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3308/4671 [1:34:52<38:43,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3308/4671 [1:34:54<38:43,  1.70s/it, training_loss=0.198]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3309/4671 [1:34:54<38:51,  1.71s/it, training_loss=0.198]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3309/4671 [1:34:55<38:51,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3310/4671 [1:34:55<38:46,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3310/4671 [1:34:57<38:46,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3311/4671 [1:34:57<38:57,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3311/4671 [1:34:59<38:57,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3312/4671 [1:34:59<38:41,  1.71s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3312/4671 [1:35:01<38:41,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3313/4671 [1:35:01<38:31,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3313/4671 [1:35:02<38:31,  1.70s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3314/4671 [1:35:02<38:29,  1.70s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3314/4671 [1:35:04<38:29,  1.70s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3315/4671 [1:35:04<38:51,  1.72s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3315/4671 [1:35:06<38:51,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3316/4671 [1:35:06<38:48,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3316/4671 [1:35:07<38:48,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3317/4671 [1:35:07<38:55,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3317/4671 [1:35:09<38:55,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3318/4671 [1:35:09<39:03,  1.73s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3318/4671 [1:35:11<39:03,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3319/4671 [1:35:11<38:55,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3319/4671 [1:35:13<38:55,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3320/4671 [1:35:13<39:03,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3320/4671 [1:35:14<39:03,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3321/4671 [1:35:14<38:55,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3321/4671 [1:35:16<38:55,  1.73s/it, training_loss=0.078]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3322/4671 [1:35:16<39:00,  1.74s/it, training_loss=0.078]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3322/4671 [1:35:18<39:00,  1.74s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3323/4671 [1:35:18<38:50,  1.73s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3323/4671 [1:35:20<38:50,  1.73s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3324/4671 [1:35:20<38:48,  1.73s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3324/4671 [1:35:22<38:48,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3325/4671 [1:35:22<40:00,  1.78s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3325/4671 [1:35:23<40:00,  1.78s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3326/4671 [1:35:23<39:47,  1.77s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3326/4671 [1:35:25<39:47,  1.77s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3327/4671 [1:35:25<40:33,  1.81s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3327/4671 [1:35:27<40:33,  1.81s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3328/4671 [1:35:27<41:01,  1.83s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  71%|███████   | 3328/4671 [1:35:29<41:01,  1.83s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3329/4671 [1:35:29<41:34,  1.86s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3329/4671 [1:35:31<41:34,  1.86s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3330/4671 [1:35:31<41:39,  1.86s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3330/4671 [1:35:33<41:39,  1.86s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3331/4671 [1:35:33<41:50,  1.87s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3331/4671 [1:35:35<41:50,  1.87s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3332/4671 [1:35:35<41:54,  1.88s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3332/4671 [1:35:37<41:54,  1.88s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3333/4671 [1:35:37<42:00,  1.88s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3333/4671 [1:35:38<42:00,  1.88s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3334/4671 [1:35:38<41:17,  1.85s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3334/4671 [1:35:40<41:17,  1.85s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3335/4671 [1:35:40<40:26,  1.82s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3335/4671 [1:35:42<40:26,  1.82s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3336/4671 [1:35:42<39:52,  1.79s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3336/4671 [1:35:43<39:52,  1.79s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3337/4671 [1:35:43<39:22,  1.77s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3337/4671 [1:35:45<39:22,  1.77s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3338/4671 [1:35:45<39:15,  1.77s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3338/4671 [1:35:47<39:15,  1.77s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3339/4671 [1:35:47<39:18,  1.77s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 3339/4671 [1:35:49<39:18,  1.77s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3340/4671 [1:35:49<39:08,  1.76s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3340/4671 [1:35:51<39:08,  1.76s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3341/4671 [1:35:51<38:59,  1.76s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3341/4671 [1:35:52<38:59,  1.76s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3342/4671 [1:35:52<38:51,  1.75s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3342/4671 [1:35:54<38:51,  1.75s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3343/4671 [1:35:54<38:46,  1.75s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3343/4671 [1:35:56<38:46,  1.75s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3344/4671 [1:35:56<38:27,  1.74s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3344/4671 [1:35:57<38:27,  1.74s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3345/4671 [1:35:57<38:09,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3345/4671 [1:35:59<38:09,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3346/4671 [1:35:59<37:54,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3346/4671 [1:36:01<37:54,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3347/4671 [1:36:01<37:36,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3347/4671 [1:36:02<37:36,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3348/4671 [1:36:02<37:37,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3348/4671 [1:36:04<37:37,  1.71s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3349/4671 [1:36:04<37:45,  1.71s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3349/4671 [1:36:06<37:45,  1.71s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3350/4671 [1:36:06<37:49,  1.72s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3350/4671 [1:36:08<37:49,  1.72s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3351/4671 [1:36:08<38:03,  1.73s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3351/4671 [1:36:09<38:03,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3352/4671 [1:36:09<37:51,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3352/4671 [1:36:11<37:51,  1.72s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3353/4671 [1:36:11<37:54,  1.73s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3353/4671 [1:36:13<37:54,  1.73s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3354/4671 [1:36:13<38:00,  1.73s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3354/4671 [1:36:15<38:00,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3355/4671 [1:36:15<38:01,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3355/4671 [1:36:16<38:01,  1.73s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3356/4671 [1:36:16<38:07,  1.74s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3356/4671 [1:36:18<38:07,  1.74s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3357/4671 [1:36:18<37:55,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3357/4671 [1:36:20<37:55,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3358/4671 [1:36:20<37:45,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3358/4671 [1:36:22<37:45,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3359/4671 [1:36:22<37:45,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3359/4671 [1:36:23<37:45,  1.73s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3360/4671 [1:36:23<37:30,  1.72s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3360/4671 [1:36:25<37:30,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3361/4671 [1:36:25<37:31,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3361/4671 [1:36:27<37:31,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3362/4671 [1:36:27<37:26,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3362/4671 [1:36:28<37:26,  1.72s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3363/4671 [1:36:28<37:29,  1.72s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3363/4671 [1:36:30<37:29,  1.72s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3364/4671 [1:36:30<37:40,  1.73s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3364/4671 [1:36:32<37:40,  1.73s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3365/4671 [1:36:32<37:30,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3365/4671 [1:36:34<37:30,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3366/4671 [1:36:34<37:25,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3366/4671 [1:36:35<37:25,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3367/4671 [1:36:35<36:57,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3367/4671 [1:36:37<36:57,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3368/4671 [1:36:37<37:24,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3368/4671 [1:36:39<37:24,  1.72s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3369/4671 [1:36:39<37:48,  1.74s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3369/4671 [1:36:40<37:48,  1.74s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3370/4671 [1:36:40<37:29,  1.73s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3370/4671 [1:36:42<37:29,  1.73s/it, training_loss=0.068]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3371/4671 [1:36:42<37:28,  1.73s/it, training_loss=0.068]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3371/4671 [1:36:44<37:28,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3372/4671 [1:36:44<37:11,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3372/4671 [1:36:46<37:11,  1.72s/it, training_loss=0.073]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3373/4671 [1:36:46<37:22,  1.73s/it, training_loss=0.073]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3373/4671 [1:36:47<37:22,  1.73s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3374/4671 [1:36:47<37:37,  1.74s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3374/4671 [1:36:49<37:37,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3375/4671 [1:36:49<37:47,  1.75s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3375/4671 [1:36:51<37:47,  1.75s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3376/4671 [1:36:51<37:32,  1.74s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3376/4671 [1:36:53<37:32,  1.74s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3377/4671 [1:36:53<39:31,  1.83s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3377/4671 [1:36:55<39:31,  1.83s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3378/4671 [1:36:55<42:08,  1.96s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3378/4671 [1:36:57<42:08,  1.96s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3379/4671 [1:36:57<41:20,  1.92s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3379/4671 [1:36:59<41:20,  1.92s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3380/4671 [1:36:59<40:09,  1.87s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3380/4671 [1:37:00<40:09,  1.87s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3381/4671 [1:37:00<39:05,  1.82s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3381/4671 [1:37:02<39:05,  1.82s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3382/4671 [1:37:02<38:18,  1.78s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3382/4671 [1:37:04<38:18,  1.78s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3383/4671 [1:37:04<37:55,  1.77s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3383/4671 [1:37:06<37:55,  1.77s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3384/4671 [1:37:06<37:45,  1.76s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3384/4671 [1:37:07<37:45,  1.76s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3385/4671 [1:37:07<37:20,  1.74s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3385/4671 [1:37:09<37:20,  1.74s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3386/4671 [1:37:09<37:13,  1.74s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 3386/4671 [1:37:11<37:13,  1.74s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3387/4671 [1:37:11<36:50,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3387/4671 [1:37:13<36:50,  1.72s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3388/4671 [1:37:13<36:56,  1.73s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3388/4671 [1:37:14<36:56,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3389/4671 [1:37:14<37:15,  1.74s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3389/4671 [1:37:16<37:15,  1.74s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3390/4671 [1:37:16<37:17,  1.75s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3390/4671 [1:37:18<37:17,  1.75s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3391/4671 [1:37:18<37:01,  1.74s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3391/4671 [1:37:19<37:01,  1.74s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3392/4671 [1:37:19<36:50,  1.73s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3392/4671 [1:37:21<36:50,  1.73s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3393/4671 [1:37:21<36:39,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3393/4671 [1:37:23<36:39,  1.72s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3394/4671 [1:37:23<36:20,  1.71s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3394/4671 [1:37:25<36:20,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3395/4671 [1:37:25<36:17,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3395/4671 [1:37:26<36:17,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3396/4671 [1:37:26<36:34,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3396/4671 [1:37:28<36:34,  1.72s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3397/4671 [1:37:28<36:39,  1.73s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3397/4671 [1:37:30<36:39,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3398/4671 [1:37:30<36:33,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3398/4671 [1:37:32<36:33,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3399/4671 [1:37:32<36:35,  1.73s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3399/4671 [1:37:33<36:35,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3400/4671 [1:37:33<36:43,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3400/4671 [1:37:35<36:43,  1.73s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3401/4671 [1:37:35<36:47,  1.74s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3401/4671 [1:37:37<36:47,  1.74s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3402/4671 [1:37:37<36:35,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3402/4671 [1:37:38<36:35,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3403/4671 [1:37:38<36:42,  1.74s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3403/4671 [1:37:40<36:42,  1.74s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3404/4671 [1:37:40<37:07,  1.76s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3404/4671 [1:37:42<37:07,  1.76s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3405/4671 [1:37:42<36:36,  1.74s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3405/4671 [1:37:44<36:36,  1.74s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3406/4671 [1:37:44<36:40,  1.74s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3406/4671 [1:37:45<36:40,  1.74s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3407/4671 [1:37:45<36:45,  1.74s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3407/4671 [1:37:47<36:45,  1.74s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3408/4671 [1:37:47<36:46,  1.75s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3408/4671 [1:37:49<36:46,  1.75s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3409/4671 [1:37:49<36:47,  1.75s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3409/4671 [1:37:51<36:47,  1.75s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3410/4671 [1:37:51<36:43,  1.75s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3410/4671 [1:37:52<36:43,  1.75s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3411/4671 [1:37:52<36:37,  1.74s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3411/4671 [1:37:54<36:37,  1.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3412/4671 [1:37:54<36:19,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3412/4671 [1:37:56<36:19,  1.73s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3413/4671 [1:37:56<36:23,  1.74s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3413/4671 [1:37:58<36:23,  1.74s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3414/4671 [1:37:58<36:25,  1.74s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3414/4671 [1:37:59<36:25,  1.74s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3415/4671 [1:37:59<36:07,  1.73s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3415/4671 [1:38:01<36:07,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3416/4671 [1:38:01<36:01,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3416/4671 [1:38:03<36:01,  1.72s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3417/4671 [1:38:03<36:16,  1.74s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3417/4671 [1:38:05<36:16,  1.74s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3418/4671 [1:38:05<36:06,  1.73s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3418/4671 [1:38:06<36:06,  1.73s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3419/4671 [1:38:06<35:51,  1.72s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3419/4671 [1:38:08<35:51,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3420/4671 [1:38:08<36:16,  1.74s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3420/4671 [1:38:10<36:16,  1.74s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3421/4671 [1:38:10<36:29,  1.75s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3421/4671 [1:38:11<36:29,  1.75s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3422/4671 [1:38:11<35:57,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3422/4671 [1:38:13<35:57,  1.73s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3423/4671 [1:38:13<35:53,  1.73s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3423/4671 [1:38:15<35:53,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3424/4671 [1:38:15<35:58,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3424/4671 [1:38:17<35:58,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3425/4671 [1:38:17<36:05,  1.74s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3425/4671 [1:38:18<36:05,  1.74s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3426/4671 [1:38:18<35:39,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3426/4671 [1:38:20<35:39,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3427/4671 [1:38:20<35:36,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3427/4671 [1:38:22<35:36,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3428/4671 [1:38:22<35:56,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3428/4671 [1:38:24<35:56,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3429/4671 [1:38:24<36:23,  1.76s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3429/4671 [1:38:25<36:23,  1.76s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3430/4671 [1:38:25<35:43,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3430/4671 [1:38:27<35:43,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3431/4671 [1:38:27<35:12,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3431/4671 [1:38:29<35:12,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3432/4671 [1:38:29<35:22,  1.71s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3432/4671 [1:38:30<35:22,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3433/4671 [1:38:30<35:33,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 3433/4671 [1:38:32<35:33,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3434/4671 [1:38:32<35:19,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3434/4671 [1:38:34<35:19,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3435/4671 [1:38:34<35:28,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3435/4671 [1:38:36<35:28,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3436/4671 [1:38:36<35:25,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3436/4671 [1:38:37<35:25,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3437/4671 [1:38:37<35:18,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3437/4671 [1:38:39<35:18,  1.72s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3438/4671 [1:38:39<35:22,  1.72s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3438/4671 [1:38:41<35:22,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3439/4671 [1:38:41<35:14,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3439/4671 [1:38:42<35:14,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3440/4671 [1:38:42<35:21,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3440/4671 [1:38:44<35:21,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3441/4671 [1:38:44<35:30,  1.73s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3441/4671 [1:38:46<35:30,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3442/4671 [1:38:46<35:29,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3442/4671 [1:38:48<35:29,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3443/4671 [1:38:48<35:09,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3443/4671 [1:38:49<35:09,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3444/4671 [1:38:49<35:30,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 3444/4671 [1:38:51<35:30,  1.74s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3445/4671 [1:38:51<35:30,  1.74s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3445/4671 [1:38:53<35:30,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3446/4671 [1:38:53<35:28,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3446/4671 [1:38:55<35:28,  1.74s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3447/4671 [1:38:55<35:25,  1.74s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3447/4671 [1:38:56<35:25,  1.74s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3448/4671 [1:38:56<35:36,  1.75s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3448/4671 [1:38:58<35:36,  1.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3449/4671 [1:38:58<35:18,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3449/4671 [1:39:00<35:18,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3450/4671 [1:39:00<35:02,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3450/4671 [1:39:02<35:02,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3451/4671 [1:39:02<34:59,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3451/4671 [1:39:03<34:59,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3452/4671 [1:39:03<34:50,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3452/4671 [1:39:05<34:50,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3453/4671 [1:39:05<34:54,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3453/4671 [1:39:07<34:54,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3454/4671 [1:39:07<34:40,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3454/4671 [1:39:08<34:40,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3455/4671 [1:39:08<34:56,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3455/4671 [1:39:10<34:56,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3456/4671 [1:39:10<34:53,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3456/4671 [1:39:12<34:53,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3457/4671 [1:39:12<34:52,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3457/4671 [1:39:14<34:52,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3458/4671 [1:39:14<34:49,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3458/4671 [1:39:15<34:49,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3459/4671 [1:39:15<34:45,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3459/4671 [1:39:17<34:45,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3460/4671 [1:39:17<34:38,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3460/4671 [1:39:19<34:38,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3461/4671 [1:39:19<34:28,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3461/4671 [1:39:20<34:28,  1.71s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3462/4671 [1:39:20<34:33,  1.71s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3462/4671 [1:39:22<34:33,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3463/4671 [1:39:22<34:17,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3463/4671 [1:39:24<34:17,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3464/4671 [1:39:24<34:35,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3464/4671 [1:39:26<34:35,  1.72s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3465/4671 [1:39:26<34:25,  1.71s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3465/4671 [1:39:27<34:25,  1.71s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3466/4671 [1:39:27<34:02,  1.70s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3466/4671 [1:39:29<34:02,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3467/4671 [1:39:29<34:13,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3467/4671 [1:39:31<34:13,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3468/4671 [1:39:31<34:10,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3468/4671 [1:39:32<34:10,  1.70s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3469/4671 [1:39:32<34:24,  1.72s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3469/4671 [1:39:34<34:24,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3470/4671 [1:39:34<34:14,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3470/4671 [1:39:36<34:14,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3471/4671 [1:39:36<34:10,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3471/4671 [1:39:38<34:10,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3472/4671 [1:39:38<34:23,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3472/4671 [1:39:39<34:23,  1.72s/it, training_loss=0.190]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3473/4671 [1:39:39<34:14,  1.71s/it, training_loss=0.190]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3473/4671 [1:39:41<34:14,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3474/4671 [1:39:41<34:23,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3474/4671 [1:39:43<34:23,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3475/4671 [1:39:43<34:19,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3475/4671 [1:39:44<34:19,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3476/4671 [1:39:44<34:17,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3476/4671 [1:39:46<34:17,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3477/4671 [1:39:46<34:08,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3477/4671 [1:39:48<34:08,  1.72s/it, training_loss=0.185]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3478/4671 [1:39:48<34:11,  1.72s/it, training_loss=0.185]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3478/4671 [1:39:50<34:11,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3479/4671 [1:39:50<34:09,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 3479/4671 [1:39:51<34:09,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3480/4671 [1:39:51<33:56,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3480/4671 [1:39:53<33:56,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3481/4671 [1:39:53<33:52,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3481/4671 [1:39:55<33:52,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3482/4671 [1:39:55<33:54,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3482/4671 [1:39:56<33:54,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3483/4671 [1:39:56<33:56,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3483/4671 [1:39:58<33:56,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3484/4671 [1:39:58<33:58,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3484/4671 [1:40:00<33:58,  1.72s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3485/4671 [1:40:00<34:05,  1.72s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3485/4671 [1:40:02<34:05,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3486/4671 [1:40:02<33:49,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3486/4671 [1:40:03<33:49,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3487/4671 [1:40:03<33:34,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3487/4671 [1:40:05<33:34,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3488/4671 [1:40:05<33:29,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3488/4671 [1:40:07<33:29,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3489/4671 [1:40:07<33:29,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3489/4671 [1:40:08<33:29,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3490/4671 [1:40:08<34:03,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3490/4671 [1:40:10<34:03,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3491/4671 [1:40:10<33:54,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3491/4671 [1:40:12<33:54,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3492/4671 [1:40:12<33:40,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3492/4671 [1:40:14<33:40,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3493/4671 [1:40:14<33:42,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3493/4671 [1:40:15<33:42,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3494/4671 [1:40:15<33:40,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3494/4671 [1:40:17<33:40,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3495/4671 [1:40:17<33:49,  1.73s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3495/4671 [1:40:19<33:49,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3496/4671 [1:40:19<34:06,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3496/4671 [1:40:20<34:06,  1.74s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3497/4671 [1:40:20<33:50,  1.73s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3497/4671 [1:40:22<33:50,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3498/4671 [1:40:22<34:13,  1.75s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3498/4671 [1:40:24<34:13,  1.75s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3499/4671 [1:40:24<33:48,  1.73s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3499/4671 [1:40:26<33:48,  1.73s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3500/4671 [1:40:26<33:54,  1.74s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3500/4671 [1:40:28<33:54,  1.74s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3501/4671 [1:40:28<34:23,  1.76s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3501/4671 [1:40:29<34:23,  1.76s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3502/4671 [1:40:29<34:43,  1.78s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3502/4671 [1:40:31<34:43,  1.78s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3503/4671 [1:40:31<34:52,  1.79s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 3503/4671 [1:40:33<34:52,  1.79s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3504/4671 [1:40:33<35:04,  1.80s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3504/4671 [1:40:35<35:04,  1.80s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3505/4671 [1:40:35<35:07,  1.81s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3505/4671 [1:40:37<35:07,  1.81s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3506/4671 [1:40:37<35:18,  1.82s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3506/4671 [1:40:38<35:18,  1.82s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3507/4671 [1:40:38<35:14,  1.82s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3507/4671 [1:40:40<35:14,  1.82s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3508/4671 [1:40:40<35:25,  1.83s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3508/4671 [1:40:42<35:25,  1.83s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3509/4671 [1:40:42<35:25,  1.83s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3509/4671 [1:40:44<35:25,  1.83s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3510/4671 [1:40:44<35:27,  1.83s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3510/4671 [1:40:46<35:27,  1.83s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3511/4671 [1:40:46<35:32,  1.84s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3511/4671 [1:40:48<35:32,  1.84s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3512/4671 [1:40:48<35:33,  1.84s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3512/4671 [1:40:50<35:33,  1.84s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3513/4671 [1:40:50<35:42,  1.85s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3513/4671 [1:40:51<35:42,  1.85s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3514/4671 [1:40:51<35:24,  1.84s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3514/4671 [1:40:53<35:24,  1.84s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3515/4671 [1:40:53<35:14,  1.83s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3515/4671 [1:40:55<35:14,  1.83s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3516/4671 [1:40:55<35:11,  1.83s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3516/4671 [1:40:57<35:11,  1.83s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3517/4671 [1:40:57<35:04,  1.82s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3517/4671 [1:40:59<35:04,  1.82s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3518/4671 [1:40:59<34:54,  1.82s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3518/4671 [1:41:01<34:54,  1.82s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3519/4671 [1:41:01<35:08,  1.83s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3519/4671 [1:41:02<35:08,  1.83s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3520/4671 [1:41:02<35:01,  1.83s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3520/4671 [1:41:04<35:01,  1.83s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3521/4671 [1:41:04<35:01,  1.83s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3521/4671 [1:41:06<35:01,  1.83s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3522/4671 [1:41:06<34:49,  1.82s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3522/4671 [1:41:08<34:49,  1.82s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3523/4671 [1:41:08<34:45,  1.82s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3523/4671 [1:41:10<34:45,  1.82s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3524/4671 [1:41:10<34:53,  1.82s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3524/4671 [1:41:11<34:53,  1.82s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3525/4671 [1:41:11<34:48,  1.82s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3525/4671 [1:41:13<34:48,  1.82s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3526/4671 [1:41:13<34:49,  1.83s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 3526/4671 [1:41:15<34:49,  1.83s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3527/4671 [1:41:15<34:34,  1.81s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3527/4671 [1:41:17<34:34,  1.81s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3528/4671 [1:41:17<34:39,  1.82s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3528/4671 [1:41:19<34:39,  1.82s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3529/4671 [1:41:19<34:36,  1.82s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3529/4671 [1:41:20<34:36,  1.82s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3530/4671 [1:41:20<34:24,  1.81s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3530/4671 [1:41:22<34:24,  1.81s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3531/4671 [1:41:22<34:37,  1.82s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3531/4671 [1:41:24<34:37,  1.82s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3532/4671 [1:41:24<34:53,  1.84s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3532/4671 [1:41:26<34:53,  1.84s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3533/4671 [1:41:26<34:44,  1.83s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3533/4671 [1:41:28<34:44,  1.83s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3534/4671 [1:41:28<35:44,  1.89s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3534/4671 [1:41:30<35:44,  1.89s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3535/4671 [1:41:30<36:41,  1.94s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3535/4671 [1:41:32<36:41,  1.94s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3536/4671 [1:41:32<35:47,  1.89s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3536/4671 [1:41:34<35:47,  1.89s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3537/4671 [1:41:34<34:52,  1.85s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3537/4671 [1:41:35<34:52,  1.85s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3538/4671 [1:41:35<33:51,  1.79s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3538/4671 [1:41:37<33:51,  1.79s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3539/4671 [1:41:37<33:26,  1.77s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3539/4671 [1:41:39<33:26,  1.77s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3540/4671 [1:41:39<32:58,  1.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3540/4671 [1:41:40<32:58,  1.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3541/4671 [1:41:40<32:53,  1.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3541/4671 [1:41:42<32:53,  1.75s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3542/4671 [1:41:42<32:36,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3542/4671 [1:41:44<32:36,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3543/4671 [1:41:44<32:26,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3543/4671 [1:41:46<32:26,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3544/4671 [1:41:46<32:30,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3544/4671 [1:41:47<32:30,  1.73s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3545/4671 [1:41:47<32:26,  1.73s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3545/4671 [1:41:49<32:26,  1.73s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3546/4671 [1:41:49<32:30,  1.73s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3546/4671 [1:41:51<32:30,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3547/4671 [1:41:51<32:35,  1.74s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3547/4671 [1:41:53<32:35,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3548/4671 [1:41:53<32:33,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3548/4671 [1:41:54<32:33,  1.74s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3549/4671 [1:41:54<32:10,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3549/4671 [1:41:56<32:10,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3550/4671 [1:41:56<31:58,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3550/4671 [1:41:58<31:58,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3551/4671 [1:41:58<31:57,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3551/4671 [1:41:59<31:57,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3552/4671 [1:41:59<32:05,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3552/4671 [1:42:01<32:05,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3553/4671 [1:42:01<31:58,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3553/4671 [1:42:03<31:58,  1.72s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3554/4671 [1:42:03<31:55,  1.72s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3554/4671 [1:42:05<31:55,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3555/4671 [1:42:05<32:06,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3555/4671 [1:42:06<32:06,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3556/4671 [1:42:06<31:56,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3556/4671 [1:42:08<31:56,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3557/4671 [1:42:08<32:11,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3557/4671 [1:42:10<32:11,  1.73s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3558/4671 [1:42:10<31:56,  1.72s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3558/4671 [1:42:11<31:56,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3559/4671 [1:42:11<31:59,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3559/4671 [1:42:13<31:59,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3560/4671 [1:42:13<32:10,  1.74s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3560/4671 [1:42:15<32:10,  1.74s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3561/4671 [1:42:15<31:53,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 3561/4671 [1:42:17<31:53,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3562/4671 [1:42:17<32:02,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3562/4671 [1:42:18<32:02,  1.73s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3563/4671 [1:42:18<31:47,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3563/4671 [1:42:20<31:47,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3564/4671 [1:42:20<31:43,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3564/4671 [1:42:22<31:43,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3565/4671 [1:42:22<31:46,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3565/4671 [1:42:24<31:46,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3566/4671 [1:42:24<31:41,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3566/4671 [1:42:25<31:41,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3567/4671 [1:42:25<31:35,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3567/4671 [1:42:27<31:35,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3568/4671 [1:42:27<31:39,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3568/4671 [1:42:29<31:39,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3569/4671 [1:42:29<31:54,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3569/4671 [1:42:30<31:54,  1.74s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3570/4671 [1:42:30<31:56,  1.74s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3570/4671 [1:42:32<31:56,  1.74s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3571/4671 [1:42:32<31:43,  1.73s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3571/4671 [1:42:34<31:43,  1.73s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3572/4671 [1:42:34<31:40,  1.73s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3572/4671 [1:42:36<31:40,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3573/4671 [1:42:36<31:46,  1.74s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 3573/4671 [1:42:37<31:46,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3574/4671 [1:42:37<31:36,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3574/4671 [1:42:39<31:36,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3575/4671 [1:42:39<31:37,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3575/4671 [1:42:41<31:37,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3576/4671 [1:42:41<31:41,  1.74s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3576/4671 [1:42:43<31:41,  1.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3577/4671 [1:42:43<31:32,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3577/4671 [1:42:44<31:32,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3578/4671 [1:42:44<31:24,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3578/4671 [1:42:46<31:24,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3579/4671 [1:42:46<31:14,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3579/4671 [1:42:48<31:14,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3580/4671 [1:42:48<31:13,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3580/4671 [1:42:49<31:13,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3581/4671 [1:42:49<31:02,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3581/4671 [1:42:51<31:02,  1.71s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3582/4671 [1:42:51<31:02,  1.71s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3582/4671 [1:42:53<31:02,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3583/4671 [1:42:53<31:19,  1.73s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3583/4671 [1:42:55<31:19,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3584/4671 [1:42:55<31:29,  1.74s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3584/4671 [1:42:56<31:29,  1.74s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3585/4671 [1:42:56<31:06,  1.72s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3585/4671 [1:42:58<31:06,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3586/4671 [1:42:58<30:56,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3586/4671 [1:43:00<30:56,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3587/4671 [1:43:00<31:06,  1.72s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3587/4671 [1:43:01<31:06,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3588/4671 [1:43:01<30:51,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3588/4671 [1:43:03<30:51,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3589/4671 [1:43:03<30:57,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3589/4671 [1:43:05<30:57,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3590/4671 [1:43:05<30:53,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3590/4671 [1:43:07<30:53,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3591/4671 [1:43:07<30:52,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3591/4671 [1:43:08<30:52,  1.72s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3592/4671 [1:43:08<30:47,  1.71s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3592/4671 [1:43:10<30:47,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3593/4671 [1:43:10<30:37,  1.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3593/4671 [1:43:12<30:37,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3594/4671 [1:43:12<30:32,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3594/4671 [1:43:13<30:32,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3595/4671 [1:43:13<30:38,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3595/4671 [1:43:15<30:38,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3596/4671 [1:43:15<30:26,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3596/4671 [1:43:17<30:26,  1.70s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3597/4671 [1:43:17<30:43,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3597/4671 [1:43:19<30:43,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3598/4671 [1:43:19<30:42,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3598/4671 [1:43:20<30:42,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3599/4671 [1:43:20<30:51,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3599/4671 [1:43:22<30:51,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3600/4671 [1:43:22<30:42,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3600/4671 [1:43:24<30:42,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3601/4671 [1:43:24<30:26,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3601/4671 [1:43:25<30:26,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3602/4671 [1:43:25<30:26,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3602/4671 [1:43:27<30:26,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3603/4671 [1:43:27<30:29,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3603/4671 [1:43:29<30:29,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3604/4671 [1:43:29<30:38,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3604/4671 [1:43:31<30:38,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3605/4671 [1:43:31<30:40,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3605/4671 [1:43:32<30:40,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3606/4671 [1:43:32<30:38,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3606/4671 [1:43:34<30:38,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3607/4671 [1:43:34<30:28,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3607/4671 [1:43:36<30:28,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3608/4671 [1:43:36<30:32,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3608/4671 [1:43:38<30:32,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3609/4671 [1:43:38<30:35,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3609/4671 [1:43:39<30:35,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3610/4671 [1:43:39<30:45,  1.74s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3610/4671 [1:43:41<30:45,  1.74s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3611/4671 [1:43:41<30:11,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3611/4671 [1:43:43<30:11,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3612/4671 [1:43:43<30:10,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3612/4671 [1:43:44<30:10,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3613/4671 [1:43:44<30:15,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3613/4671 [1:43:46<30:15,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3614/4671 [1:43:46<30:19,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3614/4671 [1:43:48<30:19,  1.72s/it, training_loss=0.206]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3615/4671 [1:43:48<30:08,  1.71s/it, training_loss=0.206]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3615/4671 [1:43:49<30:08,  1.71s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3616/4671 [1:43:49<29:56,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3616/4671 [1:43:51<29:56,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3617/4671 [1:43:51<30:00,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3617/4671 [1:43:53<30:00,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3618/4671 [1:43:53<29:59,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3618/4671 [1:43:55<29:59,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3619/4671 [1:43:55<29:59,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3619/4671 [1:43:56<29:59,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3620/4671 [1:43:56<30:02,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 3620/4671 [1:43:58<30:02,  1.71s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3621/4671 [1:43:58<30:03,  1.72s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3621/4671 [1:44:00<30:03,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3622/4671 [1:44:00<30:01,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3622/4671 [1:44:01<30:01,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3623/4671 [1:44:01<29:46,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3623/4671 [1:44:03<29:46,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3624/4671 [1:44:03<29:45,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3624/4671 [1:44:05<29:45,  1.70s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3625/4671 [1:44:05<29:58,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3625/4671 [1:44:07<29:58,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3626/4671 [1:44:07<29:55,  1.72s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3626/4671 [1:44:08<29:55,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3627/4671 [1:44:08<29:36,  1.70s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3627/4671 [1:44:10<29:36,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3628/4671 [1:44:10<29:52,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3628/4671 [1:44:12<29:52,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3629/4671 [1:44:12<30:13,  1.74s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3629/4671 [1:44:14<30:13,  1.74s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3630/4671 [1:44:14<30:13,  1.74s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3630/4671 [1:44:15<30:13,  1.74s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3631/4671 [1:44:15<29:55,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3631/4671 [1:44:17<29:55,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3632/4671 [1:44:17<30:01,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3632/4671 [1:44:19<30:01,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3633/4671 [1:44:19<29:55,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3633/4671 [1:44:20<29:55,  1.73s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3634/4671 [1:44:20<29:44,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3634/4671 [1:44:22<29:44,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3635/4671 [1:44:22<29:44,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3635/4671 [1:44:24<29:44,  1.72s/it, training_loss=0.200]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3636/4671 [1:44:24<29:43,  1.72s/it, training_loss=0.200]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3636/4671 [1:44:26<29:43,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3637/4671 [1:44:26<29:49,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3637/4671 [1:44:27<29:49,  1.73s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3638/4671 [1:44:27<29:37,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3638/4671 [1:44:29<29:37,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3639/4671 [1:44:29<29:41,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3639/4671 [1:44:31<29:41,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3640/4671 [1:44:31<29:45,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3640/4671 [1:44:33<29:45,  1.73s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3641/4671 [1:44:33<29:39,  1.73s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3641/4671 [1:44:34<29:39,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3642/4671 [1:44:34<29:34,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3642/4671 [1:44:36<29:34,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3643/4671 [1:44:36<29:30,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3643/4671 [1:44:38<29:30,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3644/4671 [1:44:38<29:23,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3644/4671 [1:44:39<29:23,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3645/4671 [1:44:39<29:18,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3645/4671 [1:44:41<29:18,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3646/4671 [1:44:41<29:15,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3646/4671 [1:44:43<29:15,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3647/4671 [1:44:43<29:13,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3647/4671 [1:44:45<29:13,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3648/4671 [1:44:45<29:05,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3648/4671 [1:44:46<29:05,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3649/4671 [1:44:46<29:08,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3649/4671 [1:44:48<29:08,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3650/4671 [1:44:48<29:26,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3650/4671 [1:44:50<29:26,  1.73s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3651/4671 [1:44:50<29:12,  1.72s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3651/4671 [1:44:51<29:12,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3652/4671 [1:44:51<29:09,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3652/4671 [1:44:53<29:09,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3653/4671 [1:44:53<29:10,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3653/4671 [1:44:55<29:10,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3654/4671 [1:44:55<29:00,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3654/4671 [1:44:57<29:00,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3655/4671 [1:44:57<28:57,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3655/4671 [1:44:58<28:57,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3656/4671 [1:44:58<28:56,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3656/4671 [1:45:00<28:56,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3657/4671 [1:45:00<29:00,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3657/4671 [1:45:02<29:00,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3658/4671 [1:45:02<29:01,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3658/4671 [1:45:03<29:01,  1.72s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3659/4671 [1:45:03<28:41,  1.70s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3659/4671 [1:45:05<28:41,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3660/4671 [1:45:05<28:44,  1.71s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3660/4671 [1:45:07<28:44,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3661/4671 [1:45:07<28:30,  1.69s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3661/4671 [1:45:08<28:30,  1.69s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3662/4671 [1:45:08<28:47,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3662/4671 [1:45:10<28:47,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3663/4671 [1:45:10<28:52,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3663/4671 [1:45:12<28:52,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3664/4671 [1:45:12<28:56,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3664/4671 [1:45:14<28:56,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3665/4671 [1:45:14<29:00,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3665/4671 [1:45:15<29:00,  1.73s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3666/4671 [1:45:15<29:08,  1.74s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 3666/4671 [1:45:17<29:08,  1.74s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3667/4671 [1:45:17<29:02,  1.74s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3667/4671 [1:45:19<29:02,  1.74s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3668/4671 [1:45:19<29:01,  1.74s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3668/4671 [1:45:21<29:01,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3669/4671 [1:45:21<29:06,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3669/4671 [1:45:22<29:06,  1.74s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3670/4671 [1:45:22<29:05,  1.74s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3670/4671 [1:45:24<29:05,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3671/4671 [1:45:24<29:00,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3671/4671 [1:45:26<29:00,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3672/4671 [1:45:26<28:55,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3672/4671 [1:45:28<28:55,  1.74s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3673/4671 [1:45:28<28:40,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3673/4671 [1:45:29<28:40,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3674/4671 [1:45:29<28:32,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3674/4671 [1:45:31<28:32,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3675/4671 [1:45:31<28:19,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3675/4671 [1:45:33<28:19,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3676/4671 [1:45:33<28:27,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3676/4671 [1:45:34<28:27,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3677/4671 [1:45:34<28:22,  1.71s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3677/4671 [1:45:36<28:22,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3678/4671 [1:45:36<28:28,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 3678/4671 [1:45:38<28:28,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3679/4671 [1:45:38<28:36,  1.73s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3679/4671 [1:45:40<28:36,  1.73s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3680/4671 [1:45:40<28:41,  1.74s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3680/4671 [1:45:41<28:41,  1.74s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3681/4671 [1:45:41<28:21,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3681/4671 [1:45:43<28:21,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3682/4671 [1:45:43<28:28,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3682/4671 [1:45:45<28:28,  1.73s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3683/4671 [1:45:45<28:36,  1.74s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3683/4671 [1:45:47<28:36,  1.74s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3684/4671 [1:45:47<28:22,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3684/4671 [1:45:48<28:22,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3685/4671 [1:45:48<28:14,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3685/4671 [1:45:50<28:14,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3686/4671 [1:45:50<28:09,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3686/4671 [1:45:52<28:09,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3687/4671 [1:45:52<27:53,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3687/4671 [1:45:53<27:53,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3688/4671 [1:45:53<27:59,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3688/4671 [1:45:55<27:59,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3689/4671 [1:45:55<28:03,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3689/4671 [1:45:57<28:03,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3690/4671 [1:45:57<28:01,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3690/4671 [1:45:59<28:01,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3691/4671 [1:45:59<27:59,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3691/4671 [1:46:00<27:59,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3692/4671 [1:46:00<27:54,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3692/4671 [1:46:02<27:54,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3693/4671 [1:46:02<27:54,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3693/4671 [1:46:04<27:54,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3694/4671 [1:46:04<28:01,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3694/4671 [1:46:05<28:01,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3695/4671 [1:46:05<28:16,  1.74s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3695/4671 [1:46:07<28:16,  1.74s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3696/4671 [1:46:07<28:04,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3696/4671 [1:46:09<28:04,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3697/4671 [1:46:09<28:16,  1.74s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3697/4671 [1:46:11<28:16,  1.74s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3698/4671 [1:46:11<28:01,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3698/4671 [1:46:12<28:01,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3699/4671 [1:46:12<27:52,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3699/4671 [1:46:14<27:52,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3700/4671 [1:46:14<27:56,  1.73s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3700/4671 [1:46:16<27:56,  1.73s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3701/4671 [1:46:16<27:45,  1.72s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3701/4671 [1:46:17<27:45,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3702/4671 [1:46:17<27:39,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3702/4671 [1:46:19<27:39,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3703/4671 [1:46:19<27:35,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3703/4671 [1:46:21<27:35,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3704/4671 [1:46:21<27:46,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3704/4671 [1:46:23<27:46,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3705/4671 [1:46:23<27:49,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3705/4671 [1:46:24<27:49,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3706/4671 [1:46:24<27:32,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3706/4671 [1:46:26<27:32,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3707/4671 [1:46:26<27:28,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3707/4671 [1:46:28<27:28,  1.71s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3708/4671 [1:46:28<27:34,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3708/4671 [1:46:29<27:34,  1.72s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3709/4671 [1:46:29<27:27,  1.71s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3709/4671 [1:46:31<27:27,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3710/4671 [1:46:31<27:26,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3710/4671 [1:46:33<27:26,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3711/4671 [1:46:33<27:29,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3711/4671 [1:46:35<27:29,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3712/4671 [1:46:35<27:32,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3712/4671 [1:46:36<27:32,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3713/4671 [1:46:36<27:31,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 3713/4671 [1:46:38<27:31,  1.72s/it, training_loss=0.194]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3714/4671 [1:46:38<27:22,  1.72s/it, training_loss=0.194]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3714/4671 [1:46:40<27:22,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3715/4671 [1:46:40<27:17,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3715/4671 [1:46:42<27:17,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3716/4671 [1:46:42<27:18,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3716/4671 [1:46:43<27:18,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3717/4671 [1:46:43<27:22,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3717/4671 [1:46:45<27:22,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3718/4671 [1:46:45<27:17,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3718/4671 [1:46:47<27:17,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3719/4671 [1:46:47<27:08,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3719/4671 [1:46:48<27:08,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3720/4671 [1:46:48<27:17,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3720/4671 [1:46:50<27:17,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3721/4671 [1:46:50<27:10,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3721/4671 [1:46:52<27:10,  1.72s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3722/4671 [1:46:52<27:16,  1.72s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3722/4671 [1:46:54<27:16,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3723/4671 [1:46:54<27:12,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3723/4671 [1:46:55<27:12,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3724/4671 [1:46:55<27:13,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3724/4671 [1:46:57<27:13,  1.72s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3725/4671 [1:46:57<27:19,  1.73s/it, training_loss=0.162]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3725/4671 [1:46:59<27:19,  1.73s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3726/4671 [1:46:59<27:16,  1.73s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3726/4671 [1:47:00<27:16,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3727/4671 [1:47:00<26:51,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3727/4671 [1:47:02<26:51,  1.71s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3728/4671 [1:47:02<26:52,  1.71s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3728/4671 [1:47:04<26:52,  1.71s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3729/4671 [1:47:04<26:44,  1.70s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3729/4671 [1:47:06<26:44,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3730/4671 [1:47:06<26:55,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3730/4671 [1:47:07<26:55,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3731/4671 [1:47:07<26:49,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3731/4671 [1:47:09<26:49,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3732/4671 [1:47:09<26:52,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3732/4671 [1:47:11<26:52,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3733/4671 [1:47:11<26:53,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3733/4671 [1:47:12<26:53,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3734/4671 [1:47:12<27:04,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3734/4671 [1:47:14<27:04,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3735/4671 [1:47:14<27:09,  1.74s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3735/4671 [1:47:16<27:09,  1.74s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3736/4671 [1:47:16<26:53,  1.73s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 3736/4671 [1:47:18<26:53,  1.73s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3737/4671 [1:47:18<26:59,  1.73s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3737/4671 [1:47:19<26:59,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3738/4671 [1:47:19<26:43,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3738/4671 [1:47:21<26:43,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3739/4671 [1:47:21<26:32,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3739/4671 [1:47:23<26:32,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3740/4671 [1:47:23<26:46,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3740/4671 [1:47:25<26:46,  1.73s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3741/4671 [1:47:25<26:37,  1.72s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3741/4671 [1:47:26<26:37,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3742/4671 [1:47:26<26:23,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3742/4671 [1:47:28<26:23,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3743/4671 [1:47:28<26:33,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3743/4671 [1:47:30<26:33,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3744/4671 [1:47:30<26:35,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3744/4671 [1:47:31<26:35,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3745/4671 [1:47:31<26:23,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3745/4671 [1:47:33<26:23,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3746/4671 [1:47:33<26:25,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3746/4671 [1:47:35<26:25,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3747/4671 [1:47:35<26:22,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3747/4671 [1:47:37<26:22,  1.71s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3748/4671 [1:47:37<26:28,  1.72s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3748/4671 [1:47:38<26:28,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3749/4671 [1:47:38<26:33,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3749/4671 [1:47:40<26:33,  1.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3750/4671 [1:47:40<26:37,  1.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3750/4671 [1:47:42<26:37,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3751/4671 [1:47:42<26:43,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3751/4671 [1:47:44<26:43,  1.74s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3752/4671 [1:47:44<26:41,  1.74s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3752/4671 [1:47:45<26:41,  1.74s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3753/4671 [1:47:45<26:36,  1.74s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3753/4671 [1:47:47<26:36,  1.74s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3754/4671 [1:47:47<26:31,  1.74s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3754/4671 [1:47:49<26:31,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3755/4671 [1:47:49<26:36,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3755/4671 [1:47:50<26:36,  1.74s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3756/4671 [1:47:50<26:21,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3756/4671 [1:47:52<26:21,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3757/4671 [1:47:52<26:21,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3757/4671 [1:47:54<26:21,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3758/4671 [1:47:54<26:05,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3758/4671 [1:47:56<26:05,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3759/4671 [1:47:56<25:56,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3759/4671 [1:47:57<25:56,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3760/4671 [1:47:57<25:57,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  80%|████████  | 3760/4671 [1:47:59<25:57,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3761/4671 [1:47:59<25:54,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3761/4671 [1:48:01<25:54,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3762/4671 [1:48:01<25:45,  1.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3762/4671 [1:48:02<25:45,  1.70s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3763/4671 [1:48:02<25:56,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3763/4671 [1:48:04<25:56,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3764/4671 [1:48:04<25:51,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3764/4671 [1:48:06<25:51,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3765/4671 [1:48:06<25:57,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3765/4671 [1:48:08<25:57,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3766/4671 [1:48:08<25:45,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3766/4671 [1:48:09<25:45,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3767/4671 [1:48:09<25:41,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3767/4671 [1:48:11<25:41,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3768/4671 [1:48:11<25:47,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3768/4671 [1:48:13<25:47,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3769/4671 [1:48:13<25:44,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3769/4671 [1:48:14<25:44,  1.71s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3770/4671 [1:48:14<25:57,  1.73s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3770/4671 [1:48:16<25:57,  1.73s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3771/4671 [1:48:16<25:54,  1.73s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3771/4671 [1:48:18<25:54,  1.73s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3772/4671 [1:48:18<25:39,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3772/4671 [1:48:20<25:39,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3773/4671 [1:48:20<25:40,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3773/4671 [1:48:21<25:40,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3774/4671 [1:48:21<25:45,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3774/4671 [1:48:23<25:45,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3775/4671 [1:48:23<25:54,  1.74s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3775/4671 [1:48:25<25:54,  1.74s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3776/4671 [1:48:25<25:40,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3776/4671 [1:48:26<25:40,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3777/4671 [1:48:26<25:36,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3777/4671 [1:48:28<25:36,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3778/4671 [1:48:28<25:37,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3778/4671 [1:48:30<25:37,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3779/4671 [1:48:30<25:48,  1.74s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3779/4671 [1:48:32<25:48,  1.74s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3780/4671 [1:48:32<25:41,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3780/4671 [1:48:33<25:41,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3781/4671 [1:48:33<25:43,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3781/4671 [1:48:35<25:43,  1.73s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3782/4671 [1:48:35<25:46,  1.74s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3782/4671 [1:48:37<25:46,  1.74s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3783/4671 [1:48:37<25:46,  1.74s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3783/4671 [1:48:39<25:46,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3784/4671 [1:48:39<25:37,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3784/4671 [1:48:40<25:37,  1.73s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3785/4671 [1:48:40<25:47,  1.75s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3785/4671 [1:48:42<25:47,  1.75s/it, training_loss=0.075]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3786/4671 [1:48:42<25:27,  1.73s/it, training_loss=0.075]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3786/4671 [1:48:44<25:27,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3787/4671 [1:48:44<25:21,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3787/4671 [1:48:46<25:21,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3788/4671 [1:48:46<25:25,  1.73s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3788/4671 [1:48:47<25:25,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3789/4671 [1:48:47<24:58,  1.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3789/4671 [1:48:49<24:58,  1.70s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3790/4671 [1:48:49<24:52,  1.69s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3790/4671 [1:48:51<24:52,  1.69s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3791/4671 [1:48:51<24:51,  1.69s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3791/4671 [1:48:52<24:51,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3792/4671 [1:48:52<24:43,  1.69s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3792/4671 [1:48:54<24:43,  1.69s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3793/4671 [1:48:54<24:51,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3793/4671 [1:48:56<24:51,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3794/4671 [1:48:56<24:54,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3794/4671 [1:48:57<24:54,  1.70s/it, training_loss=0.185]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3795/4671 [1:48:57<25:02,  1.71s/it, training_loss=0.185]\u001B[A\n",
      "Epoch 1:  81%|████████  | 3795/4671 [1:48:59<25:02,  1.71s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3796/4671 [1:48:59<24:56,  1.71s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3796/4671 [1:49:01<24:56,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3797/4671 [1:49:01<25:06,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3797/4671 [1:49:03<25:06,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3798/4671 [1:49:03<25:04,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3798/4671 [1:49:04<25:04,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3799/4671 [1:49:04<24:53,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3799/4671 [1:49:06<24:53,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3800/4671 [1:49:06<24:59,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3800/4671 [1:49:08<24:59,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3801/4671 [1:49:08<24:54,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3801/4671 [1:49:09<24:54,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3802/4671 [1:49:09<24:57,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3802/4671 [1:49:11<24:57,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3803/4671 [1:49:11<24:51,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3803/4671 [1:49:13<24:51,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3804/4671 [1:49:13<24:39,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3804/4671 [1:49:15<24:39,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3805/4671 [1:49:15<24:46,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3805/4671 [1:49:16<24:46,  1.72s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3806/4671 [1:49:16<24:37,  1.71s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 3806/4671 [1:49:18<24:37,  1.71s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3807/4671 [1:49:18<24:32,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3807/4671 [1:49:20<24:32,  1.70s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3808/4671 [1:49:20<24:34,  1.71s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3808/4671 [1:49:21<24:34,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3809/4671 [1:49:21<24:21,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3809/4671 [1:49:23<24:21,  1.70s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3810/4671 [1:49:23<24:28,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3810/4671 [1:49:25<24:28,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3811/4671 [1:49:25<24:26,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3811/4671 [1:49:27<24:26,  1.71s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3812/4671 [1:49:27<25:03,  1.75s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3812/4671 [1:49:28<25:03,  1.75s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3813/4671 [1:49:28<25:27,  1.78s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3813/4671 [1:49:30<25:27,  1.78s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3814/4671 [1:49:30<25:29,  1.78s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3814/4671 [1:49:32<25:29,  1.78s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3815/4671 [1:49:32<25:01,  1.75s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3815/4671 [1:49:34<25:01,  1.75s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3816/4671 [1:49:34<24:49,  1.74s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3816/4671 [1:49:35<24:49,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3817/4671 [1:49:35<24:49,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3817/4671 [1:49:37<24:49,  1.74s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3818/4671 [1:49:37<24:50,  1.75s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3818/4671 [1:49:39<24:50,  1.75s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3819/4671 [1:49:39<24:37,  1.73s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3819/4671 [1:49:41<24:37,  1.73s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3820/4671 [1:49:41<24:25,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3820/4671 [1:49:42<24:25,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3821/4671 [1:49:42<24:17,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3821/4671 [1:49:44<24:17,  1.72s/it, training_loss=0.197]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3822/4671 [1:49:44<24:22,  1.72s/it, training_loss=0.197]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3822/4671 [1:49:46<24:22,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3823/4671 [1:49:46<24:16,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3823/4671 [1:49:47<24:16,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3824/4671 [1:49:47<24:09,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3824/4671 [1:49:49<24:09,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3825/4671 [1:49:49<24:05,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3825/4671 [1:49:51<24:05,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3826/4671 [1:49:51<23:56,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3826/4671 [1:49:53<23:56,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3827/4671 [1:49:53<23:58,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3827/4671 [1:49:54<23:58,  1.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3828/4671 [1:49:54<23:54,  1.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3828/4671 [1:49:56<23:54,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3829/4671 [1:49:56<24:07,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3829/4671 [1:49:58<24:07,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3830/4671 [1:49:58<24:13,  1.73s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3830/4671 [1:49:59<24:13,  1.73s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3831/4671 [1:49:59<24:12,  1.73s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3831/4671 [1:50:01<24:12,  1.73s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3832/4671 [1:50:01<24:17,  1.74s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3832/4671 [1:50:03<24:17,  1.74s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3833/4671 [1:50:03<23:49,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3833/4671 [1:50:05<23:49,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3834/4671 [1:50:05<23:42,  1.70s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3834/4671 [1:50:06<23:42,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3835/4671 [1:50:06<23:53,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3835/4671 [1:50:08<23:53,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3836/4671 [1:50:08<23:42,  1.70s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3836/4671 [1:50:10<23:42,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3837/4671 [1:50:10<23:51,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3837/4671 [1:50:11<23:51,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3838/4671 [1:50:11<23:38,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3838/4671 [1:50:13<23:38,  1.70s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3839/4671 [1:50:13<23:41,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3839/4671 [1:50:15<23:41,  1.71s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3840/4671 [1:50:15<23:33,  1.70s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3840/4671 [1:50:16<23:33,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3841/4671 [1:50:16<23:36,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3841/4671 [1:50:18<23:36,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3842/4671 [1:50:18<23:52,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3842/4671 [1:50:20<23:52,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3843/4671 [1:50:20<23:44,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3843/4671 [1:50:22<23:44,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3844/4671 [1:50:22<23:56,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3844/4671 [1:50:23<23:56,  1.74s/it, training_loss=0.075]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3845/4671 [1:50:23<23:52,  1.73s/it, training_loss=0.075]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3845/4671 [1:50:25<23:52,  1.73s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3846/4671 [1:50:25<23:40,  1.72s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3846/4671 [1:50:27<23:40,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3847/4671 [1:50:27<23:39,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3847/4671 [1:50:29<23:39,  1.72s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3848/4671 [1:50:29<23:51,  1.74s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3848/4671 [1:50:30<23:51,  1.74s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3849/4671 [1:50:30<23:44,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3849/4671 [1:50:32<23:44,  1.73s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3850/4671 [1:50:32<23:35,  1.72s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3850/4671 [1:50:34<23:35,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3851/4671 [1:50:34<23:25,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3851/4671 [1:50:36<23:25,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3852/4671 [1:50:36<23:26,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3852/4671 [1:50:37<23:26,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3853/4671 [1:50:37<23:23,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 3853/4671 [1:50:39<23:23,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3854/4671 [1:50:39<23:15,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3854/4671 [1:50:41<23:15,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3855/4671 [1:50:41<23:14,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3855/4671 [1:50:42<23:14,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3856/4671 [1:50:42<23:10,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3856/4671 [1:50:44<23:10,  1.71s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3857/4671 [1:50:44<23:06,  1.70s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3857/4671 [1:50:46<23:06,  1.70s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3858/4671 [1:50:46<23:09,  1.71s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3858/4671 [1:50:47<23:09,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3859/4671 [1:50:47<23:17,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3859/4671 [1:50:49<23:17,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3860/4671 [1:50:49<23:18,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3860/4671 [1:50:51<23:18,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3861/4671 [1:50:51<23:03,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3861/4671 [1:50:53<23:03,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3862/4671 [1:50:53<22:56,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3862/4671 [1:50:54<22:56,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3863/4671 [1:50:54<23:01,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3863/4671 [1:50:56<23:01,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3864/4671 [1:50:56<22:58,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3864/4671 [1:50:58<22:58,  1.71s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3865/4671 [1:50:58<22:57,  1.71s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3865/4671 [1:50:59<22:57,  1.71s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3866/4671 [1:50:59<23:04,  1.72s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3866/4671 [1:51:01<23:04,  1.72s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3867/4671 [1:51:01<23:05,  1.72s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3867/4671 [1:51:03<23:05,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3868/4671 [1:51:03<22:56,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3868/4671 [1:51:05<22:56,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3869/4671 [1:51:05<22:50,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3869/4671 [1:51:06<22:50,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3870/4671 [1:51:06<22:47,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3870/4671 [1:51:08<22:47,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3871/4671 [1:51:08<22:42,  1.70s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3871/4671 [1:51:10<22:42,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3872/4671 [1:51:10<22:55,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3872/4671 [1:51:11<22:55,  1.72s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3873/4671 [1:51:11<22:57,  1.73s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3873/4671 [1:51:13<22:57,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3874/4671 [1:51:13<22:57,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3874/4671 [1:51:15<22:57,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3875/4671 [1:51:15<22:49,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3875/4671 [1:51:17<22:49,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3876/4671 [1:51:17<22:42,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3876/4671 [1:51:18<22:42,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3877/4671 [1:51:18<22:39,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3877/4671 [1:51:20<22:39,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3878/4671 [1:51:20<22:36,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3878/4671 [1:51:22<22:36,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3879/4671 [1:51:22<22:32,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3879/4671 [1:51:23<22:32,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3880/4671 [1:51:23<22:43,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3880/4671 [1:51:25<22:43,  1.72s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3881/4671 [1:51:25<22:46,  1.73s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3881/4671 [1:51:27<22:46,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3882/4671 [1:51:27<22:28,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3882/4671 [1:51:29<22:28,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3883/4671 [1:51:29<22:28,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3883/4671 [1:51:30<22:28,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3884/4671 [1:51:30<22:29,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3884/4671 [1:51:32<22:29,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3885/4671 [1:51:32<22:22,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3885/4671 [1:51:34<22:22,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3886/4671 [1:51:34<22:28,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3886/4671 [1:51:35<22:28,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3887/4671 [1:51:35<22:26,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3887/4671 [1:51:37<22:26,  1.72s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3888/4671 [1:51:37<22:27,  1.72s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3888/4671 [1:51:39<22:27,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3889/4671 [1:51:39<22:19,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3889/4671 [1:51:41<22:19,  1.71s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3890/4671 [1:51:41<22:24,  1.72s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3890/4671 [1:51:42<22:24,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3891/4671 [1:51:42<22:22,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3891/4671 [1:51:44<22:22,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3892/4671 [1:51:44<22:30,  1.73s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3892/4671 [1:51:46<22:30,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3893/4671 [1:51:46<22:23,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3893/4671 [1:51:48<22:23,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3894/4671 [1:51:48<22:19,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3894/4671 [1:51:49<22:19,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3895/4671 [1:51:49<22:27,  1.74s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3895/4671 [1:51:51<22:27,  1.74s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3896/4671 [1:51:51<22:25,  1.74s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3896/4671 [1:51:53<22:25,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3897/4671 [1:51:53<22:13,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3897/4671 [1:51:54<22:13,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3898/4671 [1:51:54<22:12,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3898/4671 [1:51:56<22:12,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3899/4671 [1:51:56<22:12,  1.73s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3899/4671 [1:51:58<22:12,  1.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3900/4671 [1:51:58<22:04,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 3900/4671 [1:52:01<22:04,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3901/4671 [1:52:01<25:53,  2.02s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3901/4671 [1:52:02<25:53,  2.02s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3902/4671 [1:52:02<25:02,  1.95s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3902/4671 [1:52:04<25:02,  1.95s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3903/4671 [1:52:04<24:28,  1.91s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3903/4671 [1:52:06<24:28,  1.91s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3904/4671 [1:52:06<23:45,  1.86s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3904/4671 [1:52:08<23:45,  1.86s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3905/4671 [1:52:08<23:10,  1.82s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3905/4671 [1:52:09<23:10,  1.82s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3906/4671 [1:52:09<22:47,  1.79s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3906/4671 [1:52:11<22:47,  1.79s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3907/4671 [1:52:11<22:38,  1.78s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3907/4671 [1:52:13<22:38,  1.78s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3908/4671 [1:52:13<22:24,  1.76s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3908/4671 [1:52:15<22:24,  1.76s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3909/4671 [1:52:15<22:11,  1.75s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3909/4671 [1:52:16<22:11,  1.75s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3910/4671 [1:52:16<22:12,  1.75s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3910/4671 [1:52:18<22:12,  1.75s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3911/4671 [1:52:18<22:02,  1.74s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 3911/4671 [1:52:20<22:02,  1.74s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3912/4671 [1:52:20<21:52,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3912/4671 [1:52:22<21:52,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3913/4671 [1:52:22<21:55,  1.74s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3913/4671 [1:52:23<21:55,  1.74s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3914/4671 [1:52:23<21:53,  1.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3914/4671 [1:52:25<21:53,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3915/4671 [1:52:25<21:42,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3915/4671 [1:52:27<21:42,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3916/4671 [1:52:27<21:31,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3916/4671 [1:52:28<21:31,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3917/4671 [1:52:28<21:26,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3917/4671 [1:52:30<21:26,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3918/4671 [1:52:30<21:35,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3918/4671 [1:52:32<21:35,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3919/4671 [1:52:32<21:30,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3919/4671 [1:52:34<21:30,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3920/4671 [1:52:34<21:38,  1.73s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3920/4671 [1:52:35<21:38,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3921/4671 [1:52:35<21:31,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3921/4671 [1:52:37<21:31,  1.72s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3922/4671 [1:52:37<21:29,  1.72s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3922/4671 [1:52:39<21:29,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3923/4671 [1:52:39<21:14,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3923/4671 [1:52:40<21:14,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3924/4671 [1:52:40<21:06,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3924/4671 [1:52:42<21:06,  1.70s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3925/4671 [1:52:42<21:16,  1.71s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3925/4671 [1:52:44<21:16,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3926/4671 [1:52:44<21:11,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3926/4671 [1:52:46<21:11,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3927/4671 [1:52:46<21:17,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3927/4671 [1:52:47<21:17,  1.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3928/4671 [1:52:47<21:11,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3928/4671 [1:52:49<21:11,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3929/4671 [1:52:49<21:12,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3929/4671 [1:52:51<21:12,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3930/4671 [1:52:51<21:13,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3930/4671 [1:52:52<21:13,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3931/4671 [1:52:52<21:10,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3931/4671 [1:52:54<21:10,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3932/4671 [1:52:54<21:20,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3932/4671 [1:52:56<21:20,  1.73s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3933/4671 [1:52:56<21:25,  1.74s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3933/4671 [1:52:58<21:25,  1.74s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3934/4671 [1:52:58<21:19,  1.74s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3934/4671 [1:52:59<21:19,  1.74s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3935/4671 [1:52:59<21:14,  1.73s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3935/4671 [1:53:01<21:14,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3936/4671 [1:53:01<21:09,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3936/4671 [1:53:03<21:09,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3937/4671 [1:53:03<21:09,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3937/4671 [1:53:05<21:09,  1.73s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3938/4671 [1:53:05<21:01,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3938/4671 [1:53:06<21:01,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3939/4671 [1:53:06<21:12,  1.74s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3939/4671 [1:53:08<21:12,  1.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3940/4671 [1:53:08<21:07,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3940/4671 [1:53:10<21:07,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3941/4671 [1:53:10<20:52,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3941/4671 [1:53:11<20:52,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3942/4671 [1:53:11<20:52,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3942/4671 [1:53:13<20:52,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3943/4671 [1:53:13<20:52,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3943/4671 [1:53:15<20:52,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3944/4671 [1:53:15<20:52,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3944/4671 [1:53:17<20:52,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3945/4671 [1:53:17<20:38,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3945/4671 [1:53:18<20:38,  1.71s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3946/4671 [1:53:18<20:35,  1.70s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 3946/4671 [1:53:20<20:35,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3947/4671 [1:53:20<20:36,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3947/4671 [1:53:22<20:36,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3948/4671 [1:53:22<20:37,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3948/4671 [1:53:23<20:37,  1.71s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3949/4671 [1:53:23<20:31,  1.71s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3949/4671 [1:53:25<20:31,  1.71s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3950/4671 [1:53:25<20:31,  1.71s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3950/4671 [1:53:27<20:31,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3951/4671 [1:53:27<20:30,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3951/4671 [1:53:28<20:30,  1.71s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3952/4671 [1:53:28<20:27,  1.71s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3952/4671 [1:53:30<20:27,  1.71s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3953/4671 [1:53:30<20:22,  1.70s/it, training_loss=0.083]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3953/4671 [1:53:32<20:22,  1.70s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3954/4671 [1:53:32<20:16,  1.70s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3954/4671 [1:53:34<20:16,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3955/4671 [1:53:34<20:15,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3955/4671 [1:53:35<20:15,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3956/4671 [1:53:35<20:08,  1.69s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3956/4671 [1:53:37<20:08,  1.69s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3957/4671 [1:53:37<20:15,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3957/4671 [1:53:39<20:15,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3958/4671 [1:53:39<20:27,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3958/4671 [1:53:40<20:27,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3959/4671 [1:53:40<20:20,  1.71s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3959/4671 [1:53:42<20:20,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3960/4671 [1:53:42<20:24,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3960/4671 [1:53:44<20:24,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3961/4671 [1:53:44<20:17,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3961/4671 [1:53:46<20:17,  1.71s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3962/4671 [1:53:46<20:19,  1.72s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3962/4671 [1:53:47<20:19,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3963/4671 [1:53:47<20:05,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3963/4671 [1:53:49<20:05,  1.70s/it, training_loss=0.211]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3964/4671 [1:53:49<20:12,  1.72s/it, training_loss=0.211]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3964/4671 [1:53:51<20:12,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3965/4671 [1:53:51<20:05,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3965/4671 [1:53:52<20:05,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3966/4671 [1:53:52<19:52,  1.69s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3966/4671 [1:53:54<19:52,  1.69s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3967/4671 [1:53:54<19:53,  1.70s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3967/4671 [1:53:56<19:53,  1.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3968/4671 [1:53:56<19:59,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3968/4671 [1:53:58<19:59,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3969/4671 [1:53:58<20:11,  1.73s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3969/4671 [1:53:59<20:11,  1.73s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3970/4671 [1:53:59<20:11,  1.73s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 3970/4671 [1:54:01<20:11,  1.73s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3971/4671 [1:54:01<20:14,  1.74s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3971/4671 [1:54:03<20:14,  1.74s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3972/4671 [1:54:03<20:10,  1.73s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3972/4671 [1:54:04<20:10,  1.73s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3973/4671 [1:54:04<20:02,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3973/4671 [1:54:06<20:02,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3974/4671 [1:54:06<20:14,  1.74s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3974/4671 [1:54:08<20:14,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3975/4671 [1:54:08<20:00,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3975/4671 [1:54:10<20:00,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3976/4671 [1:54:10<20:01,  1.73s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3976/4671 [1:54:11<20:01,  1.73s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3977/4671 [1:54:11<20:06,  1.74s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3977/4671 [1:54:13<20:06,  1.74s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3978/4671 [1:54:13<20:01,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3978/4671 [1:54:15<20:01,  1.73s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3979/4671 [1:54:15<19:52,  1.72s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3979/4671 [1:54:17<19:52,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3980/4671 [1:54:17<19:38,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3980/4671 [1:54:18<19:38,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3981/4671 [1:54:18<19:46,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3981/4671 [1:54:20<19:46,  1.72s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3982/4671 [1:54:20<19:32,  1.70s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3982/4671 [1:54:22<19:32,  1.70s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3983/4671 [1:54:22<19:34,  1.71s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3983/4671 [1:54:23<19:34,  1.71s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3984/4671 [1:54:23<19:28,  1.70s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3984/4671 [1:54:25<19:28,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3985/4671 [1:54:25<19:31,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3985/4671 [1:54:27<19:31,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3986/4671 [1:54:27<19:31,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3986/4671 [1:54:29<19:31,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3987/4671 [1:54:29<19:41,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3987/4671 [1:54:30<19:41,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3988/4671 [1:54:30<19:38,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3988/4671 [1:54:32<19:38,  1.73s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3989/4671 [1:54:32<19:22,  1.70s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3989/4671 [1:54:34<19:22,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3990/4671 [1:54:34<19:27,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3990/4671 [1:54:35<19:27,  1.71s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3991/4671 [1:54:35<19:20,  1.71s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3991/4671 [1:54:37<19:20,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3992/4671 [1:54:37<19:25,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3992/4671 [1:54:39<19:25,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3993/4671 [1:54:39<19:20,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 3993/4671 [1:54:40<19:20,  1.71s/it, training_loss=0.065]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 3994/4671 [1:54:40<19:16,  1.71s/it, training_loss=0.065]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 3994/4671 [1:54:42<19:16,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 3995/4671 [1:54:42<19:14,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 3995/4671 [1:54:44<19:14,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 3996/4671 [1:54:44<19:13,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 3996/4671 [1:54:46<19:13,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 3997/4671 [1:54:46<19:14,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 3997/4671 [1:54:47<19:14,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 3998/4671 [1:54:47<19:12,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 3998/4671 [1:54:49<19:12,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 3999/4671 [1:54:49<19:10,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 3999/4671 [1:54:51<19:10,  1.71s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4000/4671 [1:54:51<19:07,  1.71s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4000/4671 [1:54:53<19:07,  1.71s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4001/4671 [1:54:53<19:11,  1.72s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4001/4671 [1:54:54<19:11,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4002/4671 [1:54:54<19:02,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4002/4671 [1:54:56<19:02,  1.71s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4003/4671 [1:54:56<18:55,  1.70s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4003/4671 [1:54:58<18:55,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4004/4671 [1:54:58<18:57,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4004/4671 [1:54:59<18:57,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4005/4671 [1:54:59<18:56,  1.71s/it, training_loss=0.165]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4005/4671 [1:55:01<18:56,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4006/4671 [1:55:01<18:54,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4006/4671 [1:55:03<18:54,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4007/4671 [1:55:03<18:49,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4007/4671 [1:55:04<18:49,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4008/4671 [1:55:04<18:54,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4008/4671 [1:55:06<18:54,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4009/4671 [1:55:06<18:58,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4009/4671 [1:55:08<18:58,  1.72s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4010/4671 [1:55:08<19:02,  1.73s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4010/4671 [1:55:10<19:02,  1.73s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4011/4671 [1:55:10<19:05,  1.74s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4011/4671 [1:55:11<19:05,  1.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4012/4671 [1:55:11<19:01,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4012/4671 [1:55:13<19:01,  1.73s/it, training_loss=0.057]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4013/4671 [1:55:13<18:42,  1.71s/it, training_loss=0.057]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4013/4671 [1:55:15<18:42,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4014/4671 [1:55:15<18:44,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4014/4671 [1:55:16<18:44,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4015/4671 [1:55:16<18:40,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4015/4671 [1:55:18<18:40,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4016/4671 [1:55:18<18:43,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4016/4671 [1:55:20<18:43,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4017/4671 [1:55:20<18:47,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4017/4671 [1:55:22<18:47,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4018/4671 [1:55:22<18:45,  1.72s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4018/4671 [1:55:23<18:45,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4019/4671 [1:55:23<18:45,  1.73s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4019/4671 [1:55:25<18:45,  1.73s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4020/4671 [1:55:25<18:29,  1.70s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4020/4671 [1:55:27<18:29,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4021/4671 [1:55:27<18:36,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4021/4671 [1:55:29<18:36,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4022/4671 [1:55:29<18:44,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4022/4671 [1:55:30<18:44,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4023/4671 [1:55:30<18:40,  1.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4023/4671 [1:55:32<18:40,  1.73s/it, training_loss=0.205]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4024/4671 [1:55:32<18:31,  1.72s/it, training_loss=0.205]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4024/4671 [1:55:34<18:31,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4025/4671 [1:55:34<18:22,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4025/4671 [1:55:35<18:22,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4026/4671 [1:55:35<18:23,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4026/4671 [1:55:37<18:23,  1.71s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4027/4671 [1:55:37<18:22,  1.71s/it, training_loss=0.173]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4027/4671 [1:55:39<18:22,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4028/4671 [1:55:39<18:18,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 4028/4671 [1:55:40<18:18,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4029/4671 [1:55:40<18:15,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4029/4671 [1:55:42<18:15,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4030/4671 [1:55:42<18:14,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4030/4671 [1:55:44<18:14,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4031/4671 [1:55:44<18:13,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4031/4671 [1:55:46<18:13,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4032/4671 [1:55:46<18:01,  1.69s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4032/4671 [1:55:47<18:01,  1.69s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4033/4671 [1:55:47<18:04,  1.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4033/4671 [1:55:49<18:04,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4034/4671 [1:55:49<18:07,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4034/4671 [1:55:51<18:07,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4035/4671 [1:55:51<18:06,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4035/4671 [1:55:52<18:06,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4036/4671 [1:55:52<18:03,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4036/4671 [1:55:54<18:03,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4037/4671 [1:55:54<18:14,  1.73s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4037/4671 [1:55:56<18:14,  1.73s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4038/4671 [1:55:56<18:11,  1.72s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4038/4671 [1:55:58<18:11,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4039/4671 [1:55:58<18:08,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4039/4671 [1:55:59<18:08,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4040/4671 [1:55:59<18:08,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 4040/4671 [1:56:01<18:08,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4041/4671 [1:56:01<18:16,  1.74s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4041/4671 [1:56:03<18:16,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4042/4671 [1:56:03<18:18,  1.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4042/4671 [1:56:05<18:18,  1.75s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4043/4671 [1:56:05<18:17,  1.75s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4043/4671 [1:56:06<18:17,  1.75s/it, training_loss=0.071]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4044/4671 [1:56:06<18:18,  1.75s/it, training_loss=0.071]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4044/4671 [1:56:08<18:18,  1.75s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4045/4671 [1:56:08<18:13,  1.75s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4045/4671 [1:56:10<18:13,  1.75s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4046/4671 [1:56:10<18:13,  1.75s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4046/4671 [1:56:12<18:13,  1.75s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4047/4671 [1:56:12<18:14,  1.75s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4047/4671 [1:56:13<18:14,  1.75s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4048/4671 [1:56:13<18:04,  1.74s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4048/4671 [1:56:15<18:04,  1.74s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4049/4671 [1:56:15<18:05,  1.74s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4049/4671 [1:56:17<18:05,  1.74s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4050/4671 [1:56:17<17:57,  1.74s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4050/4671 [1:56:19<17:57,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4051/4671 [1:56:19<17:56,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4051/4671 [1:56:20<17:56,  1.74s/it, training_loss=0.185]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4052/4671 [1:56:20<17:59,  1.74s/it, training_loss=0.185]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4052/4671 [1:56:22<17:59,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4053/4671 [1:56:22<17:59,  1.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4053/4671 [1:56:24<17:59,  1.75s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4054/4671 [1:56:24<17:57,  1.75s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4054/4671 [1:56:26<17:57,  1.75s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4055/4671 [1:56:26<17:53,  1.74s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4055/4671 [1:56:27<17:53,  1.74s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4056/4671 [1:56:27<17:57,  1.75s/it, training_loss=0.177]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4056/4671 [1:56:29<17:57,  1.75s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4057/4671 [1:56:29<17:54,  1.75s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4057/4671 [1:56:31<17:54,  1.75s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4058/4671 [1:56:31<18:00,  1.76s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4058/4671 [1:56:33<18:00,  1.76s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4059/4671 [1:56:33<18:00,  1.77s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4059/4671 [1:56:34<18:00,  1.77s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4060/4671 [1:56:34<17:53,  1.76s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4060/4671 [1:56:36<17:53,  1.76s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4061/4671 [1:56:36<17:45,  1.75s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4061/4671 [1:56:38<17:45,  1.75s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4062/4671 [1:56:38<17:38,  1.74s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4062/4671 [1:56:40<17:38,  1.74s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4063/4671 [1:56:40<17:44,  1.75s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4063/4671 [1:56:41<17:44,  1.75s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4064/4671 [1:56:41<17:40,  1.75s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4064/4671 [1:56:43<17:40,  1.75s/it, training_loss=0.183]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4065/4671 [1:56:43<17:40,  1.75s/it, training_loss=0.183]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4065/4671 [1:56:45<17:40,  1.75s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4066/4671 [1:56:45<17:29,  1.73s/it, training_loss=0.191]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4066/4671 [1:56:47<17:29,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4067/4671 [1:56:47<17:21,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4067/4671 [1:56:48<17:21,  1.72s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4068/4671 [1:56:48<17:18,  1.72s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4068/4671 [1:56:50<17:18,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4069/4671 [1:56:50<17:25,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4069/4671 [1:56:52<17:25,  1.74s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4070/4671 [1:56:52<17:29,  1.75s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4070/4671 [1:56:53<17:29,  1.75s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4071/4671 [1:56:53<17:19,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4071/4671 [1:56:55<17:19,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4072/4671 [1:56:55<17:16,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4072/4671 [1:56:57<17:16,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4073/4671 [1:56:57<17:24,  1.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4073/4671 [1:56:59<17:24,  1.75s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4074/4671 [1:56:59<17:18,  1.74s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4074/4671 [1:57:00<17:18,  1.74s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4075/4671 [1:57:00<17:18,  1.74s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4075/4671 [1:57:02<17:18,  1.74s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4076/4671 [1:57:02<17:18,  1.75s/it, training_loss=0.082]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4076/4671 [1:57:04<17:18,  1.75s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4077/4671 [1:57:04<17:19,  1.75s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4077/4671 [1:57:06<17:19,  1.75s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4078/4671 [1:57:06<17:13,  1.74s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4078/4671 [1:57:07<17:13,  1.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4079/4671 [1:57:07<17:18,  1.75s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4079/4671 [1:57:09<17:18,  1.75s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4080/4671 [1:57:09<17:19,  1.76s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4080/4671 [1:57:11<17:19,  1.76s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4081/4671 [1:57:11<17:17,  1.76s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4081/4671 [1:57:13<17:17,  1.76s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4082/4671 [1:57:13<17:15,  1.76s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4082/4671 [1:57:14<17:15,  1.76s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4083/4671 [1:57:14<17:06,  1.75s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4083/4671 [1:57:16<17:06,  1.75s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4084/4671 [1:57:16<17:05,  1.75s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4084/4671 [1:57:18<17:05,  1.75s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4085/4671 [1:57:18<17:03,  1.75s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4085/4671 [1:57:20<17:03,  1.75s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4086/4671 [1:57:20<17:05,  1.75s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4086/4671 [1:57:22<17:05,  1.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4087/4671 [1:57:22<17:13,  1.77s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 4087/4671 [1:57:23<17:13,  1.77s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4088/4671 [1:57:23<16:53,  1.74s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4088/4671 [1:57:25<16:53,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4089/4671 [1:57:25<16:51,  1.74s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4089/4671 [1:57:27<16:51,  1.74s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4090/4671 [1:57:27<16:52,  1.74s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4090/4671 [1:57:28<16:52,  1.74s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4091/4671 [1:57:28<16:53,  1.75s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4091/4671 [1:57:30<16:53,  1.75s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4092/4671 [1:57:30<16:56,  1.76s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4092/4671 [1:57:32<16:56,  1.76s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4093/4671 [1:57:32<16:50,  1.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4093/4671 [1:57:34<16:50,  1.75s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4094/4671 [1:57:34<16:49,  1.75s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4094/4671 [1:57:35<16:49,  1.75s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4095/4671 [1:57:35<16:51,  1.76s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4095/4671 [1:57:37<16:51,  1.76s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4096/4671 [1:57:37<16:43,  1.75s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4096/4671 [1:57:39<16:43,  1.75s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4097/4671 [1:57:39<16:39,  1.74s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4097/4671 [1:57:41<16:39,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4098/4671 [1:57:41<16:44,  1.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4098/4671 [1:57:42<16:44,  1.75s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4099/4671 [1:57:42<16:42,  1.75s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4099/4671 [1:57:44<16:42,  1.75s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4100/4671 [1:57:44<16:46,  1.76s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4100/4671 [1:57:46<16:46,  1.76s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4101/4671 [1:57:46<16:44,  1.76s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4101/4671 [1:57:48<16:44,  1.76s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4102/4671 [1:57:48<16:38,  1.75s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4102/4671 [1:57:49<16:38,  1.75s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4103/4671 [1:57:49<16:26,  1.74s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4103/4671 [1:57:51<16:26,  1.74s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4104/4671 [1:57:51<16:18,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4104/4671 [1:57:53<16:18,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4105/4671 [1:57:53<16:06,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4105/4671 [1:57:55<16:06,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4106/4671 [1:57:55<16:12,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4106/4671 [1:57:56<16:12,  1.72s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4107/4671 [1:57:56<16:08,  1.72s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4107/4671 [1:57:58<16:08,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4108/4671 [1:57:58<16:10,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4108/4671 [1:58:00<16:10,  1.72s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4109/4671 [1:58:00<16:05,  1.72s/it, training_loss=0.095]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4109/4671 [1:58:01<16:05,  1.72s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4110/4671 [1:58:01<15:58,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4110/4671 [1:58:03<15:58,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4111/4671 [1:58:03<15:52,  1.70s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4111/4671 [1:58:05<15:52,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4112/4671 [1:58:05<15:57,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4112/4671 [1:58:06<15:57,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4113/4671 [1:58:06<15:45,  1.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4113/4671 [1:58:08<15:45,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4114/4671 [1:58:08<15:52,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4114/4671 [1:58:10<15:52,  1.71s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4115/4671 [1:58:10<15:48,  1.71s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4115/4671 [1:58:12<15:48,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4116/4671 [1:58:12<15:44,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4116/4671 [1:58:13<15:44,  1.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4117/4671 [1:58:13<15:45,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4117/4671 [1:58:15<15:45,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4118/4671 [1:58:15<15:41,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4118/4671 [1:58:17<15:41,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4119/4671 [1:58:17<15:46,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4119/4671 [1:58:18<15:46,  1.71s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4120/4671 [1:58:18<15:40,  1.71s/it, training_loss=0.182]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4120/4671 [1:58:20<15:40,  1.71s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4121/4671 [1:58:20<15:38,  1.71s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4121/4671 [1:58:22<15:38,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4122/4671 [1:58:22<15:34,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4122/4671 [1:58:24<15:34,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4123/4671 [1:58:24<15:36,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4123/4671 [1:58:25<15:36,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4124/4671 [1:58:25<15:39,  1.72s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4124/4671 [1:58:27<15:39,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4125/4671 [1:58:27<15:34,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4125/4671 [1:58:29<15:34,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4126/4671 [1:58:29<15:27,  1.70s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4126/4671 [1:58:30<15:27,  1.70s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4127/4671 [1:58:30<15:32,  1.71s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4127/4671 [1:58:32<15:32,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4128/4671 [1:58:32<15:28,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4128/4671 [1:58:34<15:28,  1.71s/it, training_loss=0.192]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4129/4671 [1:58:34<15:32,  1.72s/it, training_loss=0.192]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4129/4671 [1:58:36<15:32,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4130/4671 [1:58:36<15:32,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4130/4671 [1:58:37<15:32,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4131/4671 [1:58:37<15:27,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4131/4671 [1:58:39<15:27,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4132/4671 [1:58:39<15:23,  1.71s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4132/4671 [1:58:41<15:23,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4133/4671 [1:58:41<15:22,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 4133/4671 [1:58:43<15:22,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4134/4671 [1:58:43<15:27,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4134/4671 [1:58:44<15:27,  1.73s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4135/4671 [1:58:44<15:27,  1.73s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4135/4671 [1:58:46<15:27,  1.73s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4136/4671 [1:58:46<15:22,  1.72s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4136/4671 [1:58:48<15:22,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4137/4671 [1:58:48<15:17,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4137/4671 [1:58:49<15:17,  1.72s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4138/4671 [1:58:49<15:10,  1.71s/it, training_loss=0.090]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4138/4671 [1:58:51<15:10,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4139/4671 [1:58:51<15:10,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4139/4671 [1:58:53<15:10,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4140/4671 [1:58:53<15:02,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4140/4671 [1:58:54<15:02,  1.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4141/4671 [1:58:54<15:03,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4141/4671 [1:58:56<15:03,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4142/4671 [1:58:56<15:04,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4142/4671 [1:58:58<15:04,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4143/4671 [1:58:58<15:06,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4143/4671 [1:59:00<15:06,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4144/4671 [1:59:00<15:09,  1.73s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4144/4671 [1:59:01<15:09,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4145/4671 [1:59:01<15:03,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 4145/4671 [1:59:03<15:03,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4146/4671 [1:59:03<14:59,  1.71s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4146/4671 [1:59:05<14:59,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4147/4671 [1:59:05<15:02,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4147/4671 [1:59:07<15:02,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4148/4671 [1:59:07<14:58,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4148/4671 [1:59:08<14:58,  1.72s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4149/4671 [1:59:08<14:52,  1.71s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4149/4671 [1:59:10<14:52,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4150/4671 [1:59:10<14:45,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4150/4671 [1:59:12<14:45,  1.70s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4151/4671 [1:59:12<14:45,  1.70s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4151/4671 [1:59:13<14:45,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4152/4671 [1:59:13<14:48,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4152/4671 [1:59:15<14:48,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4153/4671 [1:59:15<14:45,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4153/4671 [1:59:17<14:45,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4154/4671 [1:59:17<14:48,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4154/4671 [1:59:18<14:48,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4155/4671 [1:59:18<14:45,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4155/4671 [1:59:20<14:45,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4156/4671 [1:59:20<14:40,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4156/4671 [1:59:22<14:40,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4157/4671 [1:59:22<14:44,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4157/4671 [1:59:24<14:44,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4158/4671 [1:59:24<14:41,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4158/4671 [1:59:25<14:41,  1.72s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4159/4671 [1:59:25<14:41,  1.72s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4159/4671 [1:59:27<14:41,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4160/4671 [1:59:27<14:37,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4160/4671 [1:59:29<14:37,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4161/4671 [1:59:29<14:35,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4161/4671 [1:59:30<14:35,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4162/4671 [1:59:30<14:30,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4162/4671 [1:59:32<14:30,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4163/4671 [1:59:32<14:31,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4163/4671 [1:59:34<14:31,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4164/4671 [1:59:34<14:32,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4164/4671 [1:59:36<14:32,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4165/4671 [1:59:36<14:26,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4165/4671 [1:59:37<14:26,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4166/4671 [1:59:37<14:23,  1.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4166/4671 [1:59:39<14:23,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4167/4671 [1:59:39<14:24,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4167/4671 [1:59:41<14:24,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4168/4671 [1:59:41<14:28,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4168/4671 [1:59:43<14:28,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4169/4671 [1:59:43<14:26,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4169/4671 [1:59:44<14:26,  1.73s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4170/4671 [1:59:44<14:25,  1.73s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4170/4671 [1:59:46<14:25,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4171/4671 [1:59:46<14:15,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4171/4671 [1:59:48<14:15,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4172/4671 [1:59:48<14:21,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4172/4671 [1:59:49<14:21,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4173/4671 [1:59:49<14:16,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4173/4671 [1:59:51<14:16,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4174/4671 [1:59:51<14:13,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4174/4671 [1:59:53<14:13,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4175/4671 [1:59:53<14:14,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4175/4671 [1:59:55<14:14,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4176/4671 [1:59:55<14:10,  1.72s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4176/4671 [1:59:56<14:10,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4177/4671 [1:59:56<14:04,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4177/4671 [1:59:58<14:04,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4178/4671 [1:59:58<14:08,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4178/4671 [2:00:00<14:08,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4179/4671 [2:00:00<14:03,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4179/4671 [2:00:01<14:03,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4180/4671 [2:00:01<14:00,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 4180/4671 [2:00:03<14:00,  1.71s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4181/4671 [2:00:03<14:04,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4181/4671 [2:00:05<14:04,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4182/4671 [2:00:05<14:00,  1.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4182/4671 [2:00:07<14:00,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4183/4671 [2:00:07<14:00,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4183/4671 [2:00:08<14:00,  1.72s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4184/4671 [2:00:08<13:52,  1.71s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4184/4671 [2:00:10<13:52,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4185/4671 [2:00:10<13:49,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4185/4671 [2:00:12<13:49,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4186/4671 [2:00:12<13:48,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4186/4671 [2:00:13<13:48,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4187/4671 [2:00:13<13:48,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4187/4671 [2:00:15<13:48,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4188/4671 [2:00:15<13:44,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4188/4671 [2:00:17<13:44,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4189/4671 [2:00:17<13:43,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4189/4671 [2:00:19<13:43,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4190/4671 [2:00:19<13:47,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4190/4671 [2:00:20<13:47,  1.72s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4191/4671 [2:00:20<13:43,  1.71s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4191/4671 [2:00:22<13:43,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4192/4671 [2:00:22<13:48,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4192/4671 [2:00:24<13:48,  1.73s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4193/4671 [2:00:24<13:43,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4193/4671 [2:00:25<13:43,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4194/4671 [2:00:25<13:42,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4194/4671 [2:00:27<13:42,  1.72s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4195/4671 [2:00:27<13:40,  1.72s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4195/4671 [2:00:29<13:40,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4196/4671 [2:00:29<13:33,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4196/4671 [2:00:31<13:33,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4197/4671 [2:00:31<13:31,  1.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4197/4671 [2:00:32<13:31,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4198/4671 [2:00:32<13:28,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4198/4671 [2:00:34<13:28,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4199/4671 [2:00:34<13:29,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4199/4671 [2:00:36<13:29,  1.71s/it, training_loss=0.193]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4200/4671 [2:00:36<13:30,  1.72s/it, training_loss=0.193]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4200/4671 [2:00:38<13:30,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4201/4671 [2:00:38<13:40,  1.75s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4201/4671 [2:00:39<13:40,  1.75s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4202/4671 [2:00:39<13:40,  1.75s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4202/4671 [2:00:41<13:40,  1.75s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4203/4671 [2:00:41<13:40,  1.75s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 4203/4671 [2:00:43<13:40,  1.75s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4204/4671 [2:00:43<13:35,  1.75s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4204/4671 [2:00:45<13:35,  1.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4205/4671 [2:00:45<13:32,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4205/4671 [2:00:46<13:32,  1.74s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4206/4671 [2:00:46<13:22,  1.73s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4206/4671 [2:00:48<13:22,  1.73s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4207/4671 [2:00:48<13:17,  1.72s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4207/4671 [2:00:50<13:17,  1.72s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4208/4671 [2:00:50<13:20,  1.73s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4208/4671 [2:00:51<13:20,  1.73s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4209/4671 [2:00:51<13:16,  1.72s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4209/4671 [2:00:53<13:16,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4210/4671 [2:00:53<13:06,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4210/4671 [2:00:55<13:06,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4211/4671 [2:00:55<13:04,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4211/4671 [2:00:56<13:04,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4212/4671 [2:00:57<13:08,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4212/4671 [2:00:58<13:08,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4213/4671 [2:00:58<13:04,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4213/4671 [2:01:00<13:04,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4214/4671 [2:01:00<12:58,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4214/4671 [2:01:02<12:58,  1.70s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4215/4671 [2:01:02<12:54,  1.70s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4215/4671 [2:01:03<12:54,  1.70s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4216/4671 [2:01:03<12:59,  1.71s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4216/4671 [2:01:05<12:59,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4217/4671 [2:01:05<12:55,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4217/4671 [2:01:07<12:55,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4218/4671 [2:01:07<12:47,  1.69s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4218/4671 [2:01:08<12:47,  1.69s/it, training_loss=0.224]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4219/4671 [2:01:08<12:53,  1.71s/it, training_loss=0.224]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4219/4671 [2:01:10<12:53,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4220/4671 [2:01:10<12:45,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4220/4671 [2:01:12<12:45,  1.70s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4221/4671 [2:01:12<12:49,  1.71s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4221/4671 [2:01:14<12:49,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4222/4671 [2:01:14<12:48,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4222/4671 [2:01:15<12:48,  1.71s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4223/4671 [2:01:15<12:49,  1.72s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4223/4671 [2:01:17<12:49,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4224/4671 [2:01:17<12:47,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4224/4671 [2:01:19<12:47,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4225/4671 [2:01:19<12:43,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4225/4671 [2:01:20<12:43,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4226/4671 [2:01:20<12:45,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4226/4671 [2:01:22<12:45,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4227/4671 [2:01:22<12:40,  1.71s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 4227/4671 [2:01:24<12:40,  1.71s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4228/4671 [2:01:24<12:38,  1.71s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4228/4671 [2:01:26<12:38,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4229/4671 [2:01:26<12:36,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4229/4671 [2:01:27<12:36,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4230/4671 [2:01:27<12:43,  1.73s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4230/4671 [2:01:29<12:43,  1.73s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4231/4671 [2:01:29<12:37,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4231/4671 [2:01:31<12:37,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4232/4671 [2:01:31<12:37,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4232/4671 [2:01:32<12:37,  1.73s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4233/4671 [2:01:32<12:33,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4233/4671 [2:01:34<12:33,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4234/4671 [2:01:34<12:28,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4234/4671 [2:01:36<12:28,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4235/4671 [2:01:36<12:27,  1.71s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4235/4671 [2:01:38<12:27,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4236/4671 [2:01:38<12:28,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4236/4671 [2:01:39<12:28,  1.72s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4237/4671 [2:01:39<12:23,  1.71s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4237/4671 [2:01:41<12:23,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4238/4671 [2:01:41<12:24,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4238/4671 [2:01:43<12:24,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4239/4671 [2:01:43<12:15,  1.70s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4239/4671 [2:01:44<12:15,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4240/4671 [2:01:44<12:16,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4240/4671 [2:01:46<12:16,  1.71s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4241/4671 [2:01:46<12:16,  1.71s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4241/4671 [2:01:48<12:16,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4242/4671 [2:01:48<12:15,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4242/4671 [2:01:50<12:15,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4243/4671 [2:01:50<12:12,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4243/4671 [2:01:51<12:12,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4244/4671 [2:01:51<12:07,  1.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4244/4671 [2:01:53<12:07,  1.70s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4245/4671 [2:01:53<12:03,  1.70s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4245/4671 [2:01:55<12:03,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4246/4671 [2:01:55<12:06,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4246/4671 [2:01:56<12:06,  1.71s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4247/4671 [2:01:56<12:01,  1.70s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4247/4671 [2:01:58<12:01,  1.70s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4248/4671 [2:01:58<12:00,  1.70s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4248/4671 [2:02:00<12:00,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4249/4671 [2:02:00<11:57,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4249/4671 [2:02:01<11:57,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4250/4671 [2:02:01<11:58,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4250/4671 [2:02:03<11:58,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4251/4671 [2:02:03<12:00,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4251/4671 [2:02:05<12:00,  1.72s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4252/4671 [2:02:05<11:56,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4252/4671 [2:02:07<11:56,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4253/4671 [2:02:07<11:54,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4253/4671 [2:02:08<11:54,  1.71s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4254/4671 [2:02:08<11:52,  1.71s/it, training_loss=0.170]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4254/4671 [2:02:10<11:52,  1.71s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4255/4671 [2:02:10<11:48,  1.70s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4255/4671 [2:02:12<11:48,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4256/4671 [2:02:12<11:50,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4256/4671 [2:02:14<11:50,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4257/4671 [2:02:14<11:54,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4257/4671 [2:02:15<11:54,  1.73s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4258/4671 [2:02:15<11:50,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4258/4671 [2:02:17<11:50,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4259/4671 [2:02:17<11:48,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4259/4671 [2:02:19<11:48,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4260/4671 [2:02:19<11:45,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4260/4671 [2:02:20<11:45,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4261/4671 [2:02:20<11:44,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4261/4671 [2:02:22<11:44,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4262/4671 [2:02:22<11:45,  1.73s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 4262/4671 [2:02:24<11:45,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4263/4671 [2:02:24<11:47,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4263/4671 [2:02:26<11:47,  1.73s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4264/4671 [2:02:26<11:35,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4264/4671 [2:02:27<11:35,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4265/4671 [2:02:27<11:36,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4265/4671 [2:02:29<11:36,  1.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4266/4671 [2:02:29<11:34,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4266/4671 [2:02:31<11:34,  1.71s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4267/4671 [2:02:31<11:25,  1.70s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4267/4671 [2:02:32<11:25,  1.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4268/4671 [2:02:32<11:28,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4268/4671 [2:02:34<11:28,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4269/4671 [2:02:34<11:28,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4269/4671 [2:02:36<11:28,  1.71s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4270/4671 [2:02:36<11:24,  1.71s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4270/4671 [2:02:38<11:24,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4271/4671 [2:02:38<11:29,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4271/4671 [2:02:39<11:29,  1.72s/it, training_loss=0.197]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4272/4671 [2:02:39<11:27,  1.72s/it, training_loss=0.197]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4272/4671 [2:02:41<11:27,  1.72s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4273/4671 [2:02:41<11:22,  1.72s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 4273/4671 [2:02:43<11:22,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4274/4671 [2:02:43<11:21,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4274/4671 [2:02:44<11:21,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4275/4671 [2:02:44<11:23,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4275/4671 [2:02:46<11:23,  1.73s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4276/4671 [2:02:46<11:19,  1.72s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4276/4671 [2:02:48<11:19,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4277/4671 [2:02:48<11:09,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4277/4671 [2:02:50<11:09,  1.70s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4278/4671 [2:02:50<11:12,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4278/4671 [2:02:51<11:12,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4279/4671 [2:02:51<11:13,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4279/4671 [2:02:53<11:13,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4280/4671 [2:02:53<11:11,  1.72s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4280/4671 [2:02:55<11:11,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4281/4671 [2:02:55<11:10,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4281/4671 [2:02:56<11:10,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4282/4671 [2:02:56<11:07,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4282/4671 [2:02:58<11:07,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4283/4671 [2:02:58<11:05,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4283/4671 [2:03:00<11:05,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4284/4671 [2:03:00<11:09,  1.73s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4284/4671 [2:03:02<11:09,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4285/4671 [2:03:02<11:04,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4285/4671 [2:03:03<11:04,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4286/4671 [2:03:03<11:04,  1.73s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4286/4671 [2:03:05<11:04,  1.73s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4287/4671 [2:03:05<11:00,  1.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4287/4671 [2:03:07<11:00,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4288/4671 [2:03:07<10:55,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4288/4671 [2:03:08<10:55,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4289/4671 [2:03:08<10:55,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4289/4671 [2:03:10<10:55,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4290/4671 [2:03:10<10:55,  1.72s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4290/4671 [2:03:12<10:55,  1.72s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4291/4671 [2:03:12<10:48,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4291/4671 [2:03:14<10:48,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4292/4671 [2:03:14<10:47,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4292/4671 [2:03:15<10:47,  1.71s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4293/4671 [2:03:15<10:44,  1.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4293/4671 [2:03:17<10:44,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4294/4671 [2:03:17<10:46,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4294/4671 [2:03:19<10:46,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4295/4671 [2:03:19<10:50,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4295/4671 [2:03:20<10:50,  1.73s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4296/4671 [2:03:20<10:48,  1.73s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4296/4671 [2:03:22<10:48,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4297/4671 [2:03:22<10:44,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4297/4671 [2:03:24<10:44,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4298/4671 [2:03:24<10:41,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4298/4671 [2:03:26<10:41,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4299/4671 [2:03:26<10:41,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4299/4671 [2:03:27<10:41,  1.72s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4300/4671 [2:03:27<10:36,  1.72s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4300/4671 [2:03:29<10:36,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4301/4671 [2:03:29<10:37,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4301/4671 [2:03:31<10:37,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4302/4671 [2:03:31<10:31,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4302/4671 [2:03:32<10:31,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4303/4671 [2:03:32<10:25,  1.70s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4303/4671 [2:03:34<10:25,  1.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4304/4671 [2:03:34<10:26,  1.71s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4304/4671 [2:03:36<10:26,  1.71s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4305/4671 [2:03:36<10:17,  1.69s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4305/4671 [2:03:38<10:17,  1.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4306/4671 [2:03:38<10:20,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4306/4671 [2:03:39<10:20,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4307/4671 [2:03:39<10:19,  1.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4307/4671 [2:03:41<10:19,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4308/4671 [2:03:41<10:15,  1.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4308/4671 [2:03:43<10:15,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4309/4671 [2:03:43<10:17,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4309/4671 [2:03:44<10:17,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4310/4671 [2:03:44<10:23,  1.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4310/4671 [2:03:46<10:23,  1.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4311/4671 [2:03:46<10:19,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4311/4671 [2:03:48<10:19,  1.72s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4312/4671 [2:03:48<10:11,  1.70s/it, training_loss=0.187]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4312/4671 [2:03:49<10:11,  1.70s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4313/4671 [2:03:50<10:10,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4313/4671 [2:03:51<10:10,  1.71s/it, training_loss=0.190]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4314/4671 [2:03:51<10:09,  1.71s/it, training_loss=0.190]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4314/4671 [2:03:53<10:09,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4315/4671 [2:03:53<10:00,  1.69s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4315/4671 [2:03:55<10:00,  1.69s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4316/4671 [2:03:55<10:00,  1.69s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4316/4671 [2:03:56<10:00,  1.69s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4317/4671 [2:03:56<09:58,  1.69s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4317/4671 [2:03:58<09:58,  1.69s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4318/4671 [2:03:58<10:00,  1.70s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4318/4671 [2:04:00<10:00,  1.70s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4319/4671 [2:04:00<10:01,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4319/4671 [2:04:01<10:01,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4320/4671 [2:04:01<09:58,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 4320/4671 [2:04:03<09:58,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4321/4671 [2:04:03<10:00,  1.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4321/4671 [2:04:05<10:00,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4322/4671 [2:04:05<09:57,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4322/4671 [2:04:07<09:57,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4323/4671 [2:04:07<09:58,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4323/4671 [2:04:08<09:58,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4324/4671 [2:04:08<09:55,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4324/4671 [2:04:10<09:55,  1.72s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4325/4671 [2:04:10<09:54,  1.72s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4325/4671 [2:04:12<09:54,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4326/4671 [2:04:12<09:52,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4326/4671 [2:04:13<09:52,  1.72s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4327/4671 [2:04:13<09:46,  1.70s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4327/4671 [2:04:15<09:46,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4328/4671 [2:04:15<09:46,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4328/4671 [2:04:17<09:46,  1.71s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4329/4671 [2:04:17<09:38,  1.69s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4329/4671 [2:04:19<09:38,  1.69s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4330/4671 [2:04:19<09:42,  1.71s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4330/4671 [2:04:20<09:42,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4331/4671 [2:04:20<09:37,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4331/4671 [2:04:22<09:37,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4332/4671 [2:04:22<09:34,  1.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4332/4671 [2:04:24<09:34,  1.69s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4333/4671 [2:04:24<09:37,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4333/4671 [2:04:25<09:37,  1.71s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4334/4671 [2:04:25<09:37,  1.71s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4334/4671 [2:04:27<09:37,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4335/4671 [2:04:27<09:31,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4335/4671 [2:04:29<09:31,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4336/4671 [2:04:29<09:28,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4336/4671 [2:04:31<09:28,  1.70s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4337/4671 [2:04:31<09:37,  1.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4337/4671 [2:04:32<09:37,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4338/4671 [2:04:32<09:49,  1.77s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4338/4671 [2:04:34<09:49,  1.77s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4339/4671 [2:04:34<09:50,  1.78s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4339/4671 [2:04:36<09:50,  1.78s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4340/4671 [2:04:36<09:51,  1.79s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4340/4671 [2:04:38<09:51,  1.79s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4341/4671 [2:04:38<09:46,  1.78s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4341/4671 [2:04:39<09:46,  1.78s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4342/4671 [2:04:39<09:38,  1.76s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4342/4671 [2:04:41<09:38,  1.76s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4343/4671 [2:04:41<09:31,  1.74s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4343/4671 [2:04:43<09:31,  1.74s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4344/4671 [2:04:43<09:24,  1.73s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4344/4671 [2:04:45<09:24,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4345/4671 [2:04:45<09:22,  1.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4345/4671 [2:04:46<09:22,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4346/4671 [2:04:46<09:21,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4346/4671 [2:04:48<09:21,  1.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4347/4671 [2:04:48<09:18,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4347/4671 [2:04:50<09:18,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4348/4671 [2:04:50<09:17,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4348/4671 [2:04:51<09:17,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4349/4671 [2:04:51<09:14,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4349/4671 [2:04:53<09:14,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4350/4671 [2:04:53<09:13,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4350/4671 [2:04:55<09:13,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4351/4671 [2:04:55<09:14,  1.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4351/4671 [2:04:57<09:14,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4352/4671 [2:04:57<09:08,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4352/4671 [2:04:58<09:08,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4353/4671 [2:04:58<09:05,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4353/4671 [2:05:00<09:05,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4354/4671 [2:05:00<09:00,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4354/4671 [2:05:02<09:00,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4355/4671 [2:05:02<08:57,  1.70s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4355/4671 [2:05:03<08:57,  1.70s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4356/4671 [2:05:03<08:59,  1.71s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4356/4671 [2:05:05<08:59,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4357/4671 [2:05:05<08:57,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4357/4671 [2:05:07<08:57,  1.71s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4358/4671 [2:05:07<08:59,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4358/4671 [2:05:09<08:59,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4359/4671 [2:05:09<08:57,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4359/4671 [2:05:10<08:57,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4360/4671 [2:05:10<08:57,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4360/4671 [2:05:12<08:57,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4361/4671 [2:05:12<08:56,  1.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4361/4671 [2:05:14<08:56,  1.73s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4362/4671 [2:05:14<08:54,  1.73s/it, training_loss=0.087]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4362/4671 [2:05:16<08:54,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4363/4671 [2:05:16<08:53,  1.73s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4363/4671 [2:05:17<08:53,  1.73s/it, training_loss=0.077]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4364/4671 [2:05:17<08:49,  1.72s/it, training_loss=0.077]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4364/4671 [2:05:19<08:49,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4365/4671 [2:05:19<08:50,  1.73s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4365/4671 [2:05:21<08:50,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4366/4671 [2:05:21<08:45,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4366/4671 [2:05:22<08:45,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4367/4671 [2:05:22<08:45,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 4367/4671 [2:05:24<08:45,  1.73s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4368/4671 [2:05:24<08:47,  1.74s/it, training_loss=0.186]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4368/4671 [2:05:26<08:47,  1.74s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4369/4671 [2:05:26<08:41,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4369/4671 [2:05:28<08:41,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4370/4671 [2:05:28<08:40,  1.73s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4370/4671 [2:05:29<08:40,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4371/4671 [2:05:29<08:34,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4371/4671 [2:05:31<08:34,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4372/4671 [2:05:31<08:38,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4372/4671 [2:05:33<08:38,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4373/4671 [2:05:33<08:38,  1.74s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4373/4671 [2:05:35<08:38,  1.74s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4374/4671 [2:05:35<08:42,  1.76s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4374/4671 [2:05:36<08:42,  1.76s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4375/4671 [2:05:36<08:36,  1.75s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4375/4671 [2:05:38<08:36,  1.75s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4376/4671 [2:05:38<08:31,  1.73s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4376/4671 [2:05:40<08:31,  1.73s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4377/4671 [2:05:40<08:32,  1.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4377/4671 [2:05:42<08:32,  1.74s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4378/4671 [2:05:42<08:33,  1.75s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4378/4671 [2:05:43<08:33,  1.75s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4379/4671 [2:05:43<08:30,  1.75s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 4379/4671 [2:05:45<08:30,  1.75s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4380/4671 [2:05:45<08:27,  1.74s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4380/4671 [2:05:47<08:27,  1.74s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4381/4671 [2:05:47<08:27,  1.75s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4381/4671 [2:05:49<08:27,  1.75s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4382/4671 [2:05:49<08:23,  1.74s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4382/4671 [2:05:50<08:23,  1.74s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4383/4671 [2:05:50<08:21,  1.74s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4383/4671 [2:05:52<08:21,  1.74s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4384/4671 [2:05:52<08:25,  1.76s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4384/4671 [2:05:54<08:25,  1.76s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4385/4671 [2:05:54<08:20,  1.75s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4385/4671 [2:05:56<08:20,  1.75s/it, training_loss=0.197]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4386/4671 [2:05:56<08:15,  1.74s/it, training_loss=0.197]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4386/4671 [2:05:57<08:15,  1.74s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4387/4671 [2:05:57<08:17,  1.75s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4387/4671 [2:05:59<08:17,  1.75s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4388/4671 [2:05:59<08:14,  1.75s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4388/4671 [2:06:01<08:14,  1.75s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4389/4671 [2:06:01<08:14,  1.75s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4389/4671 [2:06:03<08:14,  1.75s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4390/4671 [2:06:03<08:15,  1.76s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4390/4671 [2:06:04<08:15,  1.76s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4391/4671 [2:06:04<08:15,  1.77s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4391/4671 [2:06:06<08:15,  1.77s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4392/4671 [2:06:06<08:10,  1.76s/it, training_loss=0.088]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4392/4671 [2:06:08<08:10,  1.76s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4393/4671 [2:06:08<08:08,  1.76s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4393/4671 [2:06:10<08:08,  1.76s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4394/4671 [2:06:10<08:04,  1.75s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4394/4671 [2:06:11<08:04,  1.75s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4395/4671 [2:06:11<08:03,  1.75s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4395/4671 [2:06:13<08:03,  1.75s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4396/4671 [2:06:13<08:01,  1.75s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4396/4671 [2:06:15<08:01,  1.75s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4397/4671 [2:06:15<07:59,  1.75s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4397/4671 [2:06:17<07:59,  1.75s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4398/4671 [2:06:17<08:01,  1.76s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4398/4671 [2:06:18<08:01,  1.76s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4399/4671 [2:06:18<07:58,  1.76s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4399/4671 [2:06:20<07:58,  1.76s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4400/4671 [2:06:20<07:58,  1.76s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4400/4671 [2:06:22<07:58,  1.76s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4401/4671 [2:06:22<07:55,  1.76s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4401/4671 [2:06:24<07:55,  1.76s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4402/4671 [2:06:24<07:54,  1.76s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4402/4671 [2:06:26<07:54,  1.76s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4403/4671 [2:06:26<07:51,  1.76s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4403/4671 [2:06:27<07:51,  1.76s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4404/4671 [2:06:27<07:49,  1.76s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4404/4671 [2:06:29<07:49,  1.76s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4405/4671 [2:06:29<07:47,  1.76s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4405/4671 [2:06:31<07:47,  1.76s/it, training_loss=0.194]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4406/4671 [2:06:31<07:47,  1.76s/it, training_loss=0.194]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4406/4671 [2:06:33<07:47,  1.76s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4407/4671 [2:06:33<07:45,  1.76s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4407/4671 [2:06:34<07:45,  1.76s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4408/4671 [2:06:34<07:42,  1.76s/it, training_loss=0.184]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4408/4671 [2:06:36<07:42,  1.76s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4409/4671 [2:06:36<07:40,  1.76s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4409/4671 [2:06:38<07:40,  1.76s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4410/4671 [2:06:38<07:36,  1.75s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4410/4671 [2:06:40<07:36,  1.75s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4411/4671 [2:06:40<07:33,  1.75s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4411/4671 [2:06:41<07:33,  1.75s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4412/4671 [2:06:41<07:33,  1.75s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4412/4671 [2:06:43<07:33,  1.75s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4413/4671 [2:06:43<07:33,  1.76s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4413/4671 [2:06:45<07:33,  1.76s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4414/4671 [2:06:45<07:31,  1.76s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 4414/4671 [2:06:47<07:31,  1.76s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4415/4671 [2:06:47<07:24,  1.74s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4415/4671 [2:06:48<07:24,  1.74s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4416/4671 [2:06:48<07:25,  1.75s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4416/4671 [2:06:50<07:25,  1.75s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4417/4671 [2:06:50<07:22,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4417/4671 [2:06:52<07:22,  1.74s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4418/4671 [2:06:52<07:21,  1.75s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4418/4671 [2:06:54<07:21,  1.75s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4419/4671 [2:06:54<07:24,  1.76s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4419/4671 [2:06:55<07:24,  1.76s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4420/4671 [2:06:55<07:22,  1.76s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4420/4671 [2:06:57<07:22,  1.76s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4421/4671 [2:06:57<07:20,  1.76s/it, training_loss=0.091]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4421/4671 [2:06:59<07:20,  1.76s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4422/4671 [2:06:59<07:16,  1.75s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4422/4671 [2:07:01<07:16,  1.75s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4423/4671 [2:07:01<07:14,  1.75s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4423/4671 [2:07:02<07:14,  1.75s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4424/4671 [2:07:02<07:08,  1.74s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4424/4671 [2:07:04<07:08,  1.74s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4425/4671 [2:07:04<07:06,  1.73s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4425/4671 [2:07:07<07:06,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4426/4671 [2:07:07<08:18,  2.03s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4426/4671 [2:07:09<08:18,  2.03s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4427/4671 [2:07:09<08:01,  1.97s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4427/4671 [2:07:10<08:01,  1.97s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4428/4671 [2:07:10<07:45,  1.92s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4428/4671 [2:07:12<07:45,  1.92s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4429/4671 [2:07:12<07:32,  1.87s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4429/4671 [2:07:14<07:32,  1.87s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4430/4671 [2:07:14<07:20,  1.83s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4430/4671 [2:07:16<07:20,  1.83s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4431/4671 [2:07:16<07:09,  1.79s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4431/4671 [2:07:17<07:09,  1.79s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4432/4671 [2:07:17<07:02,  1.77s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4432/4671 [2:07:19<07:02,  1.77s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4433/4671 [2:07:19<06:56,  1.75s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4433/4671 [2:07:21<06:56,  1.75s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4434/4671 [2:07:21<06:53,  1.75s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4434/4671 [2:07:22<06:53,  1.75s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4435/4671 [2:07:22<06:47,  1.73s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4435/4671 [2:07:24<06:47,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4436/4671 [2:07:24<06:45,  1.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4436/4671 [2:07:26<06:45,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4437/4671 [2:07:26<06:43,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 4437/4671 [2:07:28<06:43,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4438/4671 [2:07:28<06:41,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4438/4671 [2:07:29<06:41,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4439/4671 [2:07:29<06:38,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4439/4671 [2:07:31<06:38,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4440/4671 [2:07:31<06:38,  1.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4440/4671 [2:07:33<06:38,  1.72s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4441/4671 [2:07:33<06:36,  1.72s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4441/4671 [2:07:34<06:36,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4442/4671 [2:07:34<06:33,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4442/4671 [2:07:36<06:33,  1.72s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4443/4671 [2:07:36<06:33,  1.73s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4443/4671 [2:07:38<06:33,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4444/4671 [2:07:38<06:32,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4444/4671 [2:07:40<06:32,  1.73s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4445/4671 [2:07:40<06:34,  1.74s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4445/4671 [2:07:41<06:34,  1.74s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4446/4671 [2:07:41<06:31,  1.74s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4446/4671 [2:07:43<06:31,  1.74s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4447/4671 [2:07:43<06:29,  1.74s/it, training_loss=0.081]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4447/4671 [2:07:45<06:29,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4448/4671 [2:07:45<06:23,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4448/4671 [2:07:47<06:23,  1.72s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4449/4671 [2:07:47<06:21,  1.72s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4449/4671 [2:07:48<06:21,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4450/4671 [2:07:48<06:18,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4450/4671 [2:07:50<06:18,  1.71s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4451/4671 [2:07:50<06:15,  1.71s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4451/4671 [2:07:52<06:15,  1.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4452/4671 [2:07:52<06:10,  1.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4452/4671 [2:07:53<06:10,  1.69s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4453/4671 [2:07:53<06:14,  1.72s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4453/4671 [2:07:55<06:14,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4454/4671 [2:07:55<06:14,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4454/4671 [2:07:57<06:14,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4455/4671 [2:07:57<06:09,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4455/4671 [2:07:58<06:09,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4456/4671 [2:07:58<06:05,  1.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4456/4671 [2:08:00<06:05,  1.70s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4457/4671 [2:08:00<06:04,  1.70s/it, training_loss=0.107]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4457/4671 [2:08:02<06:04,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4458/4671 [2:08:02<06:02,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4458/4671 [2:08:04<06:02,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4459/4671 [2:08:04<05:59,  1.69s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4459/4671 [2:08:05<05:59,  1.69s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4460/4671 [2:08:05<05:57,  1.69s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 4460/4671 [2:08:07<05:57,  1.69s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4461/4671 [2:08:07<05:59,  1.71s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4461/4671 [2:08:09<05:59,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4462/4671 [2:08:09<05:56,  1.71s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4462/4671 [2:08:10<05:56,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4463/4671 [2:08:10<05:56,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4463/4671 [2:08:12<05:56,  1.71s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4464/4671 [2:08:12<05:52,  1.70s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4464/4671 [2:08:14<05:52,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4465/4671 [2:08:14<05:50,  1.70s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4465/4671 [2:08:15<05:50,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4466/4671 [2:08:15<05:45,  1.69s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4466/4671 [2:08:17<05:45,  1.69s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4467/4671 [2:08:17<05:47,  1.70s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4467/4671 [2:08:19<05:47,  1.70s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4468/4671 [2:08:19<05:44,  1.70s/it, training_loss=0.084]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4468/4671 [2:08:21<05:44,  1.70s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4469/4671 [2:08:21<05:44,  1.70s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4469/4671 [2:08:22<05:44,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4470/4671 [2:08:22<05:40,  1.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4470/4671 [2:08:24<05:40,  1.70s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4471/4671 [2:08:24<05:42,  1.71s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4471/4671 [2:08:26<05:42,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4472/4671 [2:08:26<05:38,  1.70s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4472/4671 [2:08:27<05:38,  1.70s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4473/4671 [2:08:27<05:39,  1.71s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4473/4671 [2:08:29<05:39,  1.71s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4474/4671 [2:08:29<05:38,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4474/4671 [2:08:31<05:38,  1.72s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4475/4671 [2:08:31<05:38,  1.72s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4475/4671 [2:08:33<05:38,  1.72s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4476/4671 [2:08:33<05:35,  1.72s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4476/4671 [2:08:34<05:35,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4477/4671 [2:08:34<05:31,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4477/4671 [2:08:36<05:31,  1.71s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4478/4671 [2:08:36<05:30,  1.71s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4478/4671 [2:08:38<05:30,  1.71s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4479/4671 [2:08:38<05:29,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4479/4671 [2:08:39<05:29,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4480/4671 [2:08:39<05:24,  1.70s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4480/4671 [2:08:41<05:24,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4481/4671 [2:08:41<05:23,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4481/4671 [2:08:43<05:23,  1.70s/it, training_loss=0.069]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4482/4671 [2:08:43<05:22,  1.70s/it, training_loss=0.069]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4482/4671 [2:08:45<05:22,  1.70s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4483/4671 [2:08:45<05:19,  1.70s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4483/4671 [2:08:46<05:19,  1.70s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4484/4671 [2:08:46<05:18,  1.70s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4484/4671 [2:08:48<05:18,  1.70s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4485/4671 [2:08:48<05:17,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4485/4671 [2:08:50<05:17,  1.71s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4486/4671 [2:08:50<05:16,  1.71s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4486/4671 [2:08:51<05:16,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4487/4671 [2:08:51<05:14,  1.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4487/4671 [2:08:53<05:14,  1.71s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4488/4671 [2:08:53<05:12,  1.71s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4488/4671 [2:08:55<05:12,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4489/4671 [2:08:55<05:11,  1.71s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4489/4671 [2:08:56<05:11,  1.71s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4490/4671 [2:08:56<05:08,  1.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4490/4671 [2:08:58<05:08,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4491/4671 [2:08:58<05:06,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4491/4671 [2:09:00<05:06,  1.71s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4492/4671 [2:09:00<05:05,  1.71s/it, training_loss=0.096]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4492/4671 [2:09:02<05:05,  1.71s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4493/4671 [2:09:02<05:04,  1.71s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4493/4671 [2:09:03<05:04,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4494/4671 [2:09:03<05:02,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4494/4671 [2:09:05<05:02,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4495/4671 [2:09:05<05:00,  1.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 4495/4671 [2:09:07<05:00,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4496/4671 [2:09:07<04:58,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4496/4671 [2:09:08<04:58,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4497/4671 [2:09:08<04:56,  1.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4497/4671 [2:09:10<04:56,  1.70s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4498/4671 [2:09:10<04:55,  1.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4498/4671 [2:09:12<04:55,  1.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4499/4671 [2:09:12<04:53,  1.70s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4499/4671 [2:09:14<04:53,  1.70s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4500/4671 [2:09:14<04:52,  1.71s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4500/4671 [2:09:15<04:52,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4501/4671 [2:09:15<04:51,  1.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4501/4671 [2:09:17<04:51,  1.71s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4502/4671 [2:09:17<04:48,  1.71s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4502/4671 [2:09:19<04:48,  1.71s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4503/4671 [2:09:19<04:46,  1.70s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4503/4671 [2:09:20<04:46,  1.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4504/4671 [2:09:20<04:46,  1.72s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4504/4671 [2:09:22<04:46,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4505/4671 [2:09:22<04:43,  1.71s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4505/4671 [2:09:24<04:43,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4506/4671 [2:09:24<04:42,  1.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4506/4671 [2:09:26<04:42,  1.71s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4507/4671 [2:09:26<04:40,  1.71s/it, training_loss=0.097]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 4507/4671 [2:09:27<04:40,  1.71s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4508/4671 [2:09:27<04:37,  1.70s/it, training_loss=0.100]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4508/4671 [2:09:29<04:37,  1.70s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4509/4671 [2:09:29<04:34,  1.70s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4509/4671 [2:09:31<04:34,  1.70s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4510/4671 [2:09:31<04:34,  1.71s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4510/4671 [2:09:32<04:34,  1.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4511/4671 [2:09:32<04:34,  1.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4511/4671 [2:09:34<04:34,  1.72s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4512/4671 [2:09:34<04:34,  1.72s/it, training_loss=0.166]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4512/4671 [2:09:36<04:34,  1.72s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4513/4671 [2:09:36<04:31,  1.72s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4513/4671 [2:09:38<04:31,  1.72s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4514/4671 [2:09:38<04:28,  1.71s/it, training_loss=0.160]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4514/4671 [2:09:39<04:28,  1.71s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4515/4671 [2:09:39<04:24,  1.70s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4515/4671 [2:09:41<04:24,  1.70s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4516/4671 [2:09:41<04:22,  1.69s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4516/4671 [2:09:43<04:22,  1.69s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4517/4671 [2:09:43<04:24,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4517/4671 [2:09:44<04:24,  1.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4518/4671 [2:09:44<04:22,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4518/4671 [2:09:46<04:22,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4519/4671 [2:09:46<04:19,  1.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4519/4671 [2:09:48<04:19,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4520/4671 [2:09:48<04:19,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4520/4671 [2:09:50<04:19,  1.72s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4521/4671 [2:09:50<04:18,  1.73s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4521/4671 [2:09:51<04:18,  1.73s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4522/4671 [2:09:51<04:14,  1.71s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4522/4671 [2:09:53<04:14,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4523/4671 [2:09:53<04:12,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4523/4671 [2:09:55<04:12,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4524/4671 [2:09:55<04:10,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4524/4671 [2:09:56<04:10,  1.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4525/4671 [2:09:56<04:09,  1.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4525/4671 [2:09:58<04:09,  1.71s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4526/4671 [2:09:58<04:09,  1.72s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4526/4671 [2:10:00<04:09,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4527/4671 [2:10:00<04:04,  1.70s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4527/4671 [2:10:01<04:04,  1.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4528/4671 [2:10:01<04:02,  1.69s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4528/4671 [2:10:03<04:02,  1.69s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4529/4671 [2:10:03<03:59,  1.69s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4529/4671 [2:10:05<03:59,  1.69s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4530/4671 [2:10:05<03:59,  1.70s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4530/4671 [2:10:07<03:59,  1.70s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4531/4671 [2:10:07<03:58,  1.70s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4531/4671 [2:10:08<03:58,  1.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4532/4671 [2:10:08<03:59,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4532/4671 [2:10:10<03:59,  1.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4533/4671 [2:10:10<03:56,  1.71s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4533/4671 [2:10:12<03:56,  1.71s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4534/4671 [2:10:12<03:55,  1.72s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4534/4671 [2:10:13<03:55,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4535/4671 [2:10:13<03:54,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4535/4671 [2:10:15<03:54,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4536/4671 [2:10:15<03:51,  1.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4536/4671 [2:10:17<03:51,  1.72s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4537/4671 [2:10:17<03:51,  1.73s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4537/4671 [2:10:19<03:51,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4538/4671 [2:10:19<03:51,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4538/4671 [2:10:20<03:51,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4539/4671 [2:10:20<03:48,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4539/4671 [2:10:22<03:48,  1.73s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4540/4671 [2:10:22<03:46,  1.73s/it, training_loss=0.099]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4540/4671 [2:10:24<03:46,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4541/4671 [2:10:24<03:46,  1.75s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4541/4671 [2:10:26<03:46,  1.75s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4542/4671 [2:10:26<03:44,  1.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4542/4671 [2:10:27<03:44,  1.74s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4543/4671 [2:10:27<03:42,  1.74s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4543/4671 [2:10:29<03:42,  1.74s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4544/4671 [2:10:29<03:40,  1.74s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4544/4671 [2:10:31<03:40,  1.74s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4545/4671 [2:10:31<03:37,  1.73s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4545/4671 [2:10:33<03:37,  1.73s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4546/4671 [2:10:33<03:36,  1.74s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4546/4671 [2:10:34<03:36,  1.74s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4547/4671 [2:10:34<03:35,  1.74s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4547/4671 [2:10:36<03:35,  1.74s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4548/4671 [2:10:36<03:32,  1.73s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4548/4671 [2:10:38<03:32,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4549/4671 [2:10:38<03:30,  1.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4549/4671 [2:10:39<03:30,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4550/4671 [2:10:39<03:29,  1.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4550/4671 [2:10:41<03:29,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4551/4671 [2:10:41<03:28,  1.74s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4551/4671 [2:10:43<03:28,  1.74s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4552/4671 [2:10:43<03:27,  1.74s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4552/4671 [2:10:45<03:27,  1.74s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4553/4671 [2:10:45<03:23,  1.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4553/4671 [2:10:46<03:23,  1.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4554/4671 [2:10:46<03:20,  1.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 4554/4671 [2:10:48<03:20,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4555/4671 [2:10:48<03:18,  1.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4555/4671 [2:10:50<03:18,  1.71s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4556/4671 [2:10:50<03:17,  1.72s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4556/4671 [2:10:52<03:17,  1.72s/it, training_loss=0.076]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4557/4671 [2:10:52<03:16,  1.72s/it, training_loss=0.076]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4557/4671 [2:10:53<03:16,  1.72s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4558/4671 [2:10:53<03:13,  1.71s/it, training_loss=0.086]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4558/4671 [2:10:55<03:13,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4559/4671 [2:10:55<03:12,  1.72s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4559/4671 [2:10:57<03:12,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4560/4671 [2:10:57<03:10,  1.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4560/4671 [2:10:58<03:10,  1.72s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4561/4671 [2:10:58<03:10,  1.73s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4561/4671 [2:11:00<03:10,  1.73s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4562/4671 [2:11:00<03:09,  1.73s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4562/4671 [2:11:02<03:09,  1.73s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4563/4671 [2:11:02<03:05,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4563/4671 [2:11:04<03:05,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4564/4671 [2:11:04<03:04,  1.73s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4564/4671 [2:11:05<03:04,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4565/4671 [2:11:05<03:04,  1.74s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4565/4671 [2:11:07<03:04,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4566/4671 [2:11:07<03:04,  1.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4566/4671 [2:11:09<03:04,  1.75s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4567/4671 [2:11:09<03:02,  1.76s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4567/4671 [2:11:11<03:02,  1.76s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4568/4671 [2:11:11<03:01,  1.76s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4568/4671 [2:11:12<03:01,  1.76s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4569/4671 [2:11:12<03:00,  1.77s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4569/4671 [2:11:14<03:00,  1.77s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4570/4671 [2:11:14<02:58,  1.77s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4570/4671 [2:11:16<02:58,  1.77s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4571/4671 [2:11:16<02:56,  1.76s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4571/4671 [2:11:18<02:56,  1.76s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4572/4671 [2:11:18<02:54,  1.76s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4572/4671 [2:11:19<02:54,  1.76s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4573/4671 [2:11:19<02:52,  1.76s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4573/4671 [2:11:21<02:52,  1.76s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4574/4671 [2:11:21<02:50,  1.75s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4574/4671 [2:11:23<02:50,  1.75s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4575/4671 [2:11:23<02:47,  1.75s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4575/4671 [2:11:25<02:47,  1.75s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4576/4671 [2:11:25<02:45,  1.75s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4576/4671 [2:11:27<02:45,  1.75s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4577/4671 [2:11:27<02:45,  1.76s/it, training_loss=0.103]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4577/4671 [2:11:28<02:45,  1.76s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4578/4671 [2:11:28<02:42,  1.75s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4578/4671 [2:11:30<02:42,  1.75s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4579/4671 [2:11:30<02:39,  1.74s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4579/4671 [2:11:32<02:39,  1.74s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4580/4671 [2:11:32<02:38,  1.74s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4580/4671 [2:11:33<02:38,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4581/4671 [2:11:33<02:36,  1.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4581/4671 [2:11:35<02:36,  1.74s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4582/4671 [2:11:35<02:34,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4582/4671 [2:11:37<02:34,  1.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4583/4671 [2:11:37<02:34,  1.75s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4583/4671 [2:11:39<02:34,  1.75s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4584/4671 [2:11:39<02:32,  1.75s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4584/4671 [2:11:40<02:32,  1.75s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4585/4671 [2:11:40<02:31,  1.76s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4585/4671 [2:11:42<02:31,  1.76s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4586/4671 [2:11:42<02:29,  1.75s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4586/4671 [2:11:44<02:29,  1.75s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4587/4671 [2:11:44<02:27,  1.75s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4587/4671 [2:11:46<02:27,  1.75s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4588/4671 [2:11:46<02:25,  1.76s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4588/4671 [2:11:47<02:25,  1.76s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4589/4671 [2:11:47<02:24,  1.76s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4589/4671 [2:11:49<02:24,  1.76s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4590/4671 [2:11:49<02:22,  1.76s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4590/4671 [2:11:51<02:22,  1.76s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4591/4671 [2:11:51<02:20,  1.76s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4591/4671 [2:11:53<02:20,  1.76s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4592/4671 [2:11:53<02:18,  1.76s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4592/4671 [2:11:54<02:18,  1.76s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4593/4671 [2:11:54<02:16,  1.75s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4593/4671 [2:11:56<02:16,  1.75s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4594/4671 [2:11:56<02:14,  1.74s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4594/4671 [2:11:58<02:14,  1.74s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4595/4671 [2:11:58<02:11,  1.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4595/4671 [2:12:00<02:11,  1.73s/it, training_loss=0.185]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4596/4671 [2:12:00<02:09,  1.73s/it, training_loss=0.185]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4596/4671 [2:12:01<02:09,  1.73s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4597/4671 [2:12:01<02:08,  1.74s/it, training_loss=0.105]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4597/4671 [2:12:03<02:08,  1.74s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4598/4671 [2:12:03<02:07,  1.74s/it, training_loss=0.093]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4598/4671 [2:12:05<02:07,  1.74s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4599/4671 [2:12:05<02:05,  1.74s/it, training_loss=0.094]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4599/4671 [2:12:07<02:05,  1.74s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4600/4671 [2:12:07<02:02,  1.73s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 4600/4671 [2:12:08<02:02,  1.73s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4601/4671 [2:12:08<02:00,  1.72s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4601/4671 [2:12:10<02:00,  1.72s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4602/4671 [2:12:10<01:58,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4602/4671 [2:12:12<01:58,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4603/4671 [2:12:12<01:56,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4603/4671 [2:12:13<01:56,  1.72s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4604/4671 [2:12:13<01:54,  1.71s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4604/4671 [2:12:15<01:54,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4605/4671 [2:12:15<01:53,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4605/4671 [2:12:17<01:53,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4606/4671 [2:12:17<01:52,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4606/4671 [2:12:19<01:52,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4607/4671 [2:12:19<01:49,  1.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4607/4671 [2:12:20<01:49,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4608/4671 [2:12:20<01:48,  1.72s/it, training_loss=0.156]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4608/4671 [2:12:22<01:48,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4609/4671 [2:12:22<01:46,  1.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4609/4671 [2:12:24<01:46,  1.72s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4610/4671 [2:12:24<01:43,  1.70s/it, training_loss=0.176]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4610/4671 [2:12:25<01:43,  1.70s/it, training_loss=0.079]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4611/4671 [2:12:25<01:43,  1.72s/it, training_loss=0.079]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4611/4671 [2:12:27<01:43,  1.72s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4612/4671 [2:12:27<01:41,  1.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 4612/4671 [2:12:29<01:41,  1.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4613/4671 [2:12:29<01:39,  1.72s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4613/4671 [2:12:31<01:39,  1.72s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4614/4671 [2:12:31<01:37,  1.71s/it, training_loss=0.104]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4614/4671 [2:12:32<01:37,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4615/4671 [2:12:32<01:36,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4615/4671 [2:12:34<01:36,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4616/4671 [2:12:34<01:34,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4616/4671 [2:12:36<01:34,  1.72s/it, training_loss=0.214]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4617/4671 [2:12:36<01:33,  1.73s/it, training_loss=0.214]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4617/4671 [2:12:37<01:33,  1.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4618/4671 [2:12:37<01:30,  1.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4618/4671 [2:12:39<01:30,  1.72s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4619/4671 [2:12:39<01:29,  1.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4619/4671 [2:12:41<01:29,  1.71s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4620/4671 [2:12:41<01:27,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4620/4671 [2:12:43<01:27,  1.72s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4621/4671 [2:12:43<01:25,  1.72s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4621/4671 [2:12:44<01:25,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4622/4671 [2:12:44<01:24,  1.72s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4622/4671 [2:12:46<01:24,  1.72s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4623/4671 [2:12:46<01:21,  1.71s/it, training_loss=0.108]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4623/4671 [2:12:48<01:21,  1.71s/it, training_loss=0.195]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4624/4671 [2:12:48<01:20,  1.71s/it, training_loss=0.195]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4624/4671 [2:12:49<01:20,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4625/4671 [2:12:49<01:18,  1.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4625/4671 [2:12:51<01:18,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4626/4671 [2:12:51<01:16,  1.70s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4626/4671 [2:12:53<01:16,  1.70s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4627/4671 [2:12:53<01:15,  1.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4627/4671 [2:12:55<01:15,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4628/4671 [2:12:55<01:14,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4628/4671 [2:12:56<01:14,  1.73s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4629/4671 [2:12:56<01:12,  1.73s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4629/4671 [2:12:58<01:12,  1.73s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4630/4671 [2:12:58<01:11,  1.74s/it, training_loss=0.092]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4630/4671 [2:13:00<01:11,  1.74s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4631/4671 [2:13:00<01:09,  1.74s/it, training_loss=0.085]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4631/4671 [2:13:02<01:09,  1.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4632/4671 [2:13:02<01:07,  1.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4632/4671 [2:13:03<01:07,  1.73s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4633/4671 [2:13:03<01:05,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4633/4671 [2:13:05<01:05,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4634/4671 [2:13:05<01:03,  1.71s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4634/4671 [2:13:07<01:03,  1.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4635/4671 [2:13:07<01:02,  1.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4635/4671 [2:13:08<01:02,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4636/4671 [2:13:08<01:00,  1.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4636/4671 [2:13:10<01:00,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4637/4671 [2:13:10<00:58,  1.72s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4637/4671 [2:13:12<00:58,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4638/4671 [2:13:12<00:56,  1.72s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4638/4671 [2:13:14<00:56,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4639/4671 [2:13:14<00:54,  1.72s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4639/4671 [2:13:15<00:54,  1.72s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4640/4671 [2:13:15<00:53,  1.71s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4640/4671 [2:13:17<00:53,  1.71s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4641/4671 [2:13:17<00:51,  1.72s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4641/4671 [2:13:19<00:51,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4642/4671 [2:13:19<00:49,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4642/4671 [2:13:20<00:49,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4643/4671 [2:13:20<00:47,  1.70s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4643/4671 [2:13:22<00:47,  1.70s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4644/4671 [2:13:22<00:46,  1.71s/it, training_loss=0.102]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4644/4671 [2:13:24<00:46,  1.71s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4645/4671 [2:13:24<00:44,  1.73s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4645/4671 [2:13:26<00:44,  1.73s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4646/4671 [2:13:26<00:43,  1.73s/it, training_loss=0.089]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4646/4671 [2:13:27<00:43,  1.73s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4647/4671 [2:13:27<00:41,  1.74s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 4647/4671 [2:13:29<00:41,  1.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4648/4671 [2:13:29<00:39,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4648/4671 [2:13:31<00:39,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4649/4671 [2:13:31<00:37,  1.73s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4649/4671 [2:13:33<00:37,  1.73s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4650/4671 [2:13:33<00:36,  1.73s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4650/4671 [2:13:34<00:36,  1.73s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4651/4671 [2:13:34<00:34,  1.75s/it, training_loss=0.172]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4651/4671 [2:13:36<00:34,  1.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4652/4671 [2:13:36<00:33,  1.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4652/4671 [2:13:38<00:33,  1.75s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4653/4671 [2:13:38<00:31,  1.74s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4653/4671 [2:13:40<00:31,  1.74s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4654/4671 [2:13:40<00:29,  1.73s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4654/4671 [2:13:41<00:29,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4655/4671 [2:13:41<00:27,  1.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4655/4671 [2:13:43<00:27,  1.73s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4656/4671 [2:13:43<00:25,  1.73s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4656/4671 [2:13:45<00:25,  1.73s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4657/4671 [2:13:45<00:23,  1.71s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4657/4671 [2:13:46<00:23,  1.71s/it, training_loss=0.210]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4658/4671 [2:13:46<00:22,  1.71s/it, training_loss=0.210]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4658/4671 [2:13:48<00:22,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4659/4671 [2:13:48<00:20,  1.71s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4659/4671 [2:13:50<00:20,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4660/4671 [2:13:50<00:18,  1.71s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4660/4671 [2:13:52<00:18,  1.71s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4661/4671 [2:13:52<00:17,  1.73s/it, training_loss=0.101]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4661/4671 [2:13:53<00:17,  1.73s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4662/4671 [2:13:53<00:15,  1.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4662/4671 [2:13:55<00:15,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4663/4671 [2:13:55<00:13,  1.72s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4663/4671 [2:13:57<00:13,  1.72s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4664/4671 [2:13:57<00:11,  1.71s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4664/4671 [2:13:58<00:11,  1.71s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4665/4671 [2:13:58<00:10,  1.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4665/4671 [2:14:00<00:10,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4666/4671 [2:14:00<00:08,  1.72s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4666/4671 [2:14:02<00:08,  1.72s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4667/4671 [2:14:02<00:06,  1.71s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4667/4671 [2:14:04<00:06,  1.71s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4668/4671 [2:14:04<00:05,  1.72s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4668/4671 [2:14:05<00:05,  1.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4669/4671 [2:14:05<00:03,  1.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4669/4671 [2:14:07<00:03,  1.73s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4670/4671 [2:14:07<00:01,  1.72s/it, training_loss=0.098]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 4670/4671 [2:14:08<00:01,  1.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1: 100%|██████████| 4671/4671 [2:14:08<00:00,  1.45s/it, training_loss=0.126]\u001B[A\n",
      "  0%|          | 0/3 [2:14:08<?, ?it/s]                                            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.39718110597483275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [2:35:33<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 82\u001B[0m\n\u001B[0;32m     79\u001B[0m tqdm\u001B[38;5;241m.\u001B[39mwrite(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss_train_avg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     81\u001B[0m val_loss, predictions, true_vals \u001B[38;5;241m=\u001B[39m evaluate(dataloader_validation)\n\u001B[1;32m---> 82\u001B[0m val_f1 \u001B[38;5;241m=\u001B[39m f1_score_func(predictions, true_vals)\n\u001B[0;32m     83\u001B[0m tqdm\u001B[38;5;241m.\u001B[39mwrite(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mValidation loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_loss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     84\u001B[0m tqdm\u001B[38;5;241m.\u001B[39mwrite(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mF1 Score (Weighted): \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_f1\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[19], line 8\u001B[0m, in \u001B[0;36mf1_score_func\u001B[1;34m(preds, labels)\u001B[0m\n\u001B[0;32m      6\u001B[0m preds_flat \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mround(preds)\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n\u001B[0;32m      7\u001B[0m labels_flat \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f1_score(labels_flat, preds_flat, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweighted\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1293\u001B[0m, in \u001B[0;36mf1_score\u001B[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   1113\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[0;32m   1114\u001B[0m     {\n\u001B[0;32m   1115\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1140\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1141\u001B[0m ):\n\u001B[0;32m   1142\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001B[39;00m\n\u001B[0;32m   1143\u001B[0m \n\u001B[0;32m   1144\u001B[0m \u001B[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1291\u001B[0m \u001B[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001B[39;00m\n\u001B[0;32m   1292\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1293\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fbeta_score(\n\u001B[0;32m   1294\u001B[0m         y_true,\n\u001B[0;32m   1295\u001B[0m         y_pred,\n\u001B[0;32m   1296\u001B[0m         beta\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1297\u001B[0m         labels\u001B[38;5;241m=\u001B[39mlabels,\n\u001B[0;32m   1298\u001B[0m         pos_label\u001B[38;5;241m=\u001B[39mpos_label,\n\u001B[0;32m   1299\u001B[0m         average\u001B[38;5;241m=\u001B[39maverage,\n\u001B[0;32m   1300\u001B[0m         sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[0;32m   1301\u001B[0m         zero_division\u001B[38;5;241m=\u001B[39mzero_division,\n\u001B[0;32m   1302\u001B[0m     )\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    184\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[1;32m--> 186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    188\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[0;32m    190\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1485\u001B[0m, in \u001B[0;36mfbeta_score\u001B[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   1305\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[0;32m   1306\u001B[0m     {\n\u001B[0;32m   1307\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1334\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1335\u001B[0m ):\n\u001B[0;32m   1336\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the F-beta score.\u001B[39;00m\n\u001B[0;32m   1337\u001B[0m \n\u001B[0;32m   1338\u001B[0m \u001B[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1482\u001B[0m \u001B[38;5;124;03m    0.12...\u001B[39;00m\n\u001B[0;32m   1483\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1485\u001B[0m     _, _, f, _ \u001B[38;5;241m=\u001B[39m precision_recall_fscore_support(\n\u001B[0;32m   1486\u001B[0m         y_true,\n\u001B[0;32m   1487\u001B[0m         y_pred,\n\u001B[0;32m   1488\u001B[0m         beta\u001B[38;5;241m=\u001B[39mbeta,\n\u001B[0;32m   1489\u001B[0m         labels\u001B[38;5;241m=\u001B[39mlabels,\n\u001B[0;32m   1490\u001B[0m         pos_label\u001B[38;5;241m=\u001B[39mpos_label,\n\u001B[0;32m   1491\u001B[0m         average\u001B[38;5;241m=\u001B[39maverage,\n\u001B[0;32m   1492\u001B[0m         warn_for\u001B[38;5;241m=\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf-score\u001B[39m\u001B[38;5;124m\"\u001B[39m,),\n\u001B[0;32m   1493\u001B[0m         sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[0;32m   1494\u001B[0m         zero_division\u001B[38;5;241m=\u001B[39mzero_division,\n\u001B[0;32m   1495\u001B[0m     )\n\u001B[0;32m   1496\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    184\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[1;32m--> 186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    188\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[0;32m    190\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1789\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[0;32m   1626\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001B[39;00m\n\u001B[0;32m   1627\u001B[0m \n\u001B[0;32m   1628\u001B[0m \u001B[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1786\u001B[0m \u001B[38;5;124;03m array([2, 2, 2]))\u001B[39;00m\n\u001B[0;32m   1787\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1788\u001B[0m _check_zero_division(zero_division)\n\u001B[1;32m-> 1789\u001B[0m labels \u001B[38;5;241m=\u001B[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001B[0;32m   1791\u001B[0m \u001B[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[0;32m   1792\u001B[0m samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1561\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[1;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m average \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m average_options \u001B[38;5;129;01mand\u001B[39;00m average \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1559\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage has to be one of \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(average_options))\n\u001B[1;32m-> 1561\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m _check_targets(y_true, y_pred)\n\u001B[0;32m   1562\u001B[0m \u001B[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001B[39;00m\n\u001B[0;32m   1563\u001B[0m \u001B[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001B[39;00m\n\u001B[0;32m   1564\u001B[0m present_labels \u001B[38;5;241m=\u001B[39m unique_labels(y_true, y_pred)\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:112\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m    109\u001B[0m     y_type \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_type) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 112\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    113\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification metrics can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt handle a mix of \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m targets\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    114\u001B[0m             type_true, type_pred\n\u001B[0;32m    115\u001B[0m         )\n\u001B[0;32m    116\u001B[0m     )\n\u001B[0;32m    118\u001B[0m \u001B[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001B[39;00m\n\u001B[0;32m    119\u001B[0m y_type \u001B[38;5;241m=\u001B[39m y_type\u001B[38;5;241m.\u001B[39mpop()\n",
      "\u001B[1;31mValueError\u001B[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass-multioutput targets"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2],\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids) \n",
    "\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "for epoch in tqdm(range(1, EPOCHS + 1)):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2],\n",
    "        }\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "\n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "\n",
    "torch.save(model.state_dict(), 'data_volume/finetuned_BERT_final.model')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T10:21:31.917799Z",
     "start_time": "2024-09-03T07:45:57.573740Z"
    }
   },
   "id": "29d5031168643adf",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=9,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "  \n",
    "\n",
    "        \n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('data_volume/finetuned_BERT_epoch_1.model', map_location=torch.device('cpu')))\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "accuracy_per_class(predictions, true_vals)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e47ff3a6c533966"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch['Utterances'], padding=True, truncation=True, max_length=MAX_LEN, return_tensors='pt')\n",
    "#    \n",
    "# def tokenize_fn(batch):\n",
    "#     return tokenizer(batch['Utterances'], padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors='pt')\n",
    "\n",
    "tokenized_dataset = split.map(tokenize_fn, batched=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf4725b4b0c2938a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d0f646dfa3841d6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenized_dataset['train'][0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8e43d3d7ead6d29",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#trainer.train()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afb8fdf882f8a7be",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear = torch.nn.Linear(768, 9) #number of classs\n",
    "\n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids,\n",
    "            attention_mask=attn_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n",
    "\n",
    "# # Freezing BERT layers: (tested, weaker convergence)\n",
    "# for param in model.bert_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83a4aefea952e049",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b83ab6df019c59b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f7e6618581d72a0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training of the model for one epoch\n",
    "def train_model(training_loader, model, optimizer):\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    # set model to training mode (activate droput, batch norm)\n",
    "    model.train()\n",
    "    # initialize the progress bar\n",
    "    loop = tq.tqdm(enumerate(training_loader), total=len(training_loader),\n",
    "                   leave=True, colour='steelblue')\n",
    "    for batch_idx, data in loop:\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(ids, mask, token_type_ids) # (batch,predict)=(32,8)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "        # training accuracy\n",
    "        _, preds = torch.max(outputs, dim=1) # batch dim \n",
    "        _, targ = torch.max(targets, dim=1)  # batch dim\n",
    "        num_samples += len(targ)  # technically adding batch size\n",
    "        correct_predictions += torch.sum(preds == targ)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        # grad descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        #loop.set_description(f\"\")\n",
    "        #loop.set_postfix(batch_loss=loss)\n",
    "\n",
    "    # returning: trained model, model accuracy, mean loss\n",
    "    return model, float(correct_predictions)/num_samples, np.mean(losses)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0b3b0b0de857d67",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def eval_model(validation_loader, model, optimizer):\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    # set model to eval mode (turn off dropout, fix batch norm)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(validation_loader, 0):\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # validation accuracy\n",
    "            _, preds = torch.max(outputs, dim=1) # batch dim \n",
    "            _, targ = torch.max(targets, dim=1)  # batch dim\n",
    "            num_samples += len(targ)  # technically adding batch size\n",
    "            correct_predictions += torch.sum(preds == targ)\n",
    "\n",
    "    return float(correct_predictions)/num_samples, np.mean(losses)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "187cd4131ce94ba1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "be212df01fd54147",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(tokenized_dataset['train'],\n",
    "                                                batch_size=TRAIN_BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0,\n",
    "                                                collate_fn=data_collator\n",
    "                                                )\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(tokenized_dataset['test'],\n",
    "                                              batch_size=VALID_BATCH_SIZE,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=0,\n",
    "                                              collate_fn=data_collator\n",
    "                                              )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae5a736bb41df71b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    model, train_acc, train_loss = train_model(train_data_loader, model, optimizer)\n",
    "    val_acc, val_loss = eval_model(val_data_loader, model, optimizer)\n",
    "\n",
    "    print(f'train_loss={train_loss:.4f}, val_loss={val_loss:.4f} train_acc={train_acc:.4f}, val_acc={val_acc:.4f}')\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    # save the best model\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), os.path.join(data_dir,\"output\",\"best_model_state.bin\"))\n",
    "        best_accuracy = val_acc\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea9c6fdc49bb8be0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3cc86c32beae981"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d78b86e9f9b698e9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "target_list = list(tokenized_dataset.columns)\n",
    "target_list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "120e2360fa4aefab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6949581129d91408"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                batch_size=TRAIN_BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0\n",
    "                                                )\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                              batch_size=VALID_BATCH_SIZE,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=0\n",
    "                                              )\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size=TEST_BATCH_SIZE,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0\n",
    "                                               )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35de033e82340e8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df4088691d16b159",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "12c67e0f261051bc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
