{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Julix\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Julix\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import sys\n",
    "import tqdm.notebook as tq\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from googletrans import Translator\n",
    "from deep_translator import GoogleTranslator\n",
    "import random\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:23.284762Z",
     "start_time": "2024-11-12T20:43:19.421196Z"
    }
   },
   "id": "73bc3114f800d2e3",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('multi_label_binarizer_MEISD.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:23.315330Z",
     "start_time": "2024-11-12T20:43:23.285766Z"
    }
   },
   "id": "ea967bdf16d7aac8",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                        Utterances  sentiment_0  sentiment_1  \\\n0                                  look around you            0            0   \n1                    say hello to your competition            0            0   \n2  eight of you will switch to an easier specialty            0            0   \n3        five of you will crack under the pressure            0            0   \n4                two of you will be asked to leave            0            0   \n\n   sentiment_2  emotion_1  emotion_2  emotion_3  emotion_4  emotion_5  \\\n0            1          1          0          0          0          0   \n1            1          1          0          0          0          0   \n2            1          1          0          0          0          0   \n3            1          1          0          0          0          0   \n4            1          1          0          0          0          0   \n\n   emotion_6  emotion_7  emotion_8  emotion_9  intensity_1  intensity_2  \\\n0          0          0          0          0            0            0   \n1          0          0          0          0            0            0   \n2          0          0          0          0            0            0   \n3          0          0          0          0            0            0   \n4          0          0          0          0            0            0   \n\n   intensity_3  \n0            0  \n1            0  \n2            0  \n3            0  \n4            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Utterances</th>\n      <th>sentiment_0</th>\n      <th>sentiment_1</th>\n      <th>sentiment_2</th>\n      <th>emotion_1</th>\n      <th>emotion_2</th>\n      <th>emotion_3</th>\n      <th>emotion_4</th>\n      <th>emotion_5</th>\n      <th>emotion_6</th>\n      <th>emotion_7</th>\n      <th>emotion_8</th>\n      <th>emotion_9</th>\n      <th>intensity_1</th>\n      <th>intensity_2</th>\n      <th>intensity_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>look around you</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>say hello to your competition</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eight of you will switch to an easier specialty</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>five of you will crack under the pressure</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>two of you will be asked to leave</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:23.327046Z",
     "start_time": "2024-11-12T20:43:23.316338Z"
    }
   },
   "id": "7c3cd1ff6b557b79",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# For the multilabel classification we use:\n",
    "columns = ['Utterances', 'sentiment_0', 'sentiment_1', 'sentiment_2']\n",
    "multi_columns = df_data[columns].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:23.331865Z",
     "start_time": "2024-11-12T20:43:23.328050Z"
    }
   },
   "id": "3f03d650c0c3ab9",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Utterances  sentiment_0  \\\n0                                        look around you            0   \n1                          say hello to your competition            0   \n2        eight of you will switch to an easier specialty            0   \n3              five of you will crack under the pressure            0   \n4                      two of you will be asked to leave            0   \n...                                                  ...          ...   \n20012  oh, that's right, you're a woman and you need ...            1   \n20013                                     i'll try again            1   \n20014           please, pam, reconsider and have a bagel            1   \n20015                              i have an early lunch            1   \n20016  michael's been trying to get jim and me to han...            0   \n\n       sentiment_1  sentiment_2  \n0                0            1  \n1                0            1  \n2                0            1  \n3                0            1  \n4                0            1  \n...            ...          ...  \n20012            0            0  \n20013            0            0  \n20014            0            0  \n20015            0            0  \n20016            1            0  \n\n[20017 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Utterances</th>\n      <th>sentiment_0</th>\n      <th>sentiment_1</th>\n      <th>sentiment_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>look around you</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>say hello to your competition</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eight of you will switch to an easier specialty</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>five of you will crack under the pressure</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>two of you will be asked to leave</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20012</th>\n      <td>oh, that's right, you're a woman and you need ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20013</th>\n      <td>i'll try again</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20014</th>\n      <td>please, pam, reconsider and have a bagel</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20015</th>\n      <td>i have an early lunch</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20016</th>\n      <td>michael's been trying to get jim and me to han...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20017 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:23.339173Z",
     "start_time": "2024-11-12T20:43:23.332869Z"
    }
   },
   "id": "f5ac6592e7d0d12c",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Utterances  label\n0                                        look around you      2\n1                          say hello to your competition      2\n2        eight of you will switch to an easier specialty      2\n3              five of you will crack under the pressure      2\n4                      two of you will be asked to leave      2\n...                                                  ...    ...\n20012  oh, that's right, you're a woman and you need ...      0\n20013                                     i'll try again      0\n20014           please, pam, reconsider and have a bagel      0\n20015                              i have an early lunch      0\n20016  michael's been trying to get jim and me to han...      1\n\n[20017 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Utterances</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>look around you</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>say hello to your competition</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eight of you will switch to an easier specialty</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>five of you will crack under the pressure</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>two of you will be asked to leave</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20012</th>\n      <td>oh, that's right, you're a woman and you need ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20013</th>\n      <td>i'll try again</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20014</th>\n      <td>please, pam, reconsider and have a bagel</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20015</th>\n      <td>i have an early lunch</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20016</th>\n      <td>michael's been trying to get jim and me to han...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>20017 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['label'] = multi_columns[['sentiment_0', 'sentiment_1', 'sentiment_2']].idxmax(axis=1)\n",
    "df_data['label'] = df_data['label'].apply(lambda x: int(x.split('_')[1]))\n",
    "df_data = df_data[['Utterances', 'label']]\n",
    "df_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:23.359087Z",
     "start_time": "2024-11-12T20:43:23.340183Z"
    }
   },
   "id": "1b5263ecbce69516",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:23.362478Z",
     "start_time": "2024-11-12T20:43:23.360093Z"
    }
   },
   "id": "8b3904b6bd11e66c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[  101,  1284,  1132,  5193,   139,  9637,  1942, 22559, 17260,   119,\n           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0]])}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "# Test the tokenizer\n",
    "test_text = \"We are testing BERT tokenizer.\"\n",
    "# generate encodings\n",
    "encodings = tokenizer.encode_plus(test_text,\n",
    "                                  add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                                  max_length = 50,\n",
    "                                  truncation = True,\n",
    "                                  padding = \"max_length\",\n",
    "                                  return_attention_mask = True,\n",
    "                                  return_tensors = \"pt\")\n",
    "# we get a dictionary with three keys (see: https://huggingface.co/transformers/glossary.html) \n",
    "encodings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:25.807374Z",
     "start_time": "2024-11-12T20:43:23.363485Z"
    }
   },
   "id": "4583ff41d066406d",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "('[SEP]', 102)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token, tokenizer.sep_token_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:25.811568Z",
     "start_time": "2024-11-12T20:43:25.808380Z"
    }
   },
   "id": "b4e96b75767cb52b",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "('[CLS]', 101)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token, tokenizer.cls_token_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:25.815404Z",
     "start_time": "2024-11-12T20:43:25.812574Z"
    }
   },
   "id": "b6fce1b218dd6f7c",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "('[PAD]', 0)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token, tokenizer.pad_token_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:25.819320Z",
     "start_time": "2024-11-12T20:43:25.816410Z"
    }
   },
   "id": "c80afdaab10a97e6",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "('[UNK]', 100)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.unk_token, tokenizer.unk_token_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:25.823231Z",
     "start_time": "2024-11-12T20:43:25.820326Z"
    }
   },
   "id": "910c4ed511357e43",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "token_lens = []\n",
    "\n",
    "for txt in df_data['Utterances']:\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens.append(len(tokens))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:27.674098Z",
     "start_time": "2024-11-12T20:43:25.824238Z"
    }
   },
   "id": "9bcbe8d5956e2a8c",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julix\\AppData\\Local\\Temp\\ipykernel_3796\\453859461.py:4: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(token_lens)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Text(0.5, 0, 'Token count')"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGsCAYAAAAxAchvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABZj0lEQVR4nO3dd3wUdf4/8Ndsy256gwRCIJBCR0JCOYrSREXAhniK2L7W3IE5FfW+/rwT7kBP0Tvx5Ksiyqmg2LDiiQoCAhJDUUACSSAFQslu6vY2vz+WREICySabzO7O6/l47CPs7Mzu+50J5MXMZz4jiKIogoiIiEiGFFIXQERERCQVBiEiIiKSLQYhIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki2V1AX4i6qqerjdUlfRdQQBiIuLgMFQDznNLc6+2bccsG/2LQcKBRAbG9Hh92EQOksUIasfoAbsW17Yt7ywb3mRW9++6pWnxoiIiEi2GISIiIhIthiEiIiISLYYhIiIiEi2GISIiIhIthiEiIiISLYYhIiIiEi2GISIiIhIthiEiIiISLYYhIiIiEi2GISIiIhIthiEiIiISLYYhIiIiEi2GISIiIhItlRSF0B0PkEQ2rWdKIo+roSIiIIdgxD5FQcAo83Zrm3DNUqofVsOEREFOQYh8huCIMBoc2J3aTXsTpdX22pUSmT1iUFsiIpHhoiIqM0YhMjv2J0uWB1uqcsgIiIZ4GBpIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki0GISIiIpItyYKQwWBATk4OsrOzMXr0aCxZsgROp/Oi23z99deYMmVKk2U2mw1LlizBpZdeiqysLNx444348ccfO7N0IiIiChKSBaHc3FyEhoZi27Zt+PDDD7Fz506sXr26xXUdDgdWrlyJhx56CKIoNnlt2bJl2LNnD9atW4e8vDzceOONuP/++1FRUdEFXRAREVEgU0nxoaWlpcjLy8PWrVuh0+mQnJyMnJwcPPfcc7j77rubrX/XXXchJCQE99xzDz777LMmr9lsNixYsAA9evQAAMyZMwfLli3DwYMH0bNnzzbXJAieh1w09OpPPQsC0FBOe8oS0Ho//th3V2Df0tbR1di3tHV0Nbn33VGSBKHCwkJER0cjISGhcVlqaioqKipQV1eHyMjIJus/99xzSExMxMcff9zsvRYvXtzk+c6dO1FfX48BAwZ4VVNsbIRX6weLuDj/6ttSbUZ4mBZqp9ur7UJUCuhCNYiLCW3T+v7Wd1dh3/LCvuVFrn13lCRByGQyQafTNVnW8NxsNjcLQomJiW1633379iE3Nxd//OMfkZyc7FVNVVX1cHv3uzegCYLnL43BUI/zzjZKRhAEWKxOGE1W2Bze7QyHWgGL2Q6D293s9GnTz/C/vrsC+2bfcsC+5dW3QuGbgxiSBKHQ0FBYLJYmyxqeh4WFtes9P/jgAyxduhQLFizAnXfe6fX2oghZ/QA18Le+xfO+erttW/vxt767CvuWF/YtL3Lr21e9ShKE0tPTUVNTA71ej/j4eABAcXExEhMTERHhXbpzuVxYtGgRNm7ciJdffhljx47tjJKJiIgoCEly1VhKSgqysrKwdOlSGI1GlJeXY8WKFZg9e7bX7/X0009j69at+OijjxiCiIiIyCuSXT6/fPlyOJ1OTJkyBXPmzMGECROQk5MDAMjMzGx2dVhLqqqqsGbNGuj1esyYMQOZmZmNj7ZsT0RERPImiBcbWSojBoP8BkvHx0dAr/efwXWCIKDK5sTOYj2sXg6W1qoV+F1qPGJDVK0Olva3vrsC+2bfcsC+5dW3QuGbK+V4iw0iIiKSLQYhIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki0GISIiIpItBiEiIiKSLQYhIiIiki2V1AUQESAIQru2E0XRx5UQEckLgxCRxBwAjDZnu7YN1yih9m05RESywiBEJCFBEGC0ObG7tBp2p8urbTUqJbL6xCA2RMUjQ0RE7cQgROQH7E4XrA631GUQEckOB0sTERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsSRaEDAYDcnJykJ2djdGjR2PJkiVwOp0X3ebrr7/GlClTmi1fuXIlLr30UgwfPhzz5s3D0aNHO6tsIiIiCiKSBaHc3FyEhoZi27Zt+PDDD7Fz506sXr26xXUdDgdWrlyJhx56CKIoNnlt/fr1ePvtt7Fq1Srs2rULgwcPxoIFC5qtR0RERHQ+SYJQaWkp8vLysHDhQuh0OiQnJyMnJwdr1qxpcf277roLu3btwj333NPstffffx+33HIL0tPTERISgocffhgVFRXYtWtXZ7dBREREAU4lxYcWFhYiOjoaCQkJjctSU1NRUVGBuro6REZGNln/ueeeQ2JiIj7++ONm71VUVNQkIKnVaqSkpKCgoABjxoxpc02C4HnIRUOv/tSzIAAN5bSnLAGt9+NvfXdFz4D/9d1V2Le0dXQ19i1tHV3NV/1KEoRMJhN0Ol2TZQ3PzWZzsyCUmJjo1XtptVqYzWavaoqNjfBq/WARF+dffVuqzQgP00LtdHu1XYhKAV2oBnExoW1a35/67qqeAf/quyuxb3lh3+QNSYJQaGgoLBZLk2UNz8PCwrx6L51OB6vV2mSZ1Wr1+n2qqurh9u73UEATBM9fGoOhHv4ynEoQBFisThhNVtgc3u0Mh1oBi9kOg9t90fFh/tZ3V/Ts+Rz/6rursG/2LQdy7Vuh8M1BDEmCUHp6OmpqaqDX6xEfHw8AKC4uRmJiIiIivGsqPT0dhYWFmDRpEgDPwOqSkhJkZGR49T6iCFn9ADXwt77F8756u21b+/GnvruqZ3i5bjBh3/LCvuXBV71KMlg6JSUFWVlZWLp0KYxGI8rLy7FixQrMnj3b6/e64YYb8M4776CgoAA2mw3PP/884uPjkZ2d3QmVExERUTCR7PL55cuXw+l0YsqUKZgzZw4mTJiAnJwcAEBmZiY+++yzNr3P7Nmzcccdd+APf/gDxowZg19//RWvvvoq1Gp1Z5ZPREREQUAQOeEOAMBgkN8Yofj4COj1/nNOWRAEVNmc2Fmsh9XL8TJatQK/S41HbIiq1TFC/tR3V/Ts+Rz/6rursG/2LQdy7Vuh8M0Acd5ig4iIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZItBiIiIiGSLQYiIiIhkSyV1AUSdzeJw4WSdFXanG2ndwqQuh4iI/AiDEAWdkiozPv75JH6uqMPJWiuqLY7G1zRKAcN6RWNgtzAM7xWFcX1joVQIElZLRERSYhCioOAWRew8asBXB0/jx5LqZq9HhKggCECd1Yn80mrkl1bj7fzj6BsXivkT+mJ8v1gIAgMREZHcMAhRwDtZa8UXB09Db7IDAAQAE1LjcNXA7ugdo0OPSC0itCqIoojyGguO1Tuw/fBpbDqixzGDGQ99chCZvaKw4NK+GNIjUtpmiIioS0kWhAwGA5588knk5eVBqVRi1qxZeOyxx6BSNS9py5YtWLZsGcrLy9GjRw88+uijmDRpEgDAarVi6dKl+O6772C32zFo0CD8+c9/xoABA7q6Jepioijix5JqbC02wC0CEVoVrhvaA9dfkoikKF2z9QVBQJ/YUGRlRGBinyjMn9APq/PKsW7vCew9Xos71+7DTZk98eBl/aBW8joCIiI5kOxf+9zcXISGhmLbtm348MMPsXPnTqxevbrZeiUlJZg/fz4efPBB5OfnY/78+cjNzcXp06cBAC+99BJKSkrw5ZdfYvv27RgwYAD++Mc/dnE31NXqrA68u/sEvi/yhKBBieF4c94ILLisX4shqCURWhXmX9oXH901EjMHJwAA1u2twP3v/4Iz9bbOLJ+IiPyEJEGotLQUeXl5WLhwIXQ6HZKTk5GTk4M1a9Y0W3f9+vXIzs7G1KlToVKpMH36dIwcORLr1q0DABQXF0MURYiiCABQKBTQ6dr2i5AC06k6K974sQyl1RaolQKmD+qOOZk9EalVt+v9EiJC8Jcr+2PZNYMRHqLELxV1mPfOHvxU1nysERERBRdJTo0VFhYiOjoaCQkJjctSU1NRUVGBuro6REb+Nk6jqKgIGRkZTbZPS0tDQUEBAOCuu+7C/PnzMWbMGCiVSsTExOCtt97yuiZB8DzkoqFXf+pZEDzje4Dfvp7vVJ0V7+4+AavTjYSIEFw3NBGxYRoIggABrfdzsb4npsfhnW4j8Oinv+JIpQl//HA/Hp6UiptGJLWzo9a1peeLbo+27UN/3N9dgX1LW0dXY9/S1tHVfNWvJEHIZDI1O2rT8NxsNjcJQi2tq9VqYTabAQAulwtXXHEF/vCHPyAsLAzPPvsscnJy8NlnnyEkJKTNNcXGRrS3nYAWF+dffVuqzQgP00LtdDd77USNBe/uqYDV6Ubv2FDcMTYFWrUSABCiUkAXqkFcTGibPudCfcfHR+DT+XH4f58cwEd7juO5TcUQNCrkTExrf1OtuFjPF+Ntz4D/7e+uwr7lhX2TNyQJQqGhobBYLE2WNTwPC2s64Z1Op4PVam2yzGq1IiwsDA6HAw8++CBee+21xqNLTz75JEaOHInt27dj8uTJba6pqqoebu9+DwU0QfD8pTEY6nH2rKLkBEGAxeqE0WSFzdF0Z5yqs2Lt2SNBSVFa3HhJIpw2B4w2zxxBDrUCFrMdBre78TRpy5/Rtr4fn9QXsSEKrNxZhmf/exiGGgvuH9fH55fYX6zn1rS1Z8/n+N/+7grsm33LgVz7Vih8cxBDkiCUnp6Ompoa6PV6xMfHA/CM9UlMTERERNOmMjIycPDgwSbLioqKMGTIEJjNZtTW1sJutze+plQqIQgC1GrvxouIImT1A9TA3/oWz/sKAHqjvUkIumlET2hUSpxftoi299P6egLuHZsCrUqJl7Ydw6ofy2BxuJB7WT+fh6GWevZmW2/2ob/t767CvuWFfcuDr3qVZLB0SkoKsrKysHTpUhiNRpSXl2PFihWYPXt2s3VnzZqFvLw8bNiwAU6nExs2bEBeXh6uueYaREVFISsrC8uWLYPBYIDNZsNzzz2HmJgYZGVlSdAZ+ZrV4cJHP3tOh/U8G4JCVMou+/zbRiVj4eRUAMDa3Sfw7HdFrR59ISKiwCHZ5fPLly+H0+nElClTMGfOHEyYMAE5OTkAgMzMTHz22WcAPIOoX375Zbz66qsYOXIkVqxYgZdeegl9+/ZtfJ+UlBTMmjULl156KYqLi7Fq1SqEhrZ93AT5J1EU8fmB06gyOxCpVWH28B5dGoIazMlMwpPTMiAA+PDnk/jXlqMMQ0REQUKyCRXj4+OxfPnyFl/bu3dvk+cTJkzAhAkTLvg+zz77rM/rI+n9cLQKRXoTlAoB1w/rgTCNdBOhzxqaCAD428YjWLv7BHRqJe4flyJZPURE5BucPpf8UuEZI344WgUAuHJgd/SI0kpckScMNZwmW/VjGVbvKpO4IiIi6igGIfI7BpMdnx/0zByelRyFYT395/5fczKTMH+C57Tsyz+U4N09JySuiIiIOoJBiPyKWxTxyS+nYHO60StaiykZ3aQuqZnbRiXjnt/1BgC8sLkY6xiGiIgCFoMQ+ZUv9p9CWbUFGqWAWUMSoVT451Sp9/yuD+4YlQwAWMYwREQUsBiEyG+crLVi1Y4SAMDE9HhE6dp377CuIAgCcsanMAwREQU4BiHyC6Io4ulvjsDicKN3jA4jekVJXVKrWgpDHDNERBRYGITIL3x16Ax2lFRDrRRwzdBEn8/e3FnOD0MvbC7Gyp2lnGeIiChAMAiR5AwmO17YXAwAuHVUb8SHaySuyDsNYahhAPVrO0rx/OZiuBmGiIj8HoMQSe7f246h1upERvdw3JjZU+py2kUQPPcme2SSZ56hdXsr8JcNBXC6ZHQnXyKiAMQgRJIq1puw4VfPnEF/npoOlTKwfyRvGpGEv00fAKVCwNcFlXj404Mw211Sl0VERBfQrt865eXlvq6DZOqV7SVwi8DEtDgM9aOJEzviyoHd8fy1gxGiUmDHsWrc//7P0JvsUpdFREQtaFcQuuqqqzBv3jx8+umnsFqtvq6JZGJ/RR2+LzJAIQAPjE+RuhyfGtc3Fv934zBE69Q4dNqIu9buxTGDWeqyiIjoPO0KQlu2bMGkSZOwatUqjB8/Hk8++WSzG6USXYwoivj3tmMAgKsHJaBfXJjEFfne0J6ReOPm4egdo8PJOhv+59192HO8RuqyiIjoHO0KQnFxcbjrrrvw2Wef4a233kJkZCQef/xxXHXVVXj99ddRVVXl6zopyPxYWo09x2uhVgq4d2wfqcvpNMkxOqz6/XAM6xmJepsTf/xwPzYV6qUui4iIzurQyFSn04mKigpUVFTAYDBAp9Ph559/xrRp07B+/Xpf1UhBxi2KeHlbCQDgxuE9kRgp/Z3lO1N0qBovzx6KSenxcLhE/PnzX/H5gVNSl0VERABU7dlo3759+PTTT/HVV19BEATMnDkT77zzDgYMGAAA+Oabb/DEE0/guuuu82mxFBy+PVyJw2eMCNMoGyciDHZatRJPzxiIp78pxKcHTmHx10dgtLtwS1YvqUsjIpK1dgWhuXPnYvz48Vi0aBEmT54MtbrpPaEGDhyIyZMn+6RACi6iKGLVj2UAgLlZvRATGliTJ3aEUiHgiWnpCAtRYu3uE3hhczGMNiduGJEkdWlERLLVriD09ttvY8SIEc2Wb926FZdeeil69eqFZ555psPFUfD5sbQaRw1mhKqV+L0MA4AgCMi9rB8itSq8sr0Ur+0ohcMtIiVWJ3VpRESy1K4xQnfffXezZUajEQ8++GCHC6Lgtib/OABg1tBERGjblcMDniAI+J8xffCnif0AAG/+WIYDFXUSV0VEJE9t/k1UWlqKq6++Gi6XC6IoYuDAgc3WaekoEVGDokoTdpXWQCEAvx8RmLfS8KVbsnrhVL0N7+4+gfW/nMLNWUnoFc0jQ0REXanNQahPnz744IMPUFdXh3vvvRcrV65s8npISAgyMjJ8XiAFjzW7PUeDJqfHIymKv/ABIPeyVJRUWbDzWBU+2ncSt41KRkyouvUNiYjIJ7w6N9FwFOiLL75AcrI8rvYh39AbbfjvoTMAwCulzqFUCHh8Wgbuf3cvTtbZ8MG+E5g3Mhk6tVLq0oiIZMGrIPTUU0/hqaeewooVKy64ztNPP93hoij4fLCvAk63iGE9I4PmnmK+otMocUt2L7y2vRQGkwNfHzqDa4f1kLosIiJZ8GqwtCiKnVUHBTGLw4WPfj4JAJibzaNBLYnUqnDDJT0gCMCh00YcOl0vdUlERLLg1RGhRYsWAeBRH/LOFwdPo9bqRFKUFpelxkldjt/qEaXF71JiseNYFb4+VIneMTqEaeR5ZR0RUVdp1+Xzer0eS5cuBQDk5+dj7NixmDFjBoqLi31aHAU+URTx/t4TAICbRyRBqRAkrsi/je8Xi27hGlgcLmw8VCl1OUREQa9dQWjRokUoLi6GKIpYsmQJpk+fjkmTJmHx4sW+ro8C3C8VdSipskCrUmDGkASpy/F7SoWAGYMTIAhAwRkjDp3iKTIios7UruPu+/fvx4YNG1BZWYmCggK88cYbiIiIwOjRo31dHwW4zw+cBgBM7d+Np3naKDFSi7F9Y7H9aBW+LjjjOUUWwu8dEVFnaNcRIYvFAq1Wi507dyIjIwMxMTGwWq1QqfiPNf3GbHfhm8Oe0zuzhiR2+ucJQsNDuOjDs27zZf5kXN9YdA/XwOJw47sjeqnLISIKWu1KLsOGDcNTTz2F3bt346qrroJer8fixYsxatQoX9dHAey7I5UwO1xIjtZieFLnXjKvUngCTZXViYtd2ygAsFSbYTlvvXCNEv40jaFSIWD6oASszivHwVP1GNUnGomRWqnLIiIKOu0KQkuWLMELL7yA7Oxs3Hffffj1119ht9vx97//3df1UQD7/MApAMDMIYmdftRFqRBgdrjx6/Ea2Jyui64bHqaF0WRtfK5RKZHVJwaxISq/miKiR5QWgxLD8espIzYXGnBzlvxuUktE1NnaFYS6d+/e5O7yl1xyCV555RWfFUWBr6zagr0n6qAQgOmDum6QtM3pgtXhvuDrAgC10w2bw33RI0f+4rK0eBScNqKkyoxjBhP6xoVJXRIRUVBpVxAymUxYu3YtSkpK4HY3/aXDOYYIAL446DkaNCYlBgkRIRJXE7iidWqMSI5GflkNNhcakBIb6pdjmoiIAlW7Bkv/+c9/xltvvQWbzebreigIuNwivjjouVqsKwZJB7txfWMRolLgdL0NB3k5PRGRT7XriNCuXbvw4Ycf8sar1KIfS6tRabQjSqvChH6cSbqjQjVKjEmJwZYiA7YWGTAgIRwqRbv+D0NEROdp17+mISEhSEjg5HjUsoZB0lcNSoBGxV/YvjCydzTCQ5SotTqxp7xW6nKIiIJGu35L3XLLLXjmmWdQVVXl63oowNVbndhabAAAzBwcOGG5rXMQXWxuos6kVioaj679WFINp+vCA8KJiKjt2nVq7P3330dFRQXefffdZq8dOnSow0VR4Pq+SA+HS0TfuFBkdA+Xupw2aescRBfTFfMQDe0Zie3HqlBndeLAyXqM6RvTyZ9IRBT82hWEzr10nuhcDTNJX96/m8SVtJ03cxC1pKvmIVIqBIzsHY3vjuiRV1aNUSnRnfZZRERy0a4g1DCDdG1tLcrLyzFo0CA4nU5oNBqfFkeBpcbiQF5ZDYDACkINWpuDyB9ckhSFH45WwWByoPCMCePSAu/7TETkT9o1RshkMuHhhx/G6NGjceutt6KkpASXX345jh496uv6KIBsLtTD5RaR3i0MKbGhUpcTlEJUCmT2igIAbD/KMXpERB3VriD07LPPwmw246uvvoJarUZycjImTZqEJUuW+Lo+CiCBeFosEGUnR0MhAKXVFhzivEJERB3SriC0efNmPPPMM+jbty8EQYBarcbjjz+O/fv3+7o+ChAGkx27y2sAMAh1tgitCoMTIwAAH+49IXE1RESBrV1ByO12N44Hahgceu4ykp9NhXq4RWBgQjh6ReukLifojU7xXDG2vdiA4zUWiashIgpc7QpCY8aMweLFi2GxWBrnUPnXv/7VOIia5IenxbpWt/AQpHULg1sE1uQfl7ocIqKA1e57jR09ehQjR45EfX09MjMz8dNPP+Gxxx5r83sYDAbk5OQgOzsbo0ePxpIlS+B0Oltcd8uWLZg5cyaGDx+Oq666Cps3b27y+tq1a3H55ZcjMzMTM2fObPY6da5Kow37jntmO2YQ6jrjzs4j9PmBU6i3tvx3h4iILq5dl89rtVrk5ORg//79SE1NRbdu3ZCZmQmlUtnm98jNzUVCQgK2bdsGvV6PBx54AKtXr8bdd9/dZL2SkhLMnz8fL7zwAiZOnIiNGzciNzcXGzduREJCAtavX4+XX34Z//d//4ehQ4fiyy+/xPz58/Hdd9/xNiBd5LsjeogAhvaIRGKkVupyZKNvXChS4kJRYjDj84OncEtWL6lLIiIKOF4fEXr99dcxbtw43H///fj3v/+NP/3pT7jvvvvw3nvvtfk9SktLkZeXh4ULF0Kn0yE5ORk5OTlYs2ZNs3XXr1+P7OxsTJ06FSqVCtOnT8fIkSOxbt06AMAbb7yBBx98EMOGDYMgCJgxYwbWrVuH8PDAmNU4GDSeFhvAo0FdSRAEzBqaCAD4cF8F3J04mSMRUbDy6ojQBx98gFdeeQVPPPEEJk6ciJiYGBgMBmzatAn//Oc/ER8fjyuuuKLV9yksLER0dHSTIzapqamoqKhAXV0dIiMjG5cXFRUhIyOjyfZpaWkoKCiAxWJBYWEhFAoF5s6di6KiIvTt2xePPPIIwsLCvGmt8V5TctHQa0d7PlVnxS8VdRAAXN4/vkPvJwhAw+btfZtz3+NCrzd+FZu/1u7PRfu+lx3teWr/7li1oxTlNVbklVbjd31jL/g5536VC/YtbR1djX1LW0dX81W/XgWhtWvX4umnn8bll1/euCwhIQE333wzoqKi8Pbbb7cpCJlMJuh0Ta8sanhuNpubBKGW1tVqtTCbzairq4MoinjjjTfw4osvok+fPnj//fdxzz334PPPP0evXm0/VRAbG9HmdYNJXFzH+v6sQA8AGJkSi4Ep8R2ux1JtRniYFmqndzM8h4WooFYrERaqhUrT+rZhYb+dwvN22/OFqBQIDdUgLqZ9k0i2t+cQlQKx0TrcmJ2M1TtK8OmvZzBzZJ+LbtPR/R2o2Le8sG/yhldBqKSkBJMmTWrxtalTp+Lvf/97m94nNDQUFkvTS34bnp9/JEen08FqtTZZZrVaERYWBrXac5vLO++8E+np6QCAW2+9Fe+++y62bNmCuXPntqkeAKiqqofbv++u4FOC4PlLYzDUoyNnVD7d67li6dJ+MdDrOza5nyAIsFidMJqssHl5qwuFSwWHQweT2Qqr/cLbCoInBJlM1sa+27rthYghSlisDhRW1DQ7ytRq3QoBDrfYrp4dagUsZjtmDuyG1TtK8N2hM/i56AySWpi+wFf7O9Cwb/YtB3LtW6HwzUEMr4KQIAhQqVreRKPRNAssF5Keno6amhro9XrEx3uOIhQXFyMxMREREU2bysjIwMGDB5ssKyoqwpAhQxAbG4u4uDjY7fYmr7tc3t84UxQhqx+gBh3p+0y9DT+fqAMATEyL98n3Tzzvq9fbi61sK154vVa3vYCO3LQ1XKtGemLkuaV5RQTQJyYUo/tEY1dpDT76+STmX9rvwuvz51xW2Le8yK1vX/XarsvnOyolJQVZWVlYunQpjEYjysvLsWLFCsyePbvZurNmzUJeXh42bNgAp9OJDRs2IC8vD9dccw0A4Pe//z1efvllHDp0CE6nE2+99RZOnz6NqVOndnVbsvN9kee02NAekUiICJG4Guk13LTVm4ejHXe7b8mNw3sCAD7dfwpWh2/ek4hIDrw6IuR0OvHJJ59c8HVvjsQsX74cixcvxpQpU6BQKHDttdciJycHAJCZmYlFixZh1qxZSE1Nxcsvv4xly5bhiSeeQFJSEl566SX07dsXAPDHP/4R4eHhyM3NxZkzZ9CvXz+sXLmSl853ge+OeILQlIyOjw2ijhnfLw6JESE4VW/DN4crMXNIotQlEREFBK+CUHx8PJYvX37B1+Pi4nzyXnv37m3yfMKECZgwYUKL6yoUCtx1112466672vzZ1HEGkx17z06iOJlBSHJKhYAbLumBl38owQf7KjBjcELjrO9ERHRhXgWhTZs2dVYdFGC+L/JMojg4MQI9OImiX7hmaCJW7izFodNGHDxVjyE9IlvfiIhI5iQZI0SBj6fF/E9MqKbxFicf7KuQuBoiosDAIEReqzbbsbu8BgAwKZ1ByJ80DJr+5nAlqsz2VtYmIiIGIfLa90UGuEVgQPdw9GphzhqSzuAekRiUGAGHS8Sn+09JXQ4Rkd9jECKvbTp7WoyDpP3TjcN7AAA+/vkknG4ZTSpCRNQODELklVqLAz+dPS02mafF/NLl/bsjSqvCqXobfig2SF0OEZFfYxAir3xfpIfLLSK9Wxj6xLbv3lrUuUJUClwz1HNUiIOmiYgujkGIvLKxoBIAGq9OIv90wyU9IADIK6tBicEsdTlERH6LQYjarMpsR/7Z02IXC0KCILTz0UWNyEDPKC0mpHomOP3wZx4VIiK6EK8mVCR523RED7cIDEy48NViDgBGm7Nd769QCPD+3u90ITcO74GtxQZ8cfA0ciakgCO6iIiaYxCiNtt42HNabNqA7i2+LggCjDYndpdWw96Om4meeyd26rhRfWLQJ0aH0moLPv75JP7UM0bqkoiI/A5PjVGbVBpt2Hf23mJTW7ls3t6Ou7D78k7s5KEQBNw2KhkA8E7+Cd6VnoioBQxC1CbfHvHcW2xYz0gk8t5iAeOqgd3RPVwDg8mOj/Ycl7ocIiK/wyBEbfJNwRkAwDReLRZQ1EoF5o30HBV6ZUsxJ1gkIjoPgxC16mSdFftP1kMAb7IaiK4dmohonRrlVRZ8e3acFxEReTAIUasafnmOSI5CfHiIxNWQt7RqJW7OSgIAvLmrDG6RR4WIiBowCFGrvmm4WoynxQLWnOE9ER6iQrHejB+OVkldDhGR32AQoosqr7bg0GkjlAIwOZ1BKFBFaFW4dUwfAMDqXWUQeVSIiAgAgxC14qtDpwEAI3vHIDpULXE11BH/M74vQlQK7D9Zj7zSGqnLISLyCwxCdEGiKOLLXz1Xi00f3PIkihQ4ukWE4PpLPDdjfXHrUbh4BRkREYMQXdi+E3WoqLUiTKPEpDReLRYM/mdMb4SHKFFYaWo82kdEJGcMQnRBXx70/KKckhEPrVopcTXkC9E6Ne4a3RsA8H8/lHC2aSKSPQYhapHV4cK3RzxXi109OEHiasiX5mQmoUdkCM4Y7Vi7+4TU5RARSYpBiFr0fZEBJrsLPSNDMDwpSupyyIdCVAr8YXxfAMB/8sphMNklroiISDoMQtSihtNi0wclQCEIEldDvnb5gG4YlBgBs8OFlTtLpS6HiEgyDELUzJl6G/LKqgHwtFiwUggCHrzMc1Ro/S8nUaw3SVwREZE0GISoma8OnYFbBIYnRaJXtE7qcqiTjOgVjYlpcXCLwDPfFvLWG0QkSwxC1IQoio2nxa4exKNBwe6hSanQqRXYd6IOn/xyUupyiIi6HIMQNfHraSOOVZkRolJgKu8tFvR6RGrxwNmB08u3HsOZepvEFRERdS0GIWri0/2eowKXpcYhPEQlcTXUFeYM74nBiREw2V14blOR1OUQEXUpBiFqZLQ58dXZW2o03IqBgp9SIeCJaelQKgR8X2TApkK91CUREXUZBiFq9OXB07A63egbF4oRvTh3kJykdwvHbSN7AQCe+64I9VanxBUREXUNBiEC4Bkk/eHPFQCA2Zf0hMC5g2Tnf8b0Qe8YHfQmO17cclTqcoiIugSDEAEAdpfXoqTKglC1EtMH8U7zchSiUuCJaekAgE8PnML2Y1USV0RE1PkYhAgAGo8GXTWoOwdJy9iIXtH4/YgkAMCSjUdQZ3VIXBERUediECKcqbfh+7MDZGdf0lPiakhqfxifgt4xOlQa7Xh+c7HU5RARdSoGIcIn+0/CJQKZSZFI6xYmdTkkMa1aib9e2R8KAdjw6xlsKeJVZEQUvBiEZM7pcmP9L6cAALOH82gQeQzrGYlbsz1XkS39phA1Zp4iI6LgxCAkc98XGaA32REbqsak9HipyyE/cu/YFPSNC0WV2YFnOdEiEQUpBiGZW7v7BADg2mE9oFbyx4F+E6JSYNFV/aEUgG8OV+Lbw5VSl0RE5HP8zSdj+SVV+KWiDmqlgBt5WoxaMDAhAneM7g3Ac4d6g8kucUVERL7FICRjr2zxXBF09aAExIdpJK6G/NX/jOmN9G5hqLU68cy3hRBFUeqSiIh8hkFIpo7qTfj20BkIQOOgWKKWqJUKPHVlf6jO3ovsq0NnpC6JiMhnGIRk6u384wCAienx6BMbKnE15O8yuofj7t95TpEt21SMSqPNJ+8rCEK7HkREvsIphP1Ye//Bb+3Uxel6W+Nd5m8f1fLRoPZ8Nn8/BbfbR/XGliIDDp02Yuk3hXjh2sEdCiUOAEZb+27uGq5RQt3uTyYi+g2DkJ/qzF8S7+05AadbxKi+sRjSIxLn56b2frZCIcDt9VbUEYLQEEAvHkga8sr5wcWb8T4qhYCnruqPW9/egx+OVuG7I3pM7d/Ny4p/q8Noc2J3aTXsTpdX22pUSmT1iUFsiIrjlYiowyQLQgaDAU8++STy8vKgVCoxa9YsPPbYY1Cpmpe0ZcsWLFu2DOXl5ejRowceffRRTJo0qdl6H3zwAf7f//t/OHz4cFe00Gk685dEvdWJ9b+cBAA8cFmqTz87XKtGemKkV9tQ+6kUntNEVVYnWosDAgBLtRmW89b19shKv7gw3DEqGSt3luG5TUUY1Scakdr2H5uxO12wOhifiUg6kgWh3NxcJCQkYNu2bdDr9XjggQewevVq3H333U3WKykpwfz58/HCCy9g4sSJ2LhxI3Jzc7Fx40YkJCQ0rldYWIilS5d2dRudqjN+SXz8y0mY7C6kxodiYv9uMBiMPvvsEJV3wYk6RqkQYHa48evxGtjaEFrDw7QwmqyNz9t7ZOWOUb2xsaASpdUW/HvbMfzv5Rntqp+IyB9IMli6tLQUeXl5WLhwIXQ6HZKTk5GTk4M1a9Y0W3f9+vXIzs7G1KlToVKpMH36dIwcORLr1q1rXMdiseChhx7Cbbfd1u6aGk4x+M2joS4vH43btPCeNqcLa3d7BknfNjL57MBT33524/eyi7dv87ZC8/UCou6LbGt3uWBzuC/6sDvdsDnPfm1c5rrgz8rFHiFqBZ6Ylg4AWP/LKew7Ues3P+MtPdCOHoPhwb7l9ZBz3x0lyRGhwsJCREdHNzmik5qaioqKCtTV1SEy8rfTK0VFRcjIaPo/zrS0NBQUFDQ+X7x4MSZOnIixY8filVdeaVdNsbER7dqus1iqzQgP00Lt9PaojAK6UA3iYppfCfbm9mOoMjvQK0aHW8b3AwDExTXvu72fHRaiglqtRFioFiqN90eyOrK9t9uGhWkDsu6Obntu3xf7WWnNtPgI3HysGu/mleOZ74qw4cEJCFEpvXqPzvgZv5CWfs7lgH3Li1z77ihJgpDJZIJOp2uyrOG52WxuEoRaWler1cJsNgMAPv30UxQXF+Nvf/sbdu/e3e6aqqrq4faToQqCIMBidcJossLm5ekph1oBi9kOg9vd5HSH3enG/2323C9qXnYS6mpMiIuLgMFQ32SwdEc+W+FSweHQwWS2wmr3/pvZke3buq0geMKAyWRt7DsQ6u7oti31faGflba6Z1QvbDxwCsWVJiz78lfcNy6lzdt2xs94y5+DFn/Ogx37Zt9yoFD45iCGJEEoNDQUFoulybKG52FhYU2W63Q6WK3WJsusVivCwsJw9OhRPP/881izZk2Lg6y9IYrwqx8g8byv3m57fj+fHzyNM0Y7uodrMGNQYuNrLfXdkc9ufM92btvR7VvdVrzwen5dd0e3vUDfLf2stFVEiBoPTUrFE18W4D955Zg+KAG9onWtb9i0JJ/9jF90fT/7+91V2Le8yK1vX/UqyRih9PR01NTUQK/XNy4rLi5GYmIiIiKapruMjAwUFhY2WVZUVIT09HR8/fXXqKurw3XXXYfs7Gzcf//9AIDs7Gx8/vnnnd9IgHC63PjPrjIAwLyRydCoOI8m+cbl/bthVO9o2F0ilm89JnU5RERek+Q3YkpKCrKysrB06VIYjUaUl5djxYoVmD17drN1Z82ahby8PGzYsAFOpxMbNmxAXl4errnmGjzwwAPYt28f8vPzkZ+f3zg+KD8/HzNnzuzqtvzWfwvOoKLOhthQNa4dmih1ORREBEHAnyalQikAmwv1+KmsWuqSiIi8ItmhgeXLl8PpdGLKlCmYM2cOJkyYgJycHABAZmYmPvvsMwCeQdQvv/wyXn31VYwcORIrVqzASy+9hL59+0pVekBxuUW8uascADA3qxe0au8GtBK1Ji0+DDdc0hMA8MLmo3C6ZXRsnogCnmTzCMXHx2P58uUtvrZ3794mzydMmIAJEya0+p6jR48O+MkUfe27I5Uoq7YgSqvCDcN7SF0OBal7x/bB1wVnUKQ34ZNfTmL28J5Sl0RE1CYcLBLERFHE6jzP0aDfj0hCmIZ3VKHOEaVT496xKQCAV7aXoNbikLYgIqI2YhAKYjtKqlFYaUKoWok5mfwfOnWu6y/pgX5xoai1OrFyZ6nU5RARtQmDUBB7+yfP0aBrhyV26H5QRG2hUgh4eJLn/nUf7qtASZVZ4oqIiFrHIBSkDpysw+7yWigVAm4ekSR1OeSnfpuqXvD60ZJRfWIwoV8sXCLwfz+UdG0zRETtwEEjQarhaNCVA7ohMVLbytokR97cvb4lF7pz/R8m9MX2Y1XYVKjH/oo6DO0Z2cJaRET+gUEoCJ2osWDTEc9klbeOTJa4GvJX3t69/lwXu3N9anwYZgxOwGcHTuOlrUfx6k2XXPAIEhGR1HhqLAh9tLcCIoDx/WKRFh/W6vokbzanC1aH26uHvZXgdO/YFISoFNh7og7bjlZ1USdERN5jEAoyRpsTXx86DQCYN7KXxNWQXCVEhOD3Z8em/XvbMbg4ySIR+SkGoSCzq7QGDpeIIT0ikJkUJXU5JGO3j0xGlFaFYwYzvjx4WupyiIhaxCAURBwuN34q9dzr6baRyRyXQZKK0Kpw5+jeAIBXd5TA6vBuHBIRUVdgEAoiBaeNsDjcSIgIwWVp8VKXQ4Qbh/dEj8gQnDHa8d6eE1KXQ0TUDINQENl3ohYAcOXgBCgVPBpE0tOoFLh/XAoA4D8/laOGt94gIj/DIBQk9EYbjtdYoRCAKwd1b9MkeUBL60jcCAWdKwd2R3q3MBhtLry5q0zqcoiImmAQChL7TtQBAPp3D0e3CC2qrE5U2S7ysDpxvNrcbL1quwtuiXuh4KIQBMy/tC8A4IN9FaiotUpcERHRbzihYhBwuNzYX+EJQmNSYto8SV54mBZGU9NfSuFaNdITORMw+daYPjEY2TsaP5XV4JXtJfjb1QOlLomICACPCAWFw2eMsDrdiNSqkN7dM4Fia5Pk2Rxu2Jyer+cud3g5wzBRWwjnHBX676EzOHzGKHFFREQeDEJBYN9xzyDpS5IioeAgH+oi3t6wdVBiJKYN6AYRwL+3HpW6fCIiADw1FvD0RjvKa6wQBOCSnpxAkbpGe2/YOndUb2w6osfOkmrkl9V0VnlERG3GIBTgGi6ZT4sPQ4SWu5O6Rkdu2JrdOxo/llTjlW1Hccco3hSYiKTF35wBzOl2Y/9JzyDp4bydBkmgYSyaN8akxOCXE3Uoq7Jgd3kNhvFIJhFJiGOEAthRvRlWhxvhIUr0iw+VuhyiNtGplbh8gGfm881HDLDw1htEJCEGoQB26HQ9AGBgQgQHSVNAGdUnBskxOpgdLmw/WiV1OUQkYwxCAcrhcqOw0gQAGJgQLnE1RN5RKgTcPc5zOf3u8hoYTHaJKyIiuWIQClDFehMcLhFRWhV6RmmlLofIa5m9o5HRLQxuEdh0RC91OUQkUwxCAerQac+EdAMSIhrvG0YUaK4Y2B0KASjSm3BUb5K6HCKSIQahAGR3ulHUcFoskafFKHDFh2uQlRwNAPi6oBIOF+90R0Rdi0EoABXpTXC6RUTr1EiMCJG6HKIOmZAah4gQFWosDuw8Vi11OUQkMwxCAei3q8XCeVqMAl6ISoGp/T2X0+8sqeLAaSLqUgxCAcbmdKFYbwYADEyMkLgaIt/o3z0cqfGhcIuem7KKojc37iAiaj8GoQBTWGmCyy0iNlSN7uEaqcsh8glBEDBtQHeoFALKqi04cLJe6pKISCYYhALMoVOeq8UGJvJqMQou0To1xveLBQB8d0QPs50zThNR52MQCiBWhwtHDZ6rxQZxEkUKQqP6xKBbuAYWhwvfHamUuhwikgEGoQBSrDfDLQLxYRrEh/NqMQo+SoWAqwZ2hwDgwMl6FJ4xSl0SEQU5BqEAUnR2wrn0bmESV0LUeZKidRidEgMA+OrQGZ4iI6JOxSAUINxusfG0WGo8gxAFtwn9YhEfpoHJ7sLGgjNSl0NEQYxBKECcqLXC6nBDq1YgifcWoyCnUiowY0gCBMFzO5mGubOIiHyNQShAFJ89LdYvLgwKBa8Wo+DXI1KLsSmeq8i+PnQGJptT4oqIKBgxCAWIhvFBaTwtRjIyrl8sEiJCYHG48eWvpznRIhH5HINQAKi1OFBptEMA0C8+VOpyiLqMUiFgxuAEKBUCivVm5JfXSl0SEQUZBqEA0HA0qFe0Fjq1UuJqiLpW94gQTE733Its8xE9TtZaJa6IiIIJg1AAaBgfxKvFSK6ykqOQ3i0MLlHEB/sqYOEl9UTkIwxCfs7hcqO0ygIASOP8QSRTgiBg+qAERISoYDA5sGLrUalLIqIgwSDk50qqzHC6RURpVYgP401WSb5CNUrMGpIAAZ6ryP576LTUJRFREGAQ8nPFlb+dFuNNVknueseG4tK0OADAko1HGicZJSJqLwYhPyaKIor0ZgA8LUbU4LK0OAzvFQWLw42Fn/4KI+cXIqIOkCwIGQwG5OTkIDs7G6NHj8aSJUvgdLb8D9qWLVswc+ZMDB8+HFdddRU2b97c+JrNZsOSJUtw6aWXIisrCzfeeCN+/PHHrmqjU52ut6He5oRKIaB3jE7qcoj8glIh4H+v7I+EiBCUVVuw6L+H4eb8QkTUTpIFodzcXISGhmLbtm348MMPsXPnTqxevbrZeiUlJZg/fz4efPBB5OfnY/78+cjNzcXp057xAcuWLcOePXuwbt065OXl4cYbb8T999+PioqKLu7I946c8Rz2T4kNhVrJg3dEDaJ1ajw7axDUSgHfFxnwn7xyqUsiogAlyW/X0tJS5OXlYeHChdDpdEhOTkZOTg7WrFnTbN3169cjOzsbU6dOhUqlwvTp0zFy5EisW7cOgOeI0IIFC9CjRw8olUrMmTMHGo0GBw8e7Oq2fO7IGSMAnhYjasngHpFYODkNAPDK9hLsKqmWuCIiCkQqKT60sLAQ0dHRSEhIaFyWmpqKiooK1NXVITIysnF5UVERMjIymmyflpaGgoICAMDixYubvLZz507U19djwIABXtUkCJ6HPxAEoM7iwPEaz8RxafGh8LY0QcBFt2noVRAAtHBWobXtO/LZnbl9R/r257o7um1n9S3V90w4u+31l/TAwVP1+HT/Kfzvl4fwxi3DkRL72+zrTfqWEfYtbR1dTe59d5QkQchkMkGnazrmpeG52WxuEoRaWler1cJsNjd733379iE3Nxd//OMfkZyc7FVNsbERXq3f2db/egYigB5RWvSMb3ttYSEqqNVKhIVqodK4W18/rOmd7L3d3lfbdvVnn9t3INXd0W191beU37MQlQK6UA3iYjyB5x9zhqOs9kfsLavBQ5/8io9zxiI+PKTJNnFx/vX3u6uwb3mRa98dJUkQCg0NhcViabKs4XlYWNPTQDqdDlZr0yn1rVZrs/U++OADLF26FAsWLMCdd97pdU1VVfVwe//veacQBAE/HKkEAPSN1cFobPstBRQuFRwOHUxmK6z2CzckCJ5fiiaTFeeOM23r9h357M7YviN9B0LdHd3W131L+T1zqBWwmO0wuN2NN2H9x9UDcOfafSirMuOOVbvwypxh0KqVEATPLweDoR5yGk/Nvtm3HCgUvjmIIUkQSk9PR01NDfR6PeLjPfcQKi4uRmJiIiIimjaVkZHRbLxPUVERhgwZAgBwuVxYtGgRNm7ciJdffhljx45tV02iCL/5AXK63Pip1DPeITU+rKUzV60SxRbPeJ2zwsXXa3X7jnx2J27fkb79uu6ObttJfUv1PRMbtj27cUyoBv+6fgjufncfDpysx//7sgDPzBwElVL47XP85O93V2Lf8iK3vn3VqySDpVNSUpCVlYWlS5fCaDSivLwcK1aswOzZs5utO2vWLOTl5WHDhg1wOp3YsGED8vLycM011wAAnn76aWzduhUfffRRu0OQv/m5og4muwuhGiV6Rmlb34CIkBIbiueuGdx4JdmLW442HjEiIroQya7JXr58OZxOJ6ZMmYI5c+ZgwoQJyMnJAQBkZmbis88+A+AZRP3yyy/j1VdfxciRI7FixQq89NJL6Nu3L6qqqrBmzRro9XrMmDEDmZmZjY+G7QPRD8UGAEB6tzAo5Db6jagDMntF4akr+wMA3t1zAq/tKJW4IiLyd5KcGgOA+Ph4LF++vMXX9u7d2+T5hAkTMGHChGbrxcbG4tChQ51Sn5R+OFoFAMjozsvmibw1bUB3GMwOvLC5GCt3liEyXIubL0mUuiwi8lOcpc/PHK+x4FiVGQrBMz6IiLx384gkLLi0LwDg+W+OYPUuTrhIRC1jEPIz288eDRrSMxI6tVLiaogC17yRycgZnwIA+Pe2Y1iTf1zagojILzEI+ZmG02KjU2IlroQo8N01pjdyp6YDAP615ShW7izlAGoiaoJByI+Y7S7sPl4DABidEiNtMURB4sEp6bh3bB8AwGs7SvHsd0VwuRmGiMiDQciP5JVWw+ESkRSlRTLvNk/kE4Ig4N6xfbBwchoEAB/+fBJPfHkIdqefzKBKRJJiEPIjPxzznBYb3y8OAi+bJ/KpOZk9sWTGQKgUAr47oseDH+9HvdUpdVlEJDEGIT8himLjQOkJqRwfRNQZLu/fDS9ePwShaiXyy2tx59q9KKu2tL4hEQUtBiE/cfiMEXqTHTq1AiN6RUtdDlHQGtUnBq/ddAm6h2tQWm3BHWv2YldJtdRlEZFEGIT8xLaGq8X6xECj4m4h6kz9E8Lxn1tHYGiPSNTbnHjw4/14b88JXlFGJEP8jesnGk6LjevL02JEXSE+TINX5gzD1YMT4BKB5zcXY9HXR2B1uKQujYi6EIOQHzCY7Dh4qh4AMK4fgxBRawSh4SG0+vCs3/R5A41Kgb9ekYEHL+sHhQB8efA07np3H8o5bohINiS71xj9ZsfZq8UGdA9Ht/AQiash8m8qhSfQVFmdaO1ElgDAUm2G5Zx1wzVKqM9dRxBwa3YvDOgejie+PITCShNuW7MHT13ZH5elxXdOE0TkNxiE/EDDbNI8GkTUOqVCgNnhxq/Ha2Bztn4aKzxMC6PJCgDQqJTI6hOD2BBVs/FA2b2j8fatI/DnLw7hl4o6PPLpr7h9VDLuH5cClYLTWRAFK54ak5jD5cauUs8VKxMYhIjazOZ0wepwX/Rhc7hhc3q+Wh1u2FsJTt0jQvDqnGG4eUQSAOA/eeWY/9F+VJntXdESEUmAQUhie4/XwmR3ITZUjYGJEVKXQyR7KqUCD01KxZKrB0CnViC/rAa3vr0HP5+olbo0IuoEDEIS2352fNDYvrFQcDZpIr8xbUB3/GfuCKTE6lBptOO+93/B2t3HeYk9UZBhEJJYw/ig8TwtRuR3+saFYvXcTEzN6AaXW8Q/vz+Khz45iBqzQ+rSiMhHGIQkVFZtQVm1BUqFgNF9eLd5In8UplFh6YwBWDg5DRqlgB+OVuGWt3djd3mN1KURkQ8wCEnoh6MGAEBmryiEh/ACPqKu4M0cRA0PhUKBm0YkYfXcEegT4zlVlvPBL3htRwlcbp4qIwpk/O0roc2FegC8Woyoq3gzB1FL4qO0eGPeCPzzuyJ8cfA0Vu4sQ355Lf42fQASIjgHGFEgYhCSyOl6G/adqAMATE7npG1EXcHbOYjO1zAP0VNXDcCoPtF45psi7D1ei7lv7cZfr+yPCalxnVA1EXUmnhqTyHdHKgEAw5MikRiplbgaInlpyxxELT3OnYfoqoEJeHveCAzoHo5aqxMPfXIQyzYV8V5lRAGGQUgiGws8Qejy/t0kroSI2qt3jA6rbh7eOAHjur0VuG3NXhw+bbzgNt6MTbrQPdKIyHd4akwCJ2otOHiqHgoBmJzBIEQUyDQqzwSMo/vE4G8bj+CYwYw71u7FvWP74LaRyVCec3sOBwCjzdmuzzn/HmlE5BsMQhL49rBnkPSIXlGID9NIXA0R+cK4frF477YsLPnmCL4vMmDFDyX44WgVnpyWgZS4UAiCAKPNid2l1a3e6uN8F7tHGhF1DE+NSeCbw2dPiw3oLnElROSti11+HxOmwXPXDMZTV/ZHmEaJXyrqcMvbu/HmrjI43W4AgL0d45O8DU5E1HY8ItTFSqvMOHzGCKUATE7j1WJEgaStl9+PTY/Hq4kR+NemIuSX1WDFDyX4+nAlciendVmtRNQ2DEJdrOFo0Mg+MYgO5Rl/okDi7eX3MwZ3R+8YLb769QyKK0148P2fkd07GmP7xkKnVnZBxUTUGgahLtYQhKbxajGigNVw+X1b9O8egV7ROnxfaMAvFXXIK63B/op6TEyLwyVJkbwijEhiHCPUhYr1Jhw1mKFWCpjI02JEshGmUeGW7CT8bdYgdAvXwOJw4atDZ7A6rxylVWapyyOSNQahLtRwNGhMnxhEaHkwjkhuLukVjQfGp2BKRjxCVAqcqrNh7e4TeHf3cVTUWqUuj0iW+Nu4i9idbny6/xQAYBqvFiOSLaVCwKg+MRicGIHtx6qw93gtSqosKMkrR3q3MIztG4ueUZxtnqirMAh1kS9/PQ29yY7u4RpMyeBpMSK5CwtRYdqA7hjVJwY/HDXgQEU9CitNKKw0oVe0FqN6xyC9exgUHENE1KkYhLqAyy3i7Z/KAQBzs3tBreQZSSLyiNapMWNwIsb0icXOkir8eqoex2usOF5zEtE6NS5JikRmryipyyQKWgxCXeC7I5Uor7EiSqvCdcN6SF0OEfmh+HANZg5JxMS0eOw5XoM9x2tRY3FgS5EBW4oM+PaIHtcMScTE1DhOvUHkQwxCnUwURazO8xwNuikziXOHENFFRWhVuCwtHmP7xuLQqXocOFWPsioLDlTU4UBFHZYCGNIjAuP6xWJ83zhkdA/jJfhEHcAg1Ml2lFSjsNIEnVqBOZk9pS6HiAKEWqnAsKQoDEuKgs3pQp3Nha2FehypNGH/yXrsP1mPV7aXIlqnxvCkSAxPisLwXlHo3z0caiWDEVFbMQh1sv+cPRp03bAeiNLxcDYReS9Kp8aVQ3rg/rEpOFVnxfZjVdh+tAp5pdWosTjwfZEB3xcZAAA6tQJDe0ZiXHp39I/VYnBiBLQ8Ek10QQxCnejnE7XYe7wWKoWAW7J6SV0OEQWBhIgQXD+sB64f1gMOlxuHThux73gt9p6oxc8n6lBvcyKvtAZ5pTUAAKUA9IsPw6DECAxKjMDghAikxodCxYs2iAAwCHUatyjitR2lAICrByUgISJE4oqIKJA13PUe+O20l0alxCVJUbgkKQq3w/PvzlG9CXtP1OLXSjN2FetxxmhvvCy/YS6zEJUCGd3CMSgxHIMSI5AWH4aU2FBoVAxHJD8MQp3k9Z2lyCurgVop4LZRyVKXQ0QBrK13vQeA2EgtpkZqMTNLA7MpBZUmOw6fNqJEb8KhU/U4dLoeRpsL+0/WYf/JusbtlAoBvWN0SIsPQ1p8GFLjw5AaH4qeUVrOZURBjUGoE2wu1GPlzjIAwJ+npqN3jE7iiogokHl713sACA/Twmjy3LZDp1Li1tG9ERuigsvtRnm1Bb+ersfBk/U4fMaIIr0JRpsLxwxmHDOYG28HBAChaiX6xYci9WxAanjwEn4KFgxCPlasN+Gprw4DAG7K7ImZQxIlroiIgkVb73ovAFA73bA53I1HkBpOrSkVCqTEhSElLgzTB3n+fRJFEWeMdhRVekJRkd6E4koTjlWZYXa4cOBkPQ6crG/yGXFhGqSdDUj9u4djYEIE+sTqLnj0qL2X+Itia8fAiDqGQciHai0OPPLpQZgdLmQnRyH3sn5Sl0RE1KZTa2qNEgOTojAw6bdZrJ0uN07UWnGqxoISg9kTkipNOFFrhcFkh8Fkx66zg7IBz9GjAQnhyOgejpTYUPSNC0VKbCjCdSqY7G07knU+rUoB0emGQgBUSgWUQvtDFVFLGIR8pKTKjL9/fQTHa6zoGRmCp2cM4lUZROQX2nNqrUGoRoXfpcVjTD+xMURZ7C6UVJlRYjDhmMGMojMmFFYaYXa4sOd4LfYcr23yHiEqBbQqBbRqJXRqBTQqBUTRM7jbLQJutwiHW4TD5YbTJcLhdsPhEuF0ueE6L7kJANRKAaEaFSK1KkSEeL42PBJiwqByuxuXR2h/Wy9Kp4ZWpWCQoiYkC0IGgwFPPvkk8vLyoFQqMWvWLDz22GNQqZqXtGXLFixbtgzl5eXo0aMHHn30UUyaNKnx9ZUrV+Ltt99GXV0dhg4dikWLFqFfv645GlNndeD1nWV4f18FXG4ROrUCz10zmOfPicjvtPXU2rlCVO4LhqhorQqZSZHITIqEWxShN9pxotaKM/U26I12VJrsqDE7YHO6YXO6UWt1drgHEYDdJcJucaDG4vB6e5VCQKRWhTCNEiqlAmqFAJVSAZVCgFopnP3qea5UCFAKAhRn/6wSBCgUgFLwPPcEPCW0ak/I06oU0KnPPld5Ql/I2eUNIVCrUkKpYBDzJ5IFodzcXCQkJGDbtm3Q6/V44IEHsHr1atx9991N1ispKcH8+fPxwgsvYOLEidi4cSNyc3OxceNGJCQkYP369Xj77bexatUq9O7dG//85z+xYMECfP75552W+q0OFw6fMWLv8Vq8k3+88S/3+H6xePCyfkiJDe2UzyUikkpbQlSkVo1IrRoDEyIal4VqFEiIDkP+MQNqrQ5Y7G44XG4oFAIUAiBAgFIBqBQKqJRCk2ASrVNhdGo81AoBblGE0y3C5RbhcIkw212otzpgtDlRb/vtz1aXiGqjDfU2Fyx2J+ptTtRbnai1OuFye96jyuxAldn7EOUraqXgCUxnA5K28c+/BSitWokQlQJqhcITyBRCYzhTnfPnEJUCOo0S3WNNcFjsTQKZ7pz34xmKC5MkCJWWliIvLw9bt26FTqdDcnIycnJy8NxzzzULQuvXr0d2djamTp0KAJg+fTo+/vhjrFu3DgsWLMD777+PW265Benp6QCAhx9+GO+//z527dqFMWPG+Kxmp8uNlTtLsf1YNYr0Jrjcvx2v7RsXij9N7IffpcT67POIiIKBWqlAYpQWSdFaxDk0Xm0bpVNBrVK2ekovQqNAhCYEQEjj1XKhGhUy+8RAdHtO6YmiCKvDjXqbE0abE2a7C063G063CKdLPPv17POzgUshCLA6XXC5RbhFES43zvmzCPvZI11WhwvWc/5sc7phd7lhcXjCo83pajJw3eES4XA5UXfBjnxPpRB+C0fnhCW1SgH3Of15TleKcJ09Zen5s6dftxu//fnsV5fYdHnD78aG4xDC2SfC2WWer78dpBAAKATh7ED+s18Fz5i2hvFgygu8HhGixCfzJ3T8e9Phd2iHwsJCREdHIyEhoXFZamoqKioqUFdXh8jIyMblRUVFyMjIaLJ9WloaCgoKGl+/5557Gl9Tq9VISUlBQUGBV0FIEADFRQJzZZ0d7+87CQDQqZWI1anQPzECY1NiMX1wd6h8eKjTs6OBsBAV1Ervz+crBCBce/FtBQEI1Sgh6JQ496KMtm7fkc/ujO070ncg1N3RbX3dd6B8z87vO1Dq7ui2vuzbH75napUAt9j6v7GC4PmFr1F5jpRYnW4cO1MPu6vlI1lKAVAqBYQ03pvtt1uRhGlU6BUXdtHtL6SlbcWG8OTyHNGyO91wut1nn7vhcHrGRQkCoNOqcbrWDKtDhPts2BDPBhPXOeOqnKLoCXMuEU4RsNqdcLhEiKIIm8sNq8ONc/7PDhGA2eE51ek7ntOFCgjo6J1c3CIAEXDh7B9aYbT75tYxkgQhk8kEna7p3DoNz81mc5Mg1NK6Wq0WZrO5Ta+3VWxsxEVfj4uLwIFFV3j1nh0RCyC1Z3S7tx+SHNOhz+/I9oH62axbPp/NuuXz2YFaN3UdSU4ahoaGwmKxNFnW8DwsLKzJcp1OB6vV2mSZ1WptXK+114mIiIguRJIglJ6ejpqaGuj1+sZlxcXFSExMRERE0yMzGRkZKCwsbLKsqKiocUxQenp6k9cdDgdKSkqanU4jIiIiOp8kQSglJQVZWVlYunQpjEYjysvLsWLFCsyePbvZurNmzUJeXh42bNgAp9OJDRs2IC8vD9dccw0A4IYbbsA777yDgoIC2Gw2PP/884iPj0d2dnZXt0VEREQBRhAlmr9cr9dj8eLF2LVrFxQKBa699lo88sgjUCqVyMzMxKJFizBr1iwAwLZt27Bs2TKUlZUhKSkJCxcuxGWXXQbAMwDtzTffxJo1a1BVVdU4j1Dfvn2laIuIiIgCiGRBiIiIiEhqnGGJiIiIZItBiIiIiGSLQYiIiIhki0GIiIiIZEvWQchgMCAnJwfZ2dkYPXo0lixZAqez43dH9ncbNmzAoEGDkJmZ2fhYuHCh1GV1mqqqKlx++eXYtWtX47Kff/4ZN954IzIzMzF58mR88MEHElbYOVrq+69//SuGDBnSZN+vW7dOwip9o6CgAHfeeSdGjRqFcePG4dFHH0VVVRWA4N7XF+s7WPd1g507d+LGG2/EiBEjMG7cOPztb39rnFw3mPf5xfoO9n3ucrkwb948PP74443LfLKvRRm79dZbxYcfflg0m81iWVmZePXVV4srV66UuqxO98wzz4iPP/641GV0ifz8fHHq1KliRkaG+OOPP4qiKIo1NTXiqFGjxHfeeUd0OBzijh07xMzMTPHnn3+WuFrfaalvURTF6667Tvz4448lrMz3LBaLOG7cOPHFF18UbTabWFVVJd5zzz3ifffdF9T7+mJ9i2Jw7usGBoNBHDp0qPjRRx+JLpdLPH36tDhjxgzxxRdfDOp9frG+RTG497koiuK//vUvccCAAeJjjz0miqLv/i2X7RGh0tJS5OXlYeHChdDpdEhOTkZOTg7WrFkjdWmdbv/+/RgyZIjUZXS69evX45FHHsGf/vSnJss3btyI6OhozJ07FyqVCr/73e8wc+bMoNn3F+rbbrfjyJEjQbfvKyoqMGDAAPzhD3+ARqNBTEwMbrrpJvz0009Bva8v1new7usGsbGx2LFjB66//noIgoCamhrYbDbExsYG9T6/WN/Bvs937tyJjRs3Ytq0aY3LfLWvZRuECgsLER0djYSEhMZlqampqKioQF1dnYSVdS63242DBw/i+++/x6RJk3DppZfiySefRG1trdSl+dz48ePxzTffYPr06U2WFxYWNrsFS1paGgoKCrqyvE5zob4LCgrgdDqxfPlyjB07FldccQVee+01uN2+vBN11+vXrx9ef/11KJW/3Yn666+/xuDBg4N6X1+s72Dd1+cKDw8HAFx22WWYOXMmunXrhuuvvz6o9zlw4b6DeZ8bDAY88cQTeP7555vcZN1X+1q2Qailu9Y3PPf2zvWBpKqqCoMGDcIVV1yBDRs24L333kNJSUlQjhHq1q0bVCpVs+Ut7XutVhs0+/1CfdfX12PUqFGYN28etmzZgueeew5vv/023njjDQmq7ByiKOKf//wnNm/ejCeeeCLo93WD8/uWw75usHHjRmzduhUKhQILFiyQzT4/v+9g3edutxsLFy7EnXfeiQEDBjR5zVf7WrZBKDQ0tPGO9w0angfznevj4+OxZs0azJ49GzqdDj179sTChQuxdetWGI1GqcvrEjqdrnFwYQOr1RrU+x0Axo0bh7feegujRo2CWq3GsGHDcPvtt2PDhg1Sl+YTRqMRCxYswOeff4533nkH/fv3l8W+bqnvYN/X59JqtUhISMDChQuxbds2WexzoHnfQ4YMCcp9/uqrr0Kj0WDevHnNXvPVvpZtEEpPT0dNTQ30en3jsuLiYiQmJiIiIkLCyjpXQUEBli1bBvGcO6vY7XYoFApoNBoJK+s6GRkZKCwsbLKsqKgI6enpElXUNb799lu89957TZbZ7XZotVqJKvKdsrIy3HDDDTAajfjwww/Rv39/AMG/ry/UdzDvawDYs2cPrrzyStjt9sZldrsdarUaaWlpQbvPL9b39u3bg3Kff/rpp8jLy0N2djays7PxxRdf4IsvvkB2drbP/n7LNgilpKQgKysLS5cuhdFoRHl5OVasWIHZs2dLXVqnio6Oxpo1a/D666/D6XSioqICzz33HK677jrZBKHLL78cer0eq1evhsPhwI8//ojPP/8cN9xwg9SldSpRFPH0009j586dEEURe/fuxVtvvYWbbrpJ6tI6pLa2FrfffjtGjBiBVatWITY2tvG1YN7XF+s7WPd1g/79+8NqteL555+H3W7HiRMn8I9//AOzZ8/GFVdcEbT7/GJ9q9XqoNzn//3vf7Fnzx7k5+cjPz8fM2bMwIwZM5Cfn++zv9+yvumqXq/H4sWLsWvXLigUClx77bV45JFHmgw+DEZ5eXl44YUXcOTIEYSEhODqq6/GwoULERISInVpnaZ///546623MHr0aACeK+eWLFmCI0eOIDY2Fjk5Obj++uslrtL3zu/7vffew5tvvonTp08jPj4ed955J+bOnStxlR3z5ptv4plnnoFOp4MgCE1e27t3b9Du69b6DsZ9fa6ioiIsXboU+/fvR0REBGbOnNl4BV2w7nPg4n0H+z4H0DiH0DPPPAPAN/+WyzoIERERkbzJ9tQYEREREYMQERERyRaDEBEREckWgxARERHJFoMQERERyRaDEBEREckWgxARERHJFoMQEVEXcLlcKC8vl7oMIjoPgxAR+cRf/vIXZGZmIjMzE0OHDsWAAQMan2dmZiI/P/+C23788ceYPHlyF1bb9f70pz/hk08+kboMIjqPSuoCiCg4LF68GIsXLwbgCTb//ve/sWnTJomr8h/V1dVSl0BELeARISLqEocPH8Y999yDUaNG4dJLL8VTTz2F+vr6ZuvZ7Xbcc889mDt3LoxGIwDgyy+/xMyZM5GVlYXrr78eP/zwQ+P68+bNw/PPP4+5c+ciMzMTV111FTZs2HDBOg4ePIh58+YhMzMT48ePx4svvoiGOw3l5+dj7ty5yM7OxuTJk/Gvf/2r8U7fL730EubNm9fkvSZPnoyPP/641TqeeOIJ5Ofn49VXX8X999/fge8iEfkagxARdbrq6mrcdtttSEtLw9atW/HRRx/h2LFjePTRR5usZ7Va8cADD0AURaxatQrh4eHYsmUL/vrXv+Ivf/kL8vLyMH/+fMyfPx+FhYWN273//vt44oknsGvXLkybNg1/+ctfYLPZmtVRU1ODu+66C6NHj8auXbuwdu1afPzxx1i3bh2OHj2KO++8E9OmTcOOHTvw5ptvYtOmTXj22Wfb3OeF6liyZAmys7Nx33334ZVXXmn/N5KIfI5BiIg63XfffQe1Wo1HHnkEWq0W3bp1w5NPPolNmzahsrISgOdI0P333w+9Xo8VK1ZAq9UCAN555x3cfPPNGDlyJJRKJSZNmoTJkyfjvffea3z/K664AoMGDYJGo8F1112H+vp6GAyGZnVs3rwZISEhjXfr7t27N958801MnDgRn3/+Ofr374/bb78dGo0Gffr0wcMPP4wPPvgAbre7TX22tQ4i8h8cI0REnc5gMKBnz55QKpWNy3r16gUAOHHiBACgsrISAwYMQHFxMQ4cOIARI0Y0vp6Xl4d33323cVuXy4UxY8Y0Pu/WrVvjn1Uqzz9rLYWXyspK9OjRA4IgNC7r169fY43JyclN1u/VqxesVmubw0xb6yAi/8EgRESdLikpCRUVFXC5XI1hqKysDIAnPBw9ehTdu3fHypUr8eyzz+Lxxx/HJ598gtDQUCQmJuLaa6/Fvffe2/h+FRUVjUeMvJGYmIiTJ09CFMXGMPTtt9/CaDQiKSkJGzdubLJ+WVkZNBoNoqKioFAo4HA4Gl9zu92oqanxugYi8i88NUZEne6yyy4DACxbtgxWqxWVlZVYsmQJxowZg6SkJACAWq2GIAjIzc2FQqHAP/7xDwDAnDlz8NZbb+GXX34BAOzfvx/XX389vvjiC6/rmDhxIpxOJ1555RXY7XaUlZVh6dKlsNlsuPrqq1FcXIz//Oc/ja+98MILmDlzJjQaDVJTU3H48GEUFhbC6XTi9ddfh9lsbvNnazSaFgeHE5G0eESIiDpdREQE3nzzTTzzzDONoWjKlCnNBksDQEhICJ5++mnMnTsXU6ZMwZVXXgmz2Yz//d//RUVFBaKjo3HHHXc0u4KrLSIjI7Fq1So8/fTTePPNN6HT6TB37lzcdNNNAIDXX38dL7zwAl566SVotVrMmDEDubm5AICpU6dix44duOOOO+B2u3HttdciKyurzZ997bXX4qmnnsKBAwewdu1ar2snos4hiA3XjRIRERHJDE+NERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFsMQgRERGRbDEIERERkWwxCBEREZFs/X/8MNf3o0nrJAAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.distplot(token_lens)\n",
    "plt.xlim([0, 40])\n",
    "plt.xlabel('Token count')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:28.118582Z",
     "start_time": "2024-11-12T20:43:27.675103Z"
    }
   },
   "id": "82787cfc362ec257",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_LEN = 30 #50 #128  # wiekszosc tokenow zdaje sie byc ponizej 40, klasycznie wklada sie tu 256, my przystaniemy na 30\n",
    "TRAIN_BATCH_SIZE = 32 #8 #16 #32 \n",
    "#Czasami, przy bardzo niskim tempie uczenia i zbyt dużych batchach, model może wolniej konwergować. Spróbuj zmniejszyć wielkość batcha, np. z 16 do 8.\n",
    "VALID_BATCH_SIZE = 32 #8 #16 #32\n",
    "TEST_BATCH_SIZE = 32 #8 #16 #32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05 #1e-05\n",
    "# Ustawienie bardzo niskiego współczynnika uczenia (np. 1e-05) może spowodować, że model uczy się bardzo wolno, co prowadzi do sytuacji, w której po wielu epokach nie ma znaczącej poprawy w wynikach walidacji.\n",
    "\n",
    "THRESHOLD = 0.5 # threshold for the sigmoid\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:28.122216Z",
     "start_time": "2024-11-12T20:43:28.119588Z"
    }
   },
   "id": "4169540c849c5cc3",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "\n",
    "# 1. Synonym Replacement\n",
    "def synonym_replacement(text):\n",
    "    words = text.split()\n",
    "    new_words = words[:]\n",
    "    num_replacements = max(1, len(words) // 5)  # Replace about 20% of words\n",
    "    random_words = random.sample(words, num_replacements)\n",
    "\n",
    "    for word in random_words:\n",
    "        synonyms = wordnet.synsets(word)\n",
    "        if synonyms:\n",
    "            #synonym = synonyms[0].lemmas()[0].name()  # Take first synonym\n",
    "            synonym = random.choice(synonyms).lemmas()[0].name()\n",
    "            if synonym != word:  # Avoid replacement if the synonym is identical\n",
    "                new_words = [synonym if w == word else w for w in new_words]\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "\n",
    "# 2. Random Insertion\n",
    "def random_insertion(text, n=1):\n",
    "    words = text.split()\n",
    "    for _ in range(n):\n",
    "        new_word = random.choice(words)\n",
    "        insert_pos = random.randint(0, len(words))\n",
    "        words.insert(insert_pos, new_word)\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "# 3. Random Deletion\n",
    "def random_deletion(text, p=0.3):\n",
    "    words = text.split()\n",
    "    if len(words) == 1:\n",
    "        return text  # Avoid deleting single-word text\n",
    "    new_words = [word for word in words if random.uniform(0, 1) > p]\n",
    "    if not new_words:\n",
    "        return random.choice(words)  # Return one word if all words are deleted\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "# 4. Back Translation\n",
    "def back_translation(text, src_lang='en', mid_lang='fr', max_retries=3):\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            translated = GoogleTranslator(source=src_lang, target=mid_lang).translate(text)\n",
    "            back_translated = GoogleTranslator(source=mid_lang, target=src_lang).translate(translated)\n",
    "            return back_translated\n",
    "        except Exception as e:\n",
    "            print(f\"Back translation error on attempt {attempt + 1}: {e}\")\n",
    "            attempt += 1\n",
    "            time.sleep(1)\n",
    "    raise ValueError(\"Back translation failed\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:28.128431Z",
     "start_time": "2024-11-12T20:43:28.123223Z"
    }
   },
   "id": "df8410a8704c0089",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def augment_text(text, num_augments=2):\n",
    "    augmented_texts = []\n",
    "    for _ in range(num_augments):\n",
    "        augmentation_choice = random.choice(['synonym', 'insertion', 'deletion', 'back_translation'])\n",
    "        if augmentation_choice == 'synonym':\n",
    "            augmented_texts.append(synonym_replacement(text))\n",
    "        elif augmentation_choice == 'insertion':\n",
    "            augmented_texts.append(random_insertion(text))\n",
    "        elif augmentation_choice == 'deletion':\n",
    "            augmented_texts.append(random_deletion(text))\n",
    "        elif augmentation_choice == 'back_translation':\n",
    "            augmented_texts.append(back_translation(text))\n",
    "    return augmented_texts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:28.132541Z",
     "start_time": "2024-11-12T20:43:28.129437Z"
    }
   },
   "id": "1e0bdc2c2e2c2b44",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split into train and test\n",
    "df_train, df_test = train_test_split(df_data, random_state=77, test_size=0.30, shuffle=True)\n",
    "# split test into test and validation datasets\n",
    "df_test, df_valid = train_test_split(df_test, random_state=88, test_size=0.50, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T20:43:28.140099Z",
     "start_time": "2024-11-12T20:43:28.133548Z"
    }
   },
   "id": "830a2b086cc6cd51",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting class 2: 0it [00:00, ?it/s]\n",
      "Augmenting class 1:  50%|█████     | 2636/5272 [27:44<27:44,  1.58it/s]  \n",
      "Augmenting class 0:  45%|████▌     | 2601/5740 [27:18<32:57,  1.59it/s]  \n"
     ]
    }
   ],
   "source": [
    "class_counts = df_train['label'].value_counts()\n",
    "max_count = class_counts.max()\n",
    "\n",
    "augmented_data = {'Utterances': [], 'label': []}\n",
    "\n",
    "for label in class_counts.index:\n",
    "    class_subset = df_train[df_train['label'] == label]\n",
    "    augmented_data['Utterances'].extend(class_subset['Utterances'])\n",
    "    augmented_data['label'].extend(class_subset['label'])\n",
    "\n",
    "    num_to_augment = max_count - len(class_subset)\n",
    "    for _, row in tqdm(class_subset.iterrows(), total=num_to_augment, desc=f\"Augmenting class {label}\"):\n",
    "        if num_to_augment <= 0:\n",
    "            break\n",
    "        new_texts = augment_text(row['Utterances'], num_augments=2)\n",
    "        for new_text in new_texts:\n",
    "            if num_to_augment <= 0:\n",
    "                break\n",
    "            augmented_data['Utterances'].append(new_text)\n",
    "            augmented_data['label'].append(label)\n",
    "            num_to_augment -= 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:38:31.819645Z",
     "start_time": "2024-11-12T20:43:28.140099Z"
    }
   },
   "id": "c754ed339547d7bc",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data saved to 'balanced_augmented_data.csv'\n"
     ]
    }
   ],
   "source": [
    "augmented_df = pd.DataFrame(augmented_data)\n",
    "\n",
    "augmented_df.to_csv('balanced_augmented_data.csv', index=False)\n",
    "print(\"Augmented data saved to 'balanced_augmented_data.csv'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:53:20.019371Z",
     "start_time": "2024-11-12T21:53:19.991353Z"
    }
   },
   "id": "704a320f25d50fab",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "augmented_data = {'Utterances': [], 'label': []}\n",
    "\n",
    "for index, row in tqdm(df_train.iterrows(), total=len(df_train), desc=\"Augmenting data\"):\n",
    "    original_text = row['Utterances']\n",
    "    sentiment_labels = row[['label']].tolist()\n",
    "    #emotion_labels = row[['emotion_1', 'emotion_2', 'emotion_3', 'emotion_4', 'emotion_5', 'emotion_6', 'emotion_7', 'emotion_8', 'emotion_9']].tolist()\n",
    "    #intensity_labels = row[['intensity_1', 'intensity_2', 'intensity_3']].tolist()\n",
    "\n",
    "    augmented_data['Utterances'].append(original_text)\n",
    "    augmented_data['label'].append(sentiment_labels)\n",
    "    #augmented_data['Emotion_Labels'].append(emotion_labels)\n",
    "    #augmented_data['Intensity_Labels'].append(intensity_labels)\n",
    "\n",
    "    new_texts = augment_text(original_text, num_augments=2)\n",
    "    for new_text in new_texts:\n",
    "        augmented_data['Utterances'].append(new_text)\n",
    "        augmented_data['label'].append(sentiment_labels)  # Kopiuj etykiety do nowych przykładów\n",
    "        #augmented_data['Emotion_Labels'].append(emotion_labels)\n",
    "        #augmented_data['Intensity_Labels'].append(intensity_labels)\n",
    "\n",
    "augmented_df = pd.DataFrame(augmented_data)\n",
    "#augmented_df.to_csv('augmented_data.csv', index=False)\n",
    "#print(\"Augmented data saved to 'augmented_data.csv'\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae95de2a84419ff8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "augmented_df.to_csv('augmented_data.csv', index=False)\n",
    "print(\"Augmented data saved to 'augmented_data.csv'\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "477c96b92f2d9584",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train size: (14011, 2)\n",
      "Augmented train size: (24485, 2)\n",
      "Validation size: (3003, 2), Test size: (3003, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original train size: {df_train.shape}\")\n",
    "print(f\"Augmented train size: {augmented_df.shape}\")\n",
    "\n",
    "df_train = augmented_df\n",
    "\n",
    "print(f\"Validation size: {df_valid.shape}, Test size: {df_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:53:45.243173Z",
     "start_time": "2024-11-12T21:53:45.239121Z"
    }
   },
   "id": "18268b76af386902",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "2    34.065755\n",
      "1    34.065755\n",
      "0    31.868491\n",
      "Name: proportion, dtype: float64\n",
      "label\n",
      "2    8341\n",
      "1    8341\n",
      "0    7803\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_frequencies = df_train['label'].value_counts()\n",
    "label_frequencies_percent = df_train['label'].value_counts(normalize=True) * 100\n",
    "print(label_frequencies_percent)\n",
    "print(label_frequencies)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:55:22.692792Z",
     "start_time": "2024-11-12T21:55:22.687121Z"
    }
   },
   "id": "2a65c8fb4f51be18",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "sentiment_0    0.186541\nsentiment_1    0.221462\nsentiment_2    0.591997\ndtype: float64"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns = multi_columns.columns\n",
    "#categor_freq = multi_columns[columns[1:]].sum() / multi_columns.shape[0]\n",
    "#categor_freq"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:53:55.315295Z",
     "start_time": "2024-11-12T21:53:55.309781Z"
    }
   },
   "id": "1869914ba83249b7",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_0     3734\n",
      "sentiment_1     4433\n",
      "sentiment_2    11850\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#class_distribution = multi_columns[['sentiment_0', 'sentiment_1', 'sentiment_2']].sum()\n",
    "#print(class_distribution)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:55:32.758520Z",
     "start_time": "2024-11-12T21:55:32.753963Z"
    }
   },
   "id": "48368f8e1c2dbc24",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "2    0.340658\n",
      "1    0.340658\n",
      "0    0.318685\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_distribution = df_train['label'].value_counts(normalize=True)\n",
    "print(class_distribution)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:58:33.647496Z",
     "start_time": "2024-11-12T21:58:33.642886Z"
    }
   },
   "id": "fc61b895ba4d755c",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x300 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Wykres rozkładu klas\n",
    "class_distribution.plot(kind='bar')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Sentiment Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:58:35.436548Z",
     "start_time": "2024-11-12T21:58:35.331344Z"
    }
   },
   "id": "fed0bbea9aac8025",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x300 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 3)\n",
    "plt.bar(categor_freq.index, categor_freq.values)\n",
    "_ = plt.xticks(rotation=45)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:58:37.610087Z",
     "start_time": "2024-11-12T21:58:37.516397Z"
    }
   },
   "id": "bc155bc55d6fc25d",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (24485, 2), Test: (3003, 2), Valid: (3003, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {df_train.shape}, Test: {df_test.shape}, Valid: {df_valid.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:58:51.257346Z",
     "start_time": "2024-11-12T21:58:51.254291Z"
    }
   },
   "id": "4c04b06158609497",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.utterances = list(df['Utterances'])\n",
    "        # Upewnij się, że etykiety są typu całkowitego (int)\n",
    "        self.targets = self.df['label'].astype(int).values \n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.utterances)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        utterances = str(self.utterances[index])  # 'index' jest prawidłowe\n",
    "        #utterances = \" \".join(utterances.split())  # Usuwa niepotrzebne białe znaki\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            utterances,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        target = torch.tensor(self.targets[index], dtype=torch.long)  # Zapewnij typ long\n",
    "        # print(f\"Target dtype: {target.dtype}\")  # Debugging\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.long),  # Zapewnij typ long\n",
    "            'utterances': utterances\n",
    "        }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:58:52.791852Z",
     "start_time": "2024-11-12T21:58:52.787072Z"
    }
   },
   "id": "a3fcc26e8264f157",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['label']"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list = list(df_data.columns)\n",
    "target_list = target_list[1:]\n",
    "target_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:58:55.462658Z",
     "start_time": "2024-11-12T21:58:55.459340Z"
    }
   },
   "id": "73bfd1a79a83c61a",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN)\n",
    "valid_dataset = CustomDataset(df_valid, tokenizer, MAX_LEN)\n",
    "test_dataset = CustomDataset(df_test, tokenizer, MAX_LEN)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:58:56.306741Z",
     "start_time": "2024-11-12T21:58:56.299409Z"
    }
   },
   "id": "aa6ba75832e16a38",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                batch_size=TRAIN_BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0\n",
    "                                                )\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                              batch_size=VALID_BATCH_SIZE,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=0\n",
    "                                              )\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size=TEST_BATCH_SIZE,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0\n",
    "                                               )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:58:57.311856Z",
     "start_time": "2024-11-12T21:58:57.308292Z"
    }
   },
   "id": "12d6b5e711313422",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = next(iter(train_data_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:58:58.476374Z",
     "start_time": "2024-11-12T21:58:58.451365Z"
    }
   },
   "id": "1e81afbd88da7754",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'token_type_ids', 'targets', 'utterances'])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())\n",
    "\n",
    "print(data['input_ids'].shape)\n",
    "print(data['attention_mask'].shape)\n",
    "print(data['targets'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:58:59.638769Z",
     "start_time": "2024-11-12T21:58:59.635847Z"
    }
   },
   "id": "ac8f47a2b68e7431",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "last_hidden_state, pooled_output = bert_model(\n",
    "    input_ids=encodings['input_ids'],\n",
    "    attention_mask=encodings['attention_mask']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:59:02.194160Z",
     "start_time": "2024-11-12T21:59:00.435784Z"
    }
   },
   "id": "f51dd2fe8bb830a6",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "768"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.config.hidden_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T21:59:02.198904Z",
     "start_time": "2024-11-12T21:59:02.195164Z"
    }
   },
   "id": "eb9bbe80508adf34",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "BERTSentimentClass(\n  (bert_model): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (linear): Linear(in_features=768, out_features=3, bias=True)\n)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERTSentimentClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTSentimentClass, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=True)\n",
    "        self.dropout = torch.nn.Dropout(p=0.3) #0.5\n",
    "        self.linear = torch.nn.Linear(bert_model.config.hidden_size, 3)\n",
    "        #self.softmax = nn.Softmax(dim=1) #remove for sentiment analysis\n",
    "        #CrossEntropyLoss automatycznie aplikuje funkcję softmax, więc nie ma potrzeby używać Softmax w modelu.\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids,\n",
    "            attention_mask=attn_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        #pooler_output = self.pooler_output\n",
    "        dropout_output = self.dropout(output.pooler_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        #output = self.dropout(linear_output)\n",
    "        # output = self.softmax(linear_output)\n",
    "        return linear_output\n",
    "\n",
    "model = BERTSentimentClass()\n",
    "\n",
    "# # Freezing BERT layers:\n",
    "#for name, param in model.bert_model.named_parameters():\n",
    "#    if \"encoder.layer.10\" in name or \"encoder.layer.11\" in name:\n",
    "#        param.requires_grad = True\n",
    "#    else:\n",
    "#        param.requires_grad = False\n",
    "\n",
    "model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T22:01:03.676539Z",
     "start_time": "2024-11-12T22:01:03.357882Z"
    }
   },
   "id": "6b173035f9a453ad",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n"
     ]
    }
   ],
   "source": [
    "input_ids = data['input_ids'].to(device)\n",
    "attention_mask = data['attention_mask'].to(device)\n",
    "print(input_ids.shape) # batch size x seq length\n",
    "print(attention_mask.shape) # batch size x seq length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T22:01:05.066440Z",
     "start_time": "2024-11-12T22:01:05.062943Z"
    }
   },
   "id": "7384a11eae5618c1",
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "832cdad2864e4307"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#class_distribution = multi_columns[['sentiment_0', 'sentiment_1', 'sentiment_2']].sum()\n",
    "#total_samples = sum(class_distribution)\n",
    "#class_weights = [total_samples / count for count in class_distribution]\n",
    "#class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "#class_weights"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea3b10f21b6bef29",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2.9355, 2.9355, 3.1379])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_distribution = df_train['label'].value_counts(normalize=True)\n",
    "total_samples = sum(class_distribution)\n",
    "class_weights = [total_samples / count for count in class_distribution]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "class_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T22:02:06.332947Z",
     "start_time": "2024-11-12T22:02:06.316516Z"
    }
   },
   "id": "76c59d85dbe5fc53",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.CrossEntropyLoss(weight=class_weights)(outputs, targets)\n",
    "#change for sentiment analysis"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T22:02:09.885027Z",
     "start_time": "2024-11-12T22:02:09.882558Z"
    }
   },
   "id": "2e254869914b6694",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TensorBoard writer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir='logs')\n",
    "\n",
    "# Harmonogram zmiany learning rate\n",
    "from torch.optim.lr_scheduler import StepLR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T22:02:12.506640Z",
     "start_time": "2024-11-12T22:02:12.186825Z"
    }
   },
   "id": "b88113f1705b015b",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "EPOCHS = 10\n",
    "optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5, verbose=True)\n",
    "# Learning Rate Tuning\n",
    "#total_steps = len(train_data_loader) * EPOCHS\n",
    "#scheduler = get_linear_schedule_with_warmup(\n",
    "#    optimizer,\n",
    "#    num_warmup_steps=0,\n",
    "#    num_training_steps=total_steps\n",
    "#)\n",
    "#loss_fn = nn.CrossEntropyLoss().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T22:02:15.130192Z",
     "start_time": "2024-11-12T22:02:14.211626Z"
    }
   },
   "id": "e99ccc9880f86131",
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ce5b61268865d691"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regularization (Dodanie Weight Decay)\n",
    "Weight decay to inaczej L2 regularizacja, która zapobiega nadmiernemu dopasowaniu (overfittingowi). W Adam możesz dodać weight decay w następujący sposób:\n",
    "\n",
    "Dodanie Weight Decay do Optimizera: Ustaw wartość weight decay w optymalizatorze. Standardowe wartości mieszczą się w zakresie 1e-4 do 1e-5:\n",
    "\n",
    "python code\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "Analiza Wyników: Weight decay zmniejsza wielkość wag w czasie, co stabilizuje uczenie. Po dodaniu weight decay zwróć uwagę na to, czy train_loss i val_loss są bliżej siebie – powinny się zbliżyć, co jest oznaką redukcji overfittingu.\n",
    "\n",
    "Aby zwiększyć regularizację, możesz zastosować tzw. weight decay, czyli L2 regularizację, podczas tworzenia optymalizatora. weight decay dodaje karę (regularizację) na wagi modelu, co może pomóc w ograniczeniu przeuczenia (overfitting). Możesz kontrolować siłę regularizacji za pomocą wartości weight_decay przy tworzeniu optymalizatora, takiego jak Adam.\n",
    "\n",
    "Jak ustawić weight decay w optymalizatorze?\n",
    "Podczas inicjalizacji optymalizatora, dodaj parametr weight_decay i przypisz mu wartość, która określi siłę regularizacji. Przykładowo, weight_decay=0.01 to dobry punkt wyjścia, ale możesz testować różne wartości, takie jak 0.001, 0.01, czy 0.1, aby znaleźć optymalną dla Twojego modelu.\n",
    "\n",
    "# Inicjalizacja optymalizatora Adam z regularizacją L2\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "Rola weight_decay\n",
    "Wartość weight_decay=0.01 oznacza umiarkowaną regularizację.\n",
    "Wyższe wartości, np. weight_decay=0.1, zwiększają regularizację, co może zmniejszyć przeuczenie, ale też obniżyć dokładność na zbiorze treningowym.\n",
    "Niższe wartości, np. weight_decay=0.001 lub niższe, mają mniejszy wpływ na regularizację, ale mogą pomóc, jeśli model już ma dobrą dokładność na zbiorze walidacyjnym.\n",
    "\n",
    "Wybór Najlepszej Wartości\n",
    "Wybierz wartość weight_decay, która daje najlepszą równowagę między niskim val_loss a wysoką val_acc. Pamiętaj, że wyższe wartości weight_decay zwiększają regularizację, co może zmniejszyć overfitting, ale też potencjalnie obniżyć zdolność modelu do dopasowania się do danych.\n",
    "\n",
    "Zależność między learning rate a weight_decay\n",
    "Wyższe wartości weight_decay (np. 1e-2) wymagają zazwyczaj niższego learning rate, ponieważ większa regularizacja silniej wpływa na wagę parametrów, co stabilizuje model i zapobiega overfittingowi.\n",
    "Z kolei niższe wartości weight_decay (np. 1e-5 lub 1e-6) pozwalają na większą swobodę dopasowania modelu do danych i mogą lepiej działać przy nieco wyższym learning rate (np. 2e-5 lub 3e-5).\n",
    "\n",
    "\n",
    "7. Dalsze Kroki\n",
    "Layer-Wise Learning Rate: Możesz również eksperymentować z różnymi learning rates dla różnych warstw, co może jeszcze bardziej poprawić wyniki.\n",
    "Early Stopping: Dodaj mechanizm wczesnego zatrzymania treningu, aby uniknąć nadmiernego trenowania modelu.\n",
    "Eksperymenty z Hiperparametrami: Możesz rozważyć korzystanie z narzędzi do automatycznego tuningu hiperparametrów, takich jak Optuna czy Ray Tune, aby systematycznie znaleźć optymalne wartości.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79bc7b7db3c67783"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learning Rate Tuning\n",
    "\n",
    "Adaptacyjna redukcja learning rate za pomocą torch.optim.lr_scheduler.ReduceLROnPlateau pozwala obniżyć learning rate, kiedy model przestaje poprawiać wyniki. Możemy to zrobić w ten sposób:\n",
    "\n",
    "Inicjalizacja Optimizera i Schedulera\": przy optymalizatorze AdamW (lub innego). Po zdefiniowaniu optymalizatora dodaj ReduceLROnPlateau:\n",
    "\n",
    "python code\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # Początkowy learning rate\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5, verbose=True)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # Początkowy learning rate\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5, verbose=True)\n",
    "    mode='min': Zmniejsza learning rate, gdy minimalizowana jest wartość (np. val_loss).\n",
    "    patience=2: Liczba epok bez poprawy przed obniżeniem learning rate.\n",
    "    factor=0.5: Po jakim czynniku obniżyć learning rate (np. z 1e-3 na 5e-4).\n",
    "    verbose=True: Informuje w logach o zmianie learning rate.\n",
    "\n",
    "Wykorzystanie Schedulera podczas trenowania: Po zakończeniu każdej epoki przekaż do schedulera wynik val_loss, by sprawdzić, czy learning rate wymaga obniżenia:\n",
    "\n",
    "python code\n",
    "        scheduler.step(val_loss)\n",
    "Użycie scheduler.step(val_loss) automatycznie sprawi, że learning rate zostanie zmniejszony w miarę potrzeby.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b44e396491a02203"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(training_loader, model, optimizer):\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    model.train()\n",
    "    loop = tq.tqdm(enumerate(training_loader), total=len(training_loader), leave=True, colour='steelblue')\n",
    "\n",
    "    for batch_idx, data in loop:\n",
    "        ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "        targets = data['targets'].to(device, dtype=torch.long)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        correct_predictions += torch.sum(preds == targets).item()\n",
    "        num_samples += targets.size(0)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Log to TensorBoard and update progress bar\n",
    "        writer.add_scalar('Loss/train', loss.item(), epoch * len(training_loader) + batch_idx)\n",
    "        writer.add_scalar('Accuracy/train', correct_predictions / num_samples, epoch * len(training_loader) + batch_idx)\n",
    "        loop.set_description(f\"Epoch {epoch}\")\n",
    "        loop.set_postfix(batch_loss=loss.item())\n",
    "\n",
    "    return model, correct_predictions / num_samples, np.mean(losses)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T22:02:22.495078Z",
     "start_time": "2024-11-12T22:02:22.489524Z"
    }
   },
   "id": "dca06c411b50ef06",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def eval_model(validation_loader, model):\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(validation_loader, 0):\n",
    "            ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype=torch.long)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            # Calculate loss before applying argmax\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            correct_predictions += torch.sum(preds == targets).item()\n",
    "            num_samples += targets.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    writer.add_scalar('Loss/validation', np.mean(losses), epoch)\n",
    "    writer.add_scalar('Accuracy/validation', correct_predictions / num_samples, epoch)\n",
    "\n",
    "    return correct_predictions / num_samples, np.mean(losses)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T22:02:23.168720Z",
     "start_time": "2024-11-12T22:02:23.163719Z"
    }
   },
   "id": "4e92ef02b9630acb",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T22:02:24.242064Z",
     "start_time": "2024-11-12T22:02:24.239724Z"
    }
   },
   "id": "7bb674ce36fe972d",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "writer = SummaryWriter(log_dir='logs')\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, epoch):\n",
    "    figure = plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title(f'Confusion Matrix at Epoch {epoch}')\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    image = torch.tensor(np.frombuffer(buf.getvalue(), dtype=np.uint8)).float()\n",
    "    writer.add_image('Confusion Matrix', image, epoch)\n",
    "\n",
    "    plt.close(figure)  \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T22:02:25.455122Z",
     "start_time": "2024-11-12T22:02:25.449625Z"
    }
   },
   "id": "5033a49d36c4c44e",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c1f9311c7351447",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/766 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "620da2a601c34b668d8a1c1476651bea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.9839708331203959 accuracy 0.5094139268940168\n",
      "Val   loss 0.9517082090073443 accuracy 0.5208125208125208\n",
      "train_loss=0.9840, val_loss=0.9517, train_acc=0.5094, val_acc=0.5208\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/766 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2983d0ce9a19406d856f49eb360525c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6003183083263453 accuracy 0.7538084541556055\n",
      "Val   loss 1.1079074461409386 accuracy 0.5258075258075258\n",
      "train_loss=0.6003, val_loss=1.1079, train_acc=0.7538, val_acc=0.5258\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m<timed exec>:41\u001B[0m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[45], line 12\u001B[0m, in \u001B[0;36mBERTSentimentClass.forward\u001B[1;34m(self, input_ids, attn_mask, token_type_ids)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_ids, attn_mask, token_type_ids):\n\u001B[1;32m---> 12\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbert_model(\n\u001B[0;32m     13\u001B[0m         input_ids,\n\u001B[0;32m     14\u001B[0m         attention_mask\u001B[38;5;241m=\u001B[39mattn_mask,\n\u001B[0;32m     15\u001B[0m         token_type_ids\u001B[38;5;241m=\u001B[39mtoken_type_ids\n\u001B[0;32m     16\u001B[0m     )\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;66;03m#pooler_output = self.pooler_output\u001B[39;00m\n\u001B[0;32m     18\u001B[0m     dropout_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(output\u001B[38;5;241m.\u001B[39mpooler_output)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1142\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1135\u001B[0m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m \u001B[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001B[39;00m\n\u001B[0;32m   1137\u001B[0m \u001B[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001B[39;00m\n\u001B[0;32m   1138\u001B[0m \u001B[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001B[39;00m\n\u001B[0;32m   1139\u001B[0m \u001B[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001B[39;00m\n\u001B[0;32m   1140\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[1;32m-> 1142\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(\n\u001B[0;32m   1143\u001B[0m     embedding_output,\n\u001B[0;32m   1144\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mextended_attention_mask,\n\u001B[0;32m   1145\u001B[0m     head_mask\u001B[38;5;241m=\u001B[39mhead_mask,\n\u001B[0;32m   1146\u001B[0m     encoder_hidden_states\u001B[38;5;241m=\u001B[39mencoder_hidden_states,\n\u001B[0;32m   1147\u001B[0m     encoder_attention_mask\u001B[38;5;241m=\u001B[39mencoder_extended_attention_mask,\n\u001B[0;32m   1148\u001B[0m     past_key_values\u001B[38;5;241m=\u001B[39mpast_key_values,\n\u001B[0;32m   1149\u001B[0m     use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[0;32m   1150\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[0;32m   1151\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[0;32m   1152\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[0;32m   1153\u001B[0m )\n\u001B[0;32m   1154\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1155\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:695\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    684\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[0;32m    685\u001B[0m         layer_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[0;32m    686\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    692\u001B[0m         output_attentions,\n\u001B[0;32m    693\u001B[0m     )\n\u001B[0;32m    694\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 695\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m layer_module(\n\u001B[0;32m    696\u001B[0m         hidden_states,\n\u001B[0;32m    697\u001B[0m         attention_mask,\n\u001B[0;32m    698\u001B[0m         layer_head_mask,\n\u001B[0;32m    699\u001B[0m         encoder_hidden_states,\n\u001B[0;32m    700\u001B[0m         encoder_attention_mask,\n\u001B[0;32m    701\u001B[0m         past_key_value,\n\u001B[0;32m    702\u001B[0m         output_attentions,\n\u001B[0;32m    703\u001B[0m     )\n\u001B[0;32m    705\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    706\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:627\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    624\u001B[0m     cross_attn_present_key_value \u001B[38;5;241m=\u001B[39m cross_attention_outputs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    625\u001B[0m     present_key_value \u001B[38;5;241m=\u001B[39m present_key_value \u001B[38;5;241m+\u001B[39m cross_attn_present_key_value\n\u001B[1;32m--> 627\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m apply_chunking_to_forward(\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeed_forward_chunk, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunk_size_feed_forward, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseq_len_dim, attention_output\n\u001B[0;32m    629\u001B[0m )\n\u001B[0;32m    630\u001B[0m outputs \u001B[38;5;241m=\u001B[39m (layer_output,) \u001B[38;5;241m+\u001B[39m outputs\n\u001B[0;32m    632\u001B[0m \u001B[38;5;66;03m# if decoder, return the attn key/values as the last output\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\transformers\\pytorch_utils.py:248\u001B[0m, in \u001B[0;36mapply_chunking_to_forward\u001B[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001B[0m\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;66;03m# concatenate output at same dimension\u001B[39;00m\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat(output_chunks, dim\u001B[38;5;241m=\u001B[39mchunk_dim)\n\u001B[1;32m--> 248\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m forward_fn(\u001B[38;5;241m*\u001B[39minput_tensors)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:640\u001B[0m, in \u001B[0;36mBertLayer.feed_forward_chunk\u001B[1;34m(self, attention_output)\u001B[0m\n\u001B[0;32m    638\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfeed_forward_chunk\u001B[39m(\u001B[38;5;28mself\u001B[39m, attention_output):\n\u001B[0;32m    639\u001B[0m     intermediate_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintermediate(attention_output)\n\u001B[1;32m--> 640\u001B[0m     layer_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(intermediate_output, attention_output)\n\u001B[0;32m    641\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m layer_output\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:552\u001B[0m, in \u001B[0;36mBertOutput.forward\u001B[1;34m(self, hidden_states, input_tensor)\u001B[0m\n\u001B[0;32m    551\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor, input_tensor: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m--> 552\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdense(hidden_states)\n\u001B[0;32m    553\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(hidden_states)\n\u001B[0;32m    554\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLayerNorm(hidden_states \u001B[38;5;241m+\u001B[39m input_tensor)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    model, train_acc, train_loss = train_model(train_data_loader, model, optimizer)\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(val_data_loader, model)\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "\n",
    "    # Logowanie strat i dokładności do TensorBoard\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "    writer.add_scalar('Loss/validation', val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/validation', val_acc, epoch)\n",
    "\n",
    "    print(f'train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, train_acc={train_acc:.4f}, val_acc={val_acc:.4f}')\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), \"best_model_state.bin\")\n",
    "        best_accuracy = val_acc\n",
    "\n",
    "    scheduler.step(val_loss)     # Learning Rate Tuning\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in val_data_loader:\n",
    "            ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            preds = torch.argmax(outputs, axis=1).cpu().detach().numpy()\n",
    "            labels = targets.cpu().detach().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    # Oblicz confusion matrix\n",
    "    # cm = confusion_matrix(all_labels, all_preds)\n",
    "    # plot_confusion_matrix(cm, class_names=['class0', 'class1', 'class2'], epoch=epoch)\n",
    "\n",
    "writer.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T22:44:46.978714Z",
     "start_time": "2024-11-12T22:02:29.759440Z"
    }
   },
   "id": "abd94fa0b93e2013",
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Overfitting:\n",
    "Niski train_loss (0.2796) wskazuje na to, że model dobrze dopasowuje się do danych treningowych, ale wysoki val_loss (2.9933) oraz brak poprawy w val_acc (0.0000) sugerują, że model może się przeuczać, czyli dopasowuje się zbyt mocno do danych treningowych i traci zdolność do generalizacji na danych testowych.\n",
    "Rozwiązanie:\n",
    "Dodanie technik regularyzacyjnych, jak dropout, L2 regularization.\n",
    "Wykorzystanie większego zbioru danych.\n",
    "Zastosowanie wcześniejszego zatrzymania (early stopping), aby przerwać trening, gdy model zaczyna się przeuczać.\n",
    "# 2. Zbyt niski learning rate:\n",
    "Ustawienie bardzo niskiego współczynnika uczenia (np. 1e-05) może spowodować, że model uczy się bardzo wolno, co prowadzi do sytuacji, w której po wielu epokach nie ma znaczącej poprawy w wynikach walidacji.\n",
    "Rozwiązanie: Spróbuj zwiększyć learning rate np. do 1e-04 i zobacz, czy poprawia to wyniki. Zbyt niski współczynnik uczenia może blokować osiąganie optymalnych wyników.\n",
    "# 3. Zbyt skomplikowany model:\n",
    "Jeśli model jest zbyt złożony w stosunku do dostępnych danych, może to prowadzić do overfittingu. Model nauczy się bardzo dobrze danych treningowych, ale nie będzie w stanie dobrze generalizować.\n",
    "Rozwiązanie: Możesz spróbować uprościć model (np. mniejsza liczba warstw, mniejsza liczba neuronów) lub zebrać większy zbiór danych, jeśli to możliwe.\n",
    "# 4. Problemy z danymi:\n",
    "Dane walidacyjne mogą zawierać problemy, takie jak błędnie oznaczone próbki, brak różnorodności, lub mogą nie być reprezentatywne dla danych treningowych.\n",
    "Rozwiązanie: Sprawdź, czy dane walidacyjne są dobrze zrównoważone i poprawnie oznaczone. Ewentualnie przetestuj na innym zbiorze walidacyjnym.\n",
    "# 5. Złe inicjalizacje wag lub problemy z optymalizacją:\n",
    "Wysoki val_loss i brak poprawy w val_acc mogą wskazywać na problemy z optymalizacją. Np. złe inicjalizacje wag lub nieodpowiedni optymalizator mogą powodować, że model nie znajduje optymalnych rozwiązań.\n",
    "Rozwiązanie: Spróbuj zmienić optymalizator (np. Adam na RMSprop), lub zastosować inne techniki inicjalizacji wag.\n",
    "# 6. Zbyt zróżnicowane klasy:\n",
    "Jeśli Twoje klasy są bardzo niezrównoważone, to model może mieć problem z nauczeniem się klasyfikacji rzadkich klas.\n",
    "Rozwiązanie: Upewnij się, że klasy są zrównoważone lub użyj metod radzenia sobie z niezrównoważonymi danymi (np. class weights w funkcji straty).\n",
    "\n",
    "## 7. Optymalizacja i liczba epok: \n",
    "Jeśli model nie uczy się z oczekiwaną prędkością, możesz rozważyć tuning hiperparametrów, jak np. zmniejszenie wartości learning rate, co może pomóc modelowi lepiej uczyć się przy niższych wartościach początkowych. Możesz też wydłużyć trening, jeśli osiągalne wartości są powolne, ale stopniowo poprawiające się.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa92c9ea6f194565"
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://developers.google.com/machine-learning/crash-course/overfitting/regularization#early_stopping_an_alternative_to_complexity-based_regularization\n",
    "\n",
    "Picking the regularization rate\n",
    "The ideal regularization rate produces a model that generalizes well to new, previously unseen data. Unfortunately, that ideal value is data-dependent, so you must do some tuning.\n",
    "\n",
    "Early stopping: an alternative to complexity-based regularization\n",
    "Early stopping is a regularization method that doesn't involve a calculation of complexity. Instead, early stopping simply means ending training before the model fully converges. For example, you end training when the loss curve for the validation set starts to increase (slope becomes positive).\n",
    "\n",
    "Although early stopping usually increases training loss, it can decrease test loss.\n",
    "\n",
    "Early stopping is a quick, but rarely optimal, form of regularization. The resulting model is very unlikely to be as good as a model trained thoroughly on the ideal regularization rate.\n",
    "\n",
    "Finding equilibrium between learning rate and regularization rate\n",
    "Learning rate and regularization rate tend to pull weights in opposite directions. A high learning rate often pulls weights away from zero; a high regularization rate pulls weights towards zero.\n",
    "\n",
    "If the regularization rate is high with respect to the learning rate, the weak weights tend to produce a model that makes poor predictions. Conversely, if the learning rate is high with respect to the regularization rate, the strong weights tend to produce an overfit model.\n",
    "\n",
    "Your goal is to find the equilibrium between learning rate and regularization rate. This can be challenging. Worst of all, once you find that elusive balance, you may have to ultimately change the learning rate. And, when you change the learning rate, you'll again have to find the ideal regularization rate."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3019f67aedc2d335"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 7)\n",
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.grid()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f1c49aca7626a1b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "    ax.set_xlabel(\"Predicted labels\")\n",
    "    ax.set_ylabel(\"True labels\")\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    ax.set_xticklabels(class_names)\n",
    "    ax.set_yticklabels(class_names)\n",
    "    return fig\n",
    "\n",
    "# Tworzenie confusion matrix po ewaluacji\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Logowanie confusion matrix jako obraz\n",
    "fig = plot_confusion_matrix(cm, class_names=['class0', 'class1', 'class2'])\n",
    "writer.add_figure('Confusion matrix', fig, epoch)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd274764070cb547",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5303ae57d6d9c2f7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5f07c30edc7ba933"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
