{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T08:08:03.106515Z",
     "start_time": "2025-06-30T08:08:03.097554Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm.notebook as tq\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir='logs')\n",
    "#translator = Translator()\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MAX_LEN = 100\n",
    "BATCH = 32\n",
    "#PRE_TRAINED_MODEL_NAME = 'bert-base-cased' #\"roberta-base\" #'bert-base-cased'\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.00001 # dla MEISD\n",
    "LEARNING_RATE_FINE = 5e-6    # dla fine-tuningu na ESConv\n",
    "THRESHOLD = 0.2 #prog decyzyjny\n",
    "DROPOUT_RATE = 0.3\n",
    "WEIGHT_DECAY = 0.001\n",
    "LSTM_LAYERS = 2\n",
    "LSTM_HIDDEN_DIM = 128\n",
    "FOCAL_LOSS_ALFA = 4\n",
    "FOCAL_LOSS_GAMMA = 2\n",
    "MODE='min'\n",
    "PATIENCE=2\n",
    "FACTOR=0.5\n",
    "VERBOSE=True\n",
    "output_dir = './fine_tuned_bert_lstm_model'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-30T08:08:21.938401Z",
     "start_time": "2025-06-30T08:08:21.931105Z"
    }
   },
   "id": "7a7d5ffe51d43f10",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('C:/Users/juwieczo/DataspellProjects/meisd_project/data/filtered_negative_MEISD_intensity_max_first_25_conv.csv')\n",
    "df_llm_aug = pd.read_excel('C:/Users/juwieczo/DataspellProjects/meisd_project/pipeline/augmented_dataset_llm_70percent.xlsx')\n",
    "#df_data = pd.read_csv('C:/Users/juwieczo/DataspellProjects/meisd_project/pipeline/balanced_augmented_data_primary_intensity.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-30T08:08:23.869198Z",
     "start_time": "2025-06-30T08:08:22.789522Z"
    }
   },
   "id": "7511ba9431cb25f7",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'max_intensity'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:153\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:182\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'max_intensity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m label_frequencies \u001B[38;5;241m=\u001B[39m \u001B[43mdf_llm_aug\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_intensity\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mvalue_counts()\n\u001B[0;32m      2\u001B[0m label_frequencies_percent \u001B[38;5;241m=\u001B[39m df_llm_aug[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_intensity\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mvalue_counts(normalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(label_frequencies_percent)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4088\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   4089\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 4090\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4091\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   4092\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3804\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3805\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3806\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3807\u001B[0m     ):\n\u001B[0;32m   3808\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3809\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3810\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3811\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3812\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3813\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3814\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'max_intensity'"
     ]
    }
   ],
   "source": [
    "label_frequencies = df_data['max_intensity'].value_counts()\n",
    "label_frequencies_percent = df_data['max_intensity'].value_counts(normalize=True) * 100\n",
    "print(label_frequencies_percent)\n",
    "print(label_frequencies)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "132893087c52c8a6",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_data['label'] = (df_data['max_intensity'] == 2).astype(int)\n",
    "#df_data['label'] = (df_data['label'] == 2).astype(int)\n",
    "\n",
    "columns = ['Utterances', 'label']\n",
    "df = df_data[columns].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T17:59:47.761498Z",
     "start_time": "2025-06-25T17:59:47.753170Z"
    }
   },
   "id": "e27346da902b31a4",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_llm_aug], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T17:59:47.771056Z",
     "start_time": "2025-06-25T17:59:47.764608Z"
    }
   },
   "id": "f7af0254b608ff47",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                          Utterances  label\n0                                        like i said      0\n1             now you think i'm gay. no, i'm not gay      0\n2                         now i have to like it here      1\n3  yes no other reason? just a favor for an old p...      1\n4  if he doesn't respond to these tests in the ne...      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Utterances</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>like i said</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>now you think i'm gay. no, i'm not gay</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>now i have to like it here</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>yes no other reason? just a favor for an old p...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>if he doesn't respond to these tests in the ne...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T17:59:47.792940Z",
     "start_time": "2025-06-25T17:59:47.773072Z"
    }
   },
   "id": "86a42531a704d73c",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    50.324343\n",
      "1    49.675657\n",
      "Name: proportion, dtype: float64\n",
      "label\n",
      "0    1474\n",
      "1    1455\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_frequencies = df['label'].value_counts()\n",
    "label_frequencies_percent = df['label'].value_counts(normalize=True) * 100\n",
    "print(label_frequencies_percent)\n",
    "print(label_frequencies)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T17:59:47.805859Z",
     "start_time": "2025-06-25T17:59:47.794645Z"
    }
   },
   "id": "656eec943b8ae25b",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, random_state=77, test_size=0.30, shuffle=True)\n",
    "df_test, df_valid = train_test_split(df_test, random_state=88, test_size=0.50, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T17:59:47.820881Z",
     "start_time": "2025-06-25T17:59:47.809934Z"
    }
   },
   "id": "c053cc2ea6cbe64f",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train size: (1085, 4)\n",
      "Validation size: (440, 2), Test size: (439, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original train size: {df_data.shape}\")\n",
    "print(f\"Validation size: {df_valid.shape}, Test size: {df_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T17:59:47.827550Z",
     "start_time": "2025-06-25T17:59:47.822057Z"
    }
   },
   "id": "8d69bb5cab8227c",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    0.503243\n",
      "1    0.496757\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_distribution = df['label'].value_counts(normalize=True)\n",
    "print(class_distribution)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T17:59:47.838034Z",
     "start_time": "2025-06-25T17:59:47.829478Z"
    }
   },
   "id": "7064823e84ebfa8",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['label']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list = list(df.columns)\n",
    "target_list = target_list[1:]\n",
    "target_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T17:59:47.847565Z",
     "start_time": "2025-06-25T17:59:47.840035Z"
    }
   },
   "id": "981cb9e10ae1a9a5",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.utterances = list(df['Utterances'])\n",
    "        self.targets = self.df['label'].astype(int).values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.utterances)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        utterances = str(self.utterances[index])\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            utterances,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        target = torch.tensor(self.targets[index], dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            #'token_type_ids': inputs[\"token_type_ids\"].flatten(), -> nie potrzebne przy RoBERTa\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.long),\n",
    "            'utterances': utterances\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-26T10:35:37.135330Z",
     "start_time": "2025-06-26T10:35:37.128446Z"
    }
   },
   "id": "43e8c28009bdd96a",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BERTLSTMClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, lstm_hidden_dim=128, lstm_layers=1, dropout_rate=DROPOUT_RATE, bidirectional=True):\n",
    "        super(BERTLSTMClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.bert.config.hidden_size,\n",
    "            hidden_size=lstm_hidden_dim,\n",
    "            num_layers=lstm_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_rate if lstm_layers > 1 else 0\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        # Jeśli LSTM jest dwukierunkowe, rozmiar wejścia do fc to lstm_hidden_dim*2, w przeciwnym wypadku lstm_hidden_dim\n",
    "        fc_input_dim = lstm_hidden_dim * 2 if bidirectional else lstm_hidden_dim\n",
    "        self.fc = nn.Linear(fc_input_dim, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        # Pobranie reprezentacji z BERTa (cała sekwencja)\n",
    "        bert_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        # last_hidden_state: tensor o wymiarach (batch_size, seq_length, hidden_size)\n",
    "        sequence_output = bert_output.last_hidden_state\n",
    "\n",
    "        # Przepuszczenie przez LSTM\n",
    "        lstm_output, (hidden, _) = self.lstm(sequence_output)\n",
    "        # Jeśli LSTM jest dwukierunkowe, ukryty stan z ostatniej warstwy ma wymiar (num_layers*2, batch, hidden_dim)\n",
    "        if self.lstm.bidirectional:\n",
    "            # Pobieramy ostatnie stany z obu kierunków i je łączymy\n",
    "            hidden_forward = hidden[-2, :, :]  # ostatnia warstwa, kierunek \"forward\"\n",
    "            hidden_backward = hidden[-1, :, :]  # ostatnia warstwa, kierunek \"backward\"\n",
    "            hidden = torch.cat((hidden_forward, hidden_backward), dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1, :, :]\n",
    "\n",
    "        dropout_output = self.dropout(hidden)\n",
    "        logits = self.fc(dropout_output)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-26T10:35:37.639011Z",
     "start_time": "2025-06-26T10:35:37.628184Z"
    }
   },
   "id": "2082ab52f98981f",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def freeze_bert_layers(model, freeze_until_layer=6):\n",
    "    \"\"\"\n",
    "    Zamraża wszystkie warstwy enkodera BERT, których numer jest mniejszy niż freeze_until_layer.\n",
    "    W modelu BERT-base (12 warstw): przy freeze_until_layer=6, zamrożone zostaną warstwy 0-5.\n",
    "    \"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        # Szukamy parametrów, które należą do warstw enkodera\n",
    "        if \"bert.encoder.layer\" in name:\n",
    "            # Nazwa ma postać: bert.encoder.layer.<layer_num>...\n",
    "            try:\n",
    "                layer_num = int(name.split('.')[3])\n",
    "            except:\n",
    "                continue  # zabezpieczenie, gdyby parsowanie się nie udało\n",
    "            if layer_num < freeze_until_layer:\n",
    "                param.requires_grad = False\n",
    "                # Możesz też dodać print dla debugowania:\n",
    "                print(f\"Freezing parameter: {name}\")\n",
    "    print(f\"Frozen BERT layers: 0-{freeze_until_layer - 1}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-26T10:35:39.096771Z",
     "start_time": "2025-06-26T10:35:39.089671Z"
    }
   },
   "id": "1e7fdb5f2c851622",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "model = BERTLSTMClassifier(bert_model, lstm_layers=LSTM_LAYERS, lstm_hidden_dim=LSTM_HIDDEN_DIM)\n",
    "\n",
    "model.to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-26T10:37:12.981483Z",
     "start_time": "2025-06-26T10:37:10.339163Z"
    }
   },
   "id": "d5256b71691e1c46",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN)\n",
    "valid_dataset = CustomDataset(df_valid, tokenizer, MAX_LEN)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T17:59:52.251796Z",
     "start_time": "2025-06-25T17:59:52.246182Z"
    }
   },
   "id": "aadf862ae0047947",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH, shuffle=True, num_workers=0)\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH, shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T17:59:52.595095Z",
     "start_time": "2025-06-25T17:59:52.589827Z"
    }
   },
   "id": "de1b1918cc1209d9",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0092],\n",
      "        [ 0.0249],\n",
      "        [-0.0860],\n",
      "        [ 0.0373],\n",
      "        [-0.0649],\n",
      "        [ 0.0022],\n",
      "        [-0.0425],\n",
      "        [-0.0131],\n",
      "        [-0.1055],\n",
      "        [-0.0718],\n",
      "        [ 0.0666],\n",
      "        [-0.0418],\n",
      "        [-0.0600],\n",
      "        [-0.0622],\n",
      "        [-0.0295],\n",
      "        [-0.1065],\n",
      "        [-0.0071],\n",
      "        [-0.0431],\n",
      "        [-0.0666],\n",
      "        [-0.0347],\n",
      "        [-0.0542],\n",
      "        [-0.0113],\n",
      "        [ 0.0133],\n",
      "        [-0.0662],\n",
      "        [-0.0188],\n",
      "        [ 0.0187],\n",
      "        [-0.0207],\n",
      "        [-0.0160],\n",
      "        [-0.1542],\n",
      "        [-0.0030],\n",
      "        [ 0.0058],\n",
      "        [-0.0237]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "outputs = model(data[\"input_ids\"], attention_mask=data[\"attention_mask\"])\n",
    "print(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T18:00:00.930909Z",
     "start_time": "2025-06-25T17:59:52.818234Z"
    }
   },
   "id": "8e2ccb1ee90e217c",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_text = \"We are testing BERT tokenizer.\"\n",
    "encodings = tokenizer.encode_plus(test_text,\n",
    "                                  add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                                  max_length = 50,\n",
    "                                  truncation = True,\n",
    "                                  padding = \"max_length\",\n",
    "                                  return_attention_mask = True,\n",
    "                                  return_tensors = \"pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T18:00:00.939053Z",
     "start_time": "2025-06-25T18:00:00.933919Z"
    }
   },
   "id": "f1b009a33dc77303",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "#bert_model = RobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "last_hidden_state, pooled_output = bert_model(\n",
    "    input_ids=encodings['input_ids'],\n",
    "    attention_mask=encodings['attention_mask']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T18:00:01.528064Z",
     "start_time": "2025-06-25T18:00:00.941109Z"
    }
   },
   "id": "2bec695a35b6a3f",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs powinny być wyjściem z modelu (logity)\n",
    "        bce_loss = self.bce(inputs, targets.float())\n",
    "        probas = torch.sigmoid(inputs)\n",
    "        # Obliczenie p_t: dla próbki z target=1 mamy probas, dla target=0 mamy 1 - probas\n",
    "        p_t = targets * probas + (1 - targets) * (1 - probas)\n",
    "        loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "loss_fn = FocalLoss(alpha=FOCAL_LOSS_ALFA, gamma=FOCAL_LOSS_GAMMA, reduction='mean')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-26T10:35:42.644057Z",
     "start_time": "2025-06-26T10:35:42.637478Z"
    }
   },
   "id": "77a7cac8c06c5ae1",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m writer \u001B[38;5;241m=\u001B[39m SummaryWriter(log_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogs\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AdamW\n\u001B[1;32m----> 3\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m AdamW(\u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m p: p\u001B[38;5;241m.\u001B[39mrequires_grad, \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mparameters()), lr\u001B[38;5;241m=\u001B[39mLEARNING_RATE, weight_decay\u001B[38;5;241m=\u001B[39mWEIGHT_DECAY)\n\u001B[0;32m      4\u001B[0m scheduler \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mCosineAnnealingLR(optimizer, T_max\u001B[38;5;241m=\u001B[39mEPOCHS)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir='logs')\n",
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-26T10:35:44.831109Z",
     "start_time": "2025-06-26T10:35:44.806566Z"
    }
   },
   "id": "ea368685bd23d290",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(training_loader, model, optimizer):\n",
    "    \"\"\"\n",
    "    Trenuje model na danych treningowych i zwraca model, dokładność, średni loss oraz F1-score.\n",
    "\n",
    "    Args:\n",
    "        training_loader (DataLoader): DataLoader z danymi treningowymi.\n",
    "        model (torch.nn.Module): Model do trenowania.\n",
    "        optimizer (torch.optim.Optimizer): Optymalizator do aktualizacji wag modelu.\n",
    "        loss_fn (callable): Funkcja strat, np. nn.BCEWithLogitsLoss.\n",
    "\n",
    "    Returns:\n",
    "        model (torch.nn.Module): Wytrenowany model.\n",
    "        train_accuracy (float): Dokładność modelu na zbiorze treningowym.\n",
    "        avg_loss (float): Średnia wartość funkcji strat.\n",
    "        train_f1 (float): F1-score (binary) na zbiorze treningowym.\n",
    "    \"\"\"\n",
    "    # Inicjalizacja zmiennych do śledzenia wyników\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loop = tq.tqdm(enumerate(training_loader), total=len(training_loader), leave=True, colour='steelblue')\n",
    "\n",
    "    for batch_idx, data in loop:\n",
    "        ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "        #token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "        targets = data['targets'].to(device, dtype=torch.float)  # Binary targets jako float\n",
    "\n",
    "        #outputs = model(ids, mask, token_type_ids if 'token_type_ids' in data else None)\n",
    "        outputs = model(ids, mask if 'token_type_ids' in data else None)\n",
    "\n",
    "        outputs = outputs.squeeze(-1)  # Dopasowanie wymiarów do binary classification (1D)\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        preds = torch.sigmoid(outputs) >= 0.5  # Sigmoid + progowanie przy 0.5\n",
    "        correct_predictions += torch.sum(preds == targets).item()\n",
    "        num_samples += targets.size(0)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        loop.set_postfix(batch_loss=loss.item())\n",
    "\n",
    "    train_f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    return model, correct_predictions / num_samples, np.mean(losses), train_f1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T18:00:01.568613Z",
     "start_time": "2025-06-25T18:00:01.555525Z"
    }
   },
   "id": "b856ca62d79ec79c",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def eval_model(validation_loader, model, epoch):\n",
    "    \"\"\"\n",
    "    Ewaluacja modelu na danych walidacyjnych.\n",
    "\n",
    "    Args:\n",
    "        validation_loader (DataLoader): DataLoader z danymi walidacyjnymi.\n",
    "        model (torch.nn.Module): Model do oceny.\n",
    "        loss_fn (callable): Funkcja strat, np. nn.BCEWithLogitsLoss.\n",
    "        epoch (int): Aktualny numer epoki do logowania w TensorBoard.\n",
    "\n",
    "    Returns:\n",
    "        val_accuracy (float): Dokładność modelu na zbiorze walidacyjnym.\n",
    "        avg_loss (float): Średnia wartość funkcji strat na zbiorze walidacyjnym.\n",
    "        val_f1 (float): F1-score (binary) na zbiorze walidacyjnym.\n",
    "    \"\"\"\n",
    "    # Inicjalizacja zmiennych do śledzenia wyników\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Ustaw model w tryb ewaluacyjny\n",
    "    model.eval()\n",
    "\n",
    "    # Wyłącz gradienty dla ewaluacji\n",
    "    with torch.no_grad():\n",
    "        for data in validation_loader:\n",
    "            ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "            #token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype=torch.float)  # Binary targets jako float\n",
    "\n",
    "            #outputs = model(ids, mask, token_type_ids if 'token_type_ids' in data else None)\n",
    "            outputs = model(ids, mask if 'token_type_ids' in data else None)\n",
    "\n",
    "            outputs = outputs.squeeze(-1)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            preds = torch.sigmoid(outputs) >= 0.5  # Sigmoid + progowanie przy 0.5\n",
    "            correct_predictions += torch.sum(preds == targets).item()\n",
    "            num_samples += targets.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    avg_loss = np.mean(losses)\n",
    "    val_f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    writer.add_scalar('Loss/validation', avg_loss, epoch)\n",
    "    writer.add_scalar('F1-Score/validation', val_f1, epoch)\n",
    "\n",
    "    return correct_predictions / num_samples, avg_loss, val_f1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T18:00:01.581911Z",
     "start_time": "2025-06-25T18:00:01.570705Z"
    }
   },
   "id": "85ae992f90f3f334",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def count_trainable_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T18:00:01.591542Z",
     "start_time": "2025-06-25T18:00:01.584976Z"
    }
   },
   "id": "5b40517357c888be",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/65 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5079e10d39fc4af18ca1d9a1e64419ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6934 | Train accuracy 0.5215 | Train F1 0.5357\n",
      "Val loss 0.6870 | Val accuracy 0.5795 | Val F1 0.5542\n",
      "Saved new best model.\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/65 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b60708af86a434a8d01df516c4c7e98"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6870 | Train accuracy 0.5356 | Train F1 0.4974\n",
      "Val loss 0.6810 | Val accuracy 0.5500 | Val F1 0.6711\n",
      "Saved new best model.\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/65 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b61b940f4dcf4ec3a841d1bb5625ca46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6756 | Train accuracy 0.5834 | Train F1 0.6104\n",
      "Val loss 0.6612 | Val accuracy 0.6250 | Val F1 0.6857\n",
      "Saved new best model.\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/65 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "756c3f6424b041bfb68f5f546440fc4d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6458 | Train accuracy 0.6327 | Train F1 0.6385\n",
      "Val loss 0.6408 | Val accuracy 0.6455 | Val F1 0.6594\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/65 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "faeff7afed304beb84f37d792bea58cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5970 | Train accuracy 0.7185 | Train F1 0.7233\n",
      "Val loss 0.6354 | Val accuracy 0.6114 | Val F1 0.6827\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/65 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07f764ebf21e407fbf817f99deb59b8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5313 | Train accuracy 0.7761 | Train F1 0.7803\n",
      "Val loss 0.5976 | Val accuracy 0.6818 | Val F1 0.7200\n",
      "Saved new best model.\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/65 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bba19356b0c0492a9273afac9ad84c06"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.4543 | Train accuracy 0.8346 | Train F1 0.8333\n",
      "Val loss 0.5861 | Val accuracy 0.7182 | Val F1 0.7530\n",
      "Saved new best model.\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/65 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a310f5f6402041f98173828820ca7114"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.4124 | Train accuracy 0.8629 | Train F1 0.8659\n",
      "Val loss 0.5608 | Val accuracy 0.7341 | Val F1 0.7394\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/65 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb0b7dc0f70149c78b30aa9b27b991bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3827 | Train accuracy 0.8824 | Train F1 0.8820\n",
      "Val loss 0.5551 | Val accuracy 0.7341 | Val F1 0.7473\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/65 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c355a7553525450f92581de5097de2ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3669 | Train accuracy 0.8849 | Train F1 0.8860\n",
      "Val loss 0.5595 | Val accuracy 0.7409 | Val F1 0.7554\n",
      "Saved new best model.\n"
     ]
    }
   ],
   "source": [
    "history = defaultdict(list)\n",
    "best_f1 = 0\n",
    "patience_counter = 0\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "\n",
    "    model, train_acc, train_loss, train_f1 = train_model(train_data_loader, model, optimizer)\n",
    "    print(f'Train loss {train_loss:.4f} | Train accuracy {train_acc:.4f} | Train F1 {train_f1:.4f}')\n",
    "\n",
    "    val_acc, val_loss, val_f1 = eval_model(val_data_loader, model, epoch)\n",
    "    print(f'Val loss {val_loss:.4f} | Val accuracy {val_acc:.4f} | Val F1 {val_f1:.4f}')\n",
    "\n",
    "    # Logowanie metryk do TensorBoard\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "    writer.add_scalar('F1-Score/train', train_f1, epoch)\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_f1'].append(train_f1)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_f1'].append(val_f1)\n",
    "\n",
    "    if val_f1 > best_f1:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        model.bert.save_pretrained(output_dir)\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, \"best_binary_model_state.bin\"))\n",
    "        #torch.save(model.state_dict(), \"best_binary_model_state.bin\")\n",
    "        best_f1 = val_f1\n",
    "        print(\"Saved new best model.\")\n",
    "\n",
    "    #scheduler.step(val_loss)  # Tuning LR\n",
    "    scheduler.step()\n",
    "\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T21:18:18.920784Z",
     "start_time": "2025-06-25T18:00:01.595821Z"
    }
   },
   "id": "134691e19bd73c9a",
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer learning to ESConv dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f952fdde39a28c2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\", encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "#dataset = load_data(\"D:/julixus/MEISD/meisd_project/data/ESConv.json\")\n",
    "dataset = load_data(\"C:/Users/juwieczo/DataspellProjects/meisd_project/data/ESConv.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-30T08:28:37.715406Z",
     "start_time": "2025-06-30T08:28:37.490208Z"
    }
   },
   "id": "e74cfffe2519a329",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  initial_emotion_intensity                                             dialog\n0                         5  [Hello, I am having a lot of anxiety about qui...\n1                         5  [hello im looking for someone to talk to, im f...\n2                         4  [Hello, I'm concerned about my job. I have bee...\n3                         4  [I am dong good. You?, I have been staying hom...\n4                         5  [Infinitely complicated., Too many decisions. ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>initial_emotion_intensity</th>\n      <th>dialog</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>[Hello, I am having a lot of anxiety about qui...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>[hello im looking for someone to talk to, im f...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>[Hello, I'm concerned about my job. I have bee...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>[I am dong good. You?, I have been staying hom...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>[Infinitely complicated., Too many decisions. ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_seeker_data(data, key):\n",
    "    result = []\n",
    "\n",
    "    for entry in data:\n",
    "        dialog = entry['dialog']\n",
    "        seeker_dialog = [item['content'].strip() for item in dialog if item['speaker'] == 'seeker']\n",
    "\n",
    "        quarter_length = max(1, len(seeker_dialog) // 4)\n",
    "\n",
    "        if key == 'initial_emotion_intensity':\n",
    "            selected_dialog = seeker_dialog[:quarter_length]\n",
    "        elif key == 'final_emotion_intensity':\n",
    "            selected_dialog = seeker_dialog[-quarter_length:]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        result.append({\n",
    "            key: entry['survey_score']['seeker'][key],\n",
    "            'dialog': selected_dialog\n",
    "        })\n",
    "\n",
    "    return result\n",
    "\n",
    "first_25_percent = extract_seeker_data(dataset, 'initial_emotion_intensity')\n",
    "#last_25_percent = extract_seeker_data(dataset, 'final_emotion_intensity')\n",
    "\n",
    "first_25_df = pd.DataFrame(first_25_percent)\n",
    "#last_25_df = pd.DataFrame(last_25_percent)\n",
    "\n",
    "first_25_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-30T08:28:38.400500Z",
     "start_time": "2025-06-30T08:28:38.361252Z"
    }
   },
   "id": "a2a3e0a1d7d37ee0",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "first_25_df[\"dialog\"] = first_25_df[\"dialog\"].apply(\n",
    "    lambda x: \" \".join(x) if isinstance(x, list) else x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-30T08:28:39.396924Z",
     "start_time": "2025-06-30T08:28:39.384270Z"
    }
   },
   "id": "773b87872ae4f8df",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_emotion_intensity\n",
      "4    43.615385\n",
      "5    32.846154\n",
      "3    20.538462\n",
      "2     2.846154\n",
      "1     0.153846\n",
      "Name: proportion, dtype: float64\n",
      "initial_emotion_intensity\n",
      "4    567\n",
      "5    427\n",
      "3    267\n",
      "2     37\n",
      "1      2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_frequencies = first_25_df['initial_emotion_intensity'].value_counts()\n",
    "label_frequencies_percent = first_25_df['initial_emotion_intensity'].value_counts(normalize=True) * 100\n",
    "print(label_frequencies_percent)\n",
    "print(label_frequencies)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-30T08:28:43.139213Z",
     "start_time": "2025-06-30T08:28:43.126775Z"
    }
   },
   "id": "e2a2c9c2b4d21569",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  initial_emotion_intensity                                             dialog\n0                         5  [Hello, I am having a lot of anxiety about qui...\n1                         5  [hello im looking for someone to talk to, im f...\n2                         4  [Hello, I'm concerned about my job. I have bee...\n3                         4  [I am dong good. You?, I have been staying hom...\n4                         5  [Infinitely complicated., Too many decisions. ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>initial_emotion_intensity</th>\n      <th>dialog</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>[Hello, I am having a lot of anxiety about qui...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>[hello im looking for someone to talk to, im f...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>[Hello, I'm concerned about my job. I have bee...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>[I am dong good. You?, I have been staying hom...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>[Infinitely complicated., Too many decisions. ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_25_df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-30T08:09:46.465001Z",
     "start_time": "2025-06-30T08:09:46.452654Z"
    }
   },
   "id": "977be97c573bdb06",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "label_counts = first_25_df['initial_emotion_intensity'].value_counts()\n",
    "least_common_label = label_counts.idxmin()\n",
    "first_25_df = first_25_df[first_25_df['initial_emotion_intensity'] != least_common_label]\n",
    "first_25_df['initial_emotion_intensity'] = pd.to_numeric(first_25_df['initial_emotion_intensity'], errors='coerce')\n",
    "first_25_df['initial_emotion_intensity'] = first_25_df['initial_emotion_intensity'] - 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-30T08:10:40.874878Z",
     "start_time": "2025-06-30T08:10:40.863400Z"
    }
   },
   "id": "5fb5f7b4ca2c53a3",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "first_25_df.rename(columns={\n",
    "    'dialog': 'Utterances',\n",
    "    'initial_emotion_intensity': 'label'\n",
    "}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-30T08:11:06.068920Z",
     "start_time": "2025-06-30T08:11:06.061526Z"
    }
   },
   "id": "a5038c8d54db5f67",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "first_25_df['label'] = (first_25_df['label'] == 2).astype(int)\n",
    "columns = ['Utterances', 'label']\n",
    "df = first_25_df[columns].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-30T08:11:06.704404Z",
     "start_time": "2025-06-30T08:11:06.694608Z"
    }
   },
   "id": "c3d3ba2d4b569246",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESConv: Train (882, 2), Valid (189, 2), Test (190, 2)\n"
     ]
    }
   ],
   "source": [
    "df_train_esconv, df_temp_esconv = train_test_split(df, random_state=77, test_size=0.30, shuffle=True)\n",
    "df_valid_esconv, df_test_esconv = train_test_split(df_temp_esconv, random_state=88, test_size=0.50, shuffle=True)\n",
    "print(f\"ESConv: Train {df_train_esconv.shape}, Valid {df_valid_esconv.shape}, Test {df_test_esconv.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-26T10:35:08.890536Z",
     "start_time": "2025-06-26T10:35:08.876883Z"
    }
   },
   "id": "1a61879bc5efc024",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ESConvDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            # token_type_ids=False wyłączone\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-26T10:45:18.779189Z",
     "start_time": "2025-06-26T10:45:18.771390Z"
    }
   },
   "id": "79026fea5930ea9c",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "train_dataset_esconv = ESConvDataset(texts=df_train_esconv['Utterances'], labels=df_train_esconv['label'], tokenizer=tokenizer, max_len=MAX_LEN)\n",
    "valid_dataset_esconv = ESConvDataset(texts=df_valid_esconv['Utterances'], labels=df_train_esconv['label'], tokenizer=tokenizer, max_len=MAX_LEN)\n",
    "train_data_loader_esconv = torch.utils.data.DataLoader(train_dataset_esconv, batch_size=BATCH, shuffle=True)\n",
    "valid_data_loader_esconv = torch.utils.data.DataLoader(valid_dataset_esconv, batch_size=BATCH, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-26T10:49:04.834488Z",
     "start_time": "2025-06-26T10:49:04.125134Z"
    }
   },
   "id": "6476534e8c7bbcd1",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28996\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-26T10:49:06.414603Z",
     "start_time": "2025-06-26T10:49:06.406058Z"
    }
   },
   "id": "8e7b68dcbe572edc",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizer(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-26T10:49:08.651242Z",
     "start_time": "2025-06-26T10:49:08.643375Z"
    }
   },
   "id": "bc7e1a906f4a76f9",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BERTLSTMClassifier:\n\tsize mismatch for bert.embeddings.word_embeddings.weight: copying a param with shape torch.Size([30522, 768]) from checkpoint, the shape in current model is torch.Size([28996, 768]).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[52], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbest_binary_model_state.bin\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2593\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[1;34m(self, state_dict, strict, assign)\u001B[0m\n\u001B[0;32m   2585\u001B[0m         error_msgs\u001B[38;5;241m.\u001B[39minsert(\n\u001B[0;32m   2586\u001B[0m             \u001B[38;5;241m0\u001B[39m,\n\u001B[0;32m   2587\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing key(s) in state_dict: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2588\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m missing_keys)\n\u001B[0;32m   2589\u001B[0m             ),\n\u001B[0;32m   2590\u001B[0m         )\n\u001B[0;32m   2592\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(error_msgs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 2593\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   2594\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError(s) in loading state_dict for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2595\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(error_msgs)\n\u001B[0;32m   2596\u001B[0m         )\n\u001B[0;32m   2597\u001B[0m     )\n\u001B[0;32m   2598\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for BERTLSTMClassifier:\n\tsize mismatch for bert.embeddings.word_embeddings.weight: copying a param with shape torch.Size([30522, 768]) from checkpoint, the shape in current model is torch.Size([28996, 768])."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_binary_model_state.bin\"))\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-26T10:49:13.768343Z",
     "start_time": "2025-06-26T10:49:11.129195Z"
    }
   },
   "id": "4a86f720c348d6b3",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_params, trainable_params = count_trainable_parameters(model)\n",
    "print(f\"Before freezing on ESConv: Total params: {total_params}, Trainable params: {trainable_params}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-25T21:18:24.061747Z",
     "start_time": "2025-06-25T21:18:24.060869Z"
    }
   },
   "id": "7b62b214b225c503",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "freeze_bert_layers(model, freeze_until_layer=6)\n",
    "total_params, trainable_params = count_trainable_parameters(model)\n",
    "print(f\"After freezing on ESConv: Total params: {total_params}, Trainable params: {trainable_params}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-25T21:18:24.063982Z"
    }
   },
   "id": "c9de44483af3d0b6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "optimizer_esconv = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE_FINE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler_esconv = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_esconv, T_max=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-25T21:18:24.066122Z"
    }
   },
   "id": "611128487641b380",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "history_esconv = defaultdict(list)\n",
    "best_f1_esconv = 0\n",
    "\n",
    "print(\"Fine-tuning on ESConv...\")\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f'Fine-tuning Epoch {epoch}/{EPOCHS} (ESConv)')\n",
    "    model, train_acc, train_loss, train_f1 = train_model(train_data_loader_esconv, model, optimizer_esconv)\n",
    "    print(f'ESConv Train loss {train_loss:.4f} | Train accuracy {train_acc:.4f} | Train F1 {train_f1:.4f}')\n",
    "    val_acc, val_loss, val_f1 = eval_model(valid_data_loader_esconv, model, epoch)\n",
    "    print(f'ESConv Val loss {val_loss:.4f} | Val accuracy {val_acc:.4f} | Val F1 {val_f1:.4f}')\n",
    "    history_esconv['train_acc'].append(train_acc)\n",
    "    history_esconv['train_loss'].append(train_loss)\n",
    "    history_esconv['train_f1'].append(train_f1)\n",
    "    history_esconv['val_acc'].append(val_acc)\n",
    "    history_esconv['val_loss'].append(val_loss)\n",
    "    history_esconv['val_f1'].append(val_f1)\n",
    "    if val_f1 > best_f1_esconv:\n",
    "        torch.save(model.state_dict(), \"best_fine_tuned_model_state.bin\")\n",
    "        best_f1_esconv = val_f1\n",
    "        print(\"Saved new best ESConv model.\")\n",
    "    scheduler_esconv.step()\n",
    "print(\"Fine-tuning on ESConv complete!\")\n",
    "# Zamknij TensorBoard writer\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91f78b45ae0631b7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_dataset_esconv = CustomDataset(df_test_esconv, tokenizer, MAX_LEN)\n",
    "test_data_loader_esconv = torch.utils.data.DataLoader(test_dataset_esconv, batch_size=BATCH, shuffle=False)\n",
    "predictions, true_labels = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader_esconv:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['targets'].to(device)\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        outputs = outputs.squeeze(-1)\n",
    "        preds = torch.sigmoid(outputs) >= 0.5\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"ESConv Test Set Report:\")\n",
    "print(classification_report(true_labels, predictions))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6aa2f7642758f3d9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(true_labels, predictions, output_dict=True)\n",
    "\n",
    "import json\n",
    "with open(\"esconv_classification_report.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=4)\n",
    "\n",
    "print(\"Zapisano classification_report do pliku esconv_classification_report.json\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51088840e0073d0d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Zamykam komputer za 1 minutę...\")\n",
    "time.sleep(60) \n",
    "os.system(\"shutdown /s /t 1\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6b4a28e7cc68f69"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
