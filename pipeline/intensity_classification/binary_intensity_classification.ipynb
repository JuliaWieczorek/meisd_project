{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:54:14.120862Z",
     "start_time": "2025-03-09T18:54:13.057488Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm.notebook as tq\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "#from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import AdamW\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from deep_translator import GoogleTranslator\n",
    "from googletrans import Translator\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MAX_LEN = 100\n",
    "BATCH = 32\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased' #\"roberta-base\" #'bert-base-cased'\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.00001\n",
    "THRESHOLD = 0.2 #prog decyzyjny\n",
    "DROPOUT_RATE = 0.3\n",
    "WEIGHT_DECAY = 0.001\n",
    "MODE='min'\n",
    "PATIENCE=2\n",
    "FACTOR=0.5\n",
    "VERBOSE=True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:43:12.666148Z",
     "start_time": "2025-03-09T18:43:12.660807Z"
    }
   },
   "id": "7a7d5ffe51d43f10",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('C:/Users/juwieczo/DataspellProjects/meisd_project/pipeline/max_first_25_intensity.csv')\n",
    "#df_data = pd.read_csv('C:/Users/juwieczo/DataspellProjects/meisd_project/pipeline/balanced_augmented_data_primary_intensity.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:43:14.357354Z",
     "start_time": "2025-03-09T18:43:14.334038Z"
    }
   },
   "id": "7511ba9431cb25f7",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   dialog_ids                                         Utterances  \\\n0           1  you're cristina, right? - patton, monroe which...   \n1           2  i have five rules. memorize them rule number o...   \n2           3  \"i'm your sister, i'm your daughter.\" you're s...   \n3           4  just be quick about it you're the one that's s...   \n4           5  people do wake up. that's why we do a series o...   \n\n   max_intensity  \n0              3  \n1              2  \n2              1  \n3              2  \n4              2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dialog_ids</th>\n      <th>Utterances</th>\n      <th>max_intensity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>you're cristina, right? - patton, monroe which...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>i have five rules. memorize them rule number o...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>\"i'm your sister, i'm your daughter.\" you're s...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>just be quick about it you're the one that's s...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>people do wake up. that's why we do a series o...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:43:15.104859Z",
     "start_time": "2025-03-09T18:43:15.077905Z"
    }
   },
   "id": "85b5b15638a903f5",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_intensity\n",
      "2    46.797153\n",
      "3    35.676157\n",
      "1    13.345196\n",
      "0     4.181495\n",
      "Name: proportion, dtype: float64\n",
      "max_intensity\n",
      "2    526\n",
      "3    401\n",
      "1    150\n",
      "0     47\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_frequencies = df_data['max_intensity'].value_counts()\n",
    "label_frequencies_percent = df_data['max_intensity'].value_counts(normalize=True) * 100\n",
    "print(label_frequencies_percent)\n",
    "print(label_frequencies)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:43:18.158954Z",
     "start_time": "2025-03-09T18:43:18.148825Z"
    }
   },
   "id": "132893087c52c8a6",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_data['label'] = (df_data['max_intensity'] == 2).astype(int)\n",
    "#df_data['label'] = (df_data['label'] == 2).astype(int)\n",
    "\n",
    "columns = ['Utterances', 'label']\n",
    "df = df_data[columns].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:43:19.933310Z",
     "start_time": "2025-03-09T18:43:19.925733Z"
    }
   },
   "id": "e27346da902b31a4",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 1. Synonym Replacement\n",
    "def synonym_replacement(text):\n",
    "    words = text.split()\n",
    "    new_words = words[:]\n",
    "    num_replacements = max(1, len(words) // 5)  # Replace about 20% of words\n",
    "    random_words = random.sample(words, num_replacements)\n",
    "\n",
    "    for word in random_words:\n",
    "        synonyms = wordnet.synsets(word)\n",
    "        if synonyms:\n",
    "            #synonym = synonyms[0].lemmas()[0].name()  # Take first synonym\n",
    "            synonym = random.choice(synonyms).lemmas()[0].name()\n",
    "            if synonym != word:  # Avoid replacement if the synonym is identical\n",
    "                new_words = [synonym if w == word else w for w in new_words]\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "\n",
    "# 2. Random Insertion\n",
    "def random_insertion(text, n=1):\n",
    "    words = text.split()\n",
    "    for _ in range(n):\n",
    "        new_word = random.choice(words)\n",
    "        insert_pos = random.randint(0, len(words))\n",
    "        words.insert(insert_pos, new_word)\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "# 3. Random Deletion\n",
    "def random_deletion(text, p=0.3):\n",
    "    words = text.split()\n",
    "    if len(words) == 1:\n",
    "        return text  # Avoid deleting single-word text\n",
    "    new_words = [word for word in words if random.uniform(0, 1) > p]\n",
    "    if not new_words:\n",
    "        return random.choice(words)  # Return one word if all words are deleted\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "# 4. Back Translation\n",
    "def back_translation(text, src_lang='en', mid_lang='fr', max_retries=3):\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            translated = GoogleTranslator(source=src_lang, target=mid_lang).translate(text)\n",
    "            back_translated = GoogleTranslator(source=mid_lang, target=src_lang).translate(translated)\n",
    "            return back_translated\n",
    "        except Exception as e:\n",
    "            print(f\"Back translation error on attempt {attempt + 1}: {e}\")\n",
    "            attempt += 1\n",
    "            time.sleep(1)\n",
    "    raise ValueError(\"Back translation failed\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:43:23.204062Z",
     "start_time": "2025-03-09T18:43:23.195125Z"
    }
   },
   "id": "7fcc085f5564eeb6",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def augment_text(text, num_augments=2):\n",
    "    augmented_texts = []\n",
    "    for _ in range(num_augments):\n",
    "        augmentation_choice = random.choice(['synonym', 'insertion', 'deletion', 'back_translation'])\n",
    "        if augmentation_choice == 'synonym':\n",
    "            augmented_texts.append(synonym_replacement(text))\n",
    "        elif augmentation_choice == 'insertion':\n",
    "            augmented_texts.append(random_insertion(text))\n",
    "        elif augmentation_choice == 'deletion':\n",
    "            augmented_texts.append(random_deletion(text))\n",
    "        elif augmentation_choice == 'back_translation':\n",
    "            augmented_texts.append(back_translation(text))\n",
    "    return augmented_texts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:43:24.409757Z",
     "start_time": "2025-03-09T18:43:24.400695Z"
    }
   },
   "id": "507e1faa1a6e9329",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def augment_binary_data(df, label_column, augment_text, num_augments=2):\n",
    "    \"\"\"\n",
    "    Augments binary classification data to balance class distributions.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame with 'Utterances' column and a binary label column.\n",
    "    - label_column (str): Column name of the binary target label (0 or 1).\n",
    "    - augment_text (callable): Function to augment text. Should take a string and return a list of augmented strings.\n",
    "    - num_augments (int): Number of augmented samples to generate per original sample.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Augmented DataFrame with balanced class distribution.\n",
    "    \"\"\"\n",
    "    # Oblicz liczność klas\n",
    "    class_counts = df[label_column].value_counts()\n",
    "    min_class, max_class = class_counts.idxmin(), class_counts.idxmax()\n",
    "    num_min, num_max = class_counts[min_class], class_counts[max_class]\n",
    "\n",
    "    print(f\"Liczność klas przed augmentacją: {class_counts.to_dict()}\")\n",
    "\n",
    "    # Pobierz próbki z mniejszej klasy\n",
    "    class_subset = df[df[label_column] == min_class].copy()\n",
    "\n",
    "    # Oblicz ile dodatkowych próbek potrzebujemy\n",
    "    num_to_add = num_max - num_min\n",
    "\n",
    "    # Inicjalizacja nowego zbioru danych\n",
    "    augmented_data = {'Utterances': [], label_column: []}\n",
    "\n",
    "    # Augmentuj dane, ale tylko do momentu wyrównania liczby próbek\n",
    "    augment_per_sample = max(1, num_to_add // len(class_subset))  # Ile augmentacji na 1 próbkę\n",
    "    remaining = num_to_add  # Ile jeszcze próbek musimy dodać\n",
    "\n",
    "    for _, row in tqdm(class_subset.iterrows(), total=len(class_subset), desc=f\"Augmenting class {min_class}\"):\n",
    "        if remaining <= 0:\n",
    "            break\n",
    "\n",
    "        # Wykonaj augmentację tekstu\n",
    "        new_texts = augment_text(row['Utterances'], num_augments=min(augment_per_sample, remaining))\n",
    "\n",
    "        for new_text in new_texts:\n",
    "            if remaining <= 0:\n",
    "                break\n",
    "            augmented_data['Utterances'].append(new_text)\n",
    "            augmented_data[label_column].append(min_class)\n",
    "            remaining -= 1  # Zmniejsz licznik brakujących próbek\n",
    "\n",
    "    # Tworzenie DataFrame z nowymi próbkami\n",
    "    augmented_df = pd.DataFrame(augmented_data)\n",
    "\n",
    "    # Połączenie oryginalnych danych z nowymi danymi\n",
    "    final_df = pd.concat([df, augmented_df], ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Sprawdź finalny rozkład klas\n",
    "    final_counts = final_df[label_column].value_counts()\n",
    "    print(f\"Liczność klas po augmentacji: {final_counts.to_dict()}\")\n",
    "\n",
    "    return final_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:43:25.281320Z",
     "start_time": "2025-03-09T18:43:25.258068Z"
    }
   },
   "id": "bf74b5425e90d5a1",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def augment_binary_data_percent(df, label_column, augment_text, augment_percent=25):\n",
    "    \"\"\"\n",
    "    Augments binary classification data by a specified percentage.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame with 'Utterances' column and a binary label column.\n",
    "    - label_column (str): Column name of the binary target label (0 or 1).\n",
    "    - augment_text (callable): Function to augment text. Should take a string and return a list of augmented strings.\n",
    "    - augment_percent (int): Percentage increase for each class (e.g., 25 means adding 25% more samples per class).\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Augmented DataFrame with increased class distributions.\n",
    "    \"\"\"\n",
    "    # Oblicz liczność klas\n",
    "    class_counts = df[label_column].value_counts()\n",
    "    print(f\"Liczność klas przed augmentacją: {class_counts.to_dict()}\")\n",
    "\n",
    "    # Inicjalizacja nowego zbioru danych\n",
    "    augmented_data = {'Utterances': [], label_column: []}\n",
    "\n",
    "    for label in class_counts.index:\n",
    "        class_subset = df[df[label_column] == label].copy()\n",
    "        num_to_add = int(class_counts[label] * (augment_percent / 100))\n",
    "\n",
    "        augment_per_sample = max(1, num_to_add // len(class_subset))\n",
    "        remaining = num_to_add\n",
    "\n",
    "        for _, row in tqdm(class_subset.iterrows(), total=len(class_subset), desc=f\"Augmenting class {label}\"):\n",
    "            if remaining <= 0:\n",
    "                break\n",
    "\n",
    "            new_texts = augment_text(row['Utterances'], num_augments=min(augment_per_sample, remaining))\n",
    "\n",
    "            for new_text in new_texts:\n",
    "                if remaining <= 0:\n",
    "                    break\n",
    "                augmented_data['Utterances'].append(new_text)\n",
    "                augmented_data[label_column].append(label)\n",
    "                remaining -= 1\n",
    "\n",
    "    # Tworzenie DataFrame z nowymi próbkami\n",
    "    augmented_df = pd.DataFrame(augmented_data)\n",
    "\n",
    "    # Połączenie oryginalnych danych z nowymi danymi\n",
    "    final_df = pd.concat([df, augmented_df], ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Sprawdź finalny rozkład klas\n",
    "    final_counts = final_df[label_column].value_counts()\n",
    "    print(f\"Liczność klas po augmentacji: {final_counts.to_dict()}\")\n",
    "\n",
    "    return final_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:43:26.164940Z",
     "start_time": "2025-03-09T18:43:26.147162Z"
    }
   },
   "id": "120d3b0d5958947f",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczność klas przed augmentacją: {0: 598, 1: 526}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting class 1:  14%|█▎        | 72/526 [00:45<04:44,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczność klas po augmentacji: {1: 598, 0: 598}\n",
      "                                             Utterances  label\n",
      "0                                    I just saw Janice.      1\n",
      "1     um sorry. his legs what about them? they're bo...      1\n",
      "2     thank you. - i thought you loved cardio no, no...      0\n",
      "3     i was shocked to realize the degree to which y...      0\n",
      "4     they're dangerous, capricious tricksters who a...      1\n",
      "...                                                 ...    ...\n",
      "1191  what about this woman? did you ever see her? p...      0\n",
      "1192  but skorsky's saying her source believes the m...      1\n",
      "1193  Sorry. Me, uh ... I'm not sorry to have just ....      1\n",
      "1194  Oh, ain't that nice? The three of you trying o...      1\n",
      "1195  oh! i see why you're confused. no her news sou...      0\n",
      "\n",
      "[1196 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Augmentation\n",
    "augmented_df = augment_binary_data(\n",
    "    df=df,\n",
    "    label_column='label',\n",
    "    augment_text=augment_text,\n",
    "    num_augments=2\n",
    ")\n",
    "\n",
    "print(augmented_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:44:12.404174Z",
     "start_time": "2025-03-09T18:43:27.262886Z"
    }
   },
   "id": "230e9a2bfc05843e",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczność klas przed augmentacją: {1: 598, 0: 598}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting class 1:  70%|██████▉   | 418/598 [04:23<01:53,  1.59it/s]\n",
      "Augmenting class 0:  70%|██████▉   | 418/598 [04:41<02:01,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczność klas po augmentacji: {0: 1016, 1: 1016}\n",
      "                                             Utterances  label\n",
      "0     unbelievable. who would to wasn't in prison, y...      0\n",
      "1     plural, bitch you did not have my permission a...      0\n",
      "2     And the horrors she's had to endure... Losing ...      1\n",
      "3     he's evil he didn't sabotage your interview ho...      1\n",
      "4     No, its okay. Some-some kid asked me to pick ...      0\n",
      "...                                                 ...    ...\n",
      "2027  hey, person call jay leno we got the world's d...      0\n",
      "2028                                             Hello?      0\n",
      "2029  And y'know the other one over there, that's th...      0\n",
      "2030  Why did she leave their place? - She always le...      1\n",
      "2031  Ah, ladies love the bad boys mm cesar <i> \"el ...      0\n",
      "\n",
      "[2032 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = augment_binary_data_percent(\n",
    "    df=augmented_df,\n",
    "    label_column='label',\n",
    "    augment_text=augment_text,\n",
    "    augment_percent=70\n",
    ")\n",
    "\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:53:25.347638Z",
     "start_time": "2025-03-09T18:44:20.353612Z"
    }
   },
   "id": "fc800c4ee0aa2eb0",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64\n",
      "label\n",
      "0    1016\n",
      "1    1016\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_frequencies = df['label'].value_counts()\n",
    "label_frequencies_percent = df['label'].value_counts(normalize=True) * 100\n",
    "print(label_frequencies_percent)\n",
    "print(label_frequencies)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:53:31.768211Z",
     "start_time": "2025-03-09T18:53:31.760951Z"
    }
   },
   "id": "656eec943b8ae25b",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, random_state=77, test_size=0.30, shuffle=True)\n",
    "df_test, df_valid = train_test_split(df_test, random_state=88, test_size=0.50, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:53:36.184560Z",
     "start_time": "2025-03-09T18:53:36.171908Z"
    }
   },
   "id": "c053cc2ea6cbe64f",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train size: (1124, 4)\n",
      "Validation size: (305, 2), Test size: (305, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original train size: {df_data.shape}\")\n",
    "print(f\"Validation size: {df_valid.shape}, Test size: {df_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:53:39.089366Z",
     "start_time": "2025-03-09T18:53:39.083169Z"
    }
   },
   "id": "8d69bb5cab8227c",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                          Utterances  label\n0  unbelievable. who would to wasn't in prison, y...      0\n1  plural, bitch you did not have my permission a...      0\n2  And the horrors she's had to endure... Losing ...      1\n3  he's evil he didn't sabotage your interview ho...      1\n4  No, its okay. Some-some kid asked me to pick ...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Utterances</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>unbelievable. who would to wasn't in prison, y...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>plural, bitch you did not have my permission a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>And the horrors she's had to endure... Losing ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>he's evil he didn't sabotage your interview ho...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>No, its okay. Some-some kid asked me to pick ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:53:41.487543Z",
     "start_time": "2025-03-09T18:53:41.479053Z"
    }
   },
   "id": "6313a5510286cb08",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64\n",
      "label\n",
      "0    1016\n",
      "1    1016\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_frequencies = df['label'].value_counts()\n",
    "label_frequencies_percent = df['label'].value_counts(normalize=True) * 100\n",
    "print(label_frequencies_percent)\n",
    "print(label_frequencies)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:53:43.837789Z",
     "start_time": "2025-03-09T18:53:43.827077Z"
    }
   },
   "id": "7478b534ccd10119",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_distribution = df['label'].value_counts(normalize=True)\n",
    "print(class_distribution)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:53:45.060668Z",
     "start_time": "2025-03-09T18:53:45.053198Z"
    }
   },
   "id": "7064823e84ebfa8",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "class_distribution.plot(kind='bar')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Sentiment Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:53:46.869631Z",
     "start_time": "2025-03-09T18:53:46.547360Z"
    }
   },
   "id": "73c13e7f14210a32",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['label']"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list = list(df.columns)\n",
    "target_list = target_list[1:]\n",
    "target_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:53:47.848252Z",
     "start_time": "2025-03-09T18:53:47.839370Z"
    }
   },
   "id": "981cb9e10ae1a9a5",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.utterances = list(df['Utterances'])\n",
    "        self.targets = self.df['label'].astype(int).values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.utterances)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        utterances = str(self.utterances[index])\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            utterances,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        target = torch.tensor(self.targets[index], dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            #'token_type_ids': inputs[\"token_type_ids\"].flatten(), -> nie potrzebne przy RoBERTa\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.long),\n",
    "            'utterances': utterances\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:53:48.662865Z",
     "start_time": "2025-03-09T18:53:48.655083Z"
    }
   },
   "id": "43e8c28009bdd96a",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BERTBinarySentimentClassificationClass(nn.Module):\n",
    "    def __init__(self, bert_model):\n",
    "        super(BERTBinarySentimentClassificationClass, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(p=DROPOUT_RATE)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, 1)  # Binary classification (1 output)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        # Forward pass przez BERT\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        pooled_output = outputs.pooler_output\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        return self.out(dropout_output)\n",
    "        #return torch.sigmoid(self.out(dropout_output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:53:49.847633Z",
     "start_time": "2025-03-09T18:53:49.838669Z"
    }
   },
   "id": "6e94d6131ac088b5",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# class RoBERTaBinarySentimentClassificationClass(nn.Module):\n",
    "#     def __init__(self, roberta_model):\n",
    "#         super(RoBERTaBinarySentimentClassificationClass, self).__init__()\n",
    "#         self.roberta = roberta_model\n",
    "#         self.dropout = nn.Dropout(p=DROPOUT_RATE)\n",
    "#         self.out = nn.Linear(self.roberta.config.hidden_size, 1)  # Binary classification\n",
    "# \n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         # Forward pass przez RoBERTa\n",
    "#         outputs = self.roberta(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask\n",
    "#         )\n",
    "#         # Sprawdzenie, czy pooler_output jest dostępne\n",
    "#         if hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
    "#             pooled_output = outputs.pooler_output  # Preferowane, jeśli dostępne\n",
    "#         else:\n",
    "#             pooled_output = outputs.last_hidden_state[:, 0, :]  # Wykorzystanie tokena [CLS]\n",
    "# \n",
    "#         dropout_output = self.dropout(pooled_output)\n",
    "#         return self.out(dropout_output)\n",
    "#         # return torch.sigmoid(self.out(dropout_output))  # Jeśli używasz BCEWithLogitsLoss, sigmoid nie jest potrzebny"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:53:50.810206Z",
     "start_time": "2025-03-09T18:53:50.803774Z"
    }
   },
   "id": "e0a40b7814203672",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#model_path = 'best_model_state.bin'\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model = BERTBinarySentimentClassificationClass(bert_model)\n",
    "\n",
    "\n",
    "# roberta_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "# model = RoBERTaBinarySentimentClassificationClass(roberta_model)\n",
    "\n",
    "\n",
    "#model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:54:52.953529Z",
     "start_time": "2025-03-09T18:54:50.302053Z"
    }
   },
   "id": "d5256b71691e1c46",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN)\n",
    "valid_dataset = CustomDataset(df_valid, tokenizer, MAX_LEN)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:55:03.298570Z",
     "start_time": "2025-03-09T18:55:03.289884Z"
    }
   },
   "id": "aadf862ae0047947",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH, shuffle=True, num_workers=0)\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH, shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:55:04.218592Z",
     "start_time": "2025-03-09T18:55:04.208833Z"
    }
   },
   "id": "de1b1918cc1209d9",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3462],\n",
      "        [ 0.2921],\n",
      "        [ 0.7553],\n",
      "        [ 0.3867],\n",
      "        [ 0.2655],\n",
      "        [ 0.0874],\n",
      "        [ 0.6693],\n",
      "        [ 0.2125],\n",
      "        [ 0.2974],\n",
      "        [-0.0148],\n",
      "        [ 0.4685],\n",
      "        [ 0.2135],\n",
      "        [ 0.4232],\n",
      "        [ 0.3426],\n",
      "        [ 0.6051],\n",
      "        [ 0.5708],\n",
      "        [ 0.3408],\n",
      "        [ 0.4543],\n",
      "        [ 0.1383],\n",
      "        [ 0.2395],\n",
      "        [ 0.5430],\n",
      "        [ 0.1790],\n",
      "        [ 0.7461],\n",
      "        [ 0.5282],\n",
      "        [ 0.4143],\n",
      "        [ 0.2197],\n",
      "        [ 0.1922],\n",
      "        [ 0.0116],\n",
      "        [ 0.3328],\n",
      "        [ 0.4491],\n",
      "        [ 0.4760],\n",
      "        [ 0.0804]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "outputs = model(data[\"input_ids\"], attention_mask=data[\"attention_mask\"])\n",
    "print(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:55:17.469424Z",
     "start_time": "2025-03-09T18:55:05.146135Z"
    }
   },
   "id": "8e2ccb1ee90e217c",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_text = \"We are testing BERT tokenizer.\"\n",
    "encodings = tokenizer.encode_plus(test_text,\n",
    "                                  add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                                  max_length = 50,\n",
    "                                  truncation = True,\n",
    "                                  padding = \"max_length\",\n",
    "                                  return_attention_mask = True,\n",
    "                                  return_tensors = \"pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:55:22.137418Z",
     "start_time": "2025-03-09T18:55:22.131204Z"
    }
   },
   "id": "f1b009a33dc77303",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "#bert_model = RobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "last_hidden_state, pooled_output = bert_model(\n",
    "    input_ids=encodings['input_ids'],\n",
    "    attention_mask=encodings['attention_mask']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:55:25.934637Z",
     "start_time": "2025-03-09T18:55:22.838669Z"
    }
   },
   "id": "2bec695a35b6a3f",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def loss_fn(outputs, targets):\n",
    "#     # jesli uzywamy BCEWithLogitsLoss, to w modelu nie musimy dodawać sigmoid, bo ta funkcja już zawiera operację sigmoid.\n",
    "#     return torch.nn.BCEWithLogitsLoss()(outputs.squeeze(-1), targets.float())\n",
    "\n",
    "# def loss_fn(outputs, targets):\n",
    "#     return torch.nn.BCELoss()(outputs.squeeze(), targets.float())\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs powinny być wyjściem z modelu (logity)\n",
    "        bce_loss = self.bce(inputs, targets.float())\n",
    "        probas = torch.sigmoid(inputs)\n",
    "        # Obliczenie p_t: dla próbki z target=1 mamy probas, dla target=0 mamy 1 - probas\n",
    "        p_t = targets * probas + (1 - targets) * (1 - probas)\n",
    "        loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "        \n",
    "loss_fn = FocalLoss(alpha=1, gamma=2, reduction='mean')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:55:28.246066Z",
     "start_time": "2025-03-09T18:55:28.239876Z"
    }
   },
   "id": "77a7cac8c06c5ae1",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juwieczo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir='logs')\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "# learning rate scheduler\n",
    "# ReduceLROnPlateau może obniżać lr do bardzo małych wartości, co czasem prowadzi do problemów. Możesz dodać min_lr, aby ograniczyć ten efekt:\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=MODE, patience=PATIENCE, factor=FACTOR, verbose=VERBOSE)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:55:35.649045Z",
     "start_time": "2025-03-09T18:55:30.276015Z"
    }
   },
   "id": "ea368685bd23d290",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(training_loader, model, optimizer):\n",
    "    \"\"\"\n",
    "    Trenuje model na danych treningowych i zwraca model, dokładność, średni loss oraz F1-score.\n",
    "\n",
    "    Args:\n",
    "        training_loader (DataLoader): DataLoader z danymi treningowymi.\n",
    "        model (torch.nn.Module): Model do trenowania.\n",
    "        optimizer (torch.optim.Optimizer): Optymalizator do aktualizacji wag modelu.\n",
    "        loss_fn (callable): Funkcja strat, np. nn.BCEWithLogitsLoss.\n",
    "\n",
    "    Returns:\n",
    "        model (torch.nn.Module): Wytrenowany model.\n",
    "        train_accuracy (float): Dokładność modelu na zbiorze treningowym.\n",
    "        avg_loss (float): Średnia wartość funkcji strat.\n",
    "        train_f1 (float): F1-score (binary) na zbiorze treningowym.\n",
    "    \"\"\"\n",
    "    # Inicjalizacja zmiennych do śledzenia wyników\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loop = tq.tqdm(enumerate(training_loader), total=len(training_loader), leave=True, colour='steelblue')\n",
    "\n",
    "    for batch_idx, data in loop:\n",
    "        ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "        #token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "        targets = data['targets'].to(device, dtype=torch.float)  # Binary targets jako float\n",
    "\n",
    "        #outputs = model(ids, mask, token_type_ids if 'token_type_ids' in data else None)\n",
    "        outputs = model(ids, mask if 'token_type_ids' in data else None)\n",
    "\n",
    "        outputs = outputs.squeeze(-1)  # Dopasowanie wymiarów do binary classification (1D)\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        preds = torch.sigmoid(outputs) >= 0.5  # Sigmoid + progowanie przy 0.5\n",
    "        correct_predictions += torch.sum(preds == targets).item()\n",
    "        num_samples += targets.size(0)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        loop.set_postfix(batch_loss=loss.item())\n",
    "\n",
    "    train_f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    return model, correct_predictions / num_samples, np.mean(losses), train_f1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:55:37.483453Z",
     "start_time": "2025-03-09T18:55:37.469828Z"
    }
   },
   "id": "b856ca62d79ec79c",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def eval_model(validation_loader, model, epoch):\n",
    "    \"\"\"\n",
    "    Ewaluacja modelu na danych walidacyjnych.\n",
    "\n",
    "    Args:\n",
    "        validation_loader (DataLoader): DataLoader z danymi walidacyjnymi.\n",
    "        model (torch.nn.Module): Model do oceny.\n",
    "        loss_fn (callable): Funkcja strat, np. nn.BCEWithLogitsLoss.\n",
    "        epoch (int): Aktualny numer epoki do logowania w TensorBoard.\n",
    "\n",
    "    Returns:\n",
    "        val_accuracy (float): Dokładność modelu na zbiorze walidacyjnym.\n",
    "        avg_loss (float): Średnia wartość funkcji strat na zbiorze walidacyjnym.\n",
    "        val_f1 (float): F1-score (binary) na zbiorze walidacyjnym.\n",
    "    \"\"\"\n",
    "    # Inicjalizacja zmiennych do śledzenia wyników\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Ustaw model w tryb ewaluacyjny\n",
    "    model.eval()\n",
    "\n",
    "    # Wyłącz gradienty dla ewaluacji\n",
    "    with torch.no_grad():\n",
    "        for data in validation_loader:\n",
    "            ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "            #token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype=torch.float)  # Binary targets jako float\n",
    "\n",
    "            #outputs = model(ids, mask, token_type_ids if 'token_type_ids' in data else None)\n",
    "            outputs = model(ids, mask if 'token_type_ids' in data else None)\n",
    "\n",
    "            outputs = outputs.squeeze(-1)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            preds = torch.sigmoid(outputs) >= 0.5  # Sigmoid + progowanie przy 0.5\n",
    "            correct_predictions += torch.sum(preds == targets).item()\n",
    "            num_samples += targets.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    avg_loss = np.mean(losses)\n",
    "    val_f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    writer.add_scalar('Loss/validation', avg_loss, epoch)\n",
    "    writer.add_scalar('F1-Score/validation', val_f1, epoch)\n",
    "\n",
    "    return correct_predictions / num_samples, avg_loss, val_f1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T18:55:38.269290Z",
     "start_time": "2025-03-09T18:55:38.255911Z"
    }
   },
   "id": "85ae992f90f3f334",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/45 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e81d9f1f717a437296a7ea3bbe1f1c08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.7008 | Train accuracy 0.5105 | Train F1 0.5167\n",
      "Val loss 0.6900 | Val accuracy 0.5311 | Val F1 0.6651\n",
      "Saved new best model.\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/45 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed4dc86e4b32484390d90a676edfc0ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6922 | Train accuracy 0.5331 | Train F1 0.5985\n",
      "Val loss 0.6913 | Val accuracy 0.5410 | Val F1 0.6133\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/45 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04f63b4312ab4f04a5ea2395272fd888"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6868 | Train accuracy 0.5506 | Train F1 0.5917\n",
      "Val loss 0.6906 | Val accuracy 0.5508 | Val F1 0.6532\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/45 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3cefd1e0e8a3414f97307156e5dc79ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6679 | Train accuracy 0.5928 | Train F1 0.6459\n",
      "Val loss 0.7224 | Val accuracy 0.5246 | Val F1 0.6620\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/45 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edf4adb9a74b45b0983a8b6e590aa27b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6400 | Train accuracy 0.6491 | Train F1 0.6649\n",
      "Val loss 0.7648 | Val accuracy 0.5344 | Val F1 0.6698\n",
      "Saved new best model.\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/45 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03d664b22ab44ba386ceae807e27c94e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6054 | Train accuracy 0.6899 | Train F1 0.6969\n",
      "Val loss 0.7232 | Val accuracy 0.5803 | Val F1 0.6559\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/45 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb8eeab567554f7490eabebedcdfd40b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5602 | Train accuracy 0.7342 | Train F1 0.7371\n",
      "Val loss 0.7200 | Val accuracy 0.6033 | Val F1 0.6300\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/45 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b38c7602b2d44c0a6f380565b246297"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5269 | Train accuracy 0.7616 | Train F1 0.7563\n",
      "Val loss 0.7931 | Val accuracy 0.5672 | Val F1 0.6700\n",
      "Saved new best model.\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/45 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3286bccda8b84e1ba92fa4c5ddf6b283"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5078 | Train accuracy 0.7764 | Train F1 0.7735\n",
      "Val loss 0.7632 | Val accuracy 0.6033 | Val F1 0.6790\n",
      "Saved new best model.\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/45 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1257c80b45a14e10b9e3828204f94370"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.4945 | Train accuracy 0.7855 | Train F1 0.7848\n",
      "Val loss 0.7420 | Val accuracy 0.6197 | Val F1 0.6742\n"
     ]
    }
   ],
   "source": [
    "history = defaultdict(list)\n",
    "best_f1 = 0\n",
    "patience_counter = 0\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "\n",
    "    model, train_acc, train_loss, train_f1 = train_model(train_data_loader, model, optimizer)\n",
    "    print(f'Train loss {train_loss:.4f} | Train accuracy {train_acc:.4f} | Train F1 {train_f1:.4f}')\n",
    "\n",
    "    val_acc, val_loss, val_f1 = eval_model(val_data_loader, model, epoch)\n",
    "    print(f'Val loss {val_loss:.4f} | Val accuracy {val_acc:.4f} | Val F1 {val_f1:.4f}')\n",
    "\n",
    "    # Logowanie metryk do TensorBoard\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "    writer.add_scalar('F1-Score/train', train_f1, epoch)\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_f1'].append(train_f1)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_f1'].append(val_f1)\n",
    "\n",
    "    # Sprawdzenie najlepszej F1 i zapisanie modelu\n",
    "    if val_f1 > best_f1:\n",
    "        torch.save(model.state_dict(), \"best_binary_model_state.bin\")\n",
    "        best_f1 = val_f1\n",
    "        print(\"Saved new best model.\")\n",
    "\n",
    "    #scheduler.step(val_loss)  # Tuning LR\n",
    "    scheduler.step()\n",
    "\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T21:28:02.195022Z",
     "start_time": "2025-03-09T18:55:39.854822Z"
    }
   },
   "id": "134691e19bd73c9a",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e1afc6cd3268ae0f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer learinng to ESConv dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f952fdde39a28c2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\", encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "#dataset = load_data(\"D:/julixus/MEISD/meisd_project/data/ESConv.json\")\n",
    "dataset = load_data(\"C:/Users/juwieczo/DataspellProjects/meisd_project/data/ESConv.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T21:28:15.891716Z",
     "start_time": "2025-03-09T21:28:15.311408Z"
    }
   },
   "id": "e74cfffe2519a329",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  initial_emotion_intensity                                             dialog\n0                         5  [Hello, I am having a lot of anxiety about qui...\n1                         5  [hello im looking for someone to talk to, im f...\n2                         4  [Hello, I'm concerned about my job. I have bee...\n3                         4  [I am dong good. You?, I have been staying hom...\n4                         5  [Infinitely complicated., Too many decisions. ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>initial_emotion_intensity</th>\n      <th>dialog</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>[Hello, I am having a lot of anxiety about qui...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>[hello im looking for someone to talk to, im f...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>[Hello, I'm concerned about my job. I have bee...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>[I am dong good. You?, I have been staying hom...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>[Infinitely complicated., Too many decisions. ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_seeker_data(data, key):\n",
    "    result = []\n",
    "\n",
    "    for entry in data:\n",
    "        dialog = entry['dialog']\n",
    "        seeker_dialog = [item['content'].strip() for item in dialog if item['speaker'] == 'seeker']\n",
    "\n",
    "        quarter_length = max(1, len(seeker_dialog) // 4)\n",
    "\n",
    "        if key == 'initial_emotion_intensity':\n",
    "            selected_dialog = seeker_dialog[:quarter_length]\n",
    "        elif key == 'final_emotion_intensity':\n",
    "            selected_dialog = seeker_dialog[-quarter_length:]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        result.append({\n",
    "            key: entry['survey_score']['seeker'][key],\n",
    "            'dialog': selected_dialog\n",
    "        })\n",
    "\n",
    "    return result\n",
    "\n",
    "first_25_percent = extract_seeker_data(dataset, 'initial_emotion_intensity')\n",
    "#last_25_percent = extract_seeker_data(dataset, 'final_emotion_intensity')\n",
    "\n",
    "first_25_df = pd.DataFrame(first_25_percent)\n",
    "#last_25_df = pd.DataFrame(last_25_percent)\n",
    "\n",
    "first_25_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T21:28:16.869746Z",
     "start_time": "2025-03-09T21:28:16.768395Z"
    }
   },
   "id": "a2a3e0a1d7d37ee0",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "label_counts = first_25_df['initial_emotion_intensity'].value_counts()\n",
    "least_common_label = label_counts.idxmin()\n",
    "first_25_df = first_25_df[first_25_df['initial_emotion_intensity'] != least_common_label]\n",
    "first_25_df['initial_emotion_intensity'] = pd.to_numeric(first_25_df['initial_emotion_intensity'], errors='coerce')\n",
    "first_25_df['initial_emotion_intensity'] = first_25_df['initial_emotion_intensity'] - 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T21:28:17.862679Z",
     "start_time": "2025-03-09T21:28:17.834980Z"
    }
   },
   "id": "5fb5f7b4ca2c53a3",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      label                                         Utterances\n0         3  [Hello, I am having a lot of anxiety about qui...\n1         3  [hello im looking for someone to talk to, im f...\n2         2  [Hello, I'm concerned about my job. I have bee...\n3         2  [I am dong good. You?, I have been staying hom...\n4         3  [Infinitely complicated., Too many decisions. ...\n...     ...                                                ...\n1295      3  [I feel sleepy but can not sleep, It has alway...\n1296      2  [I am fine. thanks. how about you ?, I lost my...\n1297      1        [HI how are you today, Doing well, thanks.]\n1298      1  [Hello, I am a little down today.  How are you...\n1299      1                                  [hi, i'm nereida]\n\n[1298 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>Utterances</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>[Hello, I am having a lot of anxiety about qui...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>[hello im looking for someone to talk to, im f...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[Hello, I'm concerned about my job. I have bee...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>[I am dong good. You?, I have been staying hom...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>[Infinitely complicated., Too many decisions. ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1295</th>\n      <td>3</td>\n      <td>[I feel sleepy but can not sleep, It has alway...</td>\n    </tr>\n    <tr>\n      <th>1296</th>\n      <td>2</td>\n      <td>[I am fine. thanks. how about you ?, I lost my...</td>\n    </tr>\n    <tr>\n      <th>1297</th>\n      <td>1</td>\n      <td>[HI how are you today, Doing well, thanks.]</td>\n    </tr>\n    <tr>\n      <th>1298</th>\n      <td>1</td>\n      <td>[Hello, I am a little down today.  How are you...</td>\n    </tr>\n    <tr>\n      <th>1299</th>\n      <td>1</td>\n      <td>[hi, i'm nereida]</td>\n    </tr>\n  </tbody>\n</table>\n<p>1298 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_25_df.rename(columns={\n",
    "    'dialog': 'Utterances',\n",
    "    'initial_emotion_intensity': 'label'\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T21:28:18.691932Z",
     "start_time": "2025-03-09T21:28:18.665009Z"
    }
   },
   "id": "a5038c8d54db5f67",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_data['label'] = (df_data['max_intensity'] == 2).astype(int)\n",
    "columns = ['Utterances', 'label']\n",
    "df = df_data[columns].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T21:28:19.438553Z",
     "start_time": "2025-03-09T21:28:19.410951Z"
    }
   },
   "id": "c3d3ba2d4b569246",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(df_test, tokenizer, MAX_LEN)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH, shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T21:28:20.337990Z",
     "start_time": "2025-03-09T21:28:20.308117Z"
    }
   },
   "id": "6476534e8c7bbcd1",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.64       145\n",
      "           1       0.00      0.00      0.00       160\n",
      "\n",
      "    accuracy                           0.48       305\n",
      "   macro avg       0.24      0.50      0.32       305\n",
      "weighted avg       0.23      0.48      0.31       305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juwieczo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\juwieczo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\juwieczo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "def test_model(data_loader, model):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['targets'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            #outputs = model(input_ids=input_ids)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return predictions, true_labels\n",
    "\n",
    "# Run validation\n",
    "predictions, true_labels = test_model(val_data_loader, model)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(true_labels, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-09T21:29:15.818888Z",
     "start_time": "2025-03-09T21:28:21.078717Z"
    }
   },
   "id": "91b2b2fe84a323a5",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dc2acc0f4d5644c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
