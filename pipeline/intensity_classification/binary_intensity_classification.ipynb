{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:20:23.671019Z",
     "start_time": "2025-04-14T11:19:44.254440Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tq\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, RobertaTokenizer, RobertaModel, AdamW\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from deep_translator import GoogleTranslator\n",
    "from googletrans import Translator\n",
    "\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "writer = SummaryWriter(log_dir='logs')\n",
    "translator = Translator()\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MAX_LEN = 100\n",
    "BATCH = 32\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased' #\"roberta-base\" #'bert-base-cased'\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.00001 # dla MEISD\n",
    "LEARNING_RATE_FINE = 5e-6    # dla fine-tuningu na ESConv\n",
    "THRESHOLD = 0.2 #prog decyzyjny\n",
    "DROPOUT_RATE = 0.3\n",
    "WEIGHT_DECAY = 0.001\n",
    "LSTM_LAYERS = 2\n",
    "LSTM_HIDDEN_DIM = 128\n",
    "FOCAL_LOSS_ALFA = 4\n",
    "FOCAL_LOSS_GAMMA = 2\n",
    "MODE='min'\n",
    "PATIENCE=2\n",
    "FACTOR=0.5\n",
    "VERBOSE=True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:20:23.686050Z",
     "start_time": "2025-04-14T11:20:23.675231Z"
    }
   },
   "id": "7a7d5ffe51d43f10",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('C:/Users/juwieczo/DataspellProjects/meisd_project/data/filtered_negative_MEISD_intensity_max_first_25_conv.csv')\n",
    "#df_data = pd.read_csv('C:/Users/juwieczo/DataspellProjects/meisd_project/pipeline/balanced_augmented_data_primary_intensity.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:20:23.743036Z",
     "start_time": "2025-04-14T11:20:23.689600Z"
    }
   },
   "id": "7511ba9431cb25f7",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   dialog_ids                                         Utterances  \\\n0           1                                        like i said   \n1           2             now you think i'm gay. no, i'm not gay   \n2           3                         now i have to like it here   \n3           4  yes no other reason? just a favor for an old p...   \n4           5  if he doesn't respond to these tests in the ne...   \n\n   max_intensity  \n0              1  \n1              1  \n2              2  \n3              2  \n4              2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dialog_ids</th>\n      <th>Utterances</th>\n      <th>max_intensity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>like i said</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>now you think i'm gay. no, i'm not gay</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>now i have to like it here</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>yes no other reason? just a favor for an old p...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>if he doesn't respond to these tests in the ne...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:20:23.779518Z",
     "start_time": "2025-04-14T11:20:23.746515Z"
    }
   },
   "id": "85b5b15638a903f5",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_intensity\n",
      "2    49.677419\n",
      "1    29.032258\n",
      "3    21.290323\n",
      "Name: proportion, dtype: float64\n",
      "max_intensity\n",
      "2    539\n",
      "1    315\n",
      "3    231\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_frequencies = df_data['max_intensity'].value_counts()\n",
    "label_frequencies_percent = df_data['max_intensity'].value_counts(normalize=True) * 100\n",
    "print(label_frequencies_percent)\n",
    "print(label_frequencies)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:20:23.803926Z",
     "start_time": "2025-04-14T11:20:23.782473Z"
    }
   },
   "id": "132893087c52c8a6",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_data['label'] = (df_data['max_intensity'] == 2).astype(int)\n",
    "#df_data['label'] = (df_data['label'] == 2).astype(int)\n",
    "\n",
    "columns = ['Utterances', 'label']\n",
    "df = df_data[columns].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:20:23.820140Z",
     "start_time": "2025-04-14T11:20:23.806532Z"
    }
   },
   "id": "e27346da902b31a4",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 1. Synonym Replacement\n",
    "def synonym_replacement(text):\n",
    "    words = text.split()\n",
    "    new_words = words[:]\n",
    "    num_replacements = max(1, len(words) // 5)  # Replace about 20% of words\n",
    "    random_words = random.sample(words, num_replacements)\n",
    "\n",
    "    for word in random_words:\n",
    "        synonyms = wordnet.synsets(word)\n",
    "        if synonyms:\n",
    "            #synonym = synonyms[0].lemmas()[0].name()  # Take first synonym\n",
    "            synonym = random.choice(synonyms).lemmas()[0].name()\n",
    "            if synonym != word:  # Avoid replacement if the synonym is identical\n",
    "                new_words = [synonym if w == word else w for w in new_words]\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "\n",
    "# 2. Random Insertion\n",
    "def random_insertion(text, n=1):\n",
    "    words = text.split()\n",
    "    for _ in range(n):\n",
    "        new_word = random.choice(words)\n",
    "        insert_pos = random.randint(0, len(words))\n",
    "        words.insert(insert_pos, new_word)\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "# 3. Random Deletion\n",
    "def random_deletion(text, p=0.3):\n",
    "    words = text.split()\n",
    "    if len(words) == 1:\n",
    "        return text  # Avoid deleting single-word text\n",
    "    new_words = [word for word in words if random.uniform(0, 1) > p]\n",
    "    if not new_words:\n",
    "        return random.choice(words)  # Return one word if all words are deleted\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "# 4. Back Translation\n",
    "def back_translation(text, src_lang='en', mid_lang='fr', max_retries=3):\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            translated = GoogleTranslator(source=src_lang, target=mid_lang).translate(text)\n",
    "            back_translated = GoogleTranslator(source=mid_lang, target=src_lang).translate(translated)\n",
    "            return back_translated\n",
    "        except Exception as e:\n",
    "            print(f\"Back translation error on attempt {attempt + 1}: {e}\")\n",
    "            attempt += 1\n",
    "            time.sleep(1)\n",
    "    raise ValueError(\"Back translation failed\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:20:23.841840Z",
     "start_time": "2025-04-14T11:20:23.823292Z"
    }
   },
   "id": "7fcc085f5564eeb6",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def augment_text(text, num_augments=2):\n",
    "    augmented_texts = []\n",
    "    for _ in range(num_augments):\n",
    "        augmentation_choice = random.choice(['synonym', 'insertion', 'deletion', 'back_translation'])\n",
    "        if augmentation_choice == 'synonym':\n",
    "            augmented_texts.append(synonym_replacement(text))\n",
    "        elif augmentation_choice == 'insertion':\n",
    "            augmented_texts.append(random_insertion(text))\n",
    "        elif augmentation_choice == 'deletion':\n",
    "            augmented_texts.append(random_deletion(text))\n",
    "        elif augmentation_choice == 'back_translation':\n",
    "            augmented_texts.append(back_translation(text))\n",
    "    return augmented_texts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:20:23.859437Z",
     "start_time": "2025-04-14T11:20:23.845012Z"
    }
   },
   "id": "507e1faa1a6e9329",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def augment_binary_data(df, label_column, augment_text, num_augments=2):\n",
    "    \"\"\"\n",
    "    Augments binary classification data to balance class distributions.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame with 'Utterances' column and a binary label column.\n",
    "    - label_column (str): Column name of the binary target label (0 or 1).\n",
    "    - augment_text (callable): Function to augment text. Should take a string and return a list of augmented strings.\n",
    "    - num_augments (int): Number of augmented samples to generate per original sample.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Augmented DataFrame with balanced class distribution.\n",
    "    \"\"\"\n",
    "    # Oblicz liczność klas\n",
    "    class_counts = df[label_column].value_counts()\n",
    "    min_class, max_class = class_counts.idxmin(), class_counts.idxmax()\n",
    "    num_min, num_max = class_counts[min_class], class_counts[max_class]\n",
    "\n",
    "    print(f\"Liczność klas przed augmentacją: {class_counts.to_dict()}\")\n",
    "\n",
    "    # Pobierz próbki z mniejszej klasy\n",
    "    class_subset = df[df[label_column] == min_class].copy()\n",
    "\n",
    "    # Oblicz ile dodatkowych próbek potrzebujemy\n",
    "    num_to_add = num_max - num_min\n",
    "\n",
    "    # Inicjalizacja nowego zbioru danych\n",
    "    augmented_data = {'Utterances': [], label_column: []}\n",
    "\n",
    "    # Augmentuj dane, ale tylko do momentu wyrównania liczby próbek\n",
    "    augment_per_sample = max(1, num_to_add // len(class_subset))  # Ile augmentacji na 1 próbkę\n",
    "    remaining = num_to_add  # Ile jeszcze próbek musimy dodać\n",
    "\n",
    "    for _, row in tqdm(class_subset.iterrows(), total=len(class_subset), desc=f\"Augmenting class {min_class}\"):\n",
    "        if remaining <= 0:\n",
    "            break\n",
    "\n",
    "        # Wykonaj augmentację tekstu\n",
    "        new_texts = augment_text(row['Utterances'], num_augments=min(augment_per_sample, remaining))\n",
    "\n",
    "        for new_text in new_texts:\n",
    "            if remaining <= 0:\n",
    "                break\n",
    "            augmented_data['Utterances'].append(new_text)\n",
    "            augmented_data[label_column].append(min_class)\n",
    "            remaining -= 1  # Zmniejsz licznik brakujących próbek\n",
    "\n",
    "    # Tworzenie DataFrame z nowymi próbkami\n",
    "    augmented_df = pd.DataFrame(augmented_data)\n",
    "\n",
    "    # Połączenie oryginalnych danych z nowymi danymi\n",
    "    final_df = pd.concat([df, augmented_df], ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Sprawdź finalny rozkład klas\n",
    "    final_counts = final_df[label_column].value_counts()\n",
    "    print(f\"Liczność klas po augmentacji: {final_counts.to_dict()}\")\n",
    "\n",
    "    return final_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:20:23.883012Z",
     "start_time": "2025-04-14T11:20:23.863514Z"
    }
   },
   "id": "bf74b5425e90d5a1",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def augment_binary_data_percent(df, label_column, augment_text, augment_percent=25):\n",
    "    \"\"\"\n",
    "    Augments binary classification data by a specified percentage.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame with 'Utterances' column and a binary label column.\n",
    "    - label_column (str): Column name of the binary target label (0 or 1).\n",
    "    - augment_text (callable): Function to augment text. Should take a string and return a list of augmented strings.\n",
    "    - augment_percent (int): Percentage increase for each class (e.g., 25 means adding 25% more samples per class).\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Augmented DataFrame with increased class distributions.\n",
    "    \"\"\"\n",
    "    # Oblicz liczność klas\n",
    "    class_counts = df[label_column].value_counts()\n",
    "    print(f\"Liczność klas przed augmentacją: {class_counts.to_dict()}\")\n",
    "\n",
    "    # Inicjalizacja nowego zbioru danych\n",
    "    augmented_data = {'Utterances': [], label_column: []}\n",
    "\n",
    "    for label in class_counts.index:\n",
    "        class_subset = df[df[label_column] == label].copy()\n",
    "        num_to_add = int(class_counts[label] * (augment_percent / 100))\n",
    "\n",
    "        augment_per_sample = max(1, num_to_add // len(class_subset))\n",
    "        remaining = num_to_add\n",
    "\n",
    "        for _, row in tqdm(class_subset.iterrows(), total=len(class_subset), desc=f\"Augmenting class {label}\"):\n",
    "            if remaining <= 0:\n",
    "                break\n",
    "\n",
    "            new_texts = augment_text(row['Utterances'], num_augments=min(augment_per_sample, remaining))\n",
    "\n",
    "            for new_text in new_texts:\n",
    "                if remaining <= 0:\n",
    "                    break\n",
    "                augmented_data['Utterances'].append(new_text)\n",
    "                augmented_data[label_column].append(label)\n",
    "                remaining -= 1\n",
    "\n",
    "    # Tworzenie DataFrame z nowymi próbkami\n",
    "    augmented_df = pd.DataFrame(augmented_data)\n",
    "\n",
    "    # Połączenie oryginalnych danych z nowymi danymi\n",
    "    final_df = pd.concat([df, augmented_df], ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Sprawdź finalny rozkład klas\n",
    "    final_counts = final_df[label_column].value_counts()\n",
    "    print(f\"Liczność klas po augmentacji: {final_counts.to_dict()}\")\n",
    "\n",
    "    return final_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:20:23.906621Z",
     "start_time": "2025-04-14T11:20:23.889305Z"
    }
   },
   "id": "120d3b0d5958947f",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczność klas przed augmentacją: {0: 546, 1: 539}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting class 1:   1%|▏         | 7/539 [00:09<12:31,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczność klas po augmentacji: {1: 546, 0: 546}\n",
      "                                             Utterances  label\n",
      "0     My beautiful wife. When my father told me we w...      1\n",
      "1     here's what i don't get why would kay cappucci...      0\n",
      "2     but you can't stay for her, either but she nee...      0\n",
      "3     Of course my grandmother couldn't wait to go h...      0\n",
      "4     oh, come on, i touched one onion ring. and the...      0\n",
      "...                                                 ...    ...\n",
      "1087  that starts falling apart after 10 years power...      0\n",
      "1088                                No! He blew us off!      0\n",
      "1089                                     you'll have to      0\n",
      "1090       why would he do that? that much i don't know      1\n",
      "1091  You won't let me leave this room. You won't le...      1\n",
      "\n",
      "[1092 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Augmentation\n",
    "augmented_df = augment_binary_data(\n",
    "    df=df,\n",
    "    label_column='label',\n",
    "    augment_text=augment_text,\n",
    "    num_augments=2\n",
    ")\n",
    "\n",
    "print(augmented_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:20:33.816560Z",
     "start_time": "2025-04-14T11:20:23.909236Z"
    }
   },
   "id": "230e9a2bfc05843e",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczność klas przed augmentacją: {1: 546, 0: 546}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting class 1:  70%|██████▉   | 382/546 [03:54<01:40,  1.63it/s]\n",
      "Augmenting class 0:  70%|██████▉   | 382/546 [04:10<01:47,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczność klas po augmentacji: {0: 928, 1: 928}\n",
      "                                             Utterances  label\n",
      "0     without crushing their spirit now you privatio...      0\n",
      "1     i need to know the exact time that he arrived ...      0\n",
      "2     okay does anyone have experience shelving, tra...      0\n",
      "3     but not a day goes by that i don't regret it w...      0\n",
      "4     kah-ah! yes! why are you going to give me this...      0\n",
      "...                                                 ...    ...\n",
      "1851                   okay, i brought cheese, too okay      1\n",
      "1852  could use it for letters, what have you at the...      0\n",
      "1853  when the police asked if i thought she was sui...      1\n",
      "1854  i let house supervise himself. that's like han...      1\n",
      "1855      but i a in serious legend has the in plastics      0\n",
      "\n",
      "[1856 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = augment_binary_data_percent(\n",
    "    df=augmented_df,\n",
    "    label_column='label',\n",
    "    augment_text=augment_text,\n",
    "    augment_percent=70\n",
    ")\n",
    "\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:38.858063Z",
     "start_time": "2025-04-14T11:20:33.820894Z"
    }
   },
   "id": "fc800c4ee0aa2eb0",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64\n",
      "label\n",
      "0    928\n",
      "1    928\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_frequencies = df['label'].value_counts()\n",
    "label_frequencies_percent = df['label'].value_counts(normalize=True) * 100\n",
    "print(label_frequencies_percent)\n",
    "print(label_frequencies)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:38.877695Z",
     "start_time": "2025-04-14T11:28:38.862423Z"
    }
   },
   "id": "656eec943b8ae25b",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, random_state=77, test_size=0.30, shuffle=True)\n",
    "df_test, df_valid = train_test_split(df_test, random_state=88, test_size=0.50, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:38.908268Z",
     "start_time": "2025-04-14T11:28:38.887080Z"
    }
   },
   "id": "c053cc2ea6cbe64f",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train size: (1085, 4)\n",
      "Validation size: (279, 2), Test size: (278, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original train size: {df_data.shape}\")\n",
    "print(f\"Validation size: {df_valid.shape}, Test size: {df_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:38.926798Z",
     "start_time": "2025-04-14T11:28:38.914260Z"
    }
   },
   "id": "8d69bb5cab8227c",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                          Utterances  label\n0  without crushing their spirit now you privatio...      0\n1  i need to know the exact time that he arrived ...      0\n2  okay does anyone have experience shelving, tra...      0\n3  but not a day goes by that i don't regret it w...      0\n4  kah-ah! yes! why are you going to give me this...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Utterances</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>without crushing their spirit now you privatio...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i need to know the exact time that he arrived ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>okay does anyone have experience shelving, tra...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>but not a day goes by that i don't regret it w...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>kah-ah! yes! why are you going to give me this...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:38.945746Z",
     "start_time": "2025-04-14T11:28:38.929908Z"
    }
   },
   "id": "6313a5510286cb08",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64\n",
      "label\n",
      "0    928\n",
      "1    928\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_frequencies = df['label'].value_counts()\n",
    "label_frequencies_percent = df['label'].value_counts(normalize=True) * 100\n",
    "print(label_frequencies_percent)\n",
    "print(label_frequencies)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:38.960286Z",
     "start_time": "2025-04-14T11:28:38.948784Z"
    }
   },
   "id": "7478b534ccd10119",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_distribution = df['label'].value_counts(normalize=True)\n",
    "print(class_distribution)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:38.978738Z",
     "start_time": "2025-04-14T11:28:38.962366Z"
    }
   },
   "id": "7064823e84ebfa8",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "class_distribution.plot(kind='bar')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Sentiment Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:39.422692Z",
     "start_time": "2025-04-14T11:28:38.981897Z"
    }
   },
   "id": "73c13e7f14210a32",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['label']"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list = list(df.columns)\n",
    "target_list = target_list[1:]\n",
    "target_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:39.430927Z",
     "start_time": "2025-04-14T11:28:39.424691Z"
    }
   },
   "id": "981cb9e10ae1a9a5",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.utterances = list(df['Utterances'])\n",
    "        self.targets = self.df['label'].astype(int).values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.utterances)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        utterances = str(self.utterances[index])\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            utterances,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        target = torch.tensor(self.targets[index], dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            #'token_type_ids': inputs[\"token_type_ids\"].flatten(), -> nie potrzebne przy RoBERTa\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.long),\n",
    "            'utterances': utterances\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:39.444225Z",
     "start_time": "2025-04-14T11:28:39.431986Z"
    }
   },
   "id": "43e8c28009bdd96a",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# class BERTBinarySentimentClassificationClass(nn.Module):\n",
    "#     def __init__(self, bert_model):\n",
    "#         super(BERTBinarySentimentClassificationClass, self).__init__()\n",
    "#         self.bert = bert_model\n",
    "#         self.dropout = nn.Dropout(p=DROPOUT_RATE)\n",
    "#         self.out = nn.Linear(self.bert.config.hidden_size, 1)  # Binary classification (1 output)\n",
    "# \n",
    "#     def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "#         # Forward pass przez BERT\n",
    "#         outputs = self.bert(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             token_type_ids=token_type_ids\n",
    "#         )\n",
    "#         pooled_output = outputs.pooler_output\n",
    "#         dropout_output = self.dropout(pooled_output)\n",
    "#         return self.out(dropout_output)\n",
    "#         #return torch.sigmoid(self.out(dropout_output))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:39.452427Z",
     "start_time": "2025-04-14T11:28:39.446203Z"
    }
   },
   "id": "6e94d6131ac088b5",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# class RoBERTaBinarySentimentClassificationClass(nn.Module):\n",
    "#     def __init__(self, roberta_model):\n",
    "#         super(RoBERTaBinarySentimentClassificationClass, self).__init__()\n",
    "#         self.roberta = roberta_model\n",
    "#         self.dropout = nn.Dropout(p=DROPOUT_RATE)\n",
    "#         self.out = nn.Linear(self.roberta.config.hidden_size, 1)  # Binary classification\n",
    "# \n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         # Forward pass przez RoBERTa\n",
    "#         outputs = self.roberta(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask\n",
    "#         )\n",
    "#         # Sprawdzenie, czy pooler_output jest dostępne\n",
    "#         if hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
    "#             pooled_output = outputs.pooler_output  # Preferowane, jeśli dostępne\n",
    "#         else:\n",
    "#             pooled_output = outputs.last_hidden_state[:, 0, :]  # Wykorzystanie tokena [CLS]\n",
    "# \n",
    "#         dropout_output = self.dropout(pooled_output)\n",
    "#         return self.out(dropout_output)\n",
    "#         # return torch.sigmoid(self.out(dropout_output))  # Jeśli używasz BCEWithLogitsLoss, sigmoid nie jest potrzebny"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:39.465198Z",
     "start_time": "2025-04-14T11:28:39.460872Z"
    }
   },
   "id": "e0a40b7814203672",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BERTLSTMClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, lstm_hidden_dim=128, lstm_layers=1, dropout_rate=DROPOUT_RATE, bidirectional=True):\n",
    "        super(BERTLSTMClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.bert.config.hidden_size,\n",
    "            hidden_size=lstm_hidden_dim,\n",
    "            num_layers=lstm_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_rate if lstm_layers > 1 else 0\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        # Jeśli LSTM jest dwukierunkowe, rozmiar wejścia do fc to lstm_hidden_dim*2, w przeciwnym wypadku lstm_hidden_dim\n",
    "        fc_input_dim = lstm_hidden_dim * 2 if bidirectional else lstm_hidden_dim\n",
    "        self.fc = nn.Linear(fc_input_dim, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        # Pobranie reprezentacji z BERTa (cała sekwencja)\n",
    "        bert_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        # last_hidden_state: tensor o wymiarach (batch_size, seq_length, hidden_size)\n",
    "        sequence_output = bert_output.last_hidden_state\n",
    "\n",
    "        # Przepuszczenie przez LSTM\n",
    "        lstm_output, (hidden, _) = self.lstm(sequence_output)\n",
    "        # Jeśli LSTM jest dwukierunkowe, ukryty stan z ostatniej warstwy ma wymiar (num_layers*2, batch, hidden_dim)\n",
    "        if self.lstm.bidirectional:\n",
    "            # Pobieramy ostatnie stany z obu kierunków i je łączymy\n",
    "            hidden_forward = hidden[-2, :, :]  # ostatnia warstwa, kierunek \"forward\"\n",
    "            hidden_backward = hidden[-1, :, :]  # ostatnia warstwa, kierunek \"backward\"\n",
    "            hidden = torch.cat((hidden_forward, hidden_backward), dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1, :, :]\n",
    "\n",
    "        dropout_output = self.dropout(hidden)\n",
    "        logits = self.fc(dropout_output)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:39.480335Z",
     "start_time": "2025-04-14T11:28:39.469141Z"
    }
   },
   "id": "2082ab52f98981f",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# class BERTCNNClassifier(nn.Module):\n",
    "#     def __init__(self, bert_model, num_filters=100, filter_sizes=[2, 3, 4], dropout_rate=0.3):\n",
    "#         super(BERTCNNClassifier, self).__init__()\n",
    "#         self.bert = bert_model\n",
    "#         # Tworzymy listę konwolucji: każdy filtr działa na \"okno\" o danej wielkości\n",
    "#         self.convs = nn.ModuleList([\n",
    "#             nn.Conv2d(\n",
    "#                 in_channels=1,\n",
    "#                 out_channels=num_filters,\n",
    "#                 kernel_size=(fs, self.bert.config.hidden_size)\n",
    "#             )\n",
    "#             for fs in filter_sizes\n",
    "#         ])\n",
    "#         self.dropout = nn.Dropout(dropout_rate)\n",
    "#         self.fc = nn.Linear(num_filters * len(filter_sizes), 1)\n",
    "# \n",
    "#     def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "#         bert_output = self.bert(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             token_type_ids=token_type_ids\n",
    "#         )\n",
    "#         # last_hidden_state: (batch_size, seq_length, hidden_size)\n",
    "#         sequence_output = bert_output.last_hidden_state\n",
    "# \n",
    "#         # Dodajemy wymiar kanału (potrzebny dla CNN)\n",
    "#         x = sequence_output.unsqueeze(1)  # (batch_size, 1, seq_length, hidden_size)\n",
    "# \n",
    "#         # Przepuszczamy przez każdy filtr konwolucyjny\n",
    "#         conved = [F.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
    "#         # conved[i] ma wymiary: (batch_size, num_filters, seq_length - filter_size + 1)\n",
    "# \n",
    "#         # Wykonujemy max-pooling na każdej mapie cech\n",
    "#         pooled = [F.max_pool1d(feature_map, kernel_size=feature_map.size(2)).squeeze(2) for feature_map in conved]\n",
    "#         # pooled[i] ma wymiary: (batch_size, num_filters)\n",
    "# \n",
    "#         # Łączymy wyniki z różnych filtrów\n",
    "#         cat = torch.cat(pooled, dim=1)  # (batch_size, num_filters * len(filter_sizes))\n",
    "# \n",
    "#         dropout_output = self.dropout(cat)\n",
    "#         logits = self.fc(dropout_output)\n",
    "#         return logits\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:39.490021Z",
     "start_time": "2025-04-14T11:28:39.482342Z"
    }
   },
   "id": "e21b2c05a1cc0abd",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def freeze_bert_layers(model, freeze_until_layer=6):\n",
    "    \"\"\"\n",
    "    Zamraża wszystkie warstwy enkodera BERT, których numer jest mniejszy niż freeze_until_layer.\n",
    "    W modelu BERT-base (12 warstw): przy freeze_until_layer=6, zamrożone zostaną warstwy 0-5.\n",
    "    \"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        # Szukamy parametrów, które należą do warstw enkodera\n",
    "        if \"bert.encoder.layer\" in name:\n",
    "            # Nazwa ma postać: bert.encoder.layer.<layer_num>...\n",
    "            try:\n",
    "                layer_num = int(name.split('.')[3])\n",
    "            except:\n",
    "                continue  # zabezpieczenie, gdyby parsowanie się nie udało\n",
    "            if layer_num < freeze_until_layer:\n",
    "                param.requires_grad = False\n",
    "                # Możesz też dodać print dla debugowania:\n",
    "                print(f\"Freezing parameter: {name}\")\n",
    "    print(f\"Frozen BERT layers: 0-{freeze_until_layer - 1}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:39.501189Z",
     "start_time": "2025-04-14T11:28:39.493307Z"
    }
   },
   "id": "1e7fdb5f2c851622",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#model_path = 'best_model_state.bin'\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "#model = BERTBinarySentimentClassificationClass(bert_model)\n",
    "model = BERTLSTMClassifier(bert_model, lstm_layers=LSTM_LAYERS, lstm_hidden_dim=LSTM_HIDDEN_DIM)\n",
    "#model = BERTCNNClassifier(bert_model)\n",
    "\n",
    "# roberta_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "# model = RoBERTaBinarySentimentClassificationClass(roberta_model)\n",
    "\n",
    "\n",
    "#model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:41.864067Z",
     "start_time": "2025-04-14T11:28:39.507284Z"
    }
   },
   "id": "d5256b71691e1c46",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN)\n",
    "valid_dataset = CustomDataset(df_valid, tokenizer, MAX_LEN)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:41.876353Z",
     "start_time": "2025-04-14T11:28:41.867053Z"
    }
   },
   "id": "aadf862ae0047947",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH, shuffle=True, num_workers=0)\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH, shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:41.914564Z",
     "start_time": "2025-04-14T11:28:41.878850Z"
    }
   },
   "id": "de1b1918cc1209d9",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0962],\n",
      "        [ 0.0359],\n",
      "        [ 0.0798],\n",
      "        [ 0.0248],\n",
      "        [ 0.0117],\n",
      "        [ 0.0321],\n",
      "        [ 0.1125],\n",
      "        [ 0.1229],\n",
      "        [ 0.0455],\n",
      "        [ 0.0658],\n",
      "        [ 0.1004],\n",
      "        [-0.0252],\n",
      "        [ 0.0886],\n",
      "        [ 0.0527],\n",
      "        [ 0.0576],\n",
      "        [ 0.0477],\n",
      "        [ 0.0221],\n",
      "        [ 0.0595],\n",
      "        [ 0.0381],\n",
      "        [ 0.0644],\n",
      "        [ 0.1080],\n",
      "        [ 0.0888],\n",
      "        [-0.0367],\n",
      "        [ 0.1430],\n",
      "        [ 0.1247],\n",
      "        [ 0.1355],\n",
      "        [ 0.1104],\n",
      "        [ 0.0296],\n",
      "        [-0.0167],\n",
      "        [ 0.0161],\n",
      "        [ 0.0181],\n",
      "        [ 0.0107]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "outputs = model(data[\"input_ids\"], attention_mask=data[\"attention_mask\"])\n",
    "print(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:48.627458Z",
     "start_time": "2025-04-14T11:28:41.916566Z"
    }
   },
   "id": "8e2ccb1ee90e217c",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_text = \"We are testing BERT tokenizer.\"\n",
    "encodings = tokenizer.encode_plus(test_text,\n",
    "                                  add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                                  max_length = 50,\n",
    "                                  truncation = True,\n",
    "                                  padding = \"max_length\",\n",
    "                                  return_attention_mask = True,\n",
    "                                  return_tensors = \"pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:48.637191Z",
     "start_time": "2025-04-14T11:28:48.629530Z"
    }
   },
   "id": "f1b009a33dc77303",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "#bert_model = RobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "last_hidden_state, pooled_output = bert_model(\n",
    "    input_ids=encodings['input_ids'],\n",
    "    attention_mask=encodings['attention_mask']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:50.145291Z",
     "start_time": "2025-04-14T11:28:48.640341Z"
    }
   },
   "id": "2bec695a35b6a3f",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def loss_fn(outputs, targets):\n",
    "#     # jesli uzywamy BCEWithLogitsLoss, to w modelu nie musimy dodawać sigmoid, bo ta funkcja już zawiera operację sigmoid.\n",
    "#     return torch.nn.BCEWithLogitsLoss()(outputs.squeeze(-1), targets.float())\n",
    "\n",
    "# def loss_fn(outputs, targets):\n",
    "#     return torch.nn.BCELoss()(outputs.squeeze(), targets.float())\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs powinny być wyjściem z modelu (logity)\n",
    "        bce_loss = self.bce(inputs, targets.float())\n",
    "        probas = torch.sigmoid(inputs)\n",
    "        # Obliczenie p_t: dla próbki z target=1 mamy probas, dla target=0 mamy 1 - probas\n",
    "        p_t = targets * probas + (1 - targets) * (1 - probas)\n",
    "        loss = self.alpha * (1 - p_t) ** self.gamma * bce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "loss_fn = FocalLoss(alpha=FOCAL_LOSS_ALFA, gamma=FOCAL_LOSS_GAMMA, reduction='mean')\n",
    "#gamma\n",
    "#Odpowiada za redukowanie wagi łatwo sklasyfikowanych przykładów. Wyższa wartość gamma sprawia, że model skupia się bardziej na trudnych przypadkach.\n",
    "#Jeśli gamma jest zbyt wysoka (np. 2 lub więcej), może to powodować, że model zaniedbuje uczenie się na przykładach, które są łatwiejsze do sklasyfikowania, co może negatywnie wpływać na ogólną stabilność treningu.\n",
    "#W twoim przypadku, skoro klasa 1 nie jest przewidywana, warto spróbować obniżyć wartość gamma (np. do 1), aby nie tłumić gradientów zbyt mocno.\n",
    "\n",
    "#alpha\n",
    "#Umożliwia balansowanie klas poprzez przypisanie większej wagi przykładom z klasy, która jest niedoreprezentowana lub trudniejsza do nauki.\n",
    "# W twoim kodzie alpha=1 oznacza, że wszystkie próbki są traktowane jednakowo. Jeśli obserwujesz, że jedna klasa (tu klasa 1) jest pomijana, możesz spróbować nadać jej większą wagę.\n",
    "# Możesz rozważyć modyfikację alpha na wektor, np. alpha = [0.25, 0.75] lub inne wartości, w zależności od nierównowagi między klasami. To pozwoli nadać przykładom z klasy 1 większy wpływ na stratę.\n",
    "\n",
    "\n",
    "#Zmodyfikuj implementację, aby alpha było wektorem wag (np. alpha = [waga_klasy0, waga_klasy1]), co pozwoli na precyzyjne balansowanie strat między klasami.\n",
    "#Przeprowadź serię eksperymentów (np. grid search) z różnymi wartościami gamma i alpha, aby znaleźć najlepszą kombinację, która poprawi metryki takie jak F1-score, szczególnie dla klasy 1.\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:50.159219Z",
     "start_time": "2025-04-14T11:28:50.147150Z"
    }
   },
   "id": "77a7cac8c06c5ae1",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juwieczo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir='logs')\n",
    "\n",
    "#optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# learning rate scheduler\n",
    "# ReduceLROnPlateau może obniżać lr do bardzo małych wartości, co czasem prowadzi do problemów. Możesz dodać min_lr, aby ograniczyć ten efekt:\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=MODE, patience=PATIENCE, factor=FACTOR, verbose=VERBOSE)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:53.086642Z",
     "start_time": "2025-04-14T11:28:50.161473Z"
    }
   },
   "id": "ea368685bd23d290",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(training_loader, model, optimizer):\n",
    "    \"\"\"\n",
    "    Trenuje model na danych treningowych i zwraca model, dokładność, średni loss oraz F1-score.\n",
    "\n",
    "    Args:\n",
    "        training_loader (DataLoader): DataLoader z danymi treningowymi.\n",
    "        model (torch.nn.Module): Model do trenowania.\n",
    "        optimizer (torch.optim.Optimizer): Optymalizator do aktualizacji wag modelu.\n",
    "        loss_fn (callable): Funkcja strat, np. nn.BCEWithLogitsLoss.\n",
    "\n",
    "    Returns:\n",
    "        model (torch.nn.Module): Wytrenowany model.\n",
    "        train_accuracy (float): Dokładność modelu na zbiorze treningowym.\n",
    "        avg_loss (float): Średnia wartość funkcji strat.\n",
    "        train_f1 (float): F1-score (binary) na zbiorze treningowym.\n",
    "    \"\"\"\n",
    "    # Inicjalizacja zmiennych do śledzenia wyników\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loop = tq.tqdm(enumerate(training_loader), total=len(training_loader), leave=True, colour='steelblue')\n",
    "\n",
    "    for batch_idx, data in loop:\n",
    "        ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "        #token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "        targets = data['targets'].to(device, dtype=torch.float)  # Binary targets jako float\n",
    "\n",
    "        #outputs = model(ids, mask, token_type_ids if 'token_type_ids' in data else None)\n",
    "        outputs = model(ids, mask if 'token_type_ids' in data else None)\n",
    "\n",
    "        outputs = outputs.squeeze(-1)  # Dopasowanie wymiarów do binary classification (1D)\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        preds = torch.sigmoid(outputs) >= 0.5  # Sigmoid + progowanie przy 0.5\n",
    "        correct_predictions += torch.sum(preds == targets).item()\n",
    "        num_samples += targets.size(0)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        loop.set_postfix(batch_loss=loss.item())\n",
    "\n",
    "    train_f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    return model, correct_predictions / num_samples, np.mean(losses), train_f1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:53.098087Z",
     "start_time": "2025-04-14T11:28:53.088199Z"
    }
   },
   "id": "b856ca62d79ec79c",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def eval_model(validation_loader, model, epoch):\n",
    "    \"\"\"\n",
    "    Ewaluacja modelu na danych walidacyjnych.\n",
    "\n",
    "    Args:\n",
    "        validation_loader (DataLoader): DataLoader z danymi walidacyjnymi.\n",
    "        model (torch.nn.Module): Model do oceny.\n",
    "        loss_fn (callable): Funkcja strat, np. nn.BCEWithLogitsLoss.\n",
    "        epoch (int): Aktualny numer epoki do logowania w TensorBoard.\n",
    "\n",
    "    Returns:\n",
    "        val_accuracy (float): Dokładność modelu na zbiorze walidacyjnym.\n",
    "        avg_loss (float): Średnia wartość funkcji strat na zbiorze walidacyjnym.\n",
    "        val_f1 (float): F1-score (binary) na zbiorze walidacyjnym.\n",
    "    \"\"\"\n",
    "    # Inicjalizacja zmiennych do śledzenia wyników\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Ustaw model w tryb ewaluacyjny\n",
    "    model.eval()\n",
    "\n",
    "    # Wyłącz gradienty dla ewaluacji\n",
    "    with torch.no_grad():\n",
    "        for data in validation_loader:\n",
    "            ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "            #token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype=torch.float)  # Binary targets jako float\n",
    "\n",
    "            #outputs = model(ids, mask, token_type_ids if 'token_type_ids' in data else None)\n",
    "            outputs = model(ids, mask if 'token_type_ids' in data else None)\n",
    "\n",
    "            outputs = outputs.squeeze(-1)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            preds = torch.sigmoid(outputs) >= 0.5  # Sigmoid + progowanie przy 0.5\n",
    "            correct_predictions += torch.sum(preds == targets).item()\n",
    "            num_samples += targets.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    avg_loss = np.mean(losses)\n",
    "    val_f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    writer.add_scalar('Loss/validation', avg_loss, epoch)\n",
    "    writer.add_scalar('F1-Score/validation', val_f1, epoch)\n",
    "\n",
    "    return correct_predictions / num_samples, avg_loss, val_f1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:53.109298Z",
     "start_time": "2025-04-14T11:28:53.100115Z"
    }
   },
   "id": "85ae992f90f3f334",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def count_trainable_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T11:28:53.120996Z",
     "start_time": "2025-04-14T11:28:53.113544Z"
    }
   },
   "id": "5b40517357c888be",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/41 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "554341799b024180934fe9bacda5b0d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6788 | Train accuracy 0.5935 | Train F1 0.5803\n",
      "Val loss 0.6947 | Val accuracy 0.5412 | Val F1 0.5493\n",
      "Saved new best model.\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/41 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2df9c3e7d484033bb9c769585f2d84a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6742 | Train accuracy 0.5905 | Train F1 0.5710\n",
      "Val loss 0.7082 | Val accuracy 0.5305 | Val F1 0.6469\n",
      "Saved new best model.\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/41 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f75f386a5171432991119b2046dda1ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6613 | Train accuracy 0.6243 | Train F1 0.5933\n",
      "Val loss 0.6863 | Val accuracy 0.5806 | Val F1 0.5714\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/41 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6fa9caecfe1a4fd78c922cab99d0dff0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6177 | Train accuracy 0.6959 | Train F1 0.6760\n",
      "Val loss 0.7146 | Val accuracy 0.5735 | Val F1 0.6704\n",
      "Saved new best model.\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/41 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7827bfe2d722475ebc479a23ac3bfd45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5864 | Train accuracy 0.7244 | Train F1 0.7118\n",
      "Val loss 0.6852 | Val accuracy 0.5878 | Val F1 0.6075\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/41 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8651232f05f14ee6996e44608cbc48cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5523 | Train accuracy 0.7575 | Train F1 0.7368\n",
      "Val loss 0.7112 | Val accuracy 0.6022 | Val F1 0.6498\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/41 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a62b300bbb1242a6b3b179f0fa8ac484"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5312 | Train accuracy 0.7829 | Train F1 0.7685\n",
      "Val loss 0.7064 | Val accuracy 0.6057 | Val F1 0.6333\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/41 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21d8869a4e5d49d292a85b460572b6df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5214 | Train accuracy 0.7906 | Train F1 0.7752\n",
      "Val loss 0.7191 | Val accuracy 0.6093 | Val F1 0.6562\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/41 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b2b314e6c1741cc942e8376f12d50cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5187 | Train accuracy 0.7937 | Train F1 0.7803\n",
      "Val loss 0.7180 | Val accuracy 0.6057 | Val F1 0.6474\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/41 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b56e50015bc744d2a621e7a993c305b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = defaultdict(list)\n",
    "best_f1 = 0\n",
    "patience_counter = 0\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "\n",
    "    model, train_acc, train_loss, train_f1 = train_model(train_data_loader, model, optimizer)\n",
    "    print(f'Train loss {train_loss:.4f} | Train accuracy {train_acc:.4f} | Train F1 {train_f1:.4f}')\n",
    "\n",
    "    val_acc, val_loss, val_f1 = eval_model(val_data_loader, model, epoch)\n",
    "    print(f'Val loss {val_loss:.4f} | Val accuracy {val_acc:.4f} | Val F1 {val_f1:.4f}')\n",
    "\n",
    "    # Logowanie metryk do TensorBoard\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "    writer.add_scalar('F1-Score/train', train_f1, epoch)\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_f1'].append(train_f1)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_f1'].append(val_f1)\n",
    "\n",
    "    if val_f1 > best_f1:\n",
    "        torch.save(model.state_dict(), \"best_binary_model_state.bin\")\n",
    "        best_f1 = val_f1\n",
    "        print(\"Saved new best model.\")\n",
    "\n",
    "    #scheduler.step(val_loss)  # Tuning LR\n",
    "    scheduler.step()\n",
    "\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-04-14T12:01:02.859819Z"
    }
   },
   "id": "134691e19bd73c9a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e1afc6cd3268ae0f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer learning to ESConv dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f952fdde39a28c2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\", encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "#dataset = load_data(\"D:/julixus/MEISD/meisd_project/data/ESConv.json\")\n",
    "dataset = load_data(\"C:/Users/juwieczo/DataspellProjects/meisd_project/data/ESConv.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T15:02:07.261218Z",
     "start_time": "2025-04-14T15:02:07.016309Z"
    }
   },
   "id": "e74cfffe2519a329",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  initial_emotion_intensity                                             dialog\n0                         5  [Hello, I am having a lot of anxiety about qui...\n1                         5  [hello im looking for someone to talk to, im f...\n2                         4  [Hello, I'm concerned about my job. I have bee...\n3                         4  [I am dong good. You?, I have been staying hom...\n4                         5  [Infinitely complicated., Too many decisions. ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>initial_emotion_intensity</th>\n      <th>dialog</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>[Hello, I am having a lot of anxiety about qui...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>[hello im looking for someone to talk to, im f...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>[Hello, I'm concerned about my job. I have bee...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>[I am dong good. You?, I have been staying hom...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>[Infinitely complicated., Too many decisions. ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_seeker_data(data, key):\n",
    "    result = []\n",
    "\n",
    "    for entry in data:\n",
    "        dialog = entry['dialog']\n",
    "        seeker_dialog = [item['content'].strip() for item in dialog if item['speaker'] == 'seeker']\n",
    "\n",
    "        quarter_length = max(1, len(seeker_dialog) // 4)\n",
    "\n",
    "        if key == 'initial_emotion_intensity':\n",
    "            selected_dialog = seeker_dialog[:quarter_length]\n",
    "        elif key == 'final_emotion_intensity':\n",
    "            selected_dialog = seeker_dialog[-quarter_length:]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        result.append({\n",
    "            key: entry['survey_score']['seeker'][key],\n",
    "            'dialog': selected_dialog\n",
    "        })\n",
    "\n",
    "    return result\n",
    "\n",
    "first_25_percent = extract_seeker_data(dataset, 'initial_emotion_intensity')\n",
    "#last_25_percent = extract_seeker_data(dataset, 'final_emotion_intensity')\n",
    "\n",
    "first_25_df = pd.DataFrame(first_25_percent)\n",
    "#last_25_df = pd.DataFrame(last_25_percent)\n",
    "\n",
    "first_25_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T15:02:08.204050Z",
     "start_time": "2025-04-14T15:02:08.093658Z"
    }
   },
   "id": "a2a3e0a1d7d37ee0",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "label_counts = first_25_df['initial_emotion_intensity'].value_counts()\n",
    "least_common_label = label_counts.idxmin()\n",
    "first_25_df = first_25_df[first_25_df['initial_emotion_intensity'] != least_common_label]\n",
    "first_25_df['initial_emotion_intensity'] = pd.to_numeric(first_25_df['initial_emotion_intensity'], errors='coerce')\n",
    "first_25_df['initial_emotion_intensity'] = first_25_df['initial_emotion_intensity'] - 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T15:02:09.185833Z",
     "start_time": "2025-04-14T15:02:09.158950Z"
    }
   },
   "id": "5fb5f7b4ca2c53a3",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      label                                         Utterances\n0         3  [Hello, I am having a lot of anxiety about qui...\n1         3  [hello im looking for someone to talk to, im f...\n2         2  [Hello, I'm concerned about my job. I have bee...\n3         2  [I am dong good. You?, I have been staying hom...\n4         3  [Infinitely complicated., Too many decisions. ...\n...     ...                                                ...\n1295      3  [I feel sleepy but can not sleep, It has alway...\n1296      2  [I am fine. thanks. how about you ?, I lost my...\n1297      1        [HI how are you today, Doing well, thanks.]\n1298      1  [Hello, I am a little down today.  How are you...\n1299      1                                  [hi, i'm nereida]\n\n[1298 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>Utterances</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>[Hello, I am having a lot of anxiety about qui...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>[hello im looking for someone to talk to, im f...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[Hello, I'm concerned about my job. I have bee...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>[I am dong good. You?, I have been staying hom...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>[Infinitely complicated., Too many decisions. ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1295</th>\n      <td>3</td>\n      <td>[I feel sleepy but can not sleep, It has alway...</td>\n    </tr>\n    <tr>\n      <th>1296</th>\n      <td>2</td>\n      <td>[I am fine. thanks. how about you ?, I lost my...</td>\n    </tr>\n    <tr>\n      <th>1297</th>\n      <td>1</td>\n      <td>[HI how are you today, Doing well, thanks.]</td>\n    </tr>\n    <tr>\n      <th>1298</th>\n      <td>1</td>\n      <td>[Hello, I am a little down today.  How are you...</td>\n    </tr>\n    <tr>\n      <th>1299</th>\n      <td>1</td>\n      <td>[hi, i'm nereida]</td>\n    </tr>\n  </tbody>\n</table>\n<p>1298 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_25_df.rename(columns={\n",
    "    'dialog': 'Utterances',\n",
    "    'initial_emotion_intensity': 'label'\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T15:02:10.381806Z",
     "start_time": "2025-04-14T15:02:10.365309Z"
    }
   },
   "id": "a5038c8d54db5f67",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_data['label'] = (df_data['max_intensity'] == 2).astype(int)\n",
    "columns = ['Utterances', 'label']\n",
    "df = df_data[columns].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T15:02:11.542698Z",
     "start_time": "2025-04-14T15:02:11.528665Z"
    }
   },
   "id": "c3d3ba2d4b569246",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESConv: Train (759, 2), Valid (163, 2), Test (163, 2)\n"
     ]
    }
   ],
   "source": [
    "df_train_esconv, df_temp_esconv = train_test_split(df, random_state=77, test_size=0.30, shuffle=True)\n",
    "df_valid_esconv, df_test_esconv = train_test_split(df_temp_esconv, random_state=88, test_size=0.50, shuffle=True)\n",
    "print(f\"ESConv: Train {df_train_esconv.shape}, Valid {df_valid_esconv.shape}, Test {df_test_esconv.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T15:02:12.825119Z",
     "start_time": "2025-04-14T15:02:12.788254Z"
    }
   },
   "id": "1a61879bc5efc024",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset_esconv = CustomDataset(df_train_esconv, tokenizer, MAX_LEN)\n",
    "valid_dataset_esconv = CustomDataset(df_valid_esconv, tokenizer, MAX_LEN)\n",
    "train_data_loader_esconv = torch.utils.data.DataLoader(train_dataset_esconv, batch_size=BATCH, shuffle=True)\n",
    "valid_data_loader_esconv = torch.utils.data.DataLoader(valid_dataset_esconv, batch_size=BATCH, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T15:02:14.025736Z",
     "start_time": "2025-04-14T15:02:14.012958Z"
    }
   },
   "id": "6476534e8c7bbcd1",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juwieczo\\AppData\\Local\\Temp\\ipykernel_21892\\2512349191.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_meisd_model_state.bin\"))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best_meisd_model_state.bin'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbest_meisd_model_state.bin\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1319\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1316\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m   1317\u001B[0m     pickle_load_args[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1319\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m   1320\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[0;32m   1321\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[0;32m   1322\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[0;32m   1323\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[0;32m   1324\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:659\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    657\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[0;32m    658\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[1;32m--> 659\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    660\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    661\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:640\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    639\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[1;32m--> 640\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'best_meisd_model_state.bin'"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_meisd_model_state.bin\"))\n",
    "model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T15:02:16.759283Z",
     "start_time": "2025-04-14T15:02:15.686829Z"
    }
   },
   "id": "4a86f720c348d6b3",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before freezing on ESConv: Total params: 110797313, Trainable params: 110797313\n"
     ]
    }
   ],
   "source": [
    "total_params, trainable_params = count_trainable_parameters(model)\n",
    "print(f\"Before freezing on ESConv: Total params: {total_params}, Trainable params: {trainable_params}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T15:02:17.802382Z",
     "start_time": "2025-04-14T15:02:17.795659Z"
    }
   },
   "id": "7b62b214b225c503",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing parameter: bert.encoder.layer.0.attention.self.query.weight\n",
      "Freezing parameter: bert.encoder.layer.0.attention.self.query.bias\n",
      "Freezing parameter: bert.encoder.layer.0.attention.self.key.weight\n",
      "Freezing parameter: bert.encoder.layer.0.attention.self.key.bias\n",
      "Freezing parameter: bert.encoder.layer.0.attention.self.value.weight\n",
      "Freezing parameter: bert.encoder.layer.0.attention.self.value.bias\n",
      "Freezing parameter: bert.encoder.layer.0.attention.output.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.0.attention.output.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "Freezing parameter: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "Freezing parameter: bert.encoder.layer.0.intermediate.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.0.intermediate.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.0.output.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.0.output.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.0.output.LayerNorm.weight\n",
      "Freezing parameter: bert.encoder.layer.0.output.LayerNorm.bias\n",
      "Freezing parameter: bert.encoder.layer.1.attention.self.query.weight\n",
      "Freezing parameter: bert.encoder.layer.1.attention.self.query.bias\n",
      "Freezing parameter: bert.encoder.layer.1.attention.self.key.weight\n",
      "Freezing parameter: bert.encoder.layer.1.attention.self.key.bias\n",
      "Freezing parameter: bert.encoder.layer.1.attention.self.value.weight\n",
      "Freezing parameter: bert.encoder.layer.1.attention.self.value.bias\n",
      "Freezing parameter: bert.encoder.layer.1.attention.output.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.1.attention.output.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "Freezing parameter: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "Freezing parameter: bert.encoder.layer.1.intermediate.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.1.intermediate.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.1.output.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.1.output.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.1.output.LayerNorm.weight\n",
      "Freezing parameter: bert.encoder.layer.1.output.LayerNorm.bias\n",
      "Freezing parameter: bert.encoder.layer.2.attention.self.query.weight\n",
      "Freezing parameter: bert.encoder.layer.2.attention.self.query.bias\n",
      "Freezing parameter: bert.encoder.layer.2.attention.self.key.weight\n",
      "Freezing parameter: bert.encoder.layer.2.attention.self.key.bias\n",
      "Freezing parameter: bert.encoder.layer.2.attention.self.value.weight\n",
      "Freezing parameter: bert.encoder.layer.2.attention.self.value.bias\n",
      "Freezing parameter: bert.encoder.layer.2.attention.output.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.2.attention.output.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "Freezing parameter: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "Freezing parameter: bert.encoder.layer.2.intermediate.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.2.intermediate.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.2.output.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.2.output.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.2.output.LayerNorm.weight\n",
      "Freezing parameter: bert.encoder.layer.2.output.LayerNorm.bias\n",
      "Freezing parameter: bert.encoder.layer.3.attention.self.query.weight\n",
      "Freezing parameter: bert.encoder.layer.3.attention.self.query.bias\n",
      "Freezing parameter: bert.encoder.layer.3.attention.self.key.weight\n",
      "Freezing parameter: bert.encoder.layer.3.attention.self.key.bias\n",
      "Freezing parameter: bert.encoder.layer.3.attention.self.value.weight\n",
      "Freezing parameter: bert.encoder.layer.3.attention.self.value.bias\n",
      "Freezing parameter: bert.encoder.layer.3.attention.output.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.3.attention.output.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "Freezing parameter: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "Freezing parameter: bert.encoder.layer.3.intermediate.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.3.intermediate.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.3.output.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.3.output.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "Freezing parameter: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "Freezing parameter: bert.encoder.layer.4.attention.self.query.weight\n",
      "Freezing parameter: bert.encoder.layer.4.attention.self.query.bias\n",
      "Freezing parameter: bert.encoder.layer.4.attention.self.key.weight\n",
      "Freezing parameter: bert.encoder.layer.4.attention.self.key.bias\n",
      "Freezing parameter: bert.encoder.layer.4.attention.self.value.weight\n",
      "Freezing parameter: bert.encoder.layer.4.attention.self.value.bias\n",
      "Freezing parameter: bert.encoder.layer.4.attention.output.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.4.attention.output.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "Freezing parameter: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "Freezing parameter: bert.encoder.layer.4.intermediate.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.4.intermediate.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.4.output.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.4.output.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.4.output.LayerNorm.weight\n",
      "Freezing parameter: bert.encoder.layer.4.output.LayerNorm.bias\n",
      "Freezing parameter: bert.encoder.layer.5.attention.self.query.weight\n",
      "Freezing parameter: bert.encoder.layer.5.attention.self.query.bias\n",
      "Freezing parameter: bert.encoder.layer.5.attention.self.key.weight\n",
      "Freezing parameter: bert.encoder.layer.5.attention.self.key.bias\n",
      "Freezing parameter: bert.encoder.layer.5.attention.self.value.weight\n",
      "Freezing parameter: bert.encoder.layer.5.attention.self.value.bias\n",
      "Freezing parameter: bert.encoder.layer.5.attention.output.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.5.attention.output.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "Freezing parameter: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "Freezing parameter: bert.encoder.layer.5.intermediate.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.5.intermediate.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.5.output.dense.weight\n",
      "Freezing parameter: bert.encoder.layer.5.output.dense.bias\n",
      "Freezing parameter: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "Freezing parameter: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "Frozen BERT layers: 0-5\n",
      "After freezing on ESConv: Total params: 110797313, Trainable params: 68270081\n"
     ]
    }
   ],
   "source": [
    "freeze_bert_layers(model, freeze_until_layer=6)\n",
    "total_params, trainable_params = count_trainable_parameters(model)\n",
    "print(f\"After freezing on ESConv: Total params: {total_params}, Trainable params: {trainable_params}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T15:02:24.471554Z",
     "start_time": "2025-04-14T15:02:24.462387Z"
    }
   },
   "id": "c9de44483af3d0b6",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juwieczo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer_esconv = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE_FINE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler_esconv = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_esconv, T_max=EPOCHS)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T15:02:26.213324Z",
     "start_time": "2025-04-14T15:02:26.120566Z"
    }
   },
   "id": "611128487641b380",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning on ESConv...\n",
      "Fine-tuning Epoch 1/10 (ESConv)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f00584a649d84abb83b05f8a9801f38b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESConv Train loss 0.5695 | Train accuracy 0.7365 | Train F1 0.7260\n",
      "ESConv Val loss 0.6168 | Val accuracy 0.7362 | Val F1 0.7749\n",
      "Saved new best ESConv model.\n",
      "Fine-tuning Epoch 2/10 (ESConv)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7588ab1197b84f4ab5ea1ac5424f23f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESConv Train loss 0.5584 | Train accuracy 0.7523 | Train F1 0.7466\n",
      "ESConv Val loss 0.5760 | Val accuracy 0.7607 | Val F1 0.7845\n",
      "Saved new best ESConv model.\n",
      "Fine-tuning Epoch 3/10 (ESConv)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7e0bf9aa6b54eb492a7e4bc9bfc9a91"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESConv Train loss 0.5423 | Train accuracy 0.7563 | Train F1 0.7441\n",
      "ESConv Val loss 0.6426 | Val accuracy 0.7239 | Val F1 0.7692\n",
      "Fine-tuning Epoch 4/10 (ESConv)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39a153cf6de140feab8b3914aec10fbe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESConv Train loss 0.5367 | Train accuracy 0.7563 | Train F1 0.7476\n",
      "ESConv Val loss 0.6122 | Val accuracy 0.7546 | Val F1 0.7849\n",
      "Saved new best ESConv model.\n",
      "Fine-tuning Epoch 5/10 (ESConv)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdb9592782434156929746de66332a42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESConv Train loss 0.5413 | Train accuracy 0.7708 | Train F1 0.7686\n",
      "ESConv Val loss 0.6244 | Val accuracy 0.7423 | Val F1 0.7766\n",
      "Fine-tuning Epoch 6/10 (ESConv)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2343277dab2b4f3e8c81e27ebce51a07"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESConv Train loss 0.5446 | Train accuracy 0.7589 | Train F1 0.7404\n",
      "ESConv Val loss 0.6198 | Val accuracy 0.7546 | Val F1 0.7849\n",
      "Fine-tuning Epoch 7/10 (ESConv)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b172784ee8ce4791ac54b50a5d2ad3e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESConv Train loss 0.5201 | Train accuracy 0.7747 | Train F1 0.7735\n",
      "ESConv Val loss 0.6140 | Val accuracy 0.7607 | Val F1 0.7892\n",
      "Saved new best ESConv model.\n",
      "Fine-tuning Epoch 8/10 (ESConv)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3d612f898a049fda2095aa9d0fd4a0d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESConv Train loss 0.5289 | Train accuracy 0.7734 | Train F1 0.7676\n",
      "ESConv Val loss 0.6347 | Val accuracy 0.7546 | Val F1 0.7849\n",
      "Fine-tuning Epoch 9/10 (ESConv)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "afa32a69372041a39d9d78f64e91a8f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESConv Train loss 0.5210 | Train accuracy 0.7826 | Train F1 0.7749\n",
      "ESConv Val loss 0.6291 | Val accuracy 0.7546 | Val F1 0.7849\n",
      "Fine-tuning Epoch 10/10 (ESConv)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a98ea861e3b433d941abaf794de7e17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESConv Train loss 0.5205 | Train accuracy 0.7800 | Train F1 0.7671\n",
      "ESConv Val loss 0.6271 | Val accuracy 0.7607 | Val F1 0.7892\n",
      "Fine-tuning on ESConv complete!\n"
     ]
    }
   ],
   "source": [
    "history_esconv = defaultdict(list)\n",
    "best_f1_esconv = 0\n",
    "\n",
    "print(\"Fine-tuning on ESConv...\")\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f'Fine-tuning Epoch {epoch}/{EPOCHS} (ESConv)')\n",
    "    model, train_acc, train_loss, train_f1 = train_model(train_data_loader_esconv, model, optimizer_esconv)\n",
    "    print(f'ESConv Train loss {train_loss:.4f} | Train accuracy {train_acc:.4f} | Train F1 {train_f1:.4f}')\n",
    "    val_acc, val_loss, val_f1 = eval_model(valid_data_loader_esconv, model, epoch)\n",
    "    print(f'ESConv Val loss {val_loss:.4f} | Val accuracy {val_acc:.4f} | Val F1 {val_f1:.4f}')\n",
    "    history_esconv['train_acc'].append(train_acc)\n",
    "    history_esconv['train_loss'].append(train_loss)\n",
    "    history_esconv['train_f1'].append(train_f1)\n",
    "    history_esconv['val_acc'].append(val_acc)\n",
    "    history_esconv['val_loss'].append(val_loss)\n",
    "    history_esconv['val_f1'].append(val_f1)\n",
    "    if val_f1 > best_f1_esconv:\n",
    "        torch.save(model.state_dict(), \"best_fine_tuned_model_state.bin\")\n",
    "        best_f1_esconv = val_f1\n",
    "        print(\"Saved new best ESConv model.\")\n",
    "    scheduler_esconv.step()\n",
    "print(\"Fine-tuning on ESConv complete!\")\n",
    "# Zamknij TensorBoard writer\n",
    "writer.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T16:12:01.340995Z",
     "start_time": "2025-04-14T15:02:28.208252Z"
    }
   },
   "id": "91f78b45ae0631b7",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESConv Test Set Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.30      0.44        89\n",
      "           1       0.52      0.89      0.65        74\n",
      "\n",
      "    accuracy                           0.57       163\n",
      "   macro avg       0.64      0.60      0.54       163\n",
      "weighted avg       0.66      0.57      0.53       163\n"
     ]
    }
   ],
   "source": [
    "test_dataset_esconv = CustomDataset(df_test_esconv, tokenizer, MAX_LEN)\n",
    "test_data_loader_esconv = torch.utils.data.DataLoader(test_dataset_esconv, batch_size=BATCH, shuffle=False)\n",
    "predictions, true_labels = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader_esconv:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['targets'].to(device)\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        outputs = outputs.squeeze(-1)\n",
    "        preds = torch.sigmoid(outputs) >= 0.5\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"ESConv Test Set Report:\")\n",
    "print(classification_report(true_labels, predictions))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-14T16:12:43.686944Z",
     "start_time": "2025-04-14T16:12:01.378211Z"
    }
   },
   "id": "6aa2f7642758f3d9",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "51088840e0073d0d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b6b4a28e7cc68f69"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fb5ff8ddd8529238"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test_model(data_loader, model):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['targets'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            #outputs = model(input_ids=input_ids)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return predictions, true_labels\n",
    "\n",
    "# Run validation\n",
    "predictions, true_labels = test_model(val_data_loader, model)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(true_labels, predictions))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91b2b2fe84a323a5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dc2acc0f4d5644c0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "17fc756d71b62fbb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7f4d5391be3c082",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
