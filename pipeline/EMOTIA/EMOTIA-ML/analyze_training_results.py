"""
Skrypt do analizy wynikÃ³w treningu
Uruchom PO zakoÅ„czeniu treningu modelu
"""

import json
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from sklearn.metrics import confusion_matrix, classification_report

# -------------------------
# KONFIGURACJA
# -------------------------
OUTPUT_DIR = "./outputs_multitask"
LATEST_REPORT = None

# -------------------------
# ZnajdÅº najnowszy folder z raportami
# -------------------------
def find_latest_report_dir(output_dir):
    """ZnajdÅº najnowszy folder reports_XXXXXX"""
    report_dirs = [d for d in Path(output_dir).iterdir()
                   if d.is_dir() and d.name.startswith("reports_")]

    if not report_dirs:
        raise FileNotFoundError(f"Brak folderÃ³w z raportami w {output_dir}")

    # Sortuj po dacie w nazwie
    latest = sorted(report_dirs, key=lambda x: x.name)[-1]
    return str(latest)

# -------------------------
# 1. WYKRESY HISTORII TRENINGU
# -------------------------
def plot_training_history(history_path, save_dir):
    """Wykresy loss i metryk z treningu"""
    print("\n" + "="*60)
    print("Tworzenie wykresÃ³w historii treningu...")
    print("="*60)

    with open(history_path, 'r') as f:
        history = json.load(f)

    train_data = history['train']
    val_data = history['val']

    epochs = range(1, len(train_data) + 1)

    # UtwÃ³rz subplot
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('Training History', fontsize=16, fontweight='bold')

    # 1. Loss
    ax = axes[0, 0]
    ax.plot(epochs, [e['loss'] for e in train_data], 'o-', label='Train Loss', linewidth=2)
    ax.plot(epochs, [e['loss'] for e in val_data], 's-', label='Val Loss', linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Loss')
    ax.set_title('Loss Over Time')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # 2. Sentiment F1
    ax = axes[0, 1]
    ax.plot(epochs, [e['sent_f1'] for e in train_data], 'o-', label='Train Sentiment F1', linewidth=2)
    ax.plot(epochs, [e['sent_f1'] for e in val_data], 's-', label='Val Sentiment F1', linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('F1 Score')
    ax.set_title('Sentiment F1 Score')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_ylim([0, 1])

    # 3. Emotion F1 (micro)
    ax = axes[1, 0]
    ax.plot(epochs, [e['em_f1_micro'] for e in train_data], 'o-', label='Train Emotion F1', linewidth=2)
    ax.plot(epochs, [e['em_f1_micro'] for e in val_data], 's-', label='Val Emotion F1', linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('F1 Score (Micro)')
    ax.set_title('Emotion F1 Score (Micro)')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_ylim([0, 1])

    # 4. Intensity Accuracy
    ax = axes[1, 1]
    ax.plot(epochs, [e['int_acc'] for e in train_data], 'o-', label='Train Intensity Acc', linewidth=2)
    ax.plot(epochs, [e['int_acc'] for e in val_data], 's-', label='Val Intensity Acc', linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Accuracy')
    ax.set_title('Intensity Accuracy')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_ylim([0, 1])

    plt.tight_layout()

    # Zapisz
    save_path = os.path.join(save_dir, "training_history_plot.png")
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ Zapisano: {save_path}")

    plt.close()

# -------------------------
# 2. CONFUSION MATRIX dla SENTIMENT
# -------------------------
def plot_sentiment_confusion_matrix(predictions_path, save_dir):
    """Confusion matrix dla sentiment classification"""
    print("\n" + "="*60)
    print("Tworzenie confusion matrix dla sentimentu...")
    print("="*60)

    df = pd.read_csv(predictions_path)

    # Mapowanie
    label_map = {'negative': 0, 'neutral': 1, 'positive': 2}
    y_true = df['sentiment_label'].map(label_map)
    y_pred = df['sentiment_pred'].map(label_map)

    # Confusion matrix
    cm = confusion_matrix(y_true, y_pred)

    # Znormalizowana wersja
    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    # Plot
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # ZwykÅ‚a
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Negative', 'Neutral', 'Positive'],
                yticklabels=['Negative', 'Neutral', 'Positive'],
                ax=axes[0])
    axes[0].set_title('Sentiment Confusion Matrix (Counts)', fontweight='bold')
    axes[0].set_ylabel('True Label')
    axes[0].set_xlabel('Predicted Label')

    # Znormalizowana
    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',
                xticklabels=['Negative', 'Neutral', 'Positive'],
                yticklabels=['Negative', 'Neutral', 'Positive'],
                ax=axes[1])
    axes[1].set_title('Sentiment Confusion Matrix (Normalized)', fontweight='bold')
    axes[1].set_ylabel('True Label')
    axes[1].set_xlabel('Predicted Label')

    plt.tight_layout()

    save_path = os.path.join(save_dir, "sentiment_confusion_matrix.png")
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ Zapisano: {save_path}")

    plt.close()

# -------------------------
# 3. ANALIZA EMOCJI - per emotion performance
# -------------------------
def plot_emotion_performance(predictions_path, save_dir):
    """Wykres F1 score dla kaÅ¼dej emocji osobno"""
    print("\n" + "="*60)
    print("Analiza wydajnoÅ›ci per-emotion...")
    print("="*60)

    df = pd.read_csv(predictions_path)

    # ZnajdÅº kolumny z emocjami
    emotion_cols = [c for c in df.columns if c.startswith('emotion__') and c.endswith('_label')]
    emotion_names = [c.replace('emotion__', '').replace('_label', '') for c in emotion_cols]

    results = []

    for ename in emotion_names:
        label_col = f'emotion__{ename}_label'
        pred_col = f'emotion__{ename}_pred'

        y_true = df[label_col].values
        y_pred = df[pred_col].values

        # Accuracy
        acc = (y_true == y_pred).mean()

        # F1 score
        from sklearn.metrics import f1_score, precision_score, recall_score

        f1 = f1_score(y_true, y_pred, average='binary', zero_division=0)
        precision = precision_score(y_true, y_pred, average='binary', zero_division=0)
        recall = recall_score(y_true, y_pred, average='binary', zero_division=0)

        # WskaÅºnik obecnoÅ›ci
        presence = y_true.sum() / len(y_true)

        results.append({
            'emotion': ename,
            'f1': f1,
            'precision': precision,
            'recall': recall,
            'accuracy': acc,
            'presence_rate': presence
        })

    results_df = pd.DataFrame(results)
    results_df = results_df.sort_values('f1', ascending=False)

    # Plot
    fig, axes = plt.subplots(2, 1, figsize=(12, 10))

    # 1. F1, Precision, Recall
    ax = axes[0]
    x = np.arange(len(results_df))
    width = 0.25

    ax.bar(x - width, results_df['f1'], width, label='F1 Score', alpha=0.8)
    ax.bar(x, results_df['precision'], width, label='Precision', alpha=0.8)
    ax.bar(x + width, results_df['recall'], width, label='Recall', alpha=0.8)

    ax.set_xlabel('Emotion')
    ax.set_ylabel('Score')
    ax.set_title('Per-Emotion Performance Metrics', fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(results_df['emotion'], rotation=45, ha='right')
    ax.legend()
    ax.grid(True, alpha=0.3, axis='y')
    ax.set_ylim([0, 1])

    # 2. Presence rate vs F1
    ax = axes[1]
    scatter = ax.scatter(results_df['presence_rate'], results_df['f1'],
                         s=200, alpha=0.6, c=results_df['f1'], cmap='viridis')

    for idx, row in results_df.iterrows():
        ax.annotate(row['emotion'],
                    (row['presence_rate'], row['f1']),
                    xytext=(5, 5), textcoords='offset points',
                    fontsize=9)

    ax.set_xlabel('Presence Rate in Dataset')
    ax.set_ylabel('F1 Score')
    ax.set_title('Emotion F1 vs Presence Rate', fontweight='bold')
    ax.grid(True, alpha=0.3)
    plt.colorbar(scatter, ax=ax, label='F1 Score')

    plt.tight_layout()

    save_path = os.path.join(save_dir, "emotion_performance.png")
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ Zapisano: {save_path}")

    # Zapisz tabelÄ™
    table_path = os.path.join(save_dir, "emotion_performance_table.csv")
    results_df.to_csv(table_path, index=False)
    print(f"âœ“ Zapisano tabelÄ™: {table_path}")

    plt.close()

    return results_df

# -------------------------
# 4. ANALIZA INTENSITY
# -------------------------
def plot_intensity_confusion_matrices(predictions_path, save_dir):
    """Confusion matrices dla intensity kaÅ¼dej emocji"""
    print("\n" + "="*60)
    print("Tworzenie confusion matrices dla intensity...")
    print("="*60)

    df = pd.read_csv(predictions_path)

    # ZnajdÅº emocje
    intensity_cols = [c for c in df.columns if c.startswith('intensity__') and c.endswith('_label')]
    emotion_names = [c.replace('intensity__', '').replace('_label', '') for c in intensity_cols]

    # Oblicz ile bÄ™dziemy mieli subplotÃ³w
    n_emotions = len(emotion_names)
    n_cols = 3
    n_rows = (n_emotions + n_cols - 1) // n_cols

    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))
    axes = axes.flatten() if n_emotions > 1 else [axes]

    for idx, ename in enumerate(emotion_names):
        label_col = f'intensity__{ename}_label'
        pred_col = f'intensity__{ename}_pred'

        y_true = df[label_col].values
        y_pred = df[pred_col].values

        # Confusion matrix
        cm = confusion_matrix(y_true, y_pred, labels=[1, 2, 3])
        cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

        # Plot
        ax = axes[idx]
        sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',
                    xticklabels=['Low', 'Med', 'High'],
                    yticklabels=['Low', 'Med', 'High'],
                    ax=ax, vmin=0, vmax=1)
        ax.set_title(f'{ename}', fontweight='bold')
        ax.set_ylabel('True')
        ax.set_xlabel('Predicted')

    # Ukryj puste subploty
    for idx in range(n_emotions, len(axes)):
        axes[idx].axis('off')

    plt.suptitle('Intensity Confusion Matrices (Normalized)', fontsize=16, fontweight='bold')
    plt.tight_layout()

    save_path = os.path.join(save_dir, "intensity_confusion_matrices.png")
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ Zapisano: {save_path}")

    plt.close()

# -------------------------
# 5. PODSUMOWANIE TEKSTOWE
# -------------------------
def create_summary_report(report_dir, save_dir):
    """StwÃ³rz czytelne podsumowanie wszystkich metryk"""
    print("\n" + "="*60)
    print("Tworzenie podsumowania tekstowego...")
    print("="*60)

    summary_lines = []
    summary_lines.append("="*60)
    summary_lines.append("FINAL RESULTS SUMMARY")
    summary_lines.append("="*60)
    summary_lines.append("")

    # 1. Sentiment
    sent_file = os.path.join(report_dir, "sentiment_report.txt")
    if os.path.exists(sent_file):
        with open(sent_file, 'r') as f:
            content = f.read()
            summary_lines.append("--- SENTIMENT CLASSIFICATION ---")
            summary_lines.append(content)
            summary_lines.append("")

    # 2. Emotion
    em_file = os.path.join(report_dir, "emotion_report.txt")
    if os.path.exists(em_file):
        with open(em_file, 'r') as f:
            content = f.read()
            # WeÅº tylko overall metrics
            lines = content.split('\n')
            summary_lines.append("--- EMOTION CLASSIFICATION (OVERALL) ---")
            for line in lines[:10]:  # Pierwsze 10 linii
                summary_lines.append(line)
            summary_lines.append("")

    # 3. Intensity
    int_file = os.path.join(report_dir, "intensity_report.txt")
    if os.path.exists(int_file):
        with open(int_file, 'r') as f:
            content = f.read()
            lines = content.split('\n')
            summary_lines.append("--- INTENSITY CLASSIFICATION (OVERALL) ---")
            for line in lines[:6]:
                summary_lines.append(line)
            summary_lines.append("")

    summary_lines.append("="*60)
    summary_lines.append("END OF SUMMARY")
    summary_lines.append("="*60)

    # Zapisz
    summary_path = os.path.join(save_dir, "SUMMARY_READABLE.txt")
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(summary_lines))

    print(f"âœ“ Zapisano: {summary_path}")

    # WyÅ›wietl w konsoli
    print("\n" + "\n".join(summary_lines))

# -------------------------
# MAIN
# -------------------------
def main():
    print("\n" + "="*60)
    print("ANALIZA WYNIKÃ“W TRENINGU")
    print("="*60)

    # ZnajdÅº folder z raportami
    if LATEST_REPORT is None:
        report_dir = find_latest_report_dir(OUTPUT_DIR)
    else:
        report_dir = LATEST_REPORT

    print(f"\nAnalizujÄ™ folder: {report_dir}")

    # ÅšcieÅ¼ki do plikÃ³w
    history_path = os.path.join(OUTPUT_DIR, "training_history.json")
    predictions_path = os.path.join(report_dir, "predictions.csv")

    # SprawdÅº czy pliki istniejÄ…
    if not os.path.exists(history_path):
        print(f"Brak pliku: {history_path}")
        return

    if not os.path.exists(predictions_path):
        print(f"Brak pliku: {predictions_path}")
        return

    # Folder na wykresy
    plots_dir = os.path.join(report_dir, "plots")
    os.makedirs(plots_dir, exist_ok=True)
    print(f"ðŸ“Š Wykresy bÄ™dÄ… zapisane w: {plots_dir}")

    # Wykonaj analizy
    try:
        plot_training_history(history_path, plots_dir)
        plot_sentiment_confusion_matrix(predictions_path, plots_dir)
        emotion_perf = plot_emotion_performance(predictions_path, plots_dir)
        plot_intensity_confusion_matrices(predictions_path, plots_dir)
        create_summary_report(report_dir, plots_dir)

        print("\n" + "="*60)
        print("ANALIZA ZAKOÅƒCZONA POMYÅšLNIE!")
        print("="*60)
        print(f"\nWszystkie wyniki w: {plots_dir}")
        print("\nWygenerowane pliki:")
        print("  1. training_history_plot.png - wykresy loss/metryki")
        print("  2. sentiment_confusion_matrix.png - macierz pomyÅ‚ek sentiment")
        print("  3. emotion_performance.png - wydajnoÅ›Ä‡ kaÅ¼dej emocji")
        print("  4. emotion_performance_table.csv - tabela z metrykami")
        print("  5. intensity_confusion_matrices.png - macierze dla intensity")
        print("  6. SUMMARY_READABLE.txt - podsumowanie tekstowe")

    except Exception as e:
        print(f"\nBÅ‚Ä…d podczas analizy: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()