{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:25.231888Z",
     "start_time": "2024-09-19T06:36:18.829808Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import sys\n",
    "import tqdm.notebook as tq\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613\n",
    "\n",
    "#https://github.com/dtolk/multilabel-BERT/blob/master/notebooks/multi_class_text_classification_BERT.ipynb"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b58363187b02e5b1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_LEN = 256\n",
    "#MAX_LEN = 64\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "#TRAIN_BATCH_SIZE = 2\n",
    "VALID_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-05"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:25.235270Z",
     "start_time": "2024-09-19T06:36:25.231888Z"
    }
   },
   "id": "ad6570cf3d6f09f3",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = pd.read_csv('MEISD/MEISD_text.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:25.287555Z",
     "start_time": "2024-09-19T06:36:25.236272Z"
    }
   },
   "id": "c27ee3520d15ff70",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#data = data.iloc[:int(0.1 * len(data))]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "573fe00c8edf9fab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      TV Series                                         Utterances  \\\n0            GA                                    look around you   \n1            GA                      say hello to your competition   \n2            GA    eight of you will switch to an easier specialty   \n3            GA          five of you will crack under the pressure   \n4            GA                  two of you will be asked to leave   \n...         ...                                                ...   \n20012        TO  oh, that's right, you're a woman and you need ...   \n20013        TO                                     i'll try again   \n20014        TO           please, pam, reconsider and have a bagel   \n20015        TO                              i have an early lunch   \n20016        TO  michael's been trying to get jim and me to han...   \n\n       dialog_ids  uttr_ids  seasons  episodes   start_times     end_times  \\\n0               1         0        1         1  00:02:27:589  00:02:28:567   \n1               1         1        1         1  00:02:28:910  00:02:30:513   \n2               1         2        1         1  00:02:31:387  00:02:34:060   \n3               1         3        1         1  00:02:34:134  00:02:36:002   \n4               1         4        1         1  00:02:36:059  00:02:37:723   \n...           ...       ...      ...       ...           ...           ...   \n20012        1125        15        6         8  00:01:39:631  00:01:42:862   \n20013        1125        16        6         8  00:01:42:935  00:01:44:903   \n20014        1125        17        6         8  00:01:44:970  00:01:47:200   \n20015        1125        18        6         8  00:01:47:272  00:01:49:103   \n20016        1125        19        6         8  00:01:50:042  00:01:52:169   \n\n      sentiment     emotion intensity emotion2 intensity2 emotion3  intensity3  \n0       neutral     neutral       NaN      NaN        NaN      NaN         NaN  \n1       neutral     neutral       NaN      NaN        NaN      NaN         NaN  \n2       neutral     neutral       NaN      NaN        NaN      NaN         NaN  \n3       neutral     neutral       NaN      NaN        NaN      NaN         NaN  \n4       neutral     neutral       NaN      NaN        NaN      NaN         NaN  \n...         ...         ...       ...      ...        ...      ...         ...  \n20012  negative       anger         1  disgust          2      NaN         NaN  \n20013  negative       anger         1  disgust          2      NaN         NaN  \n20014  negative  acceptance         1  disgust          1      NaN         NaN  \n20015  negative       anger         1  disgust          2      NaN         NaN  \n20016  positive         joy         1      NaN        NaN      NaN         NaN  \n\n[20017 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV Series</th>\n      <th>Utterances</th>\n      <th>dialog_ids</th>\n      <th>uttr_ids</th>\n      <th>seasons</th>\n      <th>episodes</th>\n      <th>start_times</th>\n      <th>end_times</th>\n      <th>sentiment</th>\n      <th>emotion</th>\n      <th>intensity</th>\n      <th>emotion2</th>\n      <th>intensity2</th>\n      <th>emotion3</th>\n      <th>intensity3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GA</td>\n      <td>look around you</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>00:02:27:589</td>\n      <td>00:02:28:567</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GA</td>\n      <td>say hello to your competition</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>00:02:28:910</td>\n      <td>00:02:30:513</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GA</td>\n      <td>eight of you will switch to an easier specialty</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>00:02:31:387</td>\n      <td>00:02:34:060</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GA</td>\n      <td>five of you will crack under the pressure</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>00:02:34:134</td>\n      <td>00:02:36:002</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GA</td>\n      <td>two of you will be asked to leave</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>00:02:36:059</td>\n      <td>00:02:37:723</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20012</th>\n      <td>TO</td>\n      <td>oh, that's right, you're a woman and you need ...</td>\n      <td>1125</td>\n      <td>15</td>\n      <td>6</td>\n      <td>8</td>\n      <td>00:01:39:631</td>\n      <td>00:01:42:862</td>\n      <td>negative</td>\n      <td>anger</td>\n      <td>1</td>\n      <td>disgust</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>20013</th>\n      <td>TO</td>\n      <td>i'll try again</td>\n      <td>1125</td>\n      <td>16</td>\n      <td>6</td>\n      <td>8</td>\n      <td>00:01:42:935</td>\n      <td>00:01:44:903</td>\n      <td>negative</td>\n      <td>anger</td>\n      <td>1</td>\n      <td>disgust</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>20014</th>\n      <td>TO</td>\n      <td>please, pam, reconsider and have a bagel</td>\n      <td>1125</td>\n      <td>17</td>\n      <td>6</td>\n      <td>8</td>\n      <td>00:01:44:970</td>\n      <td>00:01:47:200</td>\n      <td>negative</td>\n      <td>acceptance</td>\n      <td>1</td>\n      <td>disgust</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>20015</th>\n      <td>TO</td>\n      <td>i have an early lunch</td>\n      <td>1125</td>\n      <td>18</td>\n      <td>6</td>\n      <td>8</td>\n      <td>00:01:47:272</td>\n      <td>00:01:49:103</td>\n      <td>negative</td>\n      <td>anger</td>\n      <td>1</td>\n      <td>disgust</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>20016</th>\n      <td>TO</td>\n      <td>michael's been trying to get jim and me to han...</td>\n      <td>1125</td>\n      <td>19</td>\n      <td>6</td>\n      <td>8</td>\n      <td>00:01:50:042</td>\n      <td>00:01:52:169</td>\n      <td>positive</td>\n      <td>joy</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>20017 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:25.302859Z",
     "start_time": "2024-09-19T06:36:25.288556Z"
    }
   },
   "id": "2ef591f522fb979d",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['neutral', 'acceptance', 'disgust', 'surprise', 'joy', 'sadness',\n       'anger', 'like', 'fear', 'acceptance ', 'faer', 'Fear ', 'fear ',\n       'Fear', 'Anger', 'Disgust', 'Neutral', 'Surprise', 'Joy',\n       'Sadness', 'Fera', 'ANGER', ' disgust', 'Neutral ', 'neutral '],\n      dtype=object)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(list(data['emotion'])).unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:25.309466Z",
     "start_time": "2024-09-19T06:36:25.303861Z"
    }
   },
   "id": "7c4e328fd5974985",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "emotion_map = {\n",
    "    'neutral': 0,\n",
    "    'acceptance': 1,\n",
    "    'disgust': 2,\n",
    "    'surprise': 3,\n",
    "    'joy': 4,\n",
    "    'sadness': 5,\n",
    "    'anger': 6,\n",
    "    'like': 7,\n",
    "    'fear': 8\n",
    "}\n",
    "\n",
    "data_emotion = pd.DataFrame()\n",
    "data_emotion['Utterances'] = data['Utterances']\n",
    "data_emotion['target1'] = data['emotion'].map(emotion_map).fillna(9).astype(int)\n",
    "data_emotion['target2'] = data['emotion2'].map(emotion_map).fillna(9).astype(int)\n",
    "data_emotion['target3'] = data['emotion3'].map(emotion_map).fillna(9).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:25.323121Z",
     "start_time": "2024-09-19T06:36:25.309466Z"
    }
   },
   "id": "81156bc1987f27e0",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Utterances  target1  target2  \\\n0                                        look around you        0        9   \n1                          say hello to your competition        0        9   \n2        eight of you will switch to an easier specialty        0        9   \n3              five of you will crack under the pressure        0        9   \n4                      two of you will be asked to leave        0        9   \n...                                                  ...      ...      ...   \n20012  oh, that's right, you're a woman and you need ...        6        2   \n20013                                     i'll try again        6        2   \n20014           please, pam, reconsider and have a bagel        1        2   \n20015                              i have an early lunch        6        2   \n20016  michael's been trying to get jim and me to han...        4        9   \n\n       target3  \n0            9  \n1            9  \n2            9  \n3            9  \n4            9  \n...        ...  \n20012        9  \n20013        9  \n20014        9  \n20015        9  \n20016        9  \n\n[20017 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Utterances</th>\n      <th>target1</th>\n      <th>target2</th>\n      <th>target3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>look around you</td>\n      <td>0</td>\n      <td>9</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>say hello to your competition</td>\n      <td>0</td>\n      <td>9</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eight of you will switch to an easier specialty</td>\n      <td>0</td>\n      <td>9</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>five of you will crack under the pressure</td>\n      <td>0</td>\n      <td>9</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>two of you will be asked to leave</td>\n      <td>0</td>\n      <td>9</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20012</th>\n      <td>oh, that's right, you're a woman and you need ...</td>\n      <td>6</td>\n      <td>2</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>20013</th>\n      <td>i'll try again</td>\n      <td>6</td>\n      <td>2</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>20014</th>\n      <td>please, pam, reconsider and have a bagel</td>\n      <td>1</td>\n      <td>2</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>20015</th>\n      <td>i have an early lunch</td>\n      <td>6</td>\n      <td>2</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>20016</th>\n      <td>michael's been trying to get jim and me to han...</td>\n      <td>4</td>\n      <td>9</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n<p>20017 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_emotion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:25.330079Z",
     "start_time": "2024-09-19T06:36:25.324123Z"
    }
   },
   "id": "da04ad88c7d3e16a",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def to_binary_vector(row, num_classes=9):\n",
    "    vector = np.zeros(num_classes)\n",
    "    for i in range(1, 4):  # iteracja po target1, target2, target3\n",
    "        if row[f'target{i}'] < num_classes:\n",
    "            vector[row[f'target{i}']] = 1\n",
    "    return vector\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:25.333779Z",
     "start_time": "2024-09-19T06:36:25.331080Z"
    }
   },
   "id": "e5e4f465c1e95c66",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Utterances  \\\n0                                        look around you   \n1                          say hello to your competition   \n2        eight of you will switch to an easier specialty   \n3              five of you will crack under the pressure   \n4                      two of you will be asked to leave   \n...                                                  ...   \n20012  oh, that's right, you're a woman and you need ...   \n20013                                     i'll try again   \n20014           please, pam, reconsider and have a bagel   \n20015                              i have an early lunch   \n20016  michael's been trying to get jim and me to han...   \n\n                                       target_vector  \n0      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n1      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n2      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n3      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n4      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n...                                              ...  \n20012  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n20013  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n20014  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n20015  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n20016  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n\n[20017 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Utterances</th>\n      <th>target_vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>look around you</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>say hello to your competition</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eight of you will switch to an easier specialty</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>five of you will crack under the pressure</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>two of you will be asked to leave</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20012</th>\n      <td>oh, that's right, you're a woman and you need ...</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20013</th>\n      <td>i'll try again</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20014</th>\n      <td>please, pam, reconsider and have a bagel</td>\n      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20015</th>\n      <td>i have an early lunch</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20016</th>\n      <td>michael's been trying to get jim and me to han...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n  </tbody>\n</table>\n<p>20017 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_emotion['target_vector'] = data_emotion.apply(to_binary_vector, axis=1)\n",
    "data_emotion[['Utterances', 'target_vector']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:25.592795Z",
     "start_time": "2024-09-19T06:36:25.334782Z"
    }
   },
   "id": "49408862008bfc12",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(data_emotion[['Utterances', 'target_vector']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:25.625582Z",
     "start_time": "2024-09-19T06:36:25.593797Z"
    }
   },
   "id": "3d43f7604a2b809",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['Utterances', 'target_vector'],\n    num_rows: 20017\n})"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:25.629739Z",
     "start_time": "2024-09-19T06:36:25.626584Z"
    }
   },
   "id": "bfdc4c043bba7277",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " #split = dataset['train'].train_test_split(test_size=0.3, seed=42)\n",
    "split = dataset.train_test_split(test_size=0.3, seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:25.643615Z",
     "start_time": "2024-09-19T06:36:25.630740Z"
    }
   },
   "id": "92ce2090f1b3a123",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['Utterances', 'target_vector'],\n        num_rows: 14011\n    })\n    test: Dataset({\n        features: ['Utterances', 'target_vector'],\n        num_rows: 6006\n    })\n})"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:25.649751Z",
     "start_time": "2024-09-19T06:36:25.645619Z"
    }
   },
   "id": "6a1d6e9624516e9",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = 'bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:26.344789Z",
     "start_time": "2024-09-19T06:36:25.650753Z"
    }
   },
   "id": "74e78a3884fd99e2",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = split['train']\n",
    "val_data = split['test']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:26.348781Z",
     "start_time": "2024-09-19T06:36:26.345791Z"
    }
   },
   "id": "3a18454d9c0324bd",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "D:\\conda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    train_data['Utterances'],\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=MAX_LEN,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    val_data['Utterances'],\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=MAX_LEN,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(train_data['target_vector'])\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(val_data['target_vector'])\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:29.121726Z",
     "start_time": "2024-09-19T06:36:26.349784Z"
    }
   },
   "id": "46fee38cb75061ea",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=9,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:29.652840Z",
     "start_time": "2024-09-19T06:36:29.121726Z"
    }
   },
   "id": "e356f3dac1f7aab4",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              sampler=RandomSampler(dataset_train),\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val,\n",
    "                                   sampler=SequentialSampler(dataset_val),\n",
    "                                   batch_size=batch_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:29.656623Z",
     "start_time": "2024-09-19T06:36:29.652840Z"
    }
   },
   "id": "b7fdd69253893f71",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5,\n",
    "                  eps=1e-8)\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:30.204448Z",
     "start_time": "2024-09-19T06:36:29.657625Z"
    }
   },
   "id": "f1b396beeebba70b",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    # Flatten both preds and labels\n",
    "    preds_flat = np.round(preds).astype(int).flatten()\n",
    "    labels_flat = labels.astype(int).flatten()\n",
    "\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted', zero_division=0)\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in emotion_map.items()}\n",
    "\n",
    "    preds_flat = np.round(preds).astype(int)\n",
    "    labels_flat = labels.astype(int)\n",
    "\n",
    "    # Iterate over each label/class\n",
    "    for i in range(labels_flat.shape[1]):\n",
    "        y_preds = preds_flat[:, i]\n",
    "        y_true = labels_flat[:, i]\n",
    "        class_name = label_dict_inverse[i]\n",
    "        accuracy = np.mean(y_preds == y_true)  # Calculate accuracy\n",
    "        print(f'Class: {class_name}')\n",
    "        print(f'Accuracy: {accuracy}\\n')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T06:36:30.675155Z",
     "start_time": "2024-09-19T06:36:30.204448Z"
    }
   },
   "id": "ed39f9f71bd10f49",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/438 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 1:   0%|          | 0/438 [00:21<?, ?it/s, training_loss=0.239]\u001B[A\n",
      "Epoch 1:   0%|          | 1/438 [00:21<2:36:54, 21.54s/it, training_loss=0.239]\u001B[A\n",
      "Epoch 1:   0%|          | 1/438 [00:38<2:36:54, 21.54s/it, training_loss=0.235]\u001B[A\n",
      "Epoch 1:   0%|          | 2/438 [00:38<2:18:02, 19.00s/it, training_loss=0.235]\u001B[A\n",
      "Epoch 1:   0%|          | 2/438 [00:55<2:18:02, 19.00s/it, training_loss=0.235]\u001B[A\n",
      "Epoch 1:   1%|          | 3/438 [00:55<2:09:09, 17.82s/it, training_loss=0.235]\u001B[A\n",
      "Epoch 1:   1%|          | 3/438 [01:12<2:09:09, 17.82s/it, training_loss=0.228]\u001B[A\n",
      "Epoch 1:   1%|          | 4/438 [01:12<2:07:20, 17.61s/it, training_loss=0.228]\u001B[A\n",
      "Epoch 1:   1%|          | 4/438 [01:30<2:07:20, 17.61s/it, training_loss=0.227]\u001B[A\n",
      "Epoch 1:   1%|          | 5/438 [01:30<2:07:44, 17.70s/it, training_loss=0.227]\u001B[A\n",
      "Epoch 1:   1%|          | 5/438 [01:48<2:07:44, 17.70s/it, training_loss=0.221]\u001B[A\n",
      "Epoch 1:   1%|▏         | 6/438 [01:48<2:09:25, 17.97s/it, training_loss=0.221]\u001B[A\n",
      "Epoch 1:   1%|▏         | 6/438 [02:05<2:09:25, 17.97s/it, training_loss=0.214]\u001B[A\n",
      "Epoch 1:   2%|▏         | 7/438 [02:05<2:06:03, 17.55s/it, training_loss=0.214]\u001B[A\n",
      "Epoch 1:   2%|▏         | 7/438 [02:22<2:06:03, 17.55s/it, training_loss=0.216]\u001B[A\n",
      "Epoch 1:   2%|▏         | 8/438 [02:22<2:03:40, 17.26s/it, training_loss=0.216]\u001B[A\n",
      "Epoch 1:   2%|▏         | 8/438 [02:38<2:03:40, 17.26s/it, training_loss=0.206]\u001B[A\n",
      "Epoch 1:   2%|▏         | 9/438 [02:38<2:02:02, 17.07s/it, training_loss=0.206]\u001B[A\n",
      "Epoch 1:   2%|▏         | 9/438 [02:55<2:02:02, 17.07s/it, training_loss=0.206]\u001B[A\n",
      "Epoch 1:   2%|▏         | 10/438 [02:55<2:01:10, 16.99s/it, training_loss=0.206]\u001B[A\n",
      "Epoch 1:   2%|▏         | 10/438 [03:12<2:01:10, 16.99s/it, training_loss=0.202]\u001B[A\n",
      "Epoch 1:   3%|▎         | 11/438 [03:12<2:00:18, 16.91s/it, training_loss=0.202]\u001B[A\n",
      "Epoch 1:   3%|▎         | 11/438 [03:28<2:00:18, 16.91s/it, training_loss=0.207]\u001B[A\n",
      "Epoch 1:   3%|▎         | 12/438 [03:28<1:59:13, 16.79s/it, training_loss=0.207]\u001B[A\n",
      "Epoch 1:   3%|▎         | 12/438 [03:45<1:59:13, 16.79s/it, training_loss=0.199]\u001B[A\n",
      "Epoch 1:   3%|▎         | 13/438 [03:45<1:58:36, 16.75s/it, training_loss=0.199]\u001B[A\n",
      "Epoch 1:   3%|▎         | 13/438 [04:02<1:58:36, 16.75s/it, training_loss=0.193]\u001B[A\n",
      "Epoch 1:   3%|▎         | 14/438 [04:02<1:58:22, 16.75s/it, training_loss=0.193]\u001B[A\n",
      "Epoch 1:   3%|▎         | 14/438 [04:18<1:58:22, 16.75s/it, training_loss=0.194]\u001B[A\n",
      "Epoch 1:   3%|▎         | 15/438 [04:18<1:58:02, 16.74s/it, training_loss=0.194]\u001B[A\n",
      "Epoch 1:   3%|▎         | 15/438 [04:35<1:58:02, 16.74s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:   4%|▎         | 16/438 [04:35<1:57:41, 16.73s/it, training_loss=0.196]\u001B[A\n",
      "Epoch 1:   4%|▎         | 16/438 [04:52<1:57:41, 16.73s/it, training_loss=0.194]\u001B[A\n",
      "Epoch 1:   4%|▍         | 17/438 [04:52<1:57:48, 16.79s/it, training_loss=0.194]\u001B[A\n",
      "Epoch 1:   4%|▍         | 17/438 [05:10<1:57:48, 16.79s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:   4%|▍         | 18/438 [05:10<1:59:22, 17.05s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:   4%|▍         | 18/438 [05:27<1:59:22, 17.05s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:   4%|▍         | 19/438 [05:27<1:58:39, 16.99s/it, training_loss=0.189]\u001B[A\n",
      "Epoch 1:   4%|▍         | 19/438 [05:44<1:58:39, 16.99s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:   5%|▍         | 20/438 [05:44<1:58:36, 17.02s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:   5%|▍         | 20/438 [06:00<1:58:36, 17.02s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:   5%|▍         | 21/438 [06:00<1:57:41, 16.93s/it, training_loss=0.180]\u001B[A\n",
      "Epoch 1:   5%|▍         | 21/438 [06:17<1:57:41, 16.93s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:   5%|▌         | 22/438 [06:17<1:56:46, 16.84s/it, training_loss=0.174]\u001B[A\n",
      "Epoch 1:   5%|▌         | 22/438 [06:34<1:56:46, 16.84s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:   5%|▌         | 23/438 [06:34<1:56:04, 16.78s/it, training_loss=0.181]\u001B[A\n",
      "Epoch 1:   5%|▌         | 23/438 [06:50<1:56:04, 16.78s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:   5%|▌         | 24/438 [06:50<1:55:39, 16.76s/it, training_loss=0.179]\u001B[A\n",
      "Epoch 1:   5%|▌         | 24/438 [07:07<1:55:39, 16.76s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:   6%|▌         | 25/438 [07:07<1:55:27, 16.77s/it, training_loss=0.178]\u001B[A\n",
      "Epoch 1:   6%|▌         | 25/438 [07:24<1:55:27, 16.77s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:   6%|▌         | 26/438 [07:24<1:55:32, 16.83s/it, training_loss=0.171]\u001B[A\n",
      "Epoch 1:   6%|▌         | 26/438 [07:41<1:55:32, 16.83s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:   6%|▌         | 27/438 [07:41<1:55:03, 16.80s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:   6%|▌         | 27/438 [07:57<1:55:03, 16.80s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:   6%|▋         | 28/438 [07:57<1:54:16, 16.72s/it, training_loss=0.175]\u001B[A\n",
      "Epoch 1:   6%|▋         | 28/438 [08:14<1:54:16, 16.72s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:   7%|▋         | 29/438 [08:14<1:53:47, 16.69s/it, training_loss=0.169]\u001B[A\n",
      "Epoch 1:   7%|▋         | 29/438 [08:31<1:53:47, 16.69s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:   7%|▋         | 30/438 [08:31<1:53:20, 16.67s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:   7%|▋         | 30/438 [08:47<1:53:20, 16.67s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:   7%|▋         | 31/438 [08:47<1:53:05, 16.67s/it, training_loss=0.163]\u001B[A\n",
      "Epoch 1:   7%|▋         | 31/438 [09:04<1:53:05, 16.67s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:   7%|▋         | 32/438 [09:04<1:52:52, 16.68s/it, training_loss=0.167]\u001B[A\n",
      "Epoch 1:   7%|▋         | 32/438 [09:21<1:52:52, 16.68s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   8%|▊         | 33/438 [09:21<1:52:41, 16.69s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   8%|▊         | 33/438 [09:37<1:52:41, 16.69s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   8%|▊         | 34/438 [09:37<1:52:08, 16.66s/it, training_loss=0.168]\u001B[A\n",
      "Epoch 1:   8%|▊         | 34/438 [09:54<1:52:08, 16.66s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:   8%|▊         | 35/438 [09:54<1:51:53, 16.66s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:   8%|▊         | 35/438 [10:11<1:51:53, 16.66s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:   8%|▊         | 36/438 [10:11<1:51:50, 16.69s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:   8%|▊         | 36/438 [10:27<1:51:50, 16.69s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:   8%|▊         | 37/438 [10:27<1:51:20, 16.66s/it, training_loss=0.161]\u001B[A\n",
      "Epoch 1:   8%|▊         | 37/438 [10:45<1:51:20, 16.66s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   9%|▊         | 38/438 [10:45<1:52:25, 16.86s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   9%|▊         | 38/438 [11:01<1:52:25, 16.86s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   9%|▉         | 39/438 [11:01<1:51:52, 16.82s/it, training_loss=0.157]\u001B[A\n",
      "Epoch 1:   9%|▉         | 39/438 [11:18<1:51:52, 16.82s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   9%|▉         | 40/438 [11:18<1:51:18, 16.78s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:   9%|▉         | 40/438 [11:35<1:51:18, 16.78s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:   9%|▉         | 41/438 [11:35<1:50:13, 16.66s/it, training_loss=0.164]\u001B[A\n",
      "Epoch 1:   9%|▉         | 41/438 [11:51<1:50:13, 16.66s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  10%|▉         | 42/438 [11:51<1:49:33, 16.60s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  10%|▉         | 42/438 [12:07<1:49:33, 16.60s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  10%|▉         | 43/438 [12:07<1:48:59, 16.56s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  10%|▉         | 43/438 [12:25<1:48:59, 16.56s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  10%|█         | 44/438 [12:25<1:49:52, 16.73s/it, training_loss=0.159]\u001B[A\n",
      "Epoch 1:  10%|█         | 44/438 [12:41<1:49:52, 16.73s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  10%|█         | 45/438 [12:41<1:49:11, 16.67s/it, training_loss=0.155]\u001B[A\n",
      "Epoch 1:  10%|█         | 45/438 [12:58<1:49:11, 16.67s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  11%|█         | 46/438 [12:58<1:48:35, 16.62s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 1:  11%|█         | 46/438 [13:14<1:48:35, 16.62s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  11%|█         | 47/438 [13:14<1:47:43, 16.53s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  11%|█         | 47/438 [13:30<1:47:43, 16.53s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  11%|█         | 48/438 [13:30<1:47:13, 16.50s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  11%|█         | 48/438 [13:47<1:47:13, 16.50s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  11%|█         | 49/438 [13:47<1:46:59, 16.50s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  11%|█         | 49/438 [14:04<1:46:59, 16.50s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 50/438 [14:04<1:47:23, 16.61s/it, training_loss=0.154]\u001B[A\n",
      "Epoch 1:  11%|█▏        | 50/438 [14:20<1:47:23, 16.61s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 51/438 [14:20<1:46:48, 16.56s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 51/438 [14:37<1:46:48, 16.56s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 52/438 [14:37<1:47:07, 16.65s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 52/438 [14:55<1:47:07, 16.65s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 53/438 [14:55<1:49:36, 17.08s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 53/438 [15:13<1:49:36, 17.08s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 54/438 [15:13<1:50:21, 17.24s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  12%|█▏        | 54/438 [15:29<1:50:21, 17.24s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 55/438 [15:29<1:49:02, 17.08s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 55/438 [15:47<1:49:02, 17.08s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 56/438 [15:47<1:49:02, 17.13s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 56/438 [16:03<1:49:02, 17.13s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 57/438 [16:03<1:47:52, 16.99s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 57/438 [16:20<1:47:52, 16.99s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 58/438 [16:20<1:47:25, 16.96s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 58/438 [16:37<1:47:25, 16.96s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 59/438 [16:37<1:46:33, 16.87s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  13%|█▎        | 59/438 [16:53<1:46:33, 16.87s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 60/438 [16:53<1:45:45, 16.79s/it, training_loss=0.158]\u001B[A\n",
      "Epoch 1:  14%|█▎        | 60/438 [17:10<1:45:45, 16.79s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 61/438 [17:10<1:44:59, 16.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 61/438 [17:27<1:44:59, 16.71s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 62/438 [17:27<1:44:33, 16.69s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 62/438 [17:43<1:44:33, 16.69s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 63/438 [17:43<1:44:14, 16.68s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  14%|█▍        | 63/438 [18:00<1:44:14, 16.68s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 64/438 [18:00<1:43:52, 16.67s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 64/438 [18:16<1:43:52, 16.67s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 65/438 [18:16<1:43:21, 16.63s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  15%|█▍        | 65/438 [18:33<1:43:21, 16.63s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 66/438 [18:33<1:42:46, 16.58s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 66/438 [18:49<1:42:46, 16.58s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 67/438 [18:49<1:42:24, 16.56s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  15%|█▌        | 67/438 [19:06<1:42:24, 16.56s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 68/438 [19:06<1:42:11, 16.57s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 68/438 [19:22<1:42:11, 16.57s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 69/438 [19:22<1:41:39, 16.53s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 69/438 [19:39<1:41:39, 16.53s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 70/438 [19:39<1:41:28, 16.54s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 70/438 [19:56<1:41:28, 16.54s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 71/438 [19:56<1:41:21, 16.57s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 71/438 [20:12<1:41:21, 16.57s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 72/438 [20:12<1:40:59, 16.56s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  16%|█▋        | 72/438 [20:29<1:40:59, 16.56s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 73/438 [20:29<1:40:41, 16.55s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 73/438 [20:45<1:40:41, 16.55s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 74/438 [20:45<1:40:41, 16.60s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 74/438 [21:02<1:40:41, 16.60s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 75/438 [21:02<1:40:19, 16.58s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 75/438 [21:19<1:40:19, 16.58s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 76/438 [21:19<1:40:04, 16.59s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  17%|█▋        | 76/438 [21:35<1:40:04, 16.59s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 77/438 [21:35<1:39:43, 16.58s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 77/438 [21:52<1:39:43, 16.58s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 78/438 [21:52<1:39:31, 16.59s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 78/438 [22:08<1:39:31, 16.59s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 79/438 [22:08<1:39:07, 16.57s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 79/438 [22:25<1:39:07, 16.57s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 80/438 [22:25<1:38:59, 16.59s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 80/438 [22:41<1:38:59, 16.59s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 81/438 [22:41<1:38:37, 16.58s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  18%|█▊        | 81/438 [22:58<1:38:37, 16.58s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 82/438 [22:58<1:38:08, 16.54s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  19%|█▊        | 82/438 [23:14<1:38:08, 16.54s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 83/438 [23:14<1:37:52, 16.54s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 83/438 [23:31<1:37:52, 16.54s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 84/438 [23:31<1:37:40, 16.56s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 84/438 [23:48<1:37:40, 16.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 85/438 [23:48<1:37:31, 16.58s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  19%|█▉        | 85/438 [24:04<1:37:31, 16.58s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 86/438 [24:04<1:37:24, 16.60s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 86/438 [24:21<1:37:24, 16.60s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 87/438 [24:21<1:37:12, 16.62s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  20%|█▉        | 87/438 [24:37<1:37:12, 16.62s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  20%|██        | 88/438 [24:37<1:36:43, 16.58s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  20%|██        | 88/438 [24:54<1:36:43, 16.58s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  20%|██        | 89/438 [24:54<1:36:42, 16.63s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  20%|██        | 89/438 [25:11<1:36:42, 16.63s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  21%|██        | 90/438 [25:11<1:36:47, 16.69s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  21%|██        | 90/438 [25:28<1:36:47, 16.69s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  21%|██        | 91/438 [25:28<1:36:24, 16.67s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  21%|██        | 91/438 [25:44<1:36:24, 16.67s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  21%|██        | 92/438 [25:44<1:36:11, 16.68s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  21%|██        | 92/438 [26:01<1:36:11, 16.68s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  21%|██        | 93/438 [26:01<1:35:48, 16.66s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  21%|██        | 93/438 [26:17<1:35:48, 16.66s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 94/438 [26:17<1:35:09, 16.60s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  21%|██▏       | 94/438 [26:34<1:35:09, 16.60s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 95/438 [26:34<1:34:55, 16.61s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 95/438 [26:51<1:34:55, 16.61s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 96/438 [26:51<1:34:29, 16.58s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 96/438 [27:07<1:34:29, 16.58s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 97/438 [27:07<1:34:01, 16.54s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 97/438 [27:24<1:34:01, 16.54s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 98/438 [27:24<1:33:34, 16.51s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  22%|██▏       | 98/438 [27:40<1:33:34, 16.51s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 99/438 [27:40<1:33:13, 16.50s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 99/438 [27:57<1:33:13, 16.50s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 100/438 [27:57<1:33:05, 16.53s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 100/438 [28:13<1:33:05, 16.53s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 101/438 [28:13<1:32:54, 16.54s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 101/438 [28:30<1:32:54, 16.54s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 102/438 [28:30<1:32:41, 16.55s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  23%|██▎       | 102/438 [28:46<1:32:41, 16.55s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 103/438 [28:46<1:32:17, 16.53s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 103/438 [29:03<1:32:17, 16.53s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 104/438 [29:03<1:32:03, 16.54s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  24%|██▎       | 104/438 [29:19<1:32:03, 16.54s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 105/438 [29:19<1:31:44, 16.53s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 105/438 [29:36<1:31:44, 16.53s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 106/438 [29:36<1:31:32, 16.54s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 106/438 [29:53<1:31:32, 16.54s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 107/438 [29:53<1:31:44, 16.63s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  24%|██▍       | 107/438 [30:11<1:31:44, 16.63s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 108/438 [30:11<1:33:34, 17.01s/it, training_loss=0.152]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 108/438 [30:27<1:33:34, 17.01s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 109/438 [30:27<1:32:38, 16.90s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  25%|██▍       | 109/438 [30:44<1:32:38, 16.90s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 110/438 [30:44<1:32:03, 16.84s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 110/438 [31:01<1:32:03, 16.84s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 111/438 [31:01<1:31:31, 16.79s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  25%|██▌       | 111/438 [31:17<1:31:31, 16.79s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 112/438 [31:17<1:30:58, 16.74s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 112/438 [31:34<1:30:58, 16.74s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 113/438 [31:34<1:30:34, 16.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 113/438 [31:50<1:30:34, 16.72s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 114/438 [31:50<1:30:06, 16.69s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  26%|██▌       | 114/438 [32:09<1:30:06, 16.69s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 115/438 [32:09<1:32:05, 17.11s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 115/438 [32:26<1:32:05, 17.11s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 116/438 [32:26<1:32:09, 17.17s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  26%|██▋       | 116/438 [32:43<1:32:09, 17.17s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 117/438 [32:43<1:31:44, 17.15s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 117/438 [33:00<1:31:44, 17.15s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 118/438 [33:00<1:31:25, 17.14s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 118/438 [33:17<1:31:25, 17.14s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 119/438 [33:17<1:31:05, 17.13s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 119/438 [33:34<1:31:05, 17.13s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 120/438 [33:34<1:30:38, 17.10s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  27%|██▋       | 120/438 [33:51<1:30:38, 17.10s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 121/438 [33:51<1:30:32, 17.14s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 121/438 [34:09<1:30:32, 17.14s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 122/438 [34:09<1:30:10, 17.12s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 122/438 [34:26<1:30:10, 17.12s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 123/438 [34:26<1:29:52, 17.12s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 123/438 [34:43<1:29:52, 17.12s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 124/438 [34:43<1:29:41, 17.14s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  28%|██▊       | 124/438 [35:00<1:29:41, 17.14s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 125/438 [35:00<1:29:20, 17.12s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  29%|██▊       | 125/438 [35:17<1:29:20, 17.12s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 126/438 [35:17<1:29:03, 17.13s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 126/438 [35:34<1:29:03, 17.13s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 127/438 [35:34<1:28:44, 17.12s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 127/438 [35:51<1:28:44, 17.12s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 128/438 [35:51<1:28:41, 17.16s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 128/438 [36:09<1:28:41, 17.16s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 129/438 [36:09<1:28:19, 17.15s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  29%|██▉       | 129/438 [36:26<1:28:19, 17.15s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 130/438 [36:26<1:27:51, 17.12s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 130/438 [36:43<1:27:51, 17.12s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 131/438 [36:43<1:27:31, 17.11s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  30%|██▉       | 131/438 [37:00<1:27:31, 17.11s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  30%|███       | 132/438 [37:00<1:27:21, 17.13s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  30%|███       | 132/438 [37:17<1:27:21, 17.13s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  30%|███       | 133/438 [37:17<1:26:54, 17.10s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  30%|███       | 133/438 [37:34<1:26:54, 17.10s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  31%|███       | 134/438 [37:34<1:26:25, 17.06s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  31%|███       | 134/438 [37:51<1:26:25, 17.06s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  31%|███       | 135/438 [37:51<1:26:10, 17.06s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  31%|███       | 135/438 [38:08<1:26:10, 17.06s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  31%|███       | 136/438 [38:08<1:25:55, 17.07s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  31%|███       | 136/438 [38:25<1:25:55, 17.07s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 137/438 [38:25<1:25:19, 17.01s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  31%|███▏      | 137/438 [38:42<1:25:19, 17.01s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 138/438 [38:42<1:25:07, 17.03s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 138/438 [38:59<1:25:07, 17.03s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 139/438 [38:59<1:24:53, 17.03s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 139/438 [39:16<1:24:53, 17.03s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 140/438 [39:16<1:24:40, 17.05s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 140/438 [39:33<1:24:40, 17.05s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 141/438 [39:33<1:24:19, 17.04s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 141/438 [39:50<1:24:19, 17.04s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 142/438 [39:50<1:24:00, 17.03s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  32%|███▏      | 142/438 [40:07<1:24:00, 17.03s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 143/438 [40:07<1:23:44, 17.03s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 143/438 [40:24<1:23:44, 17.03s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 144/438 [40:24<1:22:36, 16.86s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 144/438 [40:40<1:22:36, 16.86s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 145/438 [40:40<1:21:46, 16.75s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 145/438 [40:57<1:21:46, 16.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 146/438 [40:57<1:21:06, 16.67s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  33%|███▎      | 146/438 [41:13<1:21:06, 16.67s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 147/438 [41:13<1:20:41, 16.64s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  34%|███▎      | 147/438 [41:30<1:20:41, 16.64s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 148/438 [41:30<1:20:21, 16.62s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 148/438 [41:46<1:20:21, 16.62s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 149/438 [41:46<1:19:41, 16.55s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 149/438 [42:03<1:19:41, 16.55s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 150/438 [42:03<1:19:30, 16.57s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 150/438 [42:19<1:19:30, 16.57s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 151/438 [42:19<1:19:05, 16.53s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  34%|███▍      | 151/438 [42:36<1:19:05, 16.53s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 152/438 [42:36<1:18:39, 16.50s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 152/438 [42:52<1:18:39, 16.50s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 153/438 [42:52<1:18:15, 16.48s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  35%|███▍      | 153/438 [43:08<1:18:15, 16.48s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 154/438 [43:08<1:17:55, 16.46s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 154/438 [43:25<1:17:55, 16.46s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 155/438 [43:25<1:17:29, 16.43s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  35%|███▌      | 155/438 [43:41<1:17:29, 16.43s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 156/438 [43:41<1:17:20, 16.46s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 156/438 [43:58<1:17:20, 16.46s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 157/438 [43:58<1:17:16, 16.50s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 157/438 [44:14<1:17:16, 16.50s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 158/438 [44:14<1:16:49, 16.46s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  36%|███▌      | 158/438 [44:31<1:16:49, 16.46s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 159/438 [44:31<1:16:19, 16.41s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  36%|███▋      | 159/438 [44:48<1:16:19, 16.41s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 160/438 [44:48<1:16:52, 16.59s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 160/438 [45:06<1:16:52, 16.59s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 161/438 [45:06<1:19:12, 17.16s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 161/438 [45:25<1:19:12, 17.16s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 162/438 [45:25<1:21:03, 17.62s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 162/438 [45:42<1:21:03, 17.62s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 163/438 [45:42<1:19:36, 17.37s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 163/438 [45:58<1:19:36, 17.37s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 164/438 [45:58<1:18:15, 17.14s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  37%|███▋      | 164/438 [46:15<1:18:15, 17.14s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 165/438 [46:15<1:17:12, 16.97s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 165/438 [46:32<1:17:12, 16.97s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 166/438 [46:32<1:16:38, 16.91s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 166/438 [46:48<1:16:38, 16.91s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 167/438 [46:48<1:15:50, 16.79s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 167/438 [47:05<1:15:50, 16.79s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 168/438 [47:05<1:15:30, 16.78s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  38%|███▊      | 168/438 [47:21<1:15:30, 16.78s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 169/438 [47:21<1:14:58, 16.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  39%|███▊      | 169/438 [47:38<1:14:58, 16.72s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 170/438 [47:38<1:14:36, 16.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 170/438 [47:55<1:14:36, 16.70s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 171/438 [47:55<1:14:04, 16.65s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 171/438 [48:11<1:14:04, 16.65s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 172/438 [48:11<1:13:40, 16.62s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 172/438 [48:28<1:13:40, 16.62s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 173/438 [48:28<1:13:11, 16.57s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  39%|███▉      | 173/438 [48:44<1:13:11, 16.57s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 174/438 [48:44<1:12:52, 16.56s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 174/438 [49:01<1:12:52, 16.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 175/438 [49:01<1:12:29, 16.54s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  40%|███▉      | 175/438 [49:17<1:12:29, 16.54s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  40%|████      | 176/438 [49:17<1:12:20, 16.57s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  40%|████      | 176/438 [49:34<1:12:20, 16.57s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  40%|████      | 177/438 [49:34<1:12:03, 16.56s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  40%|████      | 177/438 [49:51<1:12:03, 16.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  41%|████      | 178/438 [49:51<1:12:03, 16.63s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  41%|████      | 178/438 [50:07<1:12:03, 16.63s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  41%|████      | 179/438 [50:07<1:11:43, 16.62s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  41%|████      | 179/438 [50:24<1:11:43, 16.62s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  41%|████      | 180/438 [50:24<1:11:38, 16.66s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  41%|████      | 180/438 [50:41<1:11:38, 16.66s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 181/438 [50:41<1:12:18, 16.88s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  41%|████▏     | 181/438 [50:58<1:12:18, 16.88s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 182/438 [50:58<1:12:07, 16.90s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 182/438 [51:15<1:12:07, 16.90s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 183/438 [51:15<1:11:28, 16.82s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 183/438 [51:31<1:11:28, 16.82s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 184/438 [51:31<1:10:48, 16.73s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 184/438 [51:48<1:10:48, 16.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 185/438 [51:48<1:10:21, 16.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 185/438 [52:05<1:10:21, 16.69s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 186/438 [52:05<1:09:54, 16.64s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  42%|████▏     | 186/438 [52:21<1:09:54, 16.64s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 187/438 [52:21<1:09:33, 16.63s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 187/438 [52:38<1:09:33, 16.63s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 188/438 [52:38<1:09:04, 16.58s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 188/438 [52:54<1:09:04, 16.58s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 189/438 [52:54<1:08:57, 16.62s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 189/438 [53:11<1:08:57, 16.62s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 190/438 [53:11<1:08:38, 16.61s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  43%|████▎     | 190/438 [53:27<1:08:38, 16.61s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 191/438 [53:27<1:08:15, 16.58s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  44%|████▎     | 191/438 [53:44<1:08:15, 16.58s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 192/438 [53:44<1:08:01, 16.59s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 192/438 [54:01<1:08:01, 16.59s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 193/438 [54:01<1:07:43, 16.59s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 193/438 [54:17<1:07:43, 16.59s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 194/438 [54:17<1:07:18, 16.55s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  44%|████▍     | 194/438 [54:34<1:07:18, 16.55s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 195/438 [54:34<1:07:05, 16.57s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 195/438 [54:50<1:07:05, 16.57s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 196/438 [54:50<1:07:03, 16.63s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 196/438 [55:07<1:07:03, 16.63s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 197/438 [55:07<1:06:45, 16.62s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  45%|████▍     | 197/438 [55:24<1:06:45, 16.62s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 198/438 [55:24<1:06:22, 16.59s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 198/438 [55:40<1:06:22, 16.59s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 199/438 [55:40<1:06:04, 16.59s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  45%|████▌     | 199/438 [55:57<1:06:04, 16.59s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 200/438 [55:57<1:05:41, 16.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 200/438 [56:13<1:05:41, 16.56s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 201/438 [56:13<1:05:38, 16.62s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 201/438 [56:30<1:05:38, 16.62s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 202/438 [56:30<1:05:19, 16.61s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  46%|████▌     | 202/438 [56:47<1:05:19, 16.61s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 203/438 [56:47<1:05:01, 16.60s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  46%|████▋     | 203/438 [57:03<1:05:01, 16.60s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 204/438 [57:03<1:04:40, 16.58s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 204/438 [57:20<1:04:40, 16.58s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 205/438 [57:20<1:04:20, 16.57s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 205/438 [57:36<1:04:20, 16.57s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 206/438 [57:36<1:04:01, 16.56s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 206/438 [57:53<1:04:01, 16.56s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 207/438 [57:53<1:03:50, 16.58s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 207/438 [58:09<1:03:50, 16.58s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 208/438 [58:09<1:03:36, 16.59s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  47%|████▋     | 208/438 [58:26<1:03:36, 16.59s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 209/438 [58:26<1:03:11, 16.56s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 209/438 [58:42<1:03:11, 16.56s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 210/438 [58:42<1:02:54, 16.55s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 210/438 [58:59<1:02:54, 16.55s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 211/438 [58:59<1:02:38, 16.56s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 211/438 [59:16<1:02:38, 16.56s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 212/438 [59:16<1:02:21, 16.55s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  48%|████▊     | 212/438 [59:32<1:02:21, 16.55s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 213/438 [59:32<1:02:09, 16.58s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 1:  49%|████▊     | 213/438 [59:49<1:02:09, 16.58s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 214/438 [59:49<1:02:25, 16.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 214/438 [1:00:06<1:02:25, 16.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 215/438 [1:00:06<1:01:59, 16.68s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 215/438 [1:00:24<1:01:59, 16.68s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 216/438 [1:00:24<1:03:03, 17.04s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  49%|████▉     | 216/438 [1:00:40<1:03:03, 17.04s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 217/438 [1:00:40<1:02:18, 16.92s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 217/438 [1:00:57<1:02:18, 16.92s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 218/438 [1:00:57<1:01:37, 16.81s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  50%|████▉     | 218/438 [1:01:14<1:01:37, 16.81s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  50%|█████     | 219/438 [1:01:14<1:01:09, 16.76s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  50%|█████     | 219/438 [1:01:30<1:01:09, 16.76s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  50%|█████     | 220/438 [1:01:30<1:00:45, 16.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  50%|█████     | 220/438 [1:01:47<1:00:45, 16.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  50%|█████     | 221/438 [1:01:47<1:00:22, 16.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  50%|█████     | 221/438 [1:02:03<1:00:22, 16.69s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  51%|█████     | 222/438 [1:02:03<59:53, 16.64s/it, training_loss=0.128]  \u001B[A\n",
      "Epoch 1:  51%|█████     | 222/438 [1:02:20<59:53, 16.64s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  51%|█████     | 223/438 [1:02:20<59:29, 16.60s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  51%|█████     | 223/438 [1:02:36<59:29, 16.60s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  51%|█████     | 224/438 [1:02:36<59:12, 16.60s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  51%|█████     | 224/438 [1:02:53<59:12, 16.60s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 225/438 [1:02:53<58:58, 16.61s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  51%|█████▏    | 225/438 [1:03:10<58:58, 16.61s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 226/438 [1:03:10<58:42, 16.61s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 226/438 [1:03:26<58:42, 16.61s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 227/438 [1:03:26<58:18, 16.58s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 227/438 [1:03:43<58:18, 16.58s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 228/438 [1:03:43<58:02, 16.58s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 228/438 [1:03:59<58:02, 16.58s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 229/438 [1:03:59<57:41, 16.56s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  52%|█████▏    | 229/438 [1:04:16<57:41, 16.56s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 230/438 [1:04:16<57:23, 16.56s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 230/438 [1:04:33<57:23, 16.56s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 231/438 [1:04:33<57:19, 16.62s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 231/438 [1:04:49<57:19, 16.62s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 232/438 [1:04:49<57:04, 16.63s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 232/438 [1:05:06<57:04, 16.63s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 233/438 [1:05:06<57:21, 16.79s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 233/438 [1:05:24<57:21, 16.79s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 234/438 [1:05:24<57:44, 16.98s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  53%|█████▎    | 234/438 [1:05:40<57:44, 16.98s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 235/438 [1:05:40<57:08, 16.89s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  54%|█████▎    | 235/438 [1:05:57<57:08, 16.89s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 236/438 [1:05:57<56:33, 16.80s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 236/438 [1:06:14<56:33, 16.80s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 237/438 [1:06:14<56:16, 16.80s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 237/438 [1:06:30<56:16, 16.80s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 238/438 [1:06:30<55:42, 16.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  54%|█████▍    | 238/438 [1:06:47<55:42, 16.71s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 239/438 [1:06:47<55:35, 16.76s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 239/438 [1:07:04<55:35, 16.76s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 240/438 [1:07:04<55:15, 16.75s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  55%|█████▍    | 240/438 [1:07:20<55:15, 16.75s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 241/438 [1:07:20<54:43, 16.67s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 241/438 [1:07:37<54:43, 16.67s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 242/438 [1:07:37<54:32, 16.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 242/438 [1:07:54<54:32, 16.70s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 243/438 [1:07:54<54:14, 16.69s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  55%|█████▌    | 243/438 [1:08:11<54:14, 16.69s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 244/438 [1:08:11<54:39, 16.91s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 244/438 [1:08:28<54:39, 16.91s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 245/438 [1:08:28<54:14, 16.86s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 245/438 [1:08:45<54:14, 16.86s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 246/438 [1:08:45<53:40, 16.77s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  56%|█████▌    | 246/438 [1:09:02<53:40, 16.77s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 247/438 [1:09:02<53:35, 16.83s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  56%|█████▋    | 247/438 [1:09:18<53:35, 16.83s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 248/438 [1:09:18<53:20, 16.85s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 248/438 [1:09:35<53:20, 16.85s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 249/438 [1:09:35<53:00, 16.83s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 249/438 [1:09:52<53:00, 16.83s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 250/438 [1:09:52<52:41, 16.81s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 250/438 [1:10:09<52:41, 16.81s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 251/438 [1:10:09<52:17, 16.78s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  57%|█████▋    | 251/438 [1:10:26<52:17, 16.78s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 252/438 [1:10:26<52:05, 16.81s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 252/438 [1:10:44<52:05, 16.81s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 253/438 [1:10:44<53:13, 17.26s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 253/438 [1:11:01<53:13, 17.26s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 254/438 [1:11:01<53:08, 17.33s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 254/438 [1:11:18<53:08, 17.33s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 255/438 [1:11:18<52:19, 17.16s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 255/438 [1:11:35<52:19, 17.16s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 256/438 [1:11:35<51:32, 16.99s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  58%|█████▊    | 256/438 [1:11:51<51:32, 16.99s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 257/438 [1:11:52<50:59, 16.90s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  59%|█████▊    | 257/438 [1:12:08<50:59, 16.90s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 258/438 [1:12:08<50:27, 16.82s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 258/438 [1:12:25<50:27, 16.82s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 259/438 [1:12:25<49:55, 16.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 259/438 [1:12:41<49:55, 16.74s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 260/438 [1:12:41<49:31, 16.69s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  59%|█████▉    | 260/438 [1:12:58<49:31, 16.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 261/438 [1:12:58<49:12, 16.68s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 261/438 [1:13:14<49:12, 16.68s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 262/438 [1:13:14<48:46, 16.63s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  60%|█████▉    | 262/438 [1:13:31<48:46, 16.63s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  60%|██████    | 263/438 [1:13:31<48:26, 16.61s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  60%|██████    | 263/438 [1:13:48<48:26, 16.61s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  60%|██████    | 264/438 [1:13:48<48:06, 16.59s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  60%|██████    | 264/438 [1:14:04<48:06, 16.59s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  61%|██████    | 265/438 [1:14:04<47:47, 16.58s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  61%|██████    | 265/438 [1:14:21<47:47, 16.58s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  61%|██████    | 266/438 [1:14:21<47:30, 16.57s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  61%|██████    | 266/438 [1:14:37<47:30, 16.57s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  61%|██████    | 267/438 [1:14:37<47:10, 16.55s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  61%|██████    | 267/438 [1:14:54<47:10, 16.55s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  61%|██████    | 268/438 [1:14:54<47:04, 16.62s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  61%|██████    | 268/438 [1:15:11<47:04, 16.62s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 269/438 [1:15:11<46:48, 16.62s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 1:  61%|██████▏   | 269/438 [1:15:29<46:48, 16.62s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 270/438 [1:15:29<47:45, 17.06s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 270/438 [1:15:45<47:45, 17.06s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 271/438 [1:15:45<47:13, 16.97s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 271/438 [1:16:02<47:13, 16.97s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 272/438 [1:16:02<46:40, 16.87s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 272/438 [1:16:19<46:40, 16.87s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 273/438 [1:16:19<46:15, 16.82s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  62%|██████▏   | 273/438 [1:16:35<46:15, 16.82s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 274/438 [1:16:35<45:54, 16.79s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 274/438 [1:16:52<45:54, 16.79s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 275/438 [1:16:52<45:27, 16.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 275/438 [1:17:09<45:27, 16.74s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 276/438 [1:17:09<45:07, 16.71s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 276/438 [1:17:25<45:07, 16.71s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 277/438 [1:17:25<44:47, 16.69s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 277/438 [1:17:42<44:47, 16.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 278/438 [1:17:42<44:20, 16.63s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  63%|██████▎   | 278/438 [1:17:58<44:20, 16.63s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 279/438 [1:17:58<44:04, 16.63s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  64%|██████▎   | 279/438 [1:18:15<44:04, 16.63s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 280/438 [1:18:15<43:39, 16.58s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 280/438 [1:18:31<43:39, 16.58s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 281/438 [1:18:31<43:21, 16.57s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 281/438 [1:18:48<43:21, 16.57s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 282/438 [1:18:48<43:20, 16.67s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  64%|██████▍   | 282/438 [1:19:05<43:20, 16.67s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 283/438 [1:19:05<43:13, 16.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 283/438 [1:19:22<43:13, 16.73s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 284/438 [1:19:22<42:42, 16.64s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 1:  65%|██████▍   | 284/438 [1:19:38<42:42, 16.64s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 285/438 [1:19:38<42:15, 16.57s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 285/438 [1:19:54<42:15, 16.57s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 286/438 [1:19:54<41:44, 16.48s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  65%|██████▌   | 286/438 [1:20:11<41:44, 16.48s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 287/438 [1:20:11<41:27, 16.47s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 287/438 [1:20:27<41:27, 16.47s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 288/438 [1:20:27<41:03, 16.42s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 288/438 [1:20:43<41:03, 16.42s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 289/438 [1:20:43<40:43, 16.40s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 289/438 [1:21:00<40:43, 16.40s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 290/438 [1:21:00<40:33, 16.44s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  66%|██████▌   | 290/438 [1:21:17<40:33, 16.44s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 291/438 [1:21:17<40:24, 16.50s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  66%|██████▋   | 291/438 [1:21:33<40:24, 16.50s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 292/438 [1:21:33<40:10, 16.51s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 292/438 [1:21:50<40:10, 16.51s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 293/438 [1:21:50<39:49, 16.48s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 293/438 [1:22:06<39:49, 16.48s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 294/438 [1:22:06<39:34, 16.49s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 294/438 [1:22:23<39:34, 16.49s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 295/438 [1:22:23<39:18, 16.49s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  67%|██████▋   | 295/438 [1:22:39<39:18, 16.49s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 296/438 [1:22:39<38:56, 16.45s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 296/438 [1:22:55<38:56, 16.45s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 297/438 [1:22:55<38:37, 16.43s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 297/438 [1:23:12<38:37, 16.43s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 298/438 [1:23:12<38:30, 16.50s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 298/438 [1:23:28<38:30, 16.50s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 299/438 [1:23:28<38:06, 16.45s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 299/438 [1:23:45<38:06, 16.45s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 300/438 [1:23:45<37:52, 16.47s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  68%|██████▊   | 300/438 [1:24:01<37:52, 16.47s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 301/438 [1:24:01<37:32, 16.44s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  69%|██████▊   | 301/438 [1:24:18<37:32, 16.44s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 302/438 [1:24:18<37:13, 16.42s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 302/438 [1:24:34<37:13, 16.42s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 303/438 [1:24:34<36:55, 16.41s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 303/438 [1:24:51<36:55, 16.41s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 304/438 [1:24:51<36:44, 16.45s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  69%|██████▉   | 304/438 [1:25:07<36:44, 16.45s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 305/438 [1:25:07<36:36, 16.52s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 305/438 [1:25:24<36:36, 16.52s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 306/438 [1:25:24<36:14, 16.48s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  70%|██████▉   | 306/438 [1:25:40<36:14, 16.48s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  70%|███████   | 307/438 [1:25:40<35:57, 16.47s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  70%|███████   | 307/438 [1:25:56<35:57, 16.47s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  70%|███████   | 308/438 [1:25:56<35:40, 16.46s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  70%|███████   | 308/438 [1:26:13<35:40, 16.46s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  71%|███████   | 309/438 [1:26:13<35:24, 16.47s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 1:  71%|███████   | 309/438 [1:26:29<35:24, 16.47s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  71%|███████   | 310/438 [1:26:29<35:08, 16.47s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  71%|███████   | 310/438 [1:26:46<35:08, 16.47s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  71%|███████   | 311/438 [1:26:46<34:51, 16.47s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  71%|███████   | 311/438 [1:27:02<34:51, 16.47s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  71%|███████   | 312/438 [1:27:02<34:37, 16.48s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  71%|███████   | 312/438 [1:27:19<34:37, 16.48s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 313/438 [1:27:19<34:17, 16.46s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  71%|███████▏  | 313/438 [1:27:35<34:17, 16.46s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 314/438 [1:27:35<33:59, 16.44s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 314/438 [1:27:52<33:59, 16.44s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 315/438 [1:27:52<33:42, 16.45s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 315/438 [1:28:08<33:42, 16.45s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 316/438 [1:28:08<33:25, 16.44s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 316/438 [1:28:25<33:25, 16.44s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 317/438 [1:28:25<33:13, 16.47s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  72%|███████▏  | 317/438 [1:28:41<33:13, 16.47s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 318/438 [1:28:41<32:48, 16.40s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 318/438 [1:28:57<32:48, 16.40s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 319/438 [1:28:57<32:35, 16.43s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 319/438 [1:29:14<32:35, 16.43s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 320/438 [1:29:14<32:18, 16.43s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 320/438 [1:29:30<32:18, 16.43s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 321/438 [1:29:30<32:06, 16.47s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  73%|███████▎  | 321/438 [1:29:47<32:06, 16.47s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 322/438 [1:29:47<31:53, 16.50s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 322/438 [1:30:04<31:53, 16.50s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 323/438 [1:30:04<32:08, 16.77s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  74%|███████▎  | 323/438 [1:30:21<32:08, 16.77s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 324/438 [1:30:21<31:46, 16.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 324/438 [1:30:39<31:46, 16.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 325/438 [1:30:39<32:11, 17.09s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 325/438 [1:30:55<32:11, 17.09s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 326/438 [1:30:55<31:33, 16.91s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  74%|███████▍  | 326/438 [1:31:12<31:33, 16.91s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 327/438 [1:31:12<31:06, 16.81s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 327/438 [1:31:29<31:06, 16.81s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 328/438 [1:31:29<30:41, 16.74s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  75%|███████▍  | 328/438 [1:31:45<30:41, 16.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 329/438 [1:31:45<30:20, 16.70s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 329/438 [1:32:02<30:20, 16.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 330/438 [1:32:02<29:56, 16.63s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  75%|███████▌  | 330/438 [1:32:18<29:56, 16.63s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 331/438 [1:32:18<29:34, 16.58s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 331/438 [1:32:35<29:34, 16.58s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 332/438 [1:32:35<29:12, 16.54s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 332/438 [1:32:51<29:12, 16.54s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 333/438 [1:32:51<28:53, 16.51s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  76%|███████▌  | 333/438 [1:33:08<28:53, 16.51s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 334/438 [1:33:08<28:38, 16.52s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 334/438 [1:33:24<28:38, 16.52s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 335/438 [1:33:24<28:29, 16.59s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  76%|███████▋  | 335/438 [1:33:41<28:29, 16.59s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 336/438 [1:33:41<28:19, 16.66s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 336/438 [1:33:58<28:19, 16.66s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 337/438 [1:33:58<28:05, 16.69s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 337/438 [1:34:15<28:05, 16.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 338/438 [1:34:15<27:55, 16.76s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 338/438 [1:34:32<27:55, 16.76s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 339/438 [1:34:32<27:43, 16.80s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  77%|███████▋  | 339/438 [1:34:49<27:43, 16.80s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 340/438 [1:34:49<27:36, 16.90s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 340/438 [1:35:05<27:36, 16.90s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 341/438 [1:35:05<27:10, 16.81s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 341/438 [1:35:22<27:10, 16.81s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 342/438 [1:35:22<26:45, 16.72s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 342/438 [1:35:38<26:45, 16.72s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 343/438 [1:35:38<26:22, 16.65s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  78%|███████▊  | 343/438 [1:35:55<26:22, 16.65s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 344/438 [1:35:55<26:01, 16.61s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  79%|███████▊  | 344/438 [1:36:12<26:01, 16.61s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 345/438 [1:36:12<25:57, 16.75s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 345/438 [1:36:29<25:57, 16.75s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 346/438 [1:36:29<25:37, 16.72s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 346/438 [1:36:45<25:37, 16.72s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 347/438 [1:36:45<25:16, 16.67s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 347/438 [1:37:02<25:16, 16.67s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 348/438 [1:37:02<24:55, 16.61s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  79%|███████▉  | 348/438 [1:37:18<24:55, 16.61s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 349/438 [1:37:18<24:33, 16.56s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 349/438 [1:37:35<24:33, 16.56s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 350/438 [1:37:35<24:18, 16.57s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  80%|███████▉  | 350/438 [1:37:51<24:18, 16.57s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  80%|████████  | 351/438 [1:37:51<24:00, 16.55s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  80%|████████  | 351/438 [1:38:08<24:00, 16.55s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  80%|████████  | 352/438 [1:38:08<23:44, 16.56s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  80%|████████  | 352/438 [1:38:24<23:44, 16.56s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  81%|████████  | 353/438 [1:38:24<23:25, 16.54s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 1:  81%|████████  | 353/438 [1:38:41<23:25, 16.54s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  81%|████████  | 354/438 [1:38:41<23:08, 16.54s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  81%|████████  | 354/438 [1:38:57<23:08, 16.54s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  81%|████████  | 355/438 [1:38:57<22:52, 16.54s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  81%|████████  | 355/438 [1:39:14<22:52, 16.54s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 356/438 [1:39:14<22:34, 16.52s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  81%|████████▏ | 356/438 [1:39:30<22:34, 16.52s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 357/438 [1:39:30<22:17, 16.51s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 357/438 [1:39:47<22:17, 16.51s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 358/438 [1:39:47<22:02, 16.53s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 358/438 [1:40:03<22:02, 16.53s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 359/438 [1:40:03<21:46, 16.53s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 359/438 [1:40:20<21:46, 16.53s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 360/438 [1:40:20<21:30, 16.54s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 360/438 [1:40:36<21:30, 16.54s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 361/438 [1:40:36<21:11, 16.51s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  82%|████████▏ | 361/438 [1:40:53<21:11, 16.51s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 362/438 [1:40:53<20:54, 16.51s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 362/438 [1:41:10<20:54, 16.51s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 363/438 [1:41:10<20:40, 16.54s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 363/438 [1:41:26<20:40, 16.54s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 364/438 [1:41:26<20:24, 16.54s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 364/438 [1:41:43<20:24, 16.54s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 365/438 [1:41:43<20:10, 16.58s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  83%|████████▎ | 365/438 [1:41:59<20:10, 16.58s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 366/438 [1:41:59<19:53, 16.58s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  84%|████████▎ | 366/438 [1:42:16<19:53, 16.58s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 367/438 [1:42:16<19:34, 16.54s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 367/438 [1:42:32<19:34, 16.54s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 368/438 [1:42:32<19:16, 16.52s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 368/438 [1:42:49<19:16, 16.52s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 369/438 [1:42:49<18:58, 16.51s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 369/438 [1:43:05<18:58, 16.51s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 370/438 [1:43:05<18:45, 16.55s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  84%|████████▍ | 370/438 [1:43:22<18:45, 16.55s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 371/438 [1:43:22<18:26, 16.52s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 371/438 [1:43:38<18:26, 16.52s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 372/438 [1:43:38<18:10, 16.53s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  85%|████████▍ | 372/438 [1:43:55<18:10, 16.53s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 373/438 [1:43:55<17:55, 16.54s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 373/438 [1:44:12<17:55, 16.54s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 374/438 [1:44:12<17:41, 16.58s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  85%|████████▌ | 374/438 [1:44:28<17:41, 16.58s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 375/438 [1:44:28<17:22, 16.55s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 375/438 [1:44:45<17:22, 16.55s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 376/438 [1:44:45<17:19, 16.77s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 376/438 [1:45:03<17:19, 16.77s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 377/438 [1:45:03<17:18, 17.03s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  86%|████████▌ | 377/438 [1:45:24<17:18, 17.03s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 378/438 [1:45:24<18:04, 18.08s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  86%|████████▋ | 378/438 [1:45:41<18:04, 18.08s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 379/438 [1:45:42<17:44, 18.04s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 379/438 [1:45:58<17:44, 18.04s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 380/438 [1:45:58<17:04, 17.66s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 380/438 [1:46:15<17:04, 17.66s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 381/438 [1:46:15<16:30, 17.37s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 381/438 [1:46:32<16:30, 17.37s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 382/438 [1:46:32<15:58, 17.12s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 382/438 [1:46:48<15:58, 17.12s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 383/438 [1:46:48<15:33, 16.98s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  87%|████████▋ | 383/438 [1:47:05<15:33, 16.98s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 384/438 [1:47:05<15:09, 16.85s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 384/438 [1:47:21<15:09, 16.85s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 385/438 [1:47:21<14:46, 16.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 385/438 [1:47:38<14:46, 16.73s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 386/438 [1:47:38<14:32, 16.77s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 386/438 [1:47:55<14:32, 16.77s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 387/438 [1:47:55<14:13, 16.74s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  88%|████████▊ | 387/438 [1:48:11<14:13, 16.74s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 388/438 [1:48:11<13:53, 16.66s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  89%|████████▊ | 388/438 [1:48:28<13:53, 16.66s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 389/438 [1:48:28<13:34, 16.63s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 389/438 [1:48:44<13:34, 16.63s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 390/438 [1:48:44<13:17, 16.62s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 390/438 [1:49:01<13:17, 16.62s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 391/438 [1:49:01<12:59, 16.58s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 391/438 [1:49:17<12:59, 16.58s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 392/438 [1:49:17<12:42, 16.57s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  89%|████████▉ | 392/438 [1:49:34<12:42, 16.57s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 393/438 [1:49:34<12:25, 16.57s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 393/438 [1:49:51<12:25, 16.57s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 394/438 [1:49:51<12:10, 16.59s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 1:  90%|████████▉ | 394/438 [1:50:07<12:10, 16.59s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 395/438 [1:50:07<11:52, 16.57s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 395/438 [1:50:24<11:52, 16.57s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 396/438 [1:50:24<11:35, 16.56s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 1:  90%|█████████ | 396/438 [1:50:40<11:35, 16.56s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 397/438 [1:50:40<11:20, 16.60s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 397/438 [1:50:57<11:20, 16.60s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 398/438 [1:50:57<11:09, 16.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 398/438 [1:51:14<11:09, 16.74s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 399/438 [1:51:14<10:55, 16.81s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  91%|█████████ | 399/438 [1:51:31<10:55, 16.81s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 400/438 [1:51:31<10:35, 16.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  91%|█████████▏| 400/438 [1:51:47<10:35, 16.74s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 401/438 [1:51:47<10:15, 16.63s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 401/438 [1:52:04<10:15, 16.63s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 402/438 [1:52:04<09:58, 16.63s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 402/438 [1:52:20<09:58, 16.63s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 403/438 [1:52:20<09:40, 16.60s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 403/438 [1:52:37<09:40, 16.60s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 404/438 [1:52:37<09:23, 16.58s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 404/438 [1:52:54<09:23, 16.58s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 405/438 [1:52:54<09:06, 16.58s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 1:  92%|█████████▏| 405/438 [1:53:10<09:06, 16.58s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 406/438 [1:53:10<08:48, 16.53s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 406/438 [1:53:27<08:48, 16.53s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 407/438 [1:53:27<08:33, 16.56s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 407/438 [1:53:43<08:33, 16.56s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 408/438 [1:53:43<08:16, 16.55s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 408/438 [1:54:00<08:16, 16.55s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 409/438 [1:54:00<08:00, 16.55s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 1:  93%|█████████▎| 409/438 [1:54:16<08:00, 16.55s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 410/438 [1:54:16<07:42, 16.53s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  94%|█████████▎| 410/438 [1:54:33<07:42, 16.53s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 411/438 [1:54:33<07:27, 16.58s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 411/438 [1:54:50<07:27, 16.58s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 412/438 [1:54:50<07:13, 16.67s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 412/438 [1:55:07<07:13, 16.67s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 413/438 [1:55:07<06:57, 16.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 1:  94%|█████████▍| 413/438 [1:55:24<06:57, 16.69s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 414/438 [1:55:24<06:47, 16.98s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 414/438 [1:55:45<06:47, 16.98s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 415/438 [1:55:45<06:58, 18.20s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 415/438 [1:56:05<06:58, 18.20s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 416/438 [1:56:05<06:48, 18.56s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 1:  95%|█████████▍| 416/438 [1:56:23<06:48, 18.56s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 417/438 [1:56:23<06:28, 18.50s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 417/438 [1:56:41<06:28, 18.50s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 418/438 [1:56:41<06:04, 18.23s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  95%|█████████▌| 418/438 [1:56:58<06:04, 18.23s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 419/438 [1:56:58<05:41, 17.97s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 419/438 [1:57:16<05:41, 17.97s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 420/438 [1:57:16<05:23, 17.98s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 420/438 [1:57:33<05:23, 17.98s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 421/438 [1:57:33<05:02, 17.79s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1:  96%|█████████▌| 421/438 [1:57:51<05:02, 17.79s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 422/438 [1:57:51<04:42, 17.63s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 1:  96%|█████████▋| 422/438 [1:58:08<04:42, 17.63s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 423/438 [1:58:08<04:22, 17.50s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 423/438 [1:58:25<04:22, 17.50s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 424/438 [1:58:25<04:04, 17.50s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 424/438 [1:58:43<04:04, 17.50s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 425/438 [1:58:43<03:46, 17.45s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 425/438 [1:59:00<03:46, 17.45s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 426/438 [1:59:00<03:28, 17.40s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 426/438 [1:59:17<03:28, 17.40s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 427/438 [1:59:17<03:11, 17.37s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 1:  97%|█████████▋| 427/438 [1:59:34<03:11, 17.37s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 428/438 [1:59:34<02:53, 17.34s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 428/438 [1:59:52<02:53, 17.34s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 429/438 [1:59:52<02:36, 17.35s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 429/438 [2:00:09<02:36, 17.35s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 430/438 [2:00:09<02:18, 17.33s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 430/438 [2:00:26<02:18, 17.33s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 431/438 [2:00:26<02:01, 17.33s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 1:  98%|█████████▊| 431/438 [2:00:45<02:01, 17.33s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 432/438 [2:00:45<01:46, 17.76s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 1:  99%|█████████▊| 432/438 [2:01:03<01:46, 17.76s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 433/438 [2:01:03<01:28, 17.65s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 433/438 [2:01:20<01:28, 17.65s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 434/438 [2:01:20<01:10, 17.57s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 434/438 [2:01:38<01:10, 17.57s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 435/438 [2:01:38<00:52, 17.56s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 1:  99%|█████████▉| 435/438 [2:01:55<00:52, 17.56s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 436/438 [2:01:55<00:34, 17.44s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 436/438 [2:02:12<00:34, 17.44s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 437/438 [2:02:12<00:17, 17.33s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 1: 100%|█████████▉| 437/438 [2:02:26<00:17, 17.33s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 1: 100%|██████████| 438/438 [2:02:26<00:00, 16.46s/it, training_loss=0.137]\u001B[A\n",
      "  0%|          | 0/5 [2:02:26<?, ?it/s]                                          \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Trainin loss: 0.4187786023910732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [2:23:54<9:35:38, 8634.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3978140232093791\n",
      "F1 Score (Weighted): 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2:   0%|          | 0/438 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 2:   0%|          | 0/438 [00:17<?, ?it/s, training_loss=0.151]\u001B[A\n",
      "Epoch 2:   0%|          | 1/438 [00:17<2:09:04, 17.72s/it, training_loss=0.151]\u001B[A\n",
      "Epoch 2:   0%|          | 1/438 [00:35<2:09:04, 17.72s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:   0%|          | 2/438 [00:35<2:09:49, 17.86s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:   0%|          | 2/438 [00:53<2:09:49, 17.86s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:   1%|          | 3/438 [00:53<2:07:58, 17.65s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:   1%|          | 3/438 [01:10<2:07:58, 17.65s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   1%|          | 4/438 [01:10<2:07:02, 17.56s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   1%|          | 4/438 [01:27<2:07:02, 17.56s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:   1%|          | 5/438 [01:27<2:05:37, 17.41s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:   1%|          | 5/438 [01:44<2:05:37, 17.41s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   1%|▏         | 6/438 [01:44<2:04:27, 17.29s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   1%|▏         | 6/438 [02:02<2:04:27, 17.29s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   2%|▏         | 7/438 [02:02<2:05:17, 17.44s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   2%|▏         | 7/438 [02:20<2:05:17, 17.44s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   2%|▏         | 8/438 [02:20<2:05:16, 17.48s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   2%|▏         | 8/438 [02:37<2:05:16, 17.48s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:   2%|▏         | 9/438 [02:37<2:05:54, 17.61s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:   2%|▏         | 9/438 [02:56<2:05:54, 17.61s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   2%|▏         | 10/438 [02:56<2:07:01, 17.81s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   2%|▏         | 10/438 [03:14<2:07:01, 17.81s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   3%|▎         | 11/438 [03:14<2:07:26, 17.91s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   3%|▎         | 11/438 [03:32<2:07:26, 17.91s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:   3%|▎         | 12/438 [03:32<2:07:18, 17.93s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:   3%|▎         | 12/438 [03:50<2:07:18, 17.93s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   3%|▎         | 13/438 [03:50<2:07:05, 17.94s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   3%|▎         | 13/438 [04:08<2:07:05, 17.94s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:   3%|▎         | 14/438 [04:08<2:07:00, 17.97s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:   3%|▎         | 14/438 [04:26<2:07:00, 17.97s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:   3%|▎         | 15/438 [04:26<2:06:27, 17.94s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:   3%|▎         | 15/438 [04:43<2:06:27, 17.94s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:   4%|▎         | 16/438 [04:43<2:05:42, 17.87s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:   4%|▎         | 16/438 [05:01<2:05:42, 17.87s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:   4%|▍         | 17/438 [05:01<2:05:01, 17.82s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:   4%|▍         | 17/438 [05:19<2:05:01, 17.82s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   4%|▍         | 18/438 [05:19<2:04:26, 17.78s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   4%|▍         | 18/438 [05:37<2:04:26, 17.78s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   4%|▍         | 19/438 [05:37<2:04:15, 17.79s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   4%|▍         | 19/438 [05:55<2:04:15, 17.79s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   5%|▍         | 20/438 [05:55<2:05:27, 18.01s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   5%|▍         | 20/438 [06:13<2:05:27, 18.01s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:   5%|▍         | 21/438 [06:13<2:05:29, 18.06s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:   5%|▍         | 21/438 [06:31<2:05:29, 18.06s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:   5%|▌         | 22/438 [06:31<2:03:31, 17.82s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:   5%|▌         | 22/438 [06:48<2:03:31, 17.82s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:   5%|▌         | 23/438 [06:48<2:02:40, 17.74s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:   5%|▌         | 23/438 [07:09<2:02:40, 17.74s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:   5%|▌         | 24/438 [07:09<2:09:22, 18.75s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:   5%|▌         | 24/438 [07:29<2:09:22, 18.75s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   6%|▌         | 25/438 [07:29<2:10:54, 19.02s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   6%|▌         | 25/438 [07:48<2:10:54, 19.02s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:   6%|▌         | 26/438 [07:48<2:10:07, 18.95s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:   6%|▌         | 26/438 [08:07<2:10:07, 18.95s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   6%|▌         | 27/438 [08:07<2:10:49, 19.10s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   6%|▌         | 27/438 [08:26<2:10:49, 19.10s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   6%|▋         | 28/438 [08:26<2:10:16, 19.07s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   6%|▋         | 28/438 [08:45<2:10:16, 19.07s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:   7%|▋         | 29/438 [08:45<2:09:22, 18.98s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:   7%|▋         | 29/438 [09:02<2:09:22, 18.98s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:   7%|▋         | 30/438 [09:02<2:06:21, 18.58s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:   7%|▋         | 30/438 [09:20<2:06:21, 18.58s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   7%|▋         | 31/438 [09:20<2:04:18, 18.33s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:   7%|▋         | 31/438 [09:38<2:04:18, 18.33s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:   7%|▋         | 32/438 [09:38<2:02:51, 18.16s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:   7%|▋         | 32/438 [09:56<2:02:51, 18.16s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:   8%|▊         | 33/438 [09:56<2:01:33, 18.01s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:   8%|▊         | 33/438 [10:14<2:01:33, 18.01s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:   8%|▊         | 34/438 [10:14<2:02:52, 18.25s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:   8%|▊         | 34/438 [10:33<2:02:52, 18.25s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:   8%|▊         | 35/438 [10:33<2:03:34, 18.40s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:   8%|▊         | 35/438 [10:51<2:03:34, 18.40s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:   8%|▊         | 36/438 [10:51<2:01:44, 18.17s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:   8%|▊         | 36/438 [11:09<2:01:44, 18.17s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:   8%|▊         | 37/438 [11:09<2:02:04, 18.26s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:   8%|▊         | 37/438 [11:28<2:02:04, 18.26s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   9%|▊         | 38/438 [11:28<2:02:46, 18.42s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   9%|▊         | 38/438 [11:47<2:02:46, 18.42s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   9%|▉         | 39/438 [11:47<2:02:38, 18.44s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:   9%|▉         | 39/438 [12:05<2:02:38, 18.44s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   9%|▉         | 40/438 [12:05<2:01:56, 18.38s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:   9%|▉         | 40/438 [12:23<2:01:56, 18.38s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:   9%|▉         | 41/438 [12:23<2:01:57, 18.43s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:   9%|▉         | 41/438 [12:42<2:01:57, 18.43s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  10%|▉         | 42/438 [12:42<2:01:41, 18.44s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  10%|▉         | 42/438 [13:01<2:01:41, 18.44s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  10%|▉         | 43/438 [13:01<2:02:43, 18.64s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  10%|▉         | 43/438 [13:20<2:02:43, 18.64s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  10%|█         | 44/438 [13:20<2:03:13, 18.77s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  10%|█         | 44/438 [13:39<2:03:13, 18.77s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  10%|█         | 45/438 [13:39<2:02:50, 18.75s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  10%|█         | 45/438 [13:58<2:02:50, 18.75s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  11%|█         | 46/438 [13:58<2:03:08, 18.85s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  11%|█         | 46/438 [14:16<2:03:08, 18.85s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  11%|█         | 47/438 [14:16<2:01:19, 18.62s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  11%|█         | 47/438 [14:35<2:01:19, 18.62s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  11%|█         | 48/438 [14:35<2:01:24, 18.68s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  11%|█         | 48/438 [14:52<2:01:24, 18.68s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  11%|█         | 49/438 [14:52<1:59:16, 18.40s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  11%|█         | 49/438 [15:10<1:59:16, 18.40s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  11%|█▏        | 50/438 [15:10<1:56:54, 18.08s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  11%|█▏        | 50/438 [15:28<1:56:54, 18.08s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 51/438 [15:28<1:56:11, 18.01s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 51/438 [15:46<1:56:11, 18.01s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 52/438 [15:46<1:56:20, 18.08s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 52/438 [16:03<1:56:20, 18.08s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 53/438 [16:03<1:54:53, 17.91s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 53/438 [16:22<1:54:53, 17.91s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 54/438 [16:22<1:55:06, 17.98s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  12%|█▏        | 54/438 [16:39<1:55:06, 17.98s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 55/438 [16:39<1:53:50, 17.84s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 55/438 [16:57<1:53:50, 17.84s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 56/438 [16:57<1:52:56, 17.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 56/438 [17:14<1:52:56, 17.74s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 57/438 [17:14<1:52:41, 17.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 57/438 [17:33<1:52:41, 17.75s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 58/438 [17:33<1:54:28, 18.07s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 58/438 [17:51<1:54:28, 18.07s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 59/438 [17:51<1:54:37, 18.15s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  13%|█▎        | 59/438 [18:10<1:54:37, 18.15s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  14%|█▎        | 60/438 [18:10<1:54:23, 18.16s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  14%|█▎        | 60/438 [18:28<1:54:23, 18.16s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  14%|█▍        | 61/438 [18:28<1:54:57, 18.29s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  14%|█▍        | 61/438 [18:47<1:54:57, 18.29s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  14%|█▍        | 62/438 [18:47<1:56:00, 18.51s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  14%|█▍        | 62/438 [19:06<1:56:00, 18.51s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 2:  14%|█▍        | 63/438 [19:06<1:56:28, 18.64s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 2:  14%|█▍        | 63/438 [19:25<1:56:28, 18.64s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  15%|█▍        | 64/438 [19:25<1:55:48, 18.58s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  15%|█▍        | 64/438 [19:44<1:55:48, 18.58s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  15%|█▍        | 65/438 [19:44<1:56:33, 18.75s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  15%|█▍        | 65/438 [20:02<1:56:33, 18.75s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  15%|█▌        | 66/438 [20:02<1:55:47, 18.68s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  15%|█▌        | 66/438 [20:20<1:55:47, 18.68s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  15%|█▌        | 67/438 [20:20<1:54:19, 18.49s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  15%|█▌        | 67/438 [20:39<1:54:19, 18.49s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 68/438 [20:39<1:53:46, 18.45s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 68/438 [20:57<1:53:46, 18.45s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 69/438 [20:57<1:52:45, 18.34s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 69/438 [21:16<1:52:45, 18.34s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 70/438 [21:16<1:53:09, 18.45s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 70/438 [21:34<1:53:09, 18.45s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 71/438 [21:34<1:52:18, 18.36s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  16%|█▌        | 71/438 [21:52<1:52:18, 18.36s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 2:  16%|█▋        | 72/438 [21:52<1:51:37, 18.30s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 2:  16%|█▋        | 72/438 [22:12<1:51:37, 18.30s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 73/438 [22:12<1:53:56, 18.73s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 73/438 [22:30<1:53:56, 18.73s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 74/438 [22:30<1:52:53, 18.61s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 74/438 [22:48<1:52:53, 18.61s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 75/438 [22:48<1:52:06, 18.53s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 75/438 [23:07<1:52:06, 18.53s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 76/438 [23:07<1:52:02, 18.57s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  17%|█▋        | 76/438 [23:25<1:52:02, 18.57s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 77/438 [23:25<1:51:33, 18.54s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 77/438 [23:44<1:51:33, 18.54s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 78/438 [23:44<1:51:25, 18.57s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 78/438 [24:03<1:51:25, 18.57s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 79/438 [24:03<1:51:22, 18.61s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 79/438 [24:22<1:51:22, 18.61s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 80/438 [24:22<1:52:38, 18.88s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 80/438 [24:42<1:52:38, 18.88s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 81/438 [24:42<1:53:44, 19.12s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  18%|█▊        | 81/438 [25:00<1:53:44, 19.12s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  19%|█▊        | 82/438 [25:00<1:52:26, 18.95s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  19%|█▊        | 82/438 [25:20<1:52:26, 18.95s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  19%|█▉        | 83/438 [25:20<1:53:41, 19.22s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  19%|█▉        | 83/438 [25:40<1:53:41, 19.22s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  19%|█▉        | 84/438 [25:40<1:53:40, 19.27s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  19%|█▉        | 84/438 [26:00<1:53:40, 19.27s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  19%|█▉        | 85/438 [26:00<1:55:04, 19.56s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  19%|█▉        | 85/438 [26:19<1:55:04, 19.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  20%|█▉        | 86/438 [26:19<1:53:41, 19.38s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  20%|█▉        | 86/438 [26:38<1:53:41, 19.38s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  20%|█▉        | 87/438 [26:38<1:53:22, 19.38s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  20%|█▉        | 87/438 [26:59<1:53:22, 19.38s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  20%|██        | 88/438 [26:59<1:55:20, 19.77s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  20%|██        | 88/438 [27:19<1:55:20, 19.77s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  20%|██        | 89/438 [27:19<1:56:04, 19.96s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  20%|██        | 89/438 [27:39<1:56:04, 19.96s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  21%|██        | 90/438 [27:39<1:55:27, 19.91s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  21%|██        | 90/438 [27:59<1:55:27, 19.91s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 2:  21%|██        | 91/438 [27:59<1:54:34, 19.81s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 2:  21%|██        | 91/438 [28:17<1:54:34, 19.81s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  21%|██        | 92/438 [28:17<1:52:12, 19.46s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  21%|██        | 92/438 [28:36<1:52:12, 19.46s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  21%|██        | 93/438 [28:36<1:51:20, 19.36s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  21%|██        | 93/438 [28:55<1:51:20, 19.36s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  21%|██▏       | 94/438 [28:55<1:48:45, 18.97s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  21%|██▏       | 94/438 [29:12<1:48:45, 18.97s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 95/438 [29:12<1:45:45, 18.50s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 95/438 [29:29<1:45:45, 18.50s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 96/438 [29:29<1:43:38, 18.18s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 96/438 [29:47<1:43:38, 18.18s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 97/438 [29:47<1:42:16, 18.00s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 97/438 [30:04<1:42:16, 18.00s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 98/438 [30:04<1:40:34, 17.75s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  22%|██▏       | 98/438 [30:22<1:40:34, 17.75s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 99/438 [30:22<1:39:49, 17.67s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 99/438 [30:39<1:39:49, 17.67s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 100/438 [30:39<1:38:59, 17.57s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 100/438 [30:57<1:38:59, 17.57s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 101/438 [30:57<1:38:57, 17.62s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 101/438 [31:14<1:38:57, 17.62s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 102/438 [31:14<1:38:19, 17.56s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  23%|██▎       | 102/438 [31:32<1:38:19, 17.56s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  24%|██▎       | 103/438 [31:32<1:37:55, 17.54s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  24%|██▎       | 103/438 [31:49<1:37:55, 17.54s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  24%|██▎       | 104/438 [31:49<1:37:37, 17.54s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  24%|██▎       | 104/438 [32:07<1:37:37, 17.54s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 2:  24%|██▍       | 105/438 [32:07<1:37:20, 17.54s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 2:  24%|██▍       | 105/438 [32:24<1:37:20, 17.54s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  24%|██▍       | 106/438 [32:24<1:36:54, 17.51s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  24%|██▍       | 106/438 [32:42<1:36:54, 17.51s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  24%|██▍       | 107/438 [32:42<1:36:44, 17.54s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  24%|██▍       | 107/438 [32:59<1:36:44, 17.54s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  25%|██▍       | 108/438 [32:59<1:36:27, 17.54s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  25%|██▍       | 108/438 [33:17<1:36:27, 17.54s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 2:  25%|██▍       | 109/438 [33:17<1:35:51, 17.48s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 2:  25%|██▍       | 109/438 [33:34<1:35:51, 17.48s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  25%|██▌       | 110/438 [33:34<1:35:44, 17.51s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  25%|██▌       | 110/438 [33:52<1:35:44, 17.51s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  25%|██▌       | 111/438 [33:52<1:35:33, 17.54s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  25%|██▌       | 111/438 [34:09<1:35:33, 17.54s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  26%|██▌       | 112/438 [34:09<1:34:38, 17.42s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  26%|██▌       | 112/438 [34:26<1:34:38, 17.42s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  26%|██▌       | 113/438 [34:26<1:34:07, 17.38s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  26%|██▌       | 113/438 [34:43<1:34:07, 17.38s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  26%|██▌       | 114/438 [34:43<1:33:37, 17.34s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  26%|██▌       | 114/438 [35:01<1:33:37, 17.34s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  26%|██▋       | 115/438 [35:01<1:33:11, 17.31s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  26%|██▋       | 115/438 [35:18<1:33:11, 17.31s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  26%|██▋       | 116/438 [35:18<1:32:55, 17.32s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  26%|██▋       | 116/438 [35:36<1:32:55, 17.32s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 117/438 [35:36<1:32:58, 17.38s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 117/438 [35:53<1:32:58, 17.38s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 118/438 [35:53<1:32:25, 17.33s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 118/438 [36:10<1:32:25, 17.33s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 119/438 [36:10<1:32:37, 17.42s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 119/438 [36:27<1:32:37, 17.42s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 120/438 [36:27<1:31:45, 17.31s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 2:  27%|██▋       | 120/438 [36:45<1:31:45, 17.31s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 121/438 [36:45<1:31:14, 17.27s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 121/438 [37:02<1:31:14, 17.27s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 122/438 [37:02<1:30:39, 17.21s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 122/438 [37:20<1:30:39, 17.21s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 123/438 [37:20<1:32:17, 17.58s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 123/438 [37:38<1:32:17, 17.58s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 124/438 [37:38<1:31:49, 17.55s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  28%|██▊       | 124/438 [37:55<1:31:49, 17.55s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  29%|██▊       | 125/438 [37:55<1:30:36, 17.37s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  29%|██▊       | 125/438 [38:12<1:30:36, 17.37s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 126/438 [38:12<1:29:44, 17.26s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 126/438 [38:29<1:29:44, 17.26s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 127/438 [38:29<1:29:11, 17.21s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 127/438 [38:46<1:29:11, 17.21s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 128/438 [38:46<1:28:32, 17.14s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 128/438 [39:03<1:28:32, 17.14s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 129/438 [39:03<1:28:24, 17.17s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  29%|██▉       | 129/438 [39:20<1:28:24, 17.17s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  30%|██▉       | 130/438 [39:20<1:27:39, 17.07s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  30%|██▉       | 130/438 [39:37<1:27:39, 17.07s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  30%|██▉       | 131/438 [39:37<1:27:31, 17.11s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  30%|██▉       | 131/438 [39:54<1:27:31, 17.11s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  30%|███       | 132/438 [39:54<1:27:08, 17.09s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  30%|███       | 132/438 [40:11<1:27:08, 17.09s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  30%|███       | 133/438 [40:11<1:27:00, 17.12s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  30%|███       | 133/438 [40:28<1:27:00, 17.12s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  31%|███       | 134/438 [40:28<1:27:00, 17.17s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  31%|███       | 134/438 [40:46<1:27:00, 17.17s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  31%|███       | 135/438 [40:46<1:27:07, 17.25s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  31%|███       | 135/438 [41:03<1:27:07, 17.25s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  31%|███       | 136/438 [41:03<1:26:29, 17.18s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  31%|███       | 136/438 [41:23<1:26:29, 17.18s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  31%|███▏      | 137/438 [41:23<1:30:03, 17.95s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  31%|███▏      | 137/438 [41:40<1:30:03, 17.95s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 138/438 [41:40<1:28:59, 17.80s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 138/438 [41:57<1:28:59, 17.80s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 139/438 [41:57<1:27:51, 17.63s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 139/438 [42:15<1:27:51, 17.63s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 140/438 [42:15<1:26:56, 17.51s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 140/438 [42:32<1:26:56, 17.51s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 141/438 [42:32<1:26:50, 17.54s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 141/438 [42:50<1:26:50, 17.54s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 142/438 [42:50<1:26:25, 17.52s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  32%|███▏      | 142/438 [43:07<1:26:25, 17.52s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 143/438 [43:07<1:26:01, 17.50s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 143/438 [43:24<1:26:01, 17.50s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 144/438 [43:24<1:25:39, 17.48s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 144/438 [43:42<1:25:39, 17.48s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 145/438 [43:42<1:25:20, 17.48s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 145/438 [43:59<1:25:20, 17.48s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 146/438 [43:59<1:25:03, 17.48s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  33%|███▎      | 146/438 [44:17<1:25:03, 17.48s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  34%|███▎      | 147/438 [44:17<1:24:38, 17.45s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  34%|███▎      | 147/438 [44:34<1:24:38, 17.45s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 148/438 [44:34<1:24:20, 17.45s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 148/438 [44:52<1:24:20, 17.45s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 149/438 [44:52<1:24:01, 17.44s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 149/438 [45:09<1:24:01, 17.44s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 150/438 [45:09<1:24:00, 17.50s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 150/438 [45:27<1:24:00, 17.50s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 151/438 [45:27<1:23:33, 17.47s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  34%|███▍      | 151/438 [45:44<1:23:33, 17.47s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  35%|███▍      | 152/438 [45:44<1:23:16, 17.47s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  35%|███▍      | 152/438 [46:02<1:23:16, 17.47s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  35%|███▍      | 153/438 [46:02<1:23:02, 17.48s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  35%|███▍      | 153/438 [46:19<1:23:02, 17.48s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  35%|███▌      | 154/438 [46:19<1:22:50, 17.50s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  35%|███▌      | 154/438 [46:37<1:22:50, 17.50s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:  35%|███▌      | 155/438 [46:37<1:22:30, 17.49s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:  35%|███▌      | 155/438 [46:55<1:22:30, 17.49s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  36%|███▌      | 156/438 [46:55<1:22:51, 17.63s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  36%|███▌      | 156/438 [47:12<1:22:51, 17.63s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  36%|███▌      | 157/438 [47:12<1:21:26, 17.39s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  36%|███▌      | 157/438 [47:28<1:21:26, 17.39s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  36%|███▌      | 158/438 [47:28<1:20:14, 17.20s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  36%|███▌      | 158/438 [47:46<1:20:14, 17.20s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  36%|███▋      | 159/438 [47:46<1:20:16, 17.26s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  36%|███▋      | 159/438 [48:02<1:20:16, 17.26s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 160/438 [48:02<1:19:09, 17.08s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 160/438 [48:19<1:19:09, 17.08s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 161/438 [48:19<1:18:00, 16.90s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 161/438 [48:35<1:18:00, 16.90s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 162/438 [48:35<1:17:16, 16.80s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 162/438 [48:52<1:17:16, 16.80s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 163/438 [48:52<1:16:45, 16.75s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 163/438 [49:09<1:16:45, 16.75s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 164/438 [49:09<1:16:09, 16.68s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  37%|███▋      | 164/438 [49:25<1:16:09, 16.68s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 165/438 [49:25<1:15:54, 16.68s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 165/438 [49:42<1:15:54, 16.68s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 166/438 [49:42<1:15:39, 16.69s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 166/438 [49:59<1:15:39, 16.69s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 167/438 [49:59<1:15:21, 16.68s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 167/438 [50:15<1:15:21, 16.68s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 168/438 [50:15<1:14:56, 16.65s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  38%|███▊      | 168/438 [50:32<1:14:56, 16.65s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 2:  39%|███▊      | 169/438 [50:32<1:14:40, 16.66s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 2:  39%|███▊      | 169/438 [50:49<1:14:40, 16.66s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 170/438 [50:49<1:15:05, 16.81s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 170/438 [51:06<1:15:05, 16.81s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 171/438 [51:06<1:14:38, 16.77s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 171/438 [51:22<1:14:38, 16.77s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 172/438 [51:22<1:14:06, 16.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 172/438 [51:39<1:14:06, 16.72s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 173/438 [51:39<1:13:35, 16.66s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  39%|███▉      | 173/438 [51:56<1:13:35, 16.66s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  40%|███▉      | 174/438 [51:56<1:13:42, 16.75s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  40%|███▉      | 174/438 [52:13<1:13:42, 16.75s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  40%|███▉      | 175/438 [52:13<1:13:30, 16.77s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  40%|███▉      | 175/438 [52:31<1:13:30, 16.77s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  40%|████      | 176/438 [52:31<1:14:56, 17.16s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  40%|████      | 176/438 [52:48<1:14:56, 17.16s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  40%|████      | 177/438 [52:48<1:14:20, 17.09s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  40%|████      | 177/438 [53:04<1:14:20, 17.09s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  41%|████      | 178/438 [53:04<1:13:36, 16.99s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  41%|████      | 178/438 [53:21<1:13:36, 16.99s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  41%|████      | 179/438 [53:21<1:12:47, 16.86s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  41%|████      | 179/438 [53:37<1:12:47, 16.86s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  41%|████      | 180/438 [53:37<1:12:04, 16.76s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  41%|████      | 180/438 [53:54<1:12:04, 16.76s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  41%|████▏     | 181/438 [53:54<1:11:29, 16.69s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  41%|████▏     | 181/438 [54:11<1:11:29, 16.69s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 182/438 [54:11<1:11:09, 16.68s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 182/438 [54:27<1:11:09, 16.68s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 183/438 [54:27<1:10:42, 16.64s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 183/438 [54:44<1:10:42, 16.64s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 184/438 [54:44<1:10:21, 16.62s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 184/438 [55:00<1:10:21, 16.62s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 185/438 [55:00<1:10:04, 16.62s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 185/438 [55:17<1:10:04, 16.62s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 186/438 [55:17<1:09:42, 16.60s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  42%|████▏     | 186/438 [55:33<1:09:42, 16.60s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 187/438 [55:33<1:09:25, 16.60s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 187/438 [55:50<1:09:25, 16.60s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 188/438 [55:50<1:09:05, 16.58s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 188/438 [56:07<1:09:05, 16.58s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 189/438 [56:07<1:08:42, 16.55s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 189/438 [56:23<1:08:42, 16.55s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 190/438 [56:23<1:08:24, 16.55s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  43%|████▎     | 190/438 [56:40<1:08:24, 16.55s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  44%|████▎     | 191/438 [56:40<1:08:12, 16.57s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  44%|████▎     | 191/438 [56:56<1:08:12, 16.57s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  44%|████▍     | 192/438 [56:56<1:07:57, 16.58s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  44%|████▍     | 192/438 [57:13<1:07:57, 16.58s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  44%|████▍     | 193/438 [57:13<1:07:40, 16.57s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  44%|████▍     | 193/438 [57:30<1:07:40, 16.57s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  44%|████▍     | 194/438 [57:30<1:07:33, 16.61s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  44%|████▍     | 194/438 [57:46<1:07:33, 16.61s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  45%|████▍     | 195/438 [57:46<1:07:14, 16.60s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  45%|████▍     | 195/438 [58:03<1:07:14, 16.60s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  45%|████▍     | 196/438 [58:03<1:07:07, 16.64s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  45%|████▍     | 196/438 [58:19<1:07:07, 16.64s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  45%|████▍     | 197/438 [58:19<1:06:47, 16.63s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  45%|████▍     | 197/438 [58:36<1:06:47, 16.63s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  45%|████▌     | 198/438 [58:36<1:06:27, 16.61s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  45%|████▌     | 198/438 [58:53<1:06:27, 16.61s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  45%|████▌     | 199/438 [58:53<1:06:15, 16.63s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  45%|████▌     | 199/438 [59:09<1:06:15, 16.63s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  46%|████▌     | 200/438 [59:09<1:06:04, 16.66s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  46%|████▌     | 200/438 [59:26<1:06:04, 16.66s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  46%|████▌     | 201/438 [59:26<1:05:48, 16.66s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  46%|████▌     | 201/438 [59:43<1:05:48, 16.66s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  46%|████▌     | 202/438 [59:43<1:05:26, 16.64s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  46%|████▌     | 202/438 [59:59<1:05:26, 16.64s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  46%|████▋     | 203/438 [59:59<1:05:12, 16.65s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  46%|████▋     | 203/438 [1:00:16<1:05:12, 16.65s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 204/438 [1:00:16<1:04:55, 16.65s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 204/438 [1:00:33<1:04:55, 16.65s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 205/438 [1:00:33<1:04:42, 16.66s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 205/438 [1:00:49<1:04:42, 16.66s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 206/438 [1:00:49<1:04:28, 16.68s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 206/438 [1:01:06<1:04:28, 16.68s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 207/438 [1:01:06<1:04:15, 16.69s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 207/438 [1:01:23<1:04:15, 16.69s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 208/438 [1:01:23<1:03:59, 16.69s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  47%|████▋     | 208/438 [1:01:39<1:03:59, 16.69s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 209/438 [1:01:39<1:03:35, 16.66s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 209/438 [1:01:56<1:03:35, 16.66s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 210/438 [1:01:56<1:03:16, 16.65s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 210/438 [1:02:13<1:03:16, 16.65s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 211/438 [1:02:13<1:03:01, 16.66s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 211/438 [1:02:29<1:03:01, 16.66s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 212/438 [1:02:29<1:02:34, 16.61s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  48%|████▊     | 212/438 [1:02:46<1:02:34, 16.61s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  49%|████▊     | 213/438 [1:02:46<1:02:15, 16.60s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  49%|████▊     | 213/438 [1:03:02<1:02:15, 16.60s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  49%|████▉     | 214/438 [1:03:02<1:01:49, 16.56s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  49%|████▉     | 214/438 [1:03:19<1:01:49, 16.56s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  49%|████▉     | 215/438 [1:03:19<1:01:39, 16.59s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  49%|████▉     | 215/438 [1:03:35<1:01:39, 16.59s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  49%|████▉     | 216/438 [1:03:35<1:01:16, 16.56s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  49%|████▉     | 216/438 [1:03:52<1:01:16, 16.56s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  50%|████▉     | 217/438 [1:03:52<1:00:59, 16.56s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  50%|████▉     | 217/438 [1:04:09<1:00:59, 16.56s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 2:  50%|████▉     | 218/438 [1:04:09<1:00:44, 16.57s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 2:  50%|████▉     | 218/438 [1:04:25<1:00:44, 16.57s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  50%|█████     | 219/438 [1:04:25<1:00:29, 16.58s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  50%|█████     | 219/438 [1:04:42<1:00:29, 16.58s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  50%|█████     | 220/438 [1:04:42<1:00:27, 16.64s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  50%|█████     | 220/438 [1:04:59<1:00:27, 16.64s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  50%|█████     | 221/438 [1:04:59<1:00:10, 16.64s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  50%|█████     | 221/438 [1:05:15<1:00:10, 16.64s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  51%|█████     | 222/438 [1:05:15<59:49, 16.62s/it, training_loss=0.132]  \u001B[A\n",
      "Epoch 2:  51%|█████     | 222/438 [1:05:32<59:49, 16.62s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 2:  51%|█████     | 223/438 [1:05:32<59:28, 16.60s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 2:  51%|█████     | 223/438 [1:05:48<59:28, 16.60s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  51%|█████     | 224/438 [1:05:48<59:11, 16.59s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  51%|█████     | 224/438 [1:06:05<59:11, 16.59s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  51%|█████▏    | 225/438 [1:06:05<58:55, 16.60s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  51%|█████▏    | 225/438 [1:06:22<58:55, 16.60s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 226/438 [1:06:22<58:42, 16.61s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 226/438 [1:06:38<58:42, 16.61s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 227/438 [1:06:38<58:23, 16.61s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 227/438 [1:06:55<58:23, 16.61s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 228/438 [1:06:55<58:16, 16.65s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 228/438 [1:07:12<58:16, 16.65s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 229/438 [1:07:12<58:00, 16.65s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  52%|█████▏    | 229/438 [1:07:29<58:00, 16.65s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 230/438 [1:07:29<58:49, 16.97s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 230/438 [1:07:46<58:49, 16.97s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 231/438 [1:07:46<58:13, 16.88s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 231/438 [1:08:03<58:13, 16.88s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 232/438 [1:08:03<57:42, 16.81s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 232/438 [1:08:19<57:42, 16.81s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 233/438 [1:08:19<57:12, 16.74s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 233/438 [1:08:36<57:12, 16.74s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 234/438 [1:08:36<56:48, 16.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  53%|█████▎    | 234/438 [1:08:52<56:48, 16.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  54%|█████▎    | 235/438 [1:08:52<56:29, 16.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  54%|█████▎    | 235/438 [1:09:09<56:29, 16.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  54%|█████▍    | 236/438 [1:09:09<56:05, 16.66s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  54%|█████▍    | 236/438 [1:09:26<56:05, 16.66s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  54%|█████▍    | 237/438 [1:09:26<55:49, 16.67s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  54%|█████▍    | 237/438 [1:09:42<55:49, 16.67s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  54%|█████▍    | 238/438 [1:09:42<55:29, 16.65s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  54%|█████▍    | 238/438 [1:09:59<55:29, 16.65s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  55%|█████▍    | 239/438 [1:09:59<55:11, 16.64s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  55%|█████▍    | 239/438 [1:10:16<55:11, 16.64s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  55%|█████▍    | 240/438 [1:10:16<54:52, 16.63s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  55%|█████▍    | 240/438 [1:10:32<54:52, 16.63s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  55%|█████▌    | 241/438 [1:10:32<54:35, 16.63s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  55%|█████▌    | 241/438 [1:10:49<54:35, 16.63s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  55%|█████▌    | 242/438 [1:10:49<54:11, 16.59s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  55%|█████▌    | 242/438 [1:11:05<54:11, 16.59s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  55%|█████▌    | 243/438 [1:11:05<54:02, 16.63s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  55%|█████▌    | 243/438 [1:11:22<54:02, 16.63s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  56%|█████▌    | 244/438 [1:11:22<53:42, 16.61s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  56%|█████▌    | 244/438 [1:11:39<53:42, 16.61s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  56%|█████▌    | 245/438 [1:11:39<53:24, 16.61s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  56%|█████▌    | 245/438 [1:11:55<53:24, 16.61s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 2:  56%|█████▌    | 246/438 [1:11:55<53:14, 16.64s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 2:  56%|█████▌    | 246/438 [1:12:12<53:14, 16.64s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:  56%|█████▋    | 247/438 [1:12:12<52:56, 16.63s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:  56%|█████▋    | 247/438 [1:12:28<52:56, 16.63s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 248/438 [1:12:28<52:40, 16.64s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 248/438 [1:12:45<52:40, 16.64s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 249/438 [1:12:45<52:22, 16.63s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 249/438 [1:13:02<52:22, 16.63s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 250/438 [1:13:02<52:12, 16.66s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 250/438 [1:13:18<52:12, 16.66s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 251/438 [1:13:18<51:45, 16.61s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  57%|█████▋    | 251/438 [1:13:35<51:45, 16.61s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 252/438 [1:13:35<51:30, 16.61s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 252/438 [1:13:52<51:30, 16.61s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 253/438 [1:13:52<51:15, 16.62s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 253/438 [1:14:08<51:15, 16.62s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 254/438 [1:14:08<50:58, 16.62s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 254/438 [1:14:25<50:58, 16.62s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 255/438 [1:14:25<50:39, 16.61s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 255/438 [1:14:41<50:39, 16.61s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 256/438 [1:14:41<50:26, 16.63s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  58%|█████▊    | 256/438 [1:14:58<50:26, 16.63s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  59%|█████▊    | 257/438 [1:14:58<50:10, 16.63s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  59%|█████▊    | 257/438 [1:15:15<50:10, 16.63s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  59%|█████▉    | 258/438 [1:15:15<49:56, 16.65s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  59%|█████▉    | 258/438 [1:15:31<49:56, 16.65s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  59%|█████▉    | 259/438 [1:15:31<49:39, 16.65s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  59%|█████▉    | 259/438 [1:15:48<49:39, 16.65s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  59%|█████▉    | 260/438 [1:15:48<49:28, 16.68s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  59%|█████▉    | 260/438 [1:16:05<49:28, 16.68s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  60%|█████▉    | 261/438 [1:16:05<49:07, 16.65s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  60%|█████▉    | 261/438 [1:16:21<49:07, 16.65s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  60%|█████▉    | 262/438 [1:16:21<48:45, 16.62s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  60%|█████▉    | 262/438 [1:16:38<48:45, 16.62s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  60%|██████    | 263/438 [1:16:38<48:32, 16.64s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  60%|██████    | 263/438 [1:16:55<48:32, 16.64s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  60%|██████    | 264/438 [1:16:55<48:10, 16.61s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  60%|██████    | 264/438 [1:17:11<48:10, 16.61s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  61%|██████    | 265/438 [1:17:11<47:56, 16.63s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  61%|██████    | 265/438 [1:17:28<47:56, 16.63s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  61%|██████    | 266/438 [1:17:28<47:41, 16.64s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  61%|██████    | 266/438 [1:17:44<47:41, 16.64s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  61%|██████    | 267/438 [1:17:44<47:22, 16.62s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  61%|██████    | 267/438 [1:18:01<47:22, 16.62s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  61%|██████    | 268/438 [1:18:01<47:04, 16.62s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  61%|██████    | 268/438 [1:18:18<47:04, 16.62s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  61%|██████▏   | 269/438 [1:18:18<46:48, 16.62s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  61%|██████▏   | 269/438 [1:18:34<46:48, 16.62s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 270/438 [1:18:34<46:25, 16.58s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 270/438 [1:18:51<46:25, 16.58s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 271/438 [1:18:51<46:07, 16.57s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 271/438 [1:19:07<46:07, 16.57s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 272/438 [1:19:07<45:57, 16.61s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 272/438 [1:19:24<45:57, 16.61s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 273/438 [1:19:24<45:43, 16.63s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  62%|██████▏   | 273/438 [1:19:41<45:43, 16.63s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 274/438 [1:19:41<45:24, 16.61s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 274/438 [1:19:57<45:24, 16.61s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 275/438 [1:19:57<45:09, 16.62s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 275/438 [1:20:14<45:09, 16.62s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 276/438 [1:20:14<44:57, 16.65s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 276/438 [1:20:31<44:57, 16.65s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 277/438 [1:20:31<44:39, 16.64s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 277/438 [1:20:47<44:39, 16.64s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 278/438 [1:20:47<44:23, 16.65s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  63%|██████▎   | 278/438 [1:21:04<44:23, 16.65s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  64%|██████▎   | 279/438 [1:21:04<44:11, 16.68s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  64%|██████▎   | 279/438 [1:21:22<44:11, 16.68s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  64%|██████▍   | 280/438 [1:21:22<44:50, 17.03s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  64%|██████▍   | 280/438 [1:21:39<44:50, 17.03s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  64%|██████▍   | 281/438 [1:21:39<44:29, 17.00s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  64%|██████▍   | 281/438 [1:21:56<44:29, 17.00s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  64%|██████▍   | 282/438 [1:21:56<44:17, 17.03s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  64%|██████▍   | 282/438 [1:22:13<44:17, 17.03s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  65%|██████▍   | 283/438 [1:22:13<43:45, 16.94s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  65%|██████▍   | 283/438 [1:22:30<43:45, 16.94s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  65%|██████▍   | 284/438 [1:22:30<43:58, 17.13s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  65%|██████▍   | 284/438 [1:22:47<43:58, 17.13s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  65%|██████▌   | 285/438 [1:22:47<43:28, 17.05s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  65%|██████▌   | 285/438 [1:23:04<43:28, 17.05s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 2:  65%|██████▌   | 286/438 [1:23:04<42:52, 16.93s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 2:  65%|██████▌   | 286/438 [1:23:21<42:52, 16.93s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 287/438 [1:23:21<42:30, 16.89s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 287/438 [1:23:37<42:30, 16.89s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 288/438 [1:23:37<42:09, 16.86s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 288/438 [1:23:54<42:09, 16.86s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 289/438 [1:23:54<41:44, 16.81s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 289/438 [1:24:11<41:44, 16.81s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 290/438 [1:24:11<41:17, 16.74s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  66%|██████▌   | 290/438 [1:24:27<41:17, 16.74s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  66%|██████▋   | 291/438 [1:24:27<40:55, 16.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  66%|██████▋   | 291/438 [1:24:44<40:55, 16.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 292/438 [1:24:44<40:39, 16.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 292/438 [1:25:01<40:39, 16.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 293/438 [1:25:01<40:19, 16.69s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 293/438 [1:25:17<40:19, 16.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 294/438 [1:25:17<39:58, 16.66s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 294/438 [1:25:34<39:58, 16.66s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 295/438 [1:25:34<39:42, 16.66s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  67%|██████▋   | 295/438 [1:25:51<39:42, 16.66s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 296/438 [1:25:51<39:28, 16.68s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 296/438 [1:26:09<39:28, 16.68s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 297/438 [1:26:09<40:05, 17.06s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 297/438 [1:26:26<40:05, 17.06s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 298/438 [1:26:26<39:59, 17.14s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 298/438 [1:26:43<39:59, 17.14s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 299/438 [1:26:43<39:53, 17.22s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 299/438 [1:27:00<39:53, 17.22s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 300/438 [1:27:00<39:36, 17.22s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  68%|██████▊   | 300/438 [1:27:18<39:36, 17.22s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  69%|██████▊   | 301/438 [1:27:18<39:20, 17.23s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  69%|██████▊   | 301/438 [1:27:34<39:20, 17.23s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  69%|██████▉   | 302/438 [1:27:34<38:36, 17.03s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  69%|██████▉   | 302/438 [1:27:51<38:36, 17.03s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  69%|██████▉   | 303/438 [1:27:51<37:59, 16.89s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  69%|██████▉   | 303/438 [1:28:07<37:59, 16.89s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  69%|██████▉   | 304/438 [1:28:07<37:25, 16.76s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  69%|██████▉   | 304/438 [1:28:24<37:25, 16.76s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  70%|██████▉   | 305/438 [1:28:24<37:01, 16.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  70%|██████▉   | 305/438 [1:28:41<37:01, 16.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  70%|██████▉   | 306/438 [1:28:41<36:43, 16.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  70%|██████▉   | 306/438 [1:28:57<36:43, 16.69s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 2:  70%|███████   | 307/438 [1:28:57<36:20, 16.64s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 2:  70%|███████   | 307/438 [1:29:14<36:20, 16.64s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  70%|███████   | 308/438 [1:29:14<35:58, 16.61s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  70%|███████   | 308/438 [1:29:30<35:58, 16.61s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  71%|███████   | 309/438 [1:29:30<35:39, 16.58s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  71%|███████   | 309/438 [1:29:47<35:39, 16.58s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  71%|███████   | 310/438 [1:29:47<35:16, 16.54s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 2:  71%|███████   | 310/438 [1:30:03<35:16, 16.54s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  71%|███████   | 311/438 [1:30:03<35:00, 16.54s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  71%|███████   | 311/438 [1:30:20<35:00, 16.54s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  71%|███████   | 312/438 [1:30:20<34:55, 16.63s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  71%|███████   | 312/438 [1:30:37<34:55, 16.63s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  71%|███████▏  | 313/438 [1:30:37<34:37, 16.62s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  71%|███████▏  | 313/438 [1:30:53<34:37, 16.62s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 314/438 [1:30:53<34:18, 16.60s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 314/438 [1:31:10<34:18, 16.60s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 315/438 [1:31:10<34:14, 16.70s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 315/438 [1:31:27<34:14, 16.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 316/438 [1:31:27<33:49, 16.63s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 316/438 [1:31:43<33:49, 16.63s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 317/438 [1:31:43<33:31, 16.62s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  72%|███████▏  | 317/438 [1:32:00<33:31, 16.62s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 318/438 [1:32:00<33:15, 16.63s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 318/438 [1:32:16<33:15, 16.63s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 319/438 [1:32:16<33:00, 16.64s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 319/438 [1:32:33<33:00, 16.64s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 320/438 [1:32:33<32:39, 16.61s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 320/438 [1:32:50<32:39, 16.61s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 321/438 [1:32:50<32:24, 16.62s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  73%|███████▎  | 321/438 [1:33:06<32:24, 16.62s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  74%|███████▎  | 322/438 [1:33:06<32:11, 16.66s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  74%|███████▎  | 322/438 [1:33:23<32:11, 16.66s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  74%|███████▎  | 323/438 [1:33:23<31:51, 16.62s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  74%|███████▎  | 323/438 [1:33:39<31:51, 16.62s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  74%|███████▍  | 324/438 [1:33:39<31:29, 16.58s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  74%|███████▍  | 324/438 [1:33:56<31:29, 16.58s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  74%|███████▍  | 325/438 [1:33:56<31:13, 16.58s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  74%|███████▍  | 325/438 [1:34:13<31:13, 16.58s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 2:  74%|███████▍  | 326/438 [1:34:13<30:59, 16.61s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 2:  74%|███████▍  | 326/438 [1:34:29<30:59, 16.61s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  75%|███████▍  | 327/438 [1:34:29<30:43, 16.61s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  75%|███████▍  | 327/438 [1:34:46<30:43, 16.61s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  75%|███████▍  | 328/438 [1:34:46<30:27, 16.62s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  75%|███████▍  | 328/438 [1:35:02<30:27, 16.62s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  75%|███████▌  | 329/438 [1:35:03<30:11, 16.62s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  75%|███████▌  | 329/438 [1:35:19<30:11, 16.62s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  75%|███████▌  | 330/438 [1:35:19<29:48, 16.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  75%|███████▌  | 330/438 [1:35:36<29:48, 16.56s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  76%|███████▌  | 331/438 [1:35:36<29:35, 16.59s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  76%|███████▌  | 331/438 [1:35:52<29:35, 16.59s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  76%|███████▌  | 332/438 [1:35:52<29:21, 16.62s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  76%|███████▌  | 332/438 [1:36:09<29:21, 16.62s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  76%|███████▌  | 333/438 [1:36:09<29:06, 16.64s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  76%|███████▌  | 333/438 [1:36:25<29:06, 16.64s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  76%|███████▋  | 334/438 [1:36:25<28:47, 16.61s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  76%|███████▋  | 334/438 [1:36:42<28:47, 16.61s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  76%|███████▋  | 335/438 [1:36:42<28:30, 16.60s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  76%|███████▋  | 335/438 [1:36:59<28:30, 16.60s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 336/438 [1:36:59<28:23, 16.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 336/438 [1:37:16<28:23, 16.70s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 337/438 [1:37:16<28:03, 16.66s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 337/438 [1:37:32<28:03, 16.66s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 338/438 [1:37:32<27:43, 16.63s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 338/438 [1:37:50<27:43, 16.63s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 339/438 [1:37:50<27:56, 16.93s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  77%|███████▋  | 339/438 [1:38:06<27:56, 16.93s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 340/438 [1:38:06<27:30, 16.84s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 340/438 [1:38:23<27:30, 16.84s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 341/438 [1:38:23<27:01, 16.72s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 341/438 [1:38:39<27:01, 16.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 342/438 [1:38:39<26:39, 16.67s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 342/438 [1:38:56<26:39, 16.67s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 343/438 [1:38:56<26:20, 16.63s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  78%|███████▊  | 343/438 [1:39:13<26:20, 16.63s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  79%|███████▊  | 344/438 [1:39:13<26:03, 16.63s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  79%|███████▊  | 344/438 [1:39:29<26:03, 16.63s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 345/438 [1:39:29<25:48, 16.65s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 345/438 [1:39:46<25:48, 16.65s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 346/438 [1:39:46<25:28, 16.61s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 346/438 [1:40:02<25:28, 16.61s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 347/438 [1:40:02<25:06, 16.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 347/438 [1:40:19<25:06, 16.56s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 348/438 [1:40:19<24:53, 16.60s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  79%|███████▉  | 348/438 [1:40:35<24:53, 16.60s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  80%|███████▉  | 349/438 [1:40:35<24:35, 16.58s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  80%|███████▉  | 349/438 [1:40:52<24:35, 16.58s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  80%|███████▉  | 350/438 [1:40:52<24:17, 16.56s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  80%|███████▉  | 350/438 [1:41:09<24:17, 16.56s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  80%|████████  | 351/438 [1:41:09<24:05, 16.62s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  80%|████████  | 351/438 [1:41:26<24:05, 16.62s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  80%|████████  | 352/438 [1:41:26<24:19, 16.97s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  80%|████████  | 352/438 [1:41:43<24:19, 16.97s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  81%|████████  | 353/438 [1:41:43<23:51, 16.85s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  81%|████████  | 353/438 [1:42:00<23:51, 16.85s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  81%|████████  | 354/438 [1:42:00<23:28, 16.77s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  81%|████████  | 354/438 [1:42:16<23:28, 16.77s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  81%|████████  | 355/438 [1:42:16<23:07, 16.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  81%|████████  | 355/438 [1:42:33<23:07, 16.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  81%|████████▏ | 356/438 [1:42:33<22:48, 16.69s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  81%|████████▏ | 356/438 [1:42:50<22:48, 16.69s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 357/438 [1:42:50<22:31, 16.69s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 357/438 [1:43:06<22:31, 16.69s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 358/438 [1:43:06<22:12, 16.66s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 358/438 [1:43:23<22:12, 16.66s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 359/438 [1:43:23<21:56, 16.66s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 359/438 [1:43:39<21:56, 16.66s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 360/438 [1:43:39<21:39, 16.66s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 360/438 [1:43:56<21:39, 16.66s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 361/438 [1:43:56<21:20, 16.62s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  82%|████████▏ | 361/438 [1:44:13<21:20, 16.62s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 362/438 [1:44:13<21:03, 16.63s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 362/438 [1:44:29<21:03, 16.63s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 363/438 [1:44:29<20:43, 16.58s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 363/438 [1:44:46<20:43, 16.58s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 364/438 [1:44:46<20:25, 16.56s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 364/438 [1:45:02<20:25, 16.56s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 365/438 [1:45:02<20:09, 16.57s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  83%|████████▎ | 365/438 [1:45:19<20:09, 16.57s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  84%|████████▎ | 366/438 [1:45:19<19:52, 16.57s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  84%|████████▎ | 366/438 [1:45:35<19:52, 16.57s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 367/438 [1:45:35<19:34, 16.55s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 367/438 [1:45:52<19:34, 16.55s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 368/438 [1:45:52<19:22, 16.60s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 368/438 [1:46:08<19:22, 16.60s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 369/438 [1:46:08<19:02, 16.56s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 369/438 [1:46:25<19:02, 16.56s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 370/438 [1:46:25<18:46, 16.56s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:  84%|████████▍ | 370/438 [1:46:42<18:46, 16.56s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  85%|████████▍ | 371/438 [1:46:42<18:28, 16.55s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 2:  85%|████████▍ | 371/438 [1:46:58<18:28, 16.55s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  85%|████████▍ | 372/438 [1:46:58<18:14, 16.58s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  85%|████████▍ | 372/438 [1:47:15<18:14, 16.58s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  85%|████████▌ | 373/438 [1:47:15<17:57, 16.58s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 2:  85%|████████▌ | 373/438 [1:47:31<17:57, 16.58s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  85%|████████▌ | 374/438 [1:47:31<17:41, 16.58s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  85%|████████▌ | 374/438 [1:47:48<17:41, 16.58s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  86%|████████▌ | 375/438 [1:47:48<17:26, 16.60s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  86%|████████▌ | 375/438 [1:48:05<17:26, 16.60s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  86%|████████▌ | 376/438 [1:48:05<17:08, 16.59s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  86%|████████▌ | 376/438 [1:48:21<17:08, 16.59s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  86%|████████▌ | 377/438 [1:48:21<16:52, 16.60s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  86%|████████▌ | 377/438 [1:48:38<16:52, 16.60s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  86%|████████▋ | 378/438 [1:48:38<16:34, 16.58s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  86%|████████▋ | 378/438 [1:48:54<16:34, 16.58s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 379/438 [1:48:54<16:16, 16.56s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 379/438 [1:49:11<16:16, 16.56s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 380/438 [1:49:11<16:01, 16.57s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 380/438 [1:49:27<16:01, 16.57s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 381/438 [1:49:27<15:43, 16.56s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 381/438 [1:49:44<15:43, 16.56s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 382/438 [1:49:44<15:27, 16.56s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 382/438 [1:50:01<15:27, 16.56s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 383/438 [1:50:01<15:11, 16.57s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  87%|████████▋ | 383/438 [1:50:17<15:11, 16.57s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 384/438 [1:50:17<14:54, 16.56s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 384/438 [1:50:34<14:54, 16.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 385/438 [1:50:34<14:37, 16.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 385/438 [1:50:50<14:37, 16.56s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 386/438 [1:50:50<14:22, 16.59s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 386/438 [1:51:07<14:22, 16.59s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 387/438 [1:51:07<14:08, 16.63s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  88%|████████▊ | 387/438 [1:51:24<14:08, 16.63s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  89%|████████▊ | 388/438 [1:51:24<13:50, 16.62s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  89%|████████▊ | 388/438 [1:51:40<13:50, 16.62s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 389/438 [1:51:40<13:34, 16.62s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 389/438 [1:51:57<13:34, 16.62s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 390/438 [1:51:57<13:16, 16.58s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 390/438 [1:52:14<13:16, 16.58s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 391/438 [1:52:14<13:01, 16.64s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 391/438 [1:52:30<13:01, 16.64s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 392/438 [1:52:30<12:46, 16.67s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  89%|████████▉ | 392/438 [1:52:48<12:46, 16.67s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  90%|████████▉ | 393/438 [1:52:48<12:49, 17.09s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  90%|████████▉ | 393/438 [1:53:05<12:49, 17.09s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  90%|████████▉ | 394/438 [1:53:05<12:25, 16.94s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  90%|████████▉ | 394/438 [1:53:22<12:25, 16.94s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  90%|█████████ | 395/438 [1:53:22<12:04, 16.85s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  90%|█████████ | 395/438 [1:53:38<12:04, 16.85s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  90%|█████████ | 396/438 [1:53:38<11:43, 16.76s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  90%|█████████ | 396/438 [1:53:55<11:43, 16.76s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  91%|█████████ | 397/438 [1:53:55<11:26, 16.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  91%|█████████ | 397/438 [1:54:11<11:26, 16.74s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  91%|█████████ | 398/438 [1:54:11<11:07, 16.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  91%|█████████ | 398/438 [1:54:28<11:07, 16.70s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  91%|█████████ | 399/438 [1:54:28<10:49, 16.66s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  91%|█████████ | 399/438 [1:54:45<10:49, 16.66s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  91%|█████████▏| 400/438 [1:54:45<10:33, 16.68s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  91%|█████████▏| 400/438 [1:55:01<10:33, 16.68s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 401/438 [1:55:01<10:15, 16.63s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 401/438 [1:55:18<10:15, 16.63s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 402/438 [1:55:18<09:57, 16.60s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 402/438 [1:55:34<09:57, 16.60s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 403/438 [1:55:34<09:41, 16.61s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 403/438 [1:55:51<09:41, 16.61s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 404/438 [1:55:51<09:23, 16.58s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 404/438 [1:56:07<09:23, 16.58s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 405/438 [1:56:07<09:06, 16.56s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 2:  92%|█████████▏| 405/438 [1:56:24<09:06, 16.56s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 406/438 [1:56:24<08:49, 16.55s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 406/438 [1:56:41<08:49, 16.55s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 407/438 [1:56:41<08:34, 16.59s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 407/438 [1:56:57<08:34, 16.59s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 408/438 [1:56:57<08:17, 16.59s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 408/438 [1:57:14<08:17, 16.59s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 409/438 [1:57:14<08:01, 16.59s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  93%|█████████▎| 409/438 [1:57:30<08:01, 16.59s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  94%|█████████▎| 410/438 [1:57:30<07:44, 16.57s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  94%|█████████▎| 410/438 [1:57:47<07:44, 16.57s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  94%|█████████▍| 411/438 [1:57:47<07:27, 16.57s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  94%|█████████▍| 411/438 [1:58:03<07:27, 16.57s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  94%|█████████▍| 412/438 [1:58:03<07:10, 16.57s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 2:  94%|█████████▍| 412/438 [1:58:20<07:10, 16.57s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  94%|█████████▍| 413/438 [1:58:20<06:53, 16.56s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  94%|█████████▍| 413/438 [1:58:37<06:53, 16.56s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:  95%|█████████▍| 414/438 [1:58:37<06:37, 16.57s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 2:  95%|█████████▍| 414/438 [1:58:53<06:37, 16.57s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  95%|█████████▍| 415/438 [1:58:53<06:20, 16.53s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  95%|█████████▍| 415/438 [1:59:10<06:20, 16.53s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  95%|█████████▍| 416/438 [1:59:10<06:03, 16.53s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 2:  95%|█████████▍| 416/438 [1:59:26<06:03, 16.53s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  95%|█████████▌| 417/438 [1:59:26<05:47, 16.56s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  95%|█████████▌| 417/438 [1:59:43<05:47, 16.56s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  95%|█████████▌| 418/438 [1:59:43<05:31, 16.55s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  95%|█████████▌| 418/438 [1:59:59<05:31, 16.55s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  96%|█████████▌| 419/438 [1:59:59<05:14, 16.57s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 2:  96%|█████████▌| 419/438 [2:00:16<05:14, 16.57s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 2:  96%|█████████▌| 420/438 [2:00:16<04:57, 16.55s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 2:  96%|█████████▌| 420/438 [2:00:32<04:57, 16.55s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  96%|█████████▌| 421/438 [2:00:32<04:41, 16.55s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 2:  96%|█████████▌| 421/438 [2:00:49<04:41, 16.55s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  96%|█████████▋| 422/438 [2:00:49<04:25, 16.57s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 2:  96%|█████████▋| 422/438 [2:01:06<04:25, 16.57s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 423/438 [2:01:06<04:08, 16.59s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 423/438 [2:01:22<04:08, 16.59s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 424/438 [2:01:22<03:52, 16.63s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 424/438 [2:01:39<03:52, 16.63s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 425/438 [2:01:39<03:35, 16.61s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 425/438 [2:01:56<03:35, 16.61s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 426/438 [2:01:56<03:19, 16.63s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 426/438 [2:02:12<03:19, 16.63s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 427/438 [2:02:12<03:03, 16.66s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  97%|█████████▋| 427/438 [2:02:29<03:03, 16.66s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 428/438 [2:02:29<02:46, 16.63s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 428/438 [2:02:45<02:46, 16.63s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 429/438 [2:02:45<02:29, 16.60s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 429/438 [2:03:02<02:29, 16.60s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 430/438 [2:03:02<02:12, 16.57s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 430/438 [2:03:18<02:12, 16.57s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 431/438 [2:03:18<01:55, 16.57s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 2:  98%|█████████▊| 431/438 [2:03:35<01:55, 16.57s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  99%|█████████▊| 432/438 [2:03:35<01:39, 16.55s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 2:  99%|█████████▊| 432/438 [2:03:52<01:39, 16.55s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  99%|█████████▉| 433/438 [2:03:52<01:22, 16.57s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 2:  99%|█████████▉| 433/438 [2:04:08<01:22, 16.57s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  99%|█████████▉| 434/438 [2:04:08<01:06, 16.57s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 2:  99%|█████████▉| 434/438 [2:04:25<01:06, 16.57s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  99%|█████████▉| 435/438 [2:04:25<00:49, 16.56s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2:  99%|█████████▉| 435/438 [2:04:41<00:49, 16.56s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2: 100%|█████████▉| 436/438 [2:04:41<00:33, 16.56s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 2: 100%|█████████▉| 436/438 [2:04:58<00:33, 16.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2: 100%|█████████▉| 437/438 [2:04:58<00:16, 16.57s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 2: 100%|█████████▉| 437/438 [2:05:12<00:16, 16.57s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 2: 100%|██████████| 438/438 [2:05:12<00:00, 15.78s/it, training_loss=0.128]\u001B[A\n",
      " 20%|██        | 1/5 [4:29:06<9:35:38, 8634.53s/it]                              \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Trainin loss: 0.3938083946024446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [4:49:40<7:14:59, 8699.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.39148757448221777\n",
      "F1 Score (Weighted): 0.016516759404528725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3:   0%|          | 0/438 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 3:   0%|          | 0/438 [00:16<?, ?it/s, training_loss=0.126]\u001B[A\n",
      "Epoch 3:   0%|          | 1/438 [00:16<2:02:51, 16.87s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:   0%|          | 1/438 [00:33<2:02:51, 16.87s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:   0%|          | 2/438 [00:33<2:01:58, 16.79s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:   0%|          | 2/438 [00:50<2:01:58, 16.79s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:   1%|          | 3/438 [00:50<2:01:35, 16.77s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:   1%|          | 3/438 [01:06<2:01:35, 16.77s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:   1%|          | 4/438 [01:06<2:00:50, 16.71s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:   1%|          | 4/438 [01:23<2:00:50, 16.71s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:   1%|          | 5/438 [01:23<2:00:38, 16.72s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:   1%|          | 5/438 [01:41<2:00:38, 16.72s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:   1%|▏         | 6/438 [01:41<2:02:23, 17.00s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:   1%|▏         | 6/438 [01:57<2:02:23, 17.00s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:   2%|▏         | 7/438 [01:57<2:01:23, 16.90s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:   2%|▏         | 7/438 [02:14<2:01:23, 16.90s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:   2%|▏         | 8/438 [02:14<2:00:26, 16.81s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:   2%|▏         | 8/438 [02:31<2:00:26, 16.81s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:   2%|▏         | 9/438 [02:31<1:59:37, 16.73s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:   2%|▏         | 9/438 [02:47<1:59:37, 16.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:   2%|▏         | 10/438 [02:47<1:59:06, 16.70s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:   2%|▏         | 10/438 [03:04<1:59:06, 16.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:   3%|▎         | 11/438 [03:04<1:58:45, 16.69s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:   3%|▎         | 11/438 [03:21<1:58:45, 16.69s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:   3%|▎         | 12/438 [03:21<1:58:38, 16.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:   3%|▎         | 12/438 [03:37<1:58:38, 16.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:   3%|▎         | 13/438 [03:37<1:58:16, 16.70s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:   3%|▎         | 13/438 [03:54<1:58:16, 16.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:   3%|▎         | 14/438 [03:54<1:57:39, 16.65s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:   3%|▎         | 14/438 [04:11<1:57:39, 16.65s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:   3%|▎         | 15/438 [04:11<1:57:30, 16.67s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:   3%|▎         | 15/438 [04:27<1:57:30, 16.67s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:   4%|▎         | 16/438 [04:27<1:57:24, 16.69s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:   4%|▎         | 16/438 [04:44<1:57:24, 16.69s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:   4%|▍         | 17/438 [04:44<1:56:54, 16.66s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:   4%|▍         | 17/438 [05:00<1:56:54, 16.66s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 3:   4%|▍         | 18/438 [05:00<1:56:14, 16.61s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 3:   4%|▍         | 18/438 [05:17<1:56:14, 16.61s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:   4%|▍         | 19/438 [05:17<1:55:56, 16.60s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:   4%|▍         | 19/438 [05:34<1:55:56, 16.60s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   5%|▍         | 20/438 [05:34<1:55:40, 16.60s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   5%|▍         | 20/438 [05:50<1:55:40, 16.60s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:   5%|▍         | 21/438 [05:50<1:55:29, 16.62s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:   5%|▍         | 21/438 [06:07<1:55:29, 16.62s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:   5%|▌         | 22/438 [06:07<1:54:58, 16.58s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:   5%|▌         | 22/438 [06:24<1:54:58, 16.58s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 3:   5%|▌         | 23/438 [06:24<1:55:05, 16.64s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 3:   5%|▌         | 23/438 [06:40<1:55:05, 16.64s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:   5%|▌         | 24/438 [06:40<1:55:18, 16.71s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:   5%|▌         | 24/438 [06:57<1:55:18, 16.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:   6%|▌         | 25/438 [06:57<1:54:31, 16.64s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:   6%|▌         | 25/438 [07:13<1:54:31, 16.64s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:   6%|▌         | 26/438 [07:13<1:53:38, 16.55s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:   6%|▌         | 26/438 [07:30<1:53:38, 16.55s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:   6%|▌         | 27/438 [07:30<1:52:58, 16.49s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:   6%|▌         | 27/438 [07:46<1:52:58, 16.49s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:   6%|▋         | 28/438 [07:46<1:52:36, 16.48s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:   6%|▋         | 28/438 [08:03<1:52:36, 16.48s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:   7%|▋         | 29/438 [08:03<1:52:21, 16.48s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:   7%|▋         | 29/438 [08:19<1:52:21, 16.48s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:   7%|▋         | 30/438 [08:19<1:51:53, 16.45s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:   7%|▋         | 30/438 [08:35<1:51:53, 16.45s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:   7%|▋         | 31/438 [08:35<1:51:29, 16.44s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:   7%|▋         | 31/438 [08:52<1:51:29, 16.44s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:   7%|▋         | 32/438 [08:52<1:51:06, 16.42s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:   7%|▋         | 32/438 [09:08<1:51:06, 16.42s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   8%|▊         | 33/438 [09:08<1:50:42, 16.40s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:   8%|▊         | 33/438 [09:24<1:50:42, 16.40s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:   8%|▊         | 34/438 [09:24<1:50:20, 16.39s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:   8%|▊         | 34/438 [09:41<1:50:20, 16.39s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:   8%|▊         | 35/438 [09:41<1:50:11, 16.40s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:   8%|▊         | 35/438 [09:57<1:50:11, 16.40s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:   8%|▊         | 36/438 [09:57<1:50:09, 16.44s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:   8%|▊         | 36/438 [10:14<1:50:09, 16.44s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:   8%|▊         | 37/438 [10:14<1:49:59, 16.46s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:   8%|▊         | 37/438 [10:30<1:49:59, 16.46s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:   9%|▊         | 38/438 [10:30<1:49:49, 16.47s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:   9%|▊         | 38/438 [10:47<1:49:49, 16.47s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:   9%|▉         | 39/438 [10:47<1:49:26, 16.46s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:   9%|▉         | 39/438 [11:03<1:49:26, 16.46s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:   9%|▉         | 40/438 [11:03<1:48:49, 16.41s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:   9%|▉         | 40/438 [11:20<1:48:49, 16.41s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:   9%|▉         | 41/438 [11:20<1:48:41, 16.43s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:   9%|▉         | 41/438 [11:36<1:48:41, 16.43s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  10%|▉         | 42/438 [11:36<1:48:46, 16.48s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  10%|▉         | 42/438 [11:53<1:48:46, 16.48s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  10%|▉         | 43/438 [11:53<1:48:32, 16.49s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  10%|▉         | 43/438 [12:09<1:48:32, 16.49s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  10%|█         | 44/438 [12:09<1:48:03, 16.46s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  10%|█         | 44/438 [12:27<1:48:03, 16.46s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  10%|█         | 45/438 [12:27<1:49:56, 16.78s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  10%|█         | 45/438 [12:43<1:49:56, 16.78s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  11%|█         | 46/438 [12:43<1:48:51, 16.66s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  11%|█         | 46/438 [12:59<1:48:51, 16.66s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  11%|█         | 47/438 [12:59<1:48:03, 16.58s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  11%|█         | 47/438 [13:16<1:48:03, 16.58s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  11%|█         | 48/438 [13:16<1:47:32, 16.55s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  11%|█         | 48/438 [13:32<1:47:32, 16.55s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  11%|█         | 49/438 [13:32<1:47:06, 16.52s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  11%|█         | 49/438 [13:49<1:47:06, 16.52s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  11%|█▏        | 50/438 [13:49<1:46:53, 16.53s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  11%|█▏        | 50/438 [14:05<1:46:53, 16.53s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 51/438 [14:05<1:46:28, 16.51s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 51/438 [14:22<1:46:28, 16.51s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 52/438 [14:22<1:45:57, 16.47s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 52/438 [14:38<1:45:57, 16.47s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 53/438 [14:38<1:45:35, 16.46s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 53/438 [14:54<1:45:35, 16.46s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 54/438 [14:54<1:45:07, 16.43s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  12%|█▏        | 54/438 [15:11<1:45:07, 16.43s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 55/438 [15:11<1:45:01, 16.45s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 55/438 [15:28<1:45:01, 16.45s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 56/438 [15:28<1:45:59, 16.65s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 56/438 [15:45<1:45:59, 16.65s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 57/438 [15:45<1:45:26, 16.60s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 57/438 [16:01<1:45:26, 16.60s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 58/438 [16:01<1:44:56, 16.57s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 58/438 [16:17<1:44:56, 16.57s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 59/438 [16:17<1:44:18, 16.51s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  13%|█▎        | 59/438 [16:34<1:44:18, 16.51s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  14%|█▎        | 60/438 [16:34<1:44:03, 16.52s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  14%|█▎        | 60/438 [16:50<1:44:03, 16.52s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  14%|█▍        | 61/438 [16:50<1:43:33, 16.48s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  14%|█▍        | 61/438 [17:07<1:43:33, 16.48s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 3:  14%|█▍        | 62/438 [17:07<1:43:12, 16.47s/it, training_loss=0.106]\u001B[A\n",
      "Epoch 3:  14%|█▍        | 62/438 [17:23<1:43:12, 16.47s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  14%|█▍        | 63/438 [17:23<1:42:55, 16.47s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  14%|█▍        | 63/438 [17:40<1:42:55, 16.47s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  15%|█▍        | 64/438 [17:40<1:42:36, 16.46s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  15%|█▍        | 64/438 [17:56<1:42:36, 16.46s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  15%|█▍        | 65/438 [17:56<1:42:12, 16.44s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  15%|█▍        | 65/438 [18:13<1:42:12, 16.44s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  15%|█▌        | 66/438 [18:13<1:42:11, 16.48s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  15%|█▌        | 66/438 [18:29<1:42:11, 16.48s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  15%|█▌        | 67/438 [18:29<1:41:49, 16.47s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  15%|█▌        | 67/438 [18:46<1:41:49, 16.47s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 68/438 [18:46<1:41:42, 16.49s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 68/438 [19:02<1:41:42, 16.49s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 69/438 [19:02<1:41:17, 16.47s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 69/438 [19:19<1:41:17, 16.47s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 70/438 [19:19<1:41:18, 16.52s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 70/438 [19:35<1:41:18, 16.52s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 71/438 [19:35<1:40:55, 16.50s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  16%|█▌        | 71/438 [19:52<1:40:55, 16.50s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  16%|█▋        | 72/438 [19:52<1:40:40, 16.50s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  16%|█▋        | 72/438 [20:08<1:40:40, 16.50s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 73/438 [20:08<1:40:27, 16.51s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 73/438 [20:25<1:40:27, 16.51s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 74/438 [20:25<1:40:18, 16.54s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 74/438 [20:41<1:40:18, 16.54s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 75/438 [20:41<1:39:45, 16.49s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 75/438 [20:58<1:39:45, 16.49s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 76/438 [20:58<1:39:38, 16.51s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 3:  17%|█▋        | 76/438 [21:14<1:39:38, 16.51s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 77/438 [21:14<1:39:24, 16.52s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 77/438 [21:31<1:39:24, 16.52s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 78/438 [21:31<1:39:13, 16.54s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 78/438 [21:47<1:39:13, 16.54s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 79/438 [21:47<1:38:50, 16.52s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 79/438 [22:04<1:38:50, 16.52s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 80/438 [22:04<1:38:44, 16.55s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 80/438 [22:20<1:38:44, 16.55s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 81/438 [22:20<1:38:15, 16.52s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  18%|█▊        | 81/438 [22:37<1:38:15, 16.52s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  19%|█▊        | 82/438 [22:37<1:37:59, 16.52s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  19%|█▊        | 82/438 [22:53<1:37:59, 16.52s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  19%|█▉        | 83/438 [22:53<1:37:38, 16.50s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  19%|█▉        | 83/438 [23:10<1:37:38, 16.50s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  19%|█▉        | 84/438 [23:10<1:37:16, 16.49s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  19%|█▉        | 84/438 [23:26<1:37:16, 16.49s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  19%|█▉        | 85/438 [23:26<1:37:07, 16.51s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  19%|█▉        | 85/438 [23:43<1:37:07, 16.51s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  20%|█▉        | 86/438 [23:43<1:36:46, 16.50s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  20%|█▉        | 86/438 [23:59<1:36:46, 16.50s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  20%|█▉        | 87/438 [23:59<1:36:33, 16.51s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  20%|█▉        | 87/438 [24:16<1:36:33, 16.51s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 3:  20%|██        | 88/438 [24:16<1:36:08, 16.48s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 3:  20%|██        | 88/438 [24:32<1:36:08, 16.48s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  20%|██        | 89/438 [24:32<1:35:58, 16.50s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  20%|██        | 89/438 [24:49<1:35:58, 16.50s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  21%|██        | 90/438 [24:49<1:35:44, 16.51s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  21%|██        | 90/438 [25:05<1:35:44, 16.51s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  21%|██        | 91/438 [25:05<1:35:25, 16.50s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  21%|██        | 91/438 [25:22<1:35:25, 16.50s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  21%|██        | 92/438 [25:22<1:36:04, 16.66s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  21%|██        | 92/438 [25:39<1:36:04, 16.66s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  21%|██        | 93/438 [25:39<1:35:33, 16.62s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  21%|██        | 93/438 [25:56<1:35:33, 16.62s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  21%|██▏       | 94/438 [25:56<1:35:13, 16.61s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  21%|██▏       | 94/438 [26:12<1:35:13, 16.61s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 95/438 [26:12<1:34:39, 16.56s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 95/438 [26:29<1:34:39, 16.56s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 96/438 [26:29<1:35:06, 16.69s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 96/438 [26:45<1:35:06, 16.69s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 97/438 [26:45<1:34:29, 16.63s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 97/438 [27:02<1:34:29, 16.63s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 98/438 [27:02<1:34:02, 16.59s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  22%|██▏       | 98/438 [27:18<1:34:02, 16.59s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 99/438 [27:18<1:33:28, 16.54s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 99/438 [27:36<1:33:28, 16.54s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 100/438 [27:36<1:35:14, 16.91s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 100/438 [27:53<1:35:14, 16.91s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 101/438 [27:53<1:34:17, 16.79s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 101/438 [28:09<1:34:17, 16.79s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 102/438 [28:09<1:33:34, 16.71s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  23%|██▎       | 102/438 [28:26<1:33:34, 16.71s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  24%|██▎       | 103/438 [28:26<1:32:58, 16.65s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  24%|██▎       | 103/438 [28:42<1:32:58, 16.65s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  24%|██▎       | 104/438 [28:42<1:32:29, 16.62s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  24%|██▎       | 104/438 [28:59<1:32:29, 16.62s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  24%|██▍       | 105/438 [28:59<1:32:06, 16.60s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  24%|██▍       | 105/438 [29:15<1:32:06, 16.60s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  24%|██▍       | 106/438 [29:15<1:31:30, 16.54s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  24%|██▍       | 106/438 [29:32<1:31:30, 16.54s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  24%|██▍       | 107/438 [29:32<1:31:06, 16.52s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  24%|██▍       | 107/438 [29:48<1:31:06, 16.52s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  25%|██▍       | 108/438 [29:48<1:30:42, 16.49s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  25%|██▍       | 108/438 [30:05<1:30:42, 16.49s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  25%|██▍       | 109/438 [30:05<1:30:44, 16.55s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  25%|██▍       | 109/438 [30:21<1:30:44, 16.55s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  25%|██▌       | 110/438 [30:21<1:30:16, 16.51s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  25%|██▌       | 110/438 [30:38<1:30:16, 16.51s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  25%|██▌       | 111/438 [30:38<1:30:06, 16.53s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  25%|██▌       | 111/438 [30:54<1:30:06, 16.53s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  26%|██▌       | 112/438 [30:54<1:29:55, 16.55s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  26%|██▌       | 112/438 [31:11<1:29:55, 16.55s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  26%|██▌       | 113/438 [31:11<1:29:42, 16.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  26%|██▌       | 113/438 [31:28<1:29:42, 16.56s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  26%|██▌       | 114/438 [31:28<1:29:28, 16.57s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  26%|██▌       | 114/438 [31:44<1:29:28, 16.57s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  26%|██▋       | 115/438 [31:44<1:29:19, 16.59s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  26%|██▋       | 115/438 [32:01<1:29:19, 16.59s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  26%|██▋       | 116/438 [32:01<1:28:55, 16.57s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  26%|██▋       | 116/438 [32:17<1:28:55, 16.57s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 117/438 [32:17<1:28:42, 16.58s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 117/438 [32:34<1:28:42, 16.58s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 118/438 [32:34<1:28:23, 16.57s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 118/438 [32:50<1:28:23, 16.57s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 119/438 [32:50<1:28:02, 16.56s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 119/438 [33:07<1:28:02, 16.56s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 120/438 [33:07<1:27:43, 16.55s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  27%|██▋       | 120/438 [33:23<1:27:43, 16.55s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 121/438 [33:23<1:27:24, 16.54s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 121/438 [33:40<1:27:24, 16.54s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 122/438 [33:40<1:27:35, 16.63s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 122/438 [33:57<1:27:35, 16.63s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 123/438 [33:57<1:27:17, 16.63s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 123/438 [34:13<1:27:17, 16.63s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 124/438 [34:13<1:26:46, 16.58s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  28%|██▊       | 124/438 [34:30<1:26:46, 16.58s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  29%|██▊       | 125/438 [34:30<1:26:28, 16.58s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  29%|██▊       | 125/438 [34:47<1:26:28, 16.58s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 126/438 [34:47<1:26:13, 16.58s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 126/438 [35:03<1:26:13, 16.58s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 127/438 [35:03<1:25:43, 16.54s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 127/438 [35:19<1:25:43, 16.54s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 128/438 [35:19<1:25:23, 16.53s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 128/438 [35:36<1:25:23, 16.53s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 129/438 [35:36<1:25:27, 16.59s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  29%|██▉       | 129/438 [35:53<1:25:27, 16.59s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  30%|██▉       | 130/438 [35:53<1:25:06, 16.58s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  30%|██▉       | 130/438 [36:09<1:25:06, 16.58s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  30%|██▉       | 131/438 [36:09<1:24:36, 16.54s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  30%|██▉       | 131/438 [36:26<1:24:36, 16.54s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  30%|███       | 132/438 [36:26<1:24:27, 16.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  30%|███       | 132/438 [36:42<1:24:27, 16.56s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  30%|███       | 133/438 [36:42<1:24:15, 16.58s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  30%|███       | 133/438 [36:59<1:24:15, 16.58s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  31%|███       | 134/438 [36:59<1:23:56, 16.57s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  31%|███       | 134/438 [37:16<1:23:56, 16.57s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  31%|███       | 135/438 [37:16<1:23:36, 16.56s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  31%|███       | 135/438 [37:32<1:23:36, 16.56s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  31%|███       | 136/438 [37:32<1:23:19, 16.55s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  31%|███       | 136/438 [37:49<1:23:19, 16.55s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  31%|███▏      | 137/438 [37:49<1:23:15, 16.60s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  31%|███▏      | 137/438 [38:05<1:23:15, 16.60s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 138/438 [38:05<1:22:53, 16.58s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 138/438 [38:22<1:22:53, 16.58s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 139/438 [38:22<1:22:33, 16.57s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 139/438 [38:38<1:22:33, 16.57s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 140/438 [38:38<1:22:12, 16.55s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 140/438 [38:55<1:22:12, 16.55s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 141/438 [38:55<1:21:55, 16.55s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 141/438 [39:12<1:21:55, 16.55s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 142/438 [39:12<1:21:44, 16.57s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  32%|███▏      | 142/438 [39:28<1:21:44, 16.57s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 143/438 [39:28<1:21:10, 16.51s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 143/438 [39:44<1:21:10, 16.51s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 144/438 [39:44<1:20:56, 16.52s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 144/438 [40:01<1:20:56, 16.52s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 145/438 [40:01<1:20:30, 16.49s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 145/438 [40:17<1:20:30, 16.49s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 146/438 [40:17<1:20:16, 16.49s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  33%|███▎      | 146/438 [40:34<1:20:16, 16.49s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  34%|███▎      | 147/438 [40:34<1:19:55, 16.48s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  34%|███▎      | 147/438 [40:52<1:19:55, 16.48s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 148/438 [40:52<1:22:52, 17.15s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 148/438 [41:10<1:22:52, 17.15s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 149/438 [41:10<1:23:18, 17.30s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 149/438 [41:27<1:23:18, 17.30s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 150/438 [41:27<1:22:14, 17.13s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 150/438 [41:44<1:22:14, 17.13s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 151/438 [41:44<1:21:15, 16.99s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  34%|███▍      | 151/438 [42:00<1:21:15, 16.99s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  35%|███▍      | 152/438 [42:00<1:20:36, 16.91s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  35%|███▍      | 152/438 [42:17<1:20:36, 16.91s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  35%|███▍      | 153/438 [42:17<1:19:56, 16.83s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  35%|███▍      | 153/438 [42:35<1:19:56, 16.83s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  35%|███▌      | 154/438 [42:35<1:20:51, 17.08s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  35%|███▌      | 154/438 [42:51<1:20:51, 17.08s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  35%|███▌      | 155/438 [42:51<1:20:08, 16.99s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  35%|███▌      | 155/438 [43:08<1:20:08, 16.99s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  36%|███▌      | 156/438 [43:08<1:19:20, 16.88s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  36%|███▌      | 156/438 [43:25<1:19:20, 16.88s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  36%|███▌      | 157/438 [43:25<1:18:38, 16.79s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  36%|███▌      | 157/438 [43:41<1:18:38, 16.79s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  36%|███▌      | 158/438 [43:41<1:18:16, 16.77s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  36%|███▌      | 158/438 [43:58<1:18:16, 16.77s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  36%|███▋      | 159/438 [43:58<1:18:00, 16.78s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  36%|███▋      | 159/438 [44:15<1:18:00, 16.78s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 160/438 [44:15<1:17:34, 16.74s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 160/438 [44:32<1:17:34, 16.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 161/438 [44:32<1:17:19, 16.75s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 161/438 [44:49<1:17:19, 16.75s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 162/438 [44:49<1:17:32, 16.86s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 162/438 [45:06<1:17:32, 16.86s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 163/438 [45:06<1:17:29, 16.91s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 163/438 [45:22<1:17:29, 16.91s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 164/438 [45:22<1:17:06, 16.88s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  37%|███▋      | 164/438 [45:39<1:17:06, 16.88s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 165/438 [45:39<1:16:30, 16.82s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 165/438 [45:56<1:16:30, 16.82s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 166/438 [45:56<1:15:46, 16.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 166/438 [46:12<1:15:46, 16.71s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 167/438 [46:12<1:15:15, 16.66s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 167/438 [46:29<1:15:15, 16.66s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 168/438 [46:29<1:14:55, 16.65s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  38%|███▊      | 168/438 [46:46<1:14:55, 16.65s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  39%|███▊      | 169/438 [46:46<1:15:05, 16.75s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  39%|███▊      | 169/438 [47:02<1:15:05, 16.75s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 170/438 [47:02<1:14:27, 16.67s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 170/438 [47:19<1:14:27, 16.67s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 171/438 [47:19<1:13:57, 16.62s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 171/438 [47:35<1:13:57, 16.62s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 172/438 [47:35<1:13:32, 16.59s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 172/438 [47:52<1:13:32, 16.59s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 173/438 [47:52<1:13:58, 16.75s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  39%|███▉      | 173/438 [48:09<1:13:58, 16.75s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  40%|███▉      | 174/438 [48:09<1:13:31, 16.71s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  40%|███▉      | 174/438 [48:29<1:13:31, 16.71s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  40%|███▉      | 175/438 [48:29<1:17:25, 17.66s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  40%|███▉      | 175/438 [48:46<1:17:25, 17.66s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  40%|████      | 176/438 [48:46<1:16:38, 17.55s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  40%|████      | 176/438 [49:03<1:16:38, 17.55s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  40%|████      | 177/438 [49:03<1:15:41, 17.40s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  40%|████      | 177/438 [49:20<1:15:41, 17.40s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  41%|████      | 178/438 [49:20<1:15:02, 17.32s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  41%|████      | 178/438 [49:37<1:15:02, 17.32s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  41%|████      | 179/438 [49:37<1:14:17, 17.21s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  41%|████      | 179/438 [49:55<1:14:17, 17.21s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  41%|████      | 180/438 [49:55<1:14:04, 17.23s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  41%|████      | 180/438 [50:12<1:14:04, 17.23s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  41%|████▏     | 181/438 [50:12<1:13:46, 17.22s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  41%|████▏     | 181/438 [50:29<1:13:46, 17.22s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 182/438 [50:29<1:13:28, 17.22s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 182/438 [50:46<1:13:28, 17.22s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 183/438 [50:46<1:13:07, 17.21s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 183/438 [51:03<1:13:07, 17.21s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 184/438 [51:03<1:12:42, 17.17s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 184/438 [51:20<1:12:42, 17.17s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 185/438 [51:20<1:12:27, 17.18s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 185/438 [51:38<1:12:27, 17.18s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 186/438 [51:38<1:12:29, 17.26s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  42%|████▏     | 186/438 [51:55<1:12:29, 17.26s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 187/438 [51:55<1:12:01, 17.22s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 187/438 [52:13<1:12:01, 17.22s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 188/438 [52:13<1:12:05, 17.30s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 188/438 [52:30<1:12:05, 17.30s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 189/438 [52:30<1:11:45, 17.29s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 189/438 [52:47<1:11:45, 17.29s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 190/438 [52:47<1:11:19, 17.25s/it, training_loss=0.153]\u001B[A\n",
      "Epoch 3:  43%|████▎     | 190/438 [53:04<1:11:19, 17.25s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  44%|████▎     | 191/438 [53:04<1:11:05, 17.27s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  44%|████▎     | 191/438 [53:22<1:11:05, 17.27s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  44%|████▍     | 192/438 [53:22<1:11:05, 17.34s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  44%|████▍     | 192/438 [53:39<1:11:05, 17.34s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  44%|████▍     | 193/438 [53:39<1:10:55, 17.37s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  44%|████▍     | 193/438 [53:56<1:10:55, 17.37s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  44%|████▍     | 194/438 [53:56<1:10:15, 17.28s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  44%|████▍     | 194/438 [54:14<1:10:15, 17.28s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  45%|████▍     | 195/438 [54:14<1:09:57, 17.27s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  45%|████▍     | 195/438 [54:31<1:09:57, 17.27s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  45%|████▍     | 196/438 [54:31<1:09:46, 17.30s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  45%|████▍     | 196/438 [54:48<1:09:46, 17.30s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  45%|████▍     | 197/438 [54:48<1:09:08, 17.21s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  45%|████▍     | 197/438 [55:05<1:09:08, 17.21s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 3:  45%|████▌     | 198/438 [55:05<1:08:59, 17.25s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 3:  45%|████▌     | 198/438 [55:23<1:08:59, 17.25s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 3:  45%|████▌     | 199/438 [55:23<1:08:47, 17.27s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 3:  45%|████▌     | 199/438 [55:41<1:08:47, 17.27s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  46%|████▌     | 200/438 [55:41<1:09:58, 17.64s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  46%|████▌     | 200/438 [55:58<1:09:58, 17.64s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  46%|████▌     | 201/438 [55:58<1:09:22, 17.56s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  46%|████▌     | 201/438 [56:16<1:09:22, 17.56s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  46%|████▌     | 202/438 [56:16<1:08:45, 17.48s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  46%|████▌     | 202/438 [56:33<1:08:45, 17.48s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  46%|████▋     | 203/438 [56:33<1:08:17, 17.43s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  46%|████▋     | 203/438 [56:50<1:08:17, 17.43s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 204/438 [56:50<1:07:59, 17.43s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 204/438 [57:08<1:07:59, 17.43s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 205/438 [57:08<1:08:04, 17.53s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 205/438 [57:26<1:08:04, 17.53s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 206/438 [57:26<1:07:27, 17.45s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 206/438 [57:44<1:07:27, 17.45s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 207/438 [57:44<1:08:05, 17.68s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 207/438 [58:01<1:08:05, 17.68s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 208/438 [58:01<1:07:19, 17.56s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  47%|████▋     | 208/438 [58:18<1:07:19, 17.56s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 209/438 [58:18<1:06:43, 17.48s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 209/438 [58:36<1:06:43, 17.48s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 210/438 [58:36<1:06:06, 17.40s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 210/438 [58:53<1:06:06, 17.40s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 211/438 [58:53<1:05:35, 17.34s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 211/438 [59:10<1:05:35, 17.34s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 212/438 [59:10<1:05:46, 17.46s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  48%|████▊     | 212/438 [59:28<1:05:46, 17.46s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  49%|████▊     | 213/438 [59:28<1:05:43, 17.52s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  49%|████▊     | 213/438 [59:45<1:05:43, 17.52s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  49%|████▉     | 214/438 [59:45<1:04:49, 17.36s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  49%|████▉     | 214/438 [1:00:02<1:04:49, 17.36s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  49%|████▉     | 215/438 [1:00:02<1:04:27, 17.34s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  49%|████▉     | 215/438 [1:00:20<1:04:27, 17.34s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  49%|████▉     | 216/438 [1:00:20<1:04:00, 17.30s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  49%|████▉     | 216/438 [1:00:37<1:04:00, 17.30s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  50%|████▉     | 217/438 [1:00:37<1:03:38, 17.28s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  50%|████▉     | 217/438 [1:00:54<1:03:38, 17.28s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  50%|████▉     | 218/438 [1:00:54<1:03:08, 17.22s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  50%|████▉     | 218/438 [1:01:11<1:03:08, 17.22s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  50%|█████     | 219/438 [1:01:11<1:02:39, 17.16s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  50%|█████     | 219/438 [1:01:28<1:02:39, 17.16s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  50%|█████     | 220/438 [1:01:28<1:02:07, 17.10s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  50%|█████     | 220/438 [1:01:46<1:02:07, 17.10s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  50%|█████     | 221/438 [1:01:46<1:03:00, 17.42s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  50%|█████     | 221/438 [1:02:03<1:03:00, 17.42s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  51%|█████     | 222/438 [1:02:03<1:02:21, 17.32s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  51%|█████     | 222/438 [1:02:20<1:02:21, 17.32s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  51%|█████     | 223/438 [1:02:20<1:01:55, 17.28s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  51%|█████     | 223/438 [1:02:37<1:01:55, 17.28s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  51%|█████     | 224/438 [1:02:37<1:01:19, 17.19s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  51%|█████     | 224/438 [1:02:54<1:01:19, 17.19s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  51%|█████▏    | 225/438 [1:02:54<1:00:59, 17.18s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  51%|█████▏    | 225/438 [1:03:12<1:00:59, 17.18s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  52%|█████▏    | 226/438 [1:03:12<1:00:31, 17.13s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  52%|█████▏    | 226/438 [1:03:29<1:00:31, 17.13s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  52%|█████▏    | 227/438 [1:03:29<1:00:20, 17.16s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  52%|█████▏    | 227/438 [1:03:46<1:00:20, 17.16s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  52%|█████▏    | 228/438 [1:03:46<59:56, 17.13s/it, training_loss=0.126]  \u001B[A\n",
      "Epoch 3:  52%|█████▏    | 228/438 [1:04:03<59:56, 17.13s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  52%|█████▏    | 229/438 [1:04:03<59:38, 17.12s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  52%|█████▏    | 229/438 [1:04:20<59:38, 17.12s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 230/438 [1:04:20<59:32, 17.18s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 230/438 [1:04:38<59:32, 17.18s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 231/438 [1:04:38<59:50, 17.34s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 231/438 [1:04:55<59:50, 17.34s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 232/438 [1:04:55<59:31, 17.34s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 232/438 [1:05:12<59:31, 17.34s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 233/438 [1:05:12<59:08, 17.31s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 233/438 [1:05:30<59:08, 17.31s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 234/438 [1:05:30<58:55, 17.33s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  53%|█████▎    | 234/438 [1:05:47<58:55, 17.33s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  54%|█████▎    | 235/438 [1:05:47<58:44, 17.36s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  54%|█████▎    | 235/438 [1:06:04<58:44, 17.36s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  54%|█████▍    | 236/438 [1:06:04<58:11, 17.28s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  54%|█████▍    | 236/438 [1:06:21<58:11, 17.28s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  54%|█████▍    | 237/438 [1:06:21<57:40, 17.21s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  54%|█████▍    | 237/438 [1:06:39<57:40, 17.21s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 3:  54%|█████▍    | 238/438 [1:06:39<57:15, 17.18s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 3:  54%|█████▍    | 238/438 [1:06:56<57:15, 17.18s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 3:  55%|█████▍    | 239/438 [1:06:56<56:57, 17.17s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 3:  55%|█████▍    | 239/438 [1:07:13<56:57, 17.17s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  55%|█████▍    | 240/438 [1:07:13<56:39, 17.17s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  55%|█████▍    | 240/438 [1:07:30<56:39, 17.17s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  55%|█████▌    | 241/438 [1:07:30<56:43, 17.28s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  55%|█████▌    | 241/438 [1:07:48<56:43, 17.28s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  55%|█████▌    | 242/438 [1:07:48<56:25, 17.27s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  55%|█████▌    | 242/438 [1:08:05<56:25, 17.27s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  55%|█████▌    | 243/438 [1:08:05<56:10, 17.29s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  55%|█████▌    | 243/438 [1:08:22<56:10, 17.29s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  56%|█████▌    | 244/438 [1:08:22<55:42, 17.23s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  56%|█████▌    | 244/438 [1:08:40<55:42, 17.23s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  56%|█████▌    | 245/438 [1:08:40<55:47, 17.34s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  56%|█████▌    | 245/438 [1:08:57<55:47, 17.34s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  56%|█████▌    | 246/438 [1:08:57<55:22, 17.30s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  56%|█████▌    | 246/438 [1:09:14<55:22, 17.30s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  56%|█████▋    | 247/438 [1:09:14<54:54, 17.25s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  56%|█████▋    | 247/438 [1:09:31<54:54, 17.25s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 248/438 [1:09:31<54:43, 17.28s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 248/438 [1:09:49<54:43, 17.28s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 249/438 [1:09:49<54:27, 17.29s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 249/438 [1:10:06<54:27, 17.29s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 250/438 [1:10:06<54:11, 17.29s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 250/438 [1:10:23<54:11, 17.29s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 251/438 [1:10:23<53:48, 17.26s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  57%|█████▋    | 251/438 [1:10:41<53:48, 17.26s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 252/438 [1:10:41<53:39, 17.31s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 252/438 [1:10:58<53:39, 17.31s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 253/438 [1:10:58<53:19, 17.29s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 253/438 [1:11:15<53:19, 17.29s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 254/438 [1:11:15<52:53, 17.25s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 254/438 [1:11:32<52:53, 17.25s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 255/438 [1:11:32<52:34, 17.24s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 255/438 [1:11:49<52:34, 17.24s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 256/438 [1:11:49<52:18, 17.24s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  58%|█████▊    | 256/438 [1:12:07<52:18, 17.24s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  59%|█████▊    | 257/438 [1:12:07<52:01, 17.24s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  59%|█████▊    | 257/438 [1:12:24<52:01, 17.24s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  59%|█████▉    | 258/438 [1:12:24<51:40, 17.23s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  59%|█████▉    | 258/438 [1:12:42<51:40, 17.23s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  59%|█████▉    | 259/438 [1:12:42<51:57, 17.42s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  59%|█████▉    | 259/438 [1:13:00<51:57, 17.42s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  59%|█████▉    | 260/438 [1:13:00<52:01, 17.54s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  59%|█████▉    | 260/438 [1:13:17<52:01, 17.54s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  60%|█████▉    | 261/438 [1:13:17<51:34, 17.48s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  60%|█████▉    | 261/438 [1:13:34<51:34, 17.48s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  60%|█████▉    | 262/438 [1:13:34<51:06, 17.42s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  60%|█████▉    | 262/438 [1:13:51<51:06, 17.42s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  60%|██████    | 263/438 [1:13:51<50:40, 17.37s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  60%|██████    | 263/438 [1:14:09<50:40, 17.37s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  60%|██████    | 264/438 [1:14:09<50:17, 17.34s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  60%|██████    | 264/438 [1:14:26<50:17, 17.34s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  61%|██████    | 265/438 [1:14:26<49:56, 17.32s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  61%|██████    | 265/438 [1:14:43<49:56, 17.32s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  61%|██████    | 266/438 [1:14:43<49:46, 17.36s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  61%|██████    | 266/438 [1:15:01<49:46, 17.36s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  61%|██████    | 267/438 [1:15:01<49:25, 17.34s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  61%|██████    | 267/438 [1:15:19<49:25, 17.34s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  61%|██████    | 268/438 [1:15:19<49:28, 17.46s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  61%|██████    | 268/438 [1:15:37<49:28, 17.46s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  61%|██████▏   | 269/438 [1:15:37<50:26, 17.91s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  61%|██████▏   | 269/438 [1:15:55<50:26, 17.91s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 270/438 [1:15:55<49:50, 17.80s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 270/438 [1:16:12<49:50, 17.80s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 271/438 [1:16:12<49:06, 17.64s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 271/438 [1:16:30<49:06, 17.64s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 272/438 [1:16:30<48:29, 17.53s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 272/438 [1:16:47<48:29, 17.53s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 273/438 [1:16:47<48:16, 17.56s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  62%|██████▏   | 273/438 [1:17:05<48:16, 17.56s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 274/438 [1:17:05<47:50, 17.50s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 274/438 [1:17:22<47:50, 17.50s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 275/438 [1:17:22<47:17, 17.41s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 275/438 [1:17:39<47:17, 17.41s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 276/438 [1:17:39<46:53, 17.37s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 276/438 [1:17:56<46:53, 17.37s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 277/438 [1:17:56<46:26, 17.31s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 277/438 [1:18:13<46:26, 17.31s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 278/438 [1:18:13<45:57, 17.24s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  63%|██████▎   | 278/438 [1:18:30<45:57, 17.24s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  64%|██████▎   | 279/438 [1:18:30<45:38, 17.23s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  64%|██████▎   | 279/438 [1:18:48<45:38, 17.23s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  64%|██████▍   | 280/438 [1:18:48<45:12, 17.17s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  64%|██████▍   | 280/438 [1:19:05<45:12, 17.17s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  64%|██████▍   | 281/438 [1:19:05<44:51, 17.15s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  64%|██████▍   | 281/438 [1:19:22<44:51, 17.15s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  64%|██████▍   | 282/438 [1:19:22<44:42, 17.19s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  64%|██████▍   | 282/438 [1:19:39<44:42, 17.19s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  65%|██████▍   | 283/438 [1:19:39<44:20, 17.17s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  65%|██████▍   | 283/438 [1:19:56<44:20, 17.17s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  65%|██████▍   | 284/438 [1:19:56<43:56, 17.12s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  65%|██████▍   | 284/438 [1:20:13<43:56, 17.12s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  65%|██████▌   | 285/438 [1:20:13<43:45, 17.16s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  65%|██████▌   | 285/438 [1:20:31<43:45, 17.16s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  65%|██████▌   | 286/438 [1:20:31<43:31, 17.18s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  65%|██████▌   | 286/438 [1:20:48<43:31, 17.18s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 287/438 [1:20:48<43:09, 17.15s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 287/438 [1:21:05<43:09, 17.15s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 288/438 [1:21:05<42:55, 17.17s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 288/438 [1:21:22<42:55, 17.17s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 289/438 [1:21:22<42:41, 17.19s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 289/438 [1:21:39<42:41, 17.19s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 290/438 [1:21:39<42:25, 17.20s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  66%|██████▌   | 290/438 [1:21:56<42:25, 17.20s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  66%|██████▋   | 291/438 [1:21:56<42:04, 17.17s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  66%|██████▋   | 291/438 [1:22:14<42:04, 17.17s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 292/438 [1:22:14<41:48, 17.18s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 292/438 [1:22:31<41:48, 17.18s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 293/438 [1:22:31<41:35, 17.21s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 293/438 [1:22:48<41:35, 17.21s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 294/438 [1:22:48<41:17, 17.20s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 294/438 [1:23:05<41:17, 17.20s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 295/438 [1:23:05<40:55, 17.17s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  67%|██████▋   | 295/438 [1:23:22<40:55, 17.17s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 296/438 [1:23:22<40:42, 17.20s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 296/438 [1:23:39<40:42, 17.20s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 297/438 [1:23:39<40:20, 17.17s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 297/438 [1:23:57<40:20, 17.17s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 298/438 [1:23:57<40:12, 17.23s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 298/438 [1:24:14<40:12, 17.23s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 299/438 [1:24:14<39:57, 17.25s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 299/438 [1:24:31<39:57, 17.25s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 300/438 [1:24:31<39:37, 17.23s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  68%|██████▊   | 300/438 [1:24:49<39:37, 17.23s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  69%|██████▊   | 301/438 [1:24:49<39:17, 17.21s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  69%|██████▊   | 301/438 [1:25:06<39:17, 17.21s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  69%|██████▉   | 302/438 [1:25:06<39:04, 17.24s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  69%|██████▉   | 302/438 [1:25:23<39:04, 17.24s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 3:  69%|██████▉   | 303/438 [1:25:23<38:44, 17.22s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 3:  69%|██████▉   | 303/438 [1:25:40<38:44, 17.22s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  69%|██████▉   | 304/438 [1:25:40<38:26, 17.22s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  69%|██████▉   | 304/438 [1:25:57<38:26, 17.22s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  70%|██████▉   | 305/438 [1:25:57<38:11, 17.23s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  70%|██████▉   | 305/438 [1:26:15<38:11, 17.23s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  70%|██████▉   | 306/438 [1:26:15<37:52, 17.22s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  70%|██████▉   | 306/438 [1:26:32<37:52, 17.22s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  70%|███████   | 307/438 [1:26:32<37:36, 17.23s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  70%|███████   | 307/438 [1:26:49<37:36, 17.23s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  70%|███████   | 308/438 [1:26:49<37:24, 17.27s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  70%|███████   | 308/438 [1:27:07<37:24, 17.27s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  71%|███████   | 309/438 [1:27:07<37:08, 17.27s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  71%|███████   | 309/438 [1:27:24<37:08, 17.27s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  71%|███████   | 310/438 [1:27:24<36:51, 17.27s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  71%|███████   | 310/438 [1:27:41<36:51, 17.27s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 3:  71%|███████   | 311/438 [1:27:41<36:36, 17.29s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 3:  71%|███████   | 311/438 [1:27:59<36:36, 17.29s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  71%|███████   | 312/438 [1:27:59<36:53, 17.57s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  71%|███████   | 312/438 [1:28:17<36:53, 17.57s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  71%|███████▏  | 313/438 [1:28:17<36:30, 17.52s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 3:  71%|███████▏  | 313/438 [1:28:34<36:30, 17.52s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 314/438 [1:28:34<36:07, 17.48s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 314/438 [1:28:51<36:07, 17.48s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 315/438 [1:28:51<35:39, 17.39s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 315/438 [1:29:09<35:39, 17.39s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 316/438 [1:29:09<35:17, 17.36s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 316/438 [1:29:26<35:17, 17.36s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 317/438 [1:29:26<35:13, 17.47s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  72%|███████▏  | 317/438 [1:29:44<35:13, 17.47s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 318/438 [1:29:44<34:52, 17.44s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 318/438 [1:30:01<34:52, 17.44s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 319/438 [1:30:01<34:20, 17.31s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 319/438 [1:30:18<34:20, 17.31s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 320/438 [1:30:18<33:55, 17.25s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 320/438 [1:30:35<33:55, 17.25s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 321/438 [1:30:35<33:32, 17.20s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  73%|███████▎  | 321/438 [1:30:52<33:32, 17.20s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  74%|███████▎  | 322/438 [1:30:52<33:13, 17.18s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  74%|███████▎  | 322/438 [1:31:09<33:13, 17.18s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  74%|███████▎  | 323/438 [1:31:09<32:52, 17.15s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  74%|███████▎  | 323/438 [1:31:26<32:52, 17.15s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  74%|███████▍  | 324/438 [1:31:26<32:37, 17.17s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  74%|███████▍  | 324/438 [1:31:44<32:37, 17.17s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  74%|███████▍  | 325/438 [1:31:44<32:22, 17.19s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  74%|███████▍  | 325/438 [1:32:01<32:22, 17.19s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  74%|███████▍  | 326/438 [1:32:01<32:05, 17.19s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  74%|███████▍  | 326/438 [1:32:18<32:05, 17.19s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  75%|███████▍  | 327/438 [1:32:18<31:38, 17.10s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  75%|███████▍  | 327/438 [1:32:35<31:38, 17.10s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  75%|███████▍  | 328/438 [1:32:35<31:18, 17.08s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  75%|███████▍  | 328/438 [1:32:52<31:18, 17.08s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  75%|███████▌  | 329/438 [1:32:52<31:02, 17.09s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  75%|███████▌  | 329/438 [1:33:09<31:02, 17.09s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  75%|███████▌  | 330/438 [1:33:09<30:46, 17.09s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  75%|███████▌  | 330/438 [1:33:26<30:46, 17.09s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  76%|███████▌  | 331/438 [1:33:26<30:25, 17.06s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  76%|███████▌  | 331/438 [1:33:43<30:25, 17.06s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  76%|███████▌  | 332/438 [1:33:43<30:04, 17.02s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  76%|███████▌  | 332/438 [1:34:00<30:04, 17.02s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  76%|███████▌  | 333/438 [1:34:00<29:51, 17.06s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  76%|███████▌  | 333/438 [1:34:17<29:51, 17.06s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  76%|███████▋  | 334/438 [1:34:17<29:36, 17.08s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  76%|███████▋  | 334/438 [1:34:34<29:36, 17.08s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  76%|███████▋  | 335/438 [1:34:34<29:19, 17.08s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  76%|███████▋  | 335/438 [1:34:51<29:19, 17.08s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 336/438 [1:34:51<29:06, 17.12s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 336/438 [1:35:09<29:06, 17.12s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 337/438 [1:35:09<28:51, 17.15s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 337/438 [1:35:26<28:51, 17.15s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 338/438 [1:35:26<28:39, 17.19s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 338/438 [1:35:43<28:39, 17.19s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 339/438 [1:35:43<28:15, 17.13s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  77%|███████▋  | 339/438 [1:36:00<28:15, 17.13s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 340/438 [1:36:00<28:00, 17.15s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 340/438 [1:36:17<28:00, 17.15s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 341/438 [1:36:17<27:41, 17.13s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 341/438 [1:36:34<27:41, 17.13s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 342/438 [1:36:34<27:24, 17.13s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 342/438 [1:36:51<27:24, 17.13s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 343/438 [1:36:51<27:06, 17.13s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  78%|███████▊  | 343/438 [1:37:08<27:06, 17.13s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  79%|███████▊  | 344/438 [1:37:08<26:48, 17.11s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  79%|███████▊  | 344/438 [1:37:26<26:48, 17.11s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 345/438 [1:37:26<26:30, 17.10s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 345/438 [1:37:43<26:30, 17.10s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 346/438 [1:37:43<26:11, 17.09s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 346/438 [1:38:00<26:11, 17.09s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 347/438 [1:38:00<25:57, 17.12s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 347/438 [1:38:17<25:57, 17.12s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 348/438 [1:38:17<25:49, 17.22s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  79%|███████▉  | 348/438 [1:38:34<25:49, 17.22s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  80%|███████▉  | 349/438 [1:38:34<25:16, 17.04s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  80%|███████▉  | 349/438 [1:38:50<25:16, 17.04s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  80%|███████▉  | 350/438 [1:38:50<24:47, 16.91s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  80%|███████▉  | 350/438 [1:39:07<24:47, 16.91s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  80%|████████  | 351/438 [1:39:07<24:23, 16.82s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  80%|████████  | 351/438 [1:39:24<24:23, 16.82s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  80%|████████  | 352/438 [1:39:24<24:06, 16.82s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  80%|████████  | 352/438 [1:39:40<24:06, 16.82s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  81%|████████  | 353/438 [1:39:40<23:42, 16.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  81%|████████  | 353/438 [1:39:57<23:42, 16.74s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  81%|████████  | 354/438 [1:39:57<23:25, 16.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  81%|████████  | 354/438 [1:40:14<23:25, 16.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  81%|████████  | 355/438 [1:40:14<23:08, 16.73s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  81%|████████  | 355/438 [1:40:30<23:08, 16.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  81%|████████▏ | 356/438 [1:40:30<22:48, 16.69s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  81%|████████▏ | 356/438 [1:40:47<22:48, 16.69s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 357/438 [1:40:47<22:32, 16.70s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 357/438 [1:41:04<22:32, 16.70s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 358/438 [1:41:04<22:14, 16.68s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 358/438 [1:41:21<22:14, 16.68s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 359/438 [1:41:21<21:59, 16.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 359/438 [1:41:37<21:59, 16.70s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 360/438 [1:41:37<21:39, 16.67s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 360/438 [1:41:54<21:39, 16.67s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 361/438 [1:41:54<21:23, 16.67s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  82%|████████▏ | 361/438 [1:42:10<21:23, 16.67s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 362/438 [1:42:10<21:05, 16.66s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 362/438 [1:42:27<21:05, 16.66s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 363/438 [1:42:27<20:51, 16.69s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 363/438 [1:42:44<20:51, 16.69s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 364/438 [1:42:44<20:35, 16.69s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 364/438 [1:43:02<20:35, 16.69s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 365/438 [1:43:02<20:45, 17.06s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  83%|████████▎ | 365/438 [1:43:19<20:45, 17.06s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  84%|████████▎ | 366/438 [1:43:19<20:21, 16.96s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3:  84%|████████▎ | 366/438 [1:43:35<20:21, 16.96s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 367/438 [1:43:35<19:58, 16.88s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 367/438 [1:43:52<19:58, 16.88s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 368/438 [1:43:52<19:35, 16.79s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 368/438 [1:44:09<19:35, 16.79s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 369/438 [1:44:09<19:17, 16.77s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 369/438 [1:44:25<19:17, 16.77s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 370/438 [1:44:25<18:57, 16.72s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 3:  84%|████████▍ | 370/438 [1:44:42<18:57, 16.72s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  85%|████████▍ | 371/438 [1:44:42<18:35, 16.64s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  85%|████████▍ | 371/438 [1:44:58<18:35, 16.64s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  85%|████████▍ | 372/438 [1:44:58<18:18, 16.65s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  85%|████████▍ | 372/438 [1:45:15<18:18, 16.65s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  85%|████████▌ | 373/438 [1:45:15<18:03, 16.67s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  85%|████████▌ | 373/438 [1:45:32<18:03, 16.67s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  85%|████████▌ | 374/438 [1:45:32<17:46, 16.67s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  85%|████████▌ | 374/438 [1:45:48<17:46, 16.67s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  86%|████████▌ | 375/438 [1:45:48<17:30, 16.67s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  86%|████████▌ | 375/438 [1:46:05<17:30, 16.67s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  86%|████████▌ | 376/438 [1:46:05<17:15, 16.70s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 3:  86%|████████▌ | 376/438 [1:46:22<17:15, 16.70s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 3:  86%|████████▌ | 377/438 [1:46:22<16:56, 16.66s/it, training_loss=0.150]\u001B[A\n",
      "Epoch 3:  86%|████████▌ | 377/438 [1:46:38<16:56, 16.66s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  86%|████████▋ | 378/438 [1:46:38<16:39, 16.66s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  86%|████████▋ | 378/438 [1:46:55<16:39, 16.66s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 379/438 [1:46:55<16:23, 16.68s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 379/438 [1:47:12<16:23, 16.68s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 380/438 [1:47:12<16:06, 16.66s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 380/438 [1:47:28<16:06, 16.66s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 381/438 [1:47:28<15:46, 16.61s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 381/438 [1:47:45<15:46, 16.61s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 382/438 [1:47:45<15:28, 16.58s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 382/438 [1:48:01<15:28, 16.58s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 383/438 [1:48:01<15:12, 16.60s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 3:  87%|████████▋ | 383/438 [1:48:18<15:12, 16.60s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 384/438 [1:48:18<14:54, 16.57s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 384/438 [1:48:34<14:54, 16.57s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 385/438 [1:48:34<14:38, 16.58s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 385/438 [1:48:51<14:38, 16.58s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 386/438 [1:48:51<14:21, 16.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 386/438 [1:49:08<14:21, 16.56s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 387/438 [1:49:08<14:05, 16.58s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  88%|████████▊ | 387/438 [1:49:24<14:05, 16.58s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  89%|████████▊ | 388/438 [1:49:24<13:49, 16.60s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 3:  89%|████████▊ | 388/438 [1:49:41<13:49, 16.60s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 389/438 [1:49:41<13:31, 16.56s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 389/438 [1:49:57<13:31, 16.56s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 390/438 [1:49:57<13:14, 16.54s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 390/438 [1:50:14<13:14, 16.54s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 391/438 [1:50:14<13:00, 16.61s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 391/438 [1:50:30<13:00, 16.61s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 392/438 [1:50:30<12:41, 16.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  89%|████████▉ | 392/438 [1:50:47<12:41, 16.56s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  90%|████████▉ | 393/438 [1:50:47<12:26, 16.58s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  90%|████████▉ | 393/438 [1:51:04<12:26, 16.58s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  90%|████████▉ | 394/438 [1:51:04<12:09, 16.58s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  90%|████████▉ | 394/438 [1:51:20<12:09, 16.58s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  90%|█████████ | 395/438 [1:51:20<11:53, 16.59s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  90%|█████████ | 395/438 [1:51:37<11:53, 16.59s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  90%|█████████ | 396/438 [1:51:37<11:38, 16.64s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  90%|█████████ | 396/438 [1:51:54<11:38, 16.64s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 3:  91%|█████████ | 397/438 [1:51:54<11:21, 16.63s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 3:  91%|█████████ | 397/438 [1:52:10<11:21, 16.63s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  91%|█████████ | 398/438 [1:52:10<11:03, 16.58s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  91%|█████████ | 398/438 [1:52:27<11:03, 16.58s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  91%|█████████ | 399/438 [1:52:27<10:46, 16.59s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  91%|█████████ | 399/438 [1:52:43<10:46, 16.59s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  91%|█████████▏| 400/438 [1:52:43<10:29, 16.57s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  91%|█████████▏| 400/438 [1:53:00<10:29, 16.57s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 401/438 [1:53:00<10:13, 16.57s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 401/438 [1:53:16<10:13, 16.57s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 402/438 [1:53:16<09:57, 16.59s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 402/438 [1:53:33<09:57, 16.59s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 403/438 [1:53:33<09:39, 16.57s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 403/438 [1:53:49<09:39, 16.57s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 404/438 [1:53:49<09:22, 16.53s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 404/438 [1:54:06<09:22, 16.53s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 405/438 [1:54:06<09:06, 16.56s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  92%|█████████▏| 405/438 [1:54:23<09:06, 16.56s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 406/438 [1:54:23<08:49, 16.55s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 406/438 [1:54:39<08:49, 16.55s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 407/438 [1:54:39<08:33, 16.55s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 407/438 [1:54:56<08:33, 16.55s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 408/438 [1:54:56<08:17, 16.60s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 408/438 [1:55:12<08:17, 16.60s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 409/438 [1:55:12<08:01, 16.61s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  93%|█████████▎| 409/438 [1:55:31<08:01, 16.61s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  94%|█████████▎| 410/438 [1:55:31<08:02, 17.23s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  94%|█████████▎| 410/438 [1:55:50<08:02, 17.23s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  94%|█████████▍| 411/438 [1:55:50<07:57, 17.68s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  94%|█████████▍| 411/438 [1:56:07<07:57, 17.68s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  94%|█████████▍| 412/438 [1:56:07<07:33, 17.46s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 3:  94%|█████████▍| 412/438 [1:56:24<07:33, 17.46s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  94%|█████████▍| 413/438 [1:56:24<07:10, 17.24s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  94%|█████████▍| 413/438 [1:56:40<07:10, 17.24s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  95%|█████████▍| 414/438 [1:56:40<06:50, 17.10s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3:  95%|█████████▍| 414/438 [1:56:57<06:50, 17.10s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  95%|█████████▍| 415/438 [1:56:57<06:32, 17.05s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 3:  95%|█████████▍| 415/438 [1:57:14<06:32, 17.05s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  95%|█████████▍| 416/438 [1:57:14<06:15, 17.08s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 3:  95%|█████████▍| 416/438 [1:57:31<06:15, 17.08s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  95%|█████████▌| 417/438 [1:57:31<05:56, 16.99s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  95%|█████████▌| 417/438 [1:57:48<05:56, 16.99s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  95%|█████████▌| 418/438 [1:57:48<05:37, 16.86s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 3:  95%|█████████▌| 418/438 [1:58:06<05:37, 16.86s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  96%|█████████▌| 419/438 [1:58:06<05:27, 17.24s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  96%|█████████▌| 419/438 [1:58:23<05:27, 17.24s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  96%|█████████▌| 420/438 [1:58:23<05:07, 17.07s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 3:  96%|█████████▌| 420/438 [1:58:39<05:07, 17.07s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  96%|█████████▌| 421/438 [1:58:39<04:48, 16.94s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  96%|█████████▌| 421/438 [1:58:56<04:48, 16.94s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  96%|█████████▋| 422/438 [1:58:56<04:29, 16.84s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 3:  96%|█████████▋| 422/438 [1:59:12<04:29, 16.84s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 423/438 [1:59:12<04:11, 16.78s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 423/438 [1:59:29<04:11, 16.78s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 424/438 [1:59:29<03:54, 16.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 424/438 [1:59:46<03:54, 16.73s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 425/438 [1:59:46<03:37, 16.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 425/438 [2:00:02<03:37, 16.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 426/438 [2:00:02<03:20, 16.73s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 426/438 [2:00:19<03:20, 16.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 427/438 [2:00:19<03:03, 16.72s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 3:  97%|█████████▋| 427/438 [2:00:36<03:03, 16.72s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 428/438 [2:00:36<02:46, 16.70s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 428/438 [2:00:52<02:46, 16.70s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 429/438 [2:00:52<02:30, 16.69s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 429/438 [2:01:09<02:30, 16.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 430/438 [2:01:09<02:13, 16.69s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 430/438 [2:01:26<02:13, 16.69s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 431/438 [2:01:26<01:56, 16.66s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 3:  98%|█████████▊| 431/438 [2:01:42<01:56, 16.66s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 3:  99%|█████████▊| 432/438 [2:01:42<01:39, 16.64s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 3:  99%|█████████▊| 432/438 [2:02:00<01:39, 16.64s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  99%|█████████▉| 433/438 [2:02:00<01:24, 16.95s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 3:  99%|█████████▉| 433/438 [2:02:17<01:24, 16.95s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  99%|█████████▉| 434/438 [2:02:17<01:07, 16.85s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 3:  99%|█████████▉| 434/438 [2:02:33<01:07, 16.85s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  99%|█████████▉| 435/438 [2:02:33<00:50, 16.80s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 3:  99%|█████████▉| 435/438 [2:02:50<00:50, 16.80s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3: 100%|█████████▉| 436/438 [2:02:50<00:33, 16.75s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 3: 100%|█████████▉| 436/438 [2:03:06<00:33, 16.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3: 100%|█████████▉| 437/438 [2:03:06<00:16, 16.69s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 3: 100%|█████████▉| 437/438 [2:03:21<00:16, 16.69s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 3: 100%|██████████| 438/438 [2:03:21<00:00, 15.89s/it, training_loss=0.130]\u001B[A\n",
      " 40%|████      | 2/5 [6:53:01<7:14:59, 8699.86s/it]                              \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Trainin loss: 0.3884496952845081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [7:13:27<4:48:53, 8666.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3892127971382851\n",
      "F1 Score (Weighted): 0.02348434924273023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4:   0%|          | 0/438 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 4:   0%|          | 0/438 [00:16<?, ?it/s, training_loss=0.137]\u001B[A\n",
      "Epoch 4:   0%|          | 1/438 [00:16<2:00:37, 16.56s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:   0%|          | 1/438 [00:33<2:00:37, 16.56s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:   0%|          | 2/438 [00:33<2:00:02, 16.52s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:   0%|          | 2/438 [00:49<2:00:02, 16.52s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:   1%|          | 3/438 [00:49<1:59:17, 16.45s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:   1%|          | 3/438 [01:05<1:59:17, 16.45s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:   1%|          | 4/438 [01:05<1:59:01, 16.46s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:   1%|          | 4/438 [01:22<1:59:01, 16.46s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:   1%|          | 5/438 [01:22<1:58:34, 16.43s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:   1%|          | 5/438 [01:38<1:58:34, 16.43s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:   1%|▏         | 6/438 [01:38<1:58:06, 16.40s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:   1%|▏         | 6/438 [01:55<1:58:06, 16.40s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 4:   2%|▏         | 7/438 [01:55<1:57:47, 16.40s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 4:   2%|▏         | 7/438 [02:11<1:57:47, 16.40s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:   2%|▏         | 8/438 [02:11<1:57:40, 16.42s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:   2%|▏         | 8/438 [02:27<1:57:40, 16.42s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:   2%|▏         | 9/438 [02:27<1:57:19, 16.41s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:   2%|▏         | 9/438 [02:44<1:57:19, 16.41s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:   2%|▏         | 10/438 [02:44<1:57:17, 16.44s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:   2%|▏         | 10/438 [03:00<1:57:17, 16.44s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:   3%|▎         | 11/438 [03:00<1:56:44, 16.40s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:   3%|▎         | 11/438 [03:16<1:56:44, 16.40s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:   3%|▎         | 12/438 [03:16<1:56:14, 16.37s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:   3%|▎         | 12/438 [03:33<1:56:14, 16.37s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:   3%|▎         | 13/438 [03:33<1:55:49, 16.35s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:   3%|▎         | 13/438 [03:49<1:55:49, 16.35s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:   3%|▎         | 14/438 [03:49<1:55:27, 16.34s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:   3%|▎         | 14/438 [04:05<1:55:27, 16.34s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:   3%|▎         | 15/438 [04:05<1:55:06, 16.33s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:   3%|▎         | 15/438 [04:22<1:55:06, 16.33s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:   4%|▎         | 16/438 [04:22<1:55:46, 16.46s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:   4%|▎         | 16/438 [04:40<1:55:46, 16.46s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:   4%|▍         | 17/438 [04:40<1:57:58, 16.81s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:   4%|▍         | 17/438 [04:56<1:57:58, 16.81s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 4:   4%|▍         | 18/438 [04:56<1:56:50, 16.69s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 4:   4%|▍         | 18/438 [05:13<1:56:50, 16.69s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:   4%|▍         | 19/438 [05:13<1:56:07, 16.63s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:   4%|▍         | 19/438 [05:29<1:56:07, 16.63s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:   5%|▍         | 20/438 [05:29<1:55:17, 16.55s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:   5%|▍         | 20/438 [05:46<1:55:17, 16.55s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 4:   5%|▍         | 21/438 [05:46<1:55:00, 16.55s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 4:   5%|▍         | 21/438 [06:02<1:55:00, 16.55s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:   5%|▌         | 22/438 [06:02<1:54:05, 16.46s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:   5%|▌         | 22/438 [06:18<1:54:05, 16.46s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:   5%|▌         | 23/438 [06:18<1:53:44, 16.45s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:   5%|▌         | 23/438 [06:35<1:53:44, 16.45s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:   5%|▌         | 24/438 [06:35<1:53:21, 16.43s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:   5%|▌         | 24/438 [06:51<1:53:21, 16.43s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:   6%|▌         | 25/438 [06:51<1:52:57, 16.41s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:   6%|▌         | 25/438 [07:07<1:52:57, 16.41s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:   6%|▌         | 26/438 [07:07<1:52:45, 16.42s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:   6%|▌         | 26/438 [07:24<1:52:45, 16.42s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:   6%|▌         | 27/438 [07:24<1:52:22, 16.41s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:   6%|▌         | 27/438 [07:40<1:52:22, 16.41s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:   6%|▋         | 28/438 [07:40<1:52:08, 16.41s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:   6%|▋         | 28/438 [07:57<1:52:08, 16.41s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:   7%|▋         | 29/438 [07:57<1:51:55, 16.42s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:   7%|▋         | 29/438 [08:13<1:51:55, 16.42s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 4:   7%|▋         | 30/438 [08:13<1:51:39, 16.42s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 4:   7%|▋         | 30/438 [08:29<1:51:39, 16.42s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:   7%|▋         | 31/438 [08:29<1:51:04, 16.38s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:   7%|▋         | 31/438 [08:46<1:51:04, 16.38s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:   7%|▋         | 32/438 [08:46<1:50:52, 16.39s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:   7%|▋         | 32/438 [09:02<1:50:52, 16.39s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:   8%|▊         | 33/438 [09:02<1:50:46, 16.41s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:   8%|▊         | 33/438 [09:19<1:50:46, 16.41s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 4:   8%|▊         | 34/438 [09:19<1:50:18, 16.38s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 4:   8%|▊         | 34/438 [09:35<1:50:18, 16.38s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:   8%|▊         | 35/438 [09:35<1:50:09, 16.40s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:   8%|▊         | 35/438 [09:52<1:50:09, 16.40s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:   8%|▊         | 36/438 [09:52<1:50:05, 16.43s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:   8%|▊         | 36/438 [10:08<1:50:05, 16.43s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:   8%|▊         | 37/438 [10:08<1:49:58, 16.45s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:   8%|▊         | 37/438 [10:24<1:49:58, 16.45s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:   9%|▊         | 38/438 [10:24<1:49:32, 16.43s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:   9%|▊         | 38/438 [10:41<1:49:32, 16.43s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:   9%|▉         | 39/438 [10:41<1:49:19, 16.44s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:   9%|▉         | 39/438 [10:57<1:49:19, 16.44s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:   9%|▉         | 40/438 [10:57<1:48:55, 16.42s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:   9%|▉         | 40/438 [11:14<1:48:55, 16.42s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:   9%|▉         | 41/438 [11:14<1:48:48, 16.45s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:   9%|▉         | 41/438 [11:30<1:48:48, 16.45s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  10%|▉         | 42/438 [11:30<1:48:32, 16.44s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  10%|▉         | 42/438 [11:47<1:48:32, 16.44s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 4:  10%|▉         | 43/438 [11:47<1:48:27, 16.48s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 4:  10%|▉         | 43/438 [12:03<1:48:27, 16.48s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  10%|█         | 44/438 [12:03<1:48:21, 16.50s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  10%|█         | 44/438 [12:20<1:48:21, 16.50s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  10%|█         | 45/438 [12:20<1:48:04, 16.50s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  10%|█         | 45/438 [12:36<1:48:04, 16.50s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  11%|█         | 46/438 [12:36<1:47:35, 16.47s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  11%|█         | 46/438 [12:53<1:47:35, 16.47s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  11%|█         | 47/438 [12:53<1:47:09, 16.44s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  11%|█         | 47/438 [13:09<1:47:09, 16.44s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  11%|█         | 48/438 [13:09<1:46:56, 16.45s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  11%|█         | 48/438 [13:25<1:46:56, 16.45s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  11%|█         | 49/438 [13:25<1:46:35, 16.44s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  11%|█         | 49/438 [13:42<1:46:35, 16.44s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 4:  11%|█▏        | 50/438 [13:42<1:46:20, 16.45s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 4:  11%|█▏        | 50/438 [13:59<1:46:20, 16.45s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  12%|█▏        | 51/438 [13:59<1:46:25, 16.50s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  12%|█▏        | 51/438 [14:15<1:46:25, 16.50s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  12%|█▏        | 52/438 [14:15<1:46:00, 16.48s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  12%|█▏        | 52/438 [14:32<1:46:00, 16.48s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  12%|█▏        | 53/438 [14:32<1:45:53, 16.50s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  12%|█▏        | 53/438 [14:48<1:45:53, 16.50s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  12%|█▏        | 54/438 [14:48<1:45:42, 16.52s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  12%|█▏        | 54/438 [15:05<1:45:42, 16.52s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  13%|█▎        | 55/438 [15:05<1:45:20, 16.50s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  13%|█▎        | 55/438 [15:21<1:45:20, 16.50s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 4:  13%|█▎        | 56/438 [15:21<1:45:03, 16.50s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 4:  13%|█▎        | 56/438 [15:38<1:45:03, 16.50s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  13%|█▎        | 57/438 [15:38<1:44:55, 16.52s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  13%|█▎        | 57/438 [15:54<1:44:55, 16.52s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  13%|█▎        | 58/438 [15:54<1:44:27, 16.49s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  13%|█▎        | 58/438 [16:11<1:44:27, 16.49s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  13%|█▎        | 59/438 [16:11<1:44:10, 16.49s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  13%|█▎        | 59/438 [16:27<1:44:10, 16.49s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  14%|█▎        | 60/438 [16:27<1:43:56, 16.50s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  14%|█▎        | 60/438 [16:44<1:43:56, 16.50s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  14%|█▍        | 61/438 [16:44<1:43:47, 16.52s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  14%|█▍        | 61/438 [17:00<1:43:47, 16.52s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  14%|█▍        | 62/438 [17:00<1:43:08, 16.46s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  14%|█▍        | 62/438 [17:16<1:43:08, 16.46s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 4:  14%|█▍        | 63/438 [17:16<1:42:44, 16.44s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 4:  14%|█▍        | 63/438 [17:33<1:42:44, 16.44s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  15%|█▍        | 64/438 [17:33<1:42:34, 16.46s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  15%|█▍        | 64/438 [17:49<1:42:34, 16.46s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  15%|█▍        | 65/438 [17:49<1:42:23, 16.47s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  15%|█▍        | 65/438 [18:06<1:42:23, 16.47s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 4:  15%|█▌        | 66/438 [18:06<1:42:11, 16.48s/it, training_loss=0.146]\u001B[A\n",
      "Epoch 4:  15%|█▌        | 66/438 [18:22<1:42:11, 16.48s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  15%|█▌        | 67/438 [18:22<1:41:41, 16.45s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  15%|█▌        | 67/438 [18:39<1:41:41, 16.45s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  16%|█▌        | 68/438 [18:39<1:41:39, 16.49s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  16%|█▌        | 68/438 [18:55<1:41:39, 16.49s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  16%|█▌        | 69/438 [18:55<1:41:16, 16.47s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  16%|█▌        | 69/438 [19:12<1:41:16, 16.47s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 4:  16%|█▌        | 70/438 [19:12<1:41:04, 16.48s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 4:  16%|█▌        | 70/438 [19:28<1:41:04, 16.48s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  16%|█▌        | 71/438 [19:28<1:41:05, 16.53s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  16%|█▌        | 71/438 [19:46<1:41:05, 16.53s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  16%|█▋        | 72/438 [19:46<1:42:50, 16.86s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  16%|█▋        | 72/438 [20:02<1:42:50, 16.86s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 4:  17%|█▋        | 73/438 [20:02<1:41:45, 16.73s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 4:  17%|█▋        | 73/438 [20:19<1:41:45, 16.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  17%|█▋        | 74/438 [20:19<1:40:53, 16.63s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  17%|█▋        | 74/438 [20:35<1:40:53, 16.63s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  17%|█▋        | 75/438 [20:35<1:40:33, 16.62s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  17%|█▋        | 75/438 [20:52<1:40:33, 16.62s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  17%|█▋        | 76/438 [20:52<1:39:55, 16.56s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  17%|█▋        | 76/438 [21:08<1:39:55, 16.56s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  18%|█▊        | 77/438 [21:08<1:39:37, 16.56s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  18%|█▊        | 77/438 [21:25<1:39:37, 16.56s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  18%|█▊        | 78/438 [21:25<1:39:09, 16.53s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  18%|█▊        | 78/438 [21:41<1:39:09, 16.53s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  18%|█▊        | 79/438 [21:41<1:38:58, 16.54s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  18%|█▊        | 79/438 [21:58<1:38:58, 16.54s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  18%|█▊        | 80/438 [21:58<1:38:34, 16.52s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  18%|█▊        | 80/438 [22:15<1:38:34, 16.52s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  18%|█▊        | 81/438 [22:15<1:38:33, 16.56s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  18%|█▊        | 81/438 [22:31<1:38:33, 16.56s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  19%|█▊        | 82/438 [22:31<1:38:42, 16.64s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  19%|█▊        | 82/438 [22:49<1:38:42, 16.64s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  19%|█▉        | 83/438 [22:49<1:40:13, 16.94s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  19%|█▉        | 83/438 [23:08<1:40:13, 16.94s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  19%|█▉        | 84/438 [23:08<1:43:19, 17.51s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  19%|█▉        | 84/438 [23:25<1:43:19, 17.51s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  19%|█▉        | 85/438 [23:25<1:42:50, 17.48s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  19%|█▉        | 85/438 [23:42<1:42:50, 17.48s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  20%|█▉        | 86/438 [23:42<1:41:47, 17.35s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  20%|█▉        | 86/438 [23:59<1:41:47, 17.35s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  20%|█▉        | 87/438 [23:59<1:40:34, 17.19s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  20%|█▉        | 87/438 [24:16<1:40:34, 17.19s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  20%|██        | 88/438 [24:16<1:39:38, 17.08s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  20%|██        | 88/438 [24:32<1:39:38, 17.08s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  20%|██        | 89/438 [24:32<1:38:21, 16.91s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  20%|██        | 89/438 [24:49<1:38:21, 16.91s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  21%|██        | 90/438 [24:49<1:37:43, 16.85s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  21%|██        | 90/438 [25:06<1:37:43, 16.85s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  21%|██        | 91/438 [25:06<1:36:46, 16.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  21%|██        | 91/438 [25:22<1:36:46, 16.73s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  21%|██        | 92/438 [25:22<1:36:16, 16.69s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  21%|██        | 92/438 [25:39<1:36:16, 16.69s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  21%|██        | 93/438 [25:39<1:35:36, 16.63s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  21%|██        | 93/438 [25:55<1:35:36, 16.63s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  21%|██▏       | 94/438 [25:55<1:35:18, 16.62s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  21%|██▏       | 94/438 [26:12<1:35:18, 16.62s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  22%|██▏       | 95/438 [26:12<1:35:06, 16.64s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  22%|██▏       | 95/438 [26:29<1:35:06, 16.64s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  22%|██▏       | 96/438 [26:29<1:34:55, 16.65s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  22%|██▏       | 96/438 [26:45<1:34:55, 16.65s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  22%|██▏       | 97/438 [26:45<1:34:46, 16.68s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  22%|██▏       | 97/438 [27:02<1:34:46, 16.68s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  22%|██▏       | 98/438 [27:02<1:34:12, 16.63s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  22%|██▏       | 98/438 [27:19<1:34:12, 16.63s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  23%|██▎       | 99/438 [27:19<1:33:49, 16.61s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  23%|██▎       | 99/438 [27:35<1:33:49, 16.61s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  23%|██▎       | 100/438 [27:35<1:33:35, 16.61s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  23%|██▎       | 100/438 [27:52<1:33:35, 16.61s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  23%|██▎       | 101/438 [27:52<1:33:36, 16.66s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  23%|██▎       | 101/438 [28:08<1:33:36, 16.66s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:  23%|██▎       | 102/438 [28:08<1:32:54, 16.59s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:  23%|██▎       | 102/438 [28:25<1:32:54, 16.59s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  24%|██▎       | 103/438 [28:25<1:32:43, 16.61s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  24%|██▎       | 103/438 [28:42<1:32:43, 16.61s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  24%|██▎       | 104/438 [28:42<1:32:36, 16.64s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  24%|██▎       | 104/438 [28:58<1:32:36, 16.64s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  24%|██▍       | 105/438 [28:58<1:32:12, 16.62s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  24%|██▍       | 105/438 [29:15<1:32:12, 16.62s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  24%|██▍       | 106/438 [29:15<1:31:48, 16.59s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  24%|██▍       | 106/438 [29:31<1:31:48, 16.59s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 4:  24%|██▍       | 107/438 [29:31<1:31:26, 16.58s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 4:  24%|██▍       | 107/438 [29:48<1:31:26, 16.58s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:  25%|██▍       | 108/438 [29:48<1:31:10, 16.58s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:  25%|██▍       | 108/438 [30:04<1:31:10, 16.58s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  25%|██▍       | 109/438 [30:04<1:30:46, 16.55s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  25%|██▍       | 109/438 [30:21<1:30:46, 16.55s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  25%|██▌       | 110/438 [30:21<1:30:36, 16.58s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  25%|██▌       | 110/438 [30:38<1:30:36, 16.58s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  25%|██▌       | 111/438 [30:38<1:30:22, 16.58s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  25%|██▌       | 111/438 [30:54<1:30:22, 16.58s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  26%|██▌       | 112/438 [30:54<1:30:08, 16.59s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  26%|██▌       | 112/438 [31:11<1:30:08, 16.59s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  26%|██▌       | 113/438 [31:11<1:29:53, 16.60s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  26%|██▌       | 113/438 [31:28<1:29:53, 16.60s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  26%|██▌       | 114/438 [31:28<1:29:52, 16.64s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  26%|██▌       | 114/438 [31:46<1:29:52, 16.64s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  26%|██▋       | 115/438 [31:46<1:31:36, 17.02s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  26%|██▋       | 115/438 [32:02<1:31:36, 17.02s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  26%|██▋       | 116/438 [32:02<1:31:10, 16.99s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  26%|██▋       | 116/438 [32:19<1:31:10, 16.99s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  27%|██▋       | 117/438 [32:19<1:30:03, 16.83s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  27%|██▋       | 117/438 [32:36<1:30:03, 16.83s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  27%|██▋       | 118/438 [32:36<1:29:26, 16.77s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  27%|██▋       | 118/438 [32:52<1:29:26, 16.77s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  27%|██▋       | 119/438 [32:52<1:28:57, 16.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  27%|██▋       | 119/438 [33:09<1:28:57, 16.73s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  27%|██▋       | 120/438 [33:09<1:28:13, 16.65s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  27%|██▋       | 120/438 [33:25<1:28:13, 16.65s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:  28%|██▊       | 121/438 [33:25<1:27:56, 16.65s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:  28%|██▊       | 121/438 [33:42<1:27:56, 16.65s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  28%|██▊       | 122/438 [33:42<1:27:34, 16.63s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  28%|██▊       | 122/438 [33:58<1:27:34, 16.63s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  28%|██▊       | 123/438 [33:58<1:27:05, 16.59s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  28%|██▊       | 123/438 [34:15<1:27:05, 16.59s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  28%|██▊       | 124/438 [34:15<1:26:41, 16.57s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  28%|██▊       | 124/438 [34:32<1:26:41, 16.57s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  29%|██▊       | 125/438 [34:32<1:27:34, 16.79s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  29%|██▊       | 125/438 [34:50<1:27:34, 16.79s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  29%|██▉       | 126/438 [34:50<1:29:24, 17.20s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  29%|██▉       | 126/438 [35:07<1:29:24, 17.20s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  29%|██▉       | 127/438 [35:07<1:28:54, 17.15s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  29%|██▉       | 127/438 [35:26<1:28:54, 17.15s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 4:  29%|██▉       | 128/438 [35:26<1:30:20, 17.49s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 4:  29%|██▉       | 128/438 [35:46<1:30:20, 17.49s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  29%|██▉       | 129/438 [35:46<1:34:57, 18.44s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  29%|██▉       | 129/438 [36:04<1:34:57, 18.44s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  30%|██▉       | 130/438 [36:04<1:34:18, 18.37s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  30%|██▉       | 130/438 [36:23<1:34:18, 18.37s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  30%|██▉       | 131/438 [36:23<1:33:33, 18.28s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  30%|██▉       | 131/438 [36:40<1:33:33, 18.28s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  30%|███       | 132/438 [36:40<1:32:35, 18.16s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  30%|███       | 132/438 [36:58<1:32:35, 18.16s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  30%|███       | 133/438 [36:58<1:31:10, 17.94s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  30%|███       | 133/438 [37:16<1:31:10, 17.94s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  31%|███       | 134/438 [37:16<1:31:03, 17.97s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  31%|███       | 134/438 [37:34<1:31:03, 17.97s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  31%|███       | 135/438 [37:34<1:30:27, 17.91s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  31%|███       | 135/438 [37:52<1:30:27, 17.91s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  31%|███       | 136/438 [37:52<1:30:32, 17.99s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  31%|███       | 136/438 [38:10<1:30:32, 17.99s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  31%|███▏      | 137/438 [38:10<1:29:58, 17.94s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  31%|███▏      | 137/438 [38:28<1:29:58, 17.94s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  32%|███▏      | 138/438 [38:28<1:30:29, 18.10s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  32%|███▏      | 138/438 [38:46<1:30:29, 18.10s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  32%|███▏      | 139/438 [38:46<1:29:13, 17.90s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  32%|███▏      | 139/438 [39:03<1:29:13, 17.90s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  32%|███▏      | 140/438 [39:03<1:28:47, 17.88s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  32%|███▏      | 140/438 [39:21<1:28:47, 17.88s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  32%|███▏      | 141/438 [39:21<1:28:34, 17.89s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  32%|███▏      | 141/438 [39:39<1:28:34, 17.89s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  32%|███▏      | 142/438 [39:39<1:28:17, 17.90s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  32%|███▏      | 142/438 [39:57<1:28:17, 17.90s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  33%|███▎      | 143/438 [39:57<1:28:01, 17.90s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  33%|███▎      | 143/438 [40:15<1:28:01, 17.90s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  33%|███▎      | 144/438 [40:15<1:27:45, 17.91s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  33%|███▎      | 144/438 [40:33<1:27:45, 17.91s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  33%|███▎      | 145/438 [40:33<1:27:08, 17.84s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  33%|███▎      | 145/438 [40:51<1:27:08, 17.84s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 4:  33%|███▎      | 146/438 [40:51<1:26:59, 17.88s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 4:  33%|███▎      | 146/438 [41:09<1:26:59, 17.88s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  34%|███▎      | 147/438 [41:09<1:26:58, 17.93s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  34%|███▎      | 147/438 [41:27<1:26:58, 17.93s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  34%|███▍      | 148/438 [41:27<1:26:57, 17.99s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  34%|███▍      | 148/438 [41:45<1:26:57, 17.99s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  34%|███▍      | 149/438 [41:45<1:26:33, 17.97s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  34%|███▍      | 149/438 [42:03<1:26:33, 17.97s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  34%|███▍      | 150/438 [42:03<1:26:50, 18.09s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  34%|███▍      | 150/438 [42:21<1:26:50, 18.09s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  34%|███▍      | 151/438 [42:21<1:26:36, 18.11s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  34%|███▍      | 151/438 [42:39<1:26:36, 18.11s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  35%|███▍      | 152/438 [42:39<1:26:20, 18.11s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  35%|███▍      | 152/438 [42:57<1:26:20, 18.11s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  35%|███▍      | 153/438 [42:57<1:25:36, 18.02s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  35%|███▍      | 153/438 [43:15<1:25:36, 18.02s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  35%|███▌      | 154/438 [43:15<1:25:27, 18.05s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  35%|███▌      | 154/438 [43:35<1:25:27, 18.05s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  35%|███▌      | 155/438 [43:35<1:26:39, 18.37s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  35%|███▌      | 155/438 [43:53<1:26:39, 18.37s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  36%|███▌      | 156/438 [43:53<1:26:54, 18.49s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  36%|███▌      | 156/438 [44:11<1:26:54, 18.49s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  36%|███▌      | 157/438 [44:11<1:26:02, 18.37s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  36%|███▌      | 157/438 [44:29<1:26:02, 18.37s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  36%|███▌      | 158/438 [44:29<1:24:56, 18.20s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  36%|███▌      | 158/438 [44:47<1:24:56, 18.20s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 4:  36%|███▋      | 159/438 [44:47<1:24:31, 18.18s/it, training_loss=0.148]\u001B[A\n",
      "Epoch 4:  36%|███▋      | 159/438 [45:05<1:24:31, 18.18s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  37%|███▋      | 160/438 [45:05<1:24:08, 18.16s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  37%|███▋      | 160/438 [45:23<1:24:08, 18.16s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  37%|███▋      | 161/438 [45:23<1:23:37, 18.11s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  37%|███▋      | 161/438 [45:41<1:23:37, 18.11s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:  37%|███▋      | 162/438 [45:41<1:23:03, 18.06s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:  37%|███▋      | 162/438 [45:59<1:23:03, 18.06s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  37%|███▋      | 163/438 [45:59<1:22:46, 18.06s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  37%|███▋      | 163/438 [46:18<1:22:46, 18.06s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  37%|███▋      | 164/438 [46:18<1:22:36, 18.09s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  37%|███▋      | 164/438 [46:36<1:22:36, 18.09s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 4:  38%|███▊      | 165/438 [46:36<1:22:31, 18.14s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 4:  38%|███▊      | 165/438 [46:54<1:22:31, 18.14s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  38%|███▊      | 166/438 [46:54<1:22:02, 18.10s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  38%|███▊      | 166/438 [47:12<1:22:02, 18.10s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  38%|███▊      | 167/438 [47:12<1:21:55, 18.14s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  38%|███▊      | 167/438 [47:30<1:21:55, 18.14s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  38%|███▊      | 168/438 [47:30<1:21:20, 18.08s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  38%|███▊      | 168/438 [47:48<1:21:20, 18.08s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  39%|███▊      | 169/438 [47:48<1:20:51, 18.03s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  39%|███▊      | 169/438 [48:06<1:20:51, 18.03s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  39%|███▉      | 170/438 [48:06<1:20:34, 18.04s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  39%|███▉      | 170/438 [48:24<1:20:34, 18.04s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:  39%|███▉      | 171/438 [48:24<1:20:06, 18.00s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:  39%|███▉      | 171/438 [48:42<1:20:06, 18.00s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 4:  39%|███▉      | 172/438 [48:42<1:19:31, 17.94s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 4:  39%|███▉      | 172/438 [49:00<1:19:31, 17.94s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  39%|███▉      | 173/438 [49:01<1:20:21, 18.19s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  39%|███▉      | 173/438 [49:19<1:20:21, 18.19s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 4:  40%|███▉      | 174/438 [49:19<1:19:56, 18.17s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 4:  40%|███▉      | 174/438 [49:36<1:19:56, 18.17s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  40%|███▉      | 175/438 [49:36<1:19:05, 18.04s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  40%|███▉      | 175/438 [49:56<1:19:05, 18.04s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  40%|████      | 176/438 [49:56<1:20:37, 18.46s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  40%|████      | 176/438 [50:14<1:20:37, 18.46s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  40%|████      | 177/438 [50:14<1:19:44, 18.33s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  40%|████      | 177/438 [50:31<1:19:44, 18.33s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 4:  41%|████      | 178/438 [50:31<1:18:31, 18.12s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 4:  41%|████      | 178/438 [50:49<1:18:31, 18.12s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  41%|████      | 179/438 [50:49<1:17:29, 17.95s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  41%|████      | 179/438 [51:07<1:17:29, 17.95s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  41%|████      | 180/438 [51:07<1:17:03, 17.92s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  41%|████      | 180/438 [51:25<1:17:03, 17.92s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  41%|████▏     | 181/438 [51:25<1:16:36, 17.89s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  41%|████▏     | 181/438 [51:43<1:16:36, 17.89s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  42%|████▏     | 182/438 [51:43<1:16:56, 18.03s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  42%|████▏     | 182/438 [52:02<1:16:56, 18.03s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  42%|████▏     | 183/438 [52:02<1:17:29, 18.23s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  42%|████▏     | 183/438 [52:20<1:17:29, 18.23s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:  42%|████▏     | 184/438 [52:20<1:17:08, 18.22s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:  42%|████▏     | 184/438 [52:38<1:17:08, 18.22s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:  42%|████▏     | 185/438 [52:38<1:16:31, 18.15s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:  42%|████▏     | 185/438 [52:56<1:16:31, 18.15s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  42%|████▏     | 186/438 [52:56<1:16:12, 18.14s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  42%|████▏     | 186/438 [53:14<1:16:12, 18.14s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  43%|████▎     | 187/438 [53:14<1:15:24, 18.03s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  43%|████▎     | 187/438 [53:31<1:15:24, 18.03s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  43%|████▎     | 188/438 [53:31<1:14:41, 17.93s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  43%|████▎     | 188/438 [53:49<1:14:41, 17.93s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  43%|████▎     | 189/438 [53:49<1:13:53, 17.80s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  43%|████▎     | 189/438 [54:06<1:13:53, 17.80s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  43%|████▎     | 190/438 [54:06<1:13:08, 17.70s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  43%|████▎     | 190/438 [54:24<1:13:08, 17.70s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  44%|████▎     | 191/438 [54:24<1:13:03, 17.75s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  44%|████▎     | 191/438 [54:42<1:13:03, 17.75s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  44%|████▍     | 192/438 [54:42<1:12:56, 17.79s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  44%|████▍     | 192/438 [55:00<1:12:56, 17.79s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  44%|████▍     | 193/438 [55:00<1:12:52, 17.85s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  44%|████▍     | 193/438 [55:18<1:12:52, 17.85s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 4:  44%|████▍     | 194/438 [55:18<1:12:28, 17.82s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 4:  44%|████▍     | 194/438 [55:36<1:12:28, 17.82s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  45%|████▍     | 195/438 [55:36<1:12:08, 17.81s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  45%|████▍     | 195/438 [55:54<1:12:08, 17.81s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  45%|████▍     | 196/438 [55:54<1:12:14, 17.91s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  45%|████▍     | 196/438 [56:12<1:12:14, 17.91s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  45%|████▍     | 197/438 [56:12<1:12:01, 17.93s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  45%|████▍     | 197/438 [56:29<1:12:01, 17.93s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:  45%|████▌     | 198/438 [56:29<1:11:01, 17.76s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:  45%|████▌     | 198/438 [56:47<1:11:01, 17.76s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  45%|████▌     | 199/438 [56:47<1:10:58, 17.82s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  45%|████▌     | 199/438 [57:06<1:10:58, 17.82s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  46%|████▌     | 200/438 [57:06<1:11:18, 17.98s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  46%|████▌     | 200/438 [57:23<1:11:18, 17.98s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  46%|████▌     | 201/438 [57:23<1:10:57, 17.96s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  46%|████▌     | 201/438 [57:41<1:10:57, 17.96s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  46%|████▌     | 202/438 [57:41<1:10:30, 17.92s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  46%|████▌     | 202/438 [57:59<1:10:30, 17.92s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  46%|████▋     | 203/438 [57:59<1:10:14, 17.94s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  46%|████▋     | 203/438 [58:17<1:10:14, 17.94s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  47%|████▋     | 204/438 [58:17<1:09:56, 17.94s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  47%|████▋     | 204/438 [58:36<1:09:56, 17.94s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  47%|████▋     | 205/438 [58:36<1:10:24, 18.13s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  47%|████▋     | 205/438 [58:53<1:10:24, 18.13s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  47%|████▋     | 206/438 [58:53<1:09:35, 18.00s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  47%|████▋     | 206/438 [59:12<1:09:35, 18.00s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  47%|████▋     | 207/438 [59:12<1:09:24, 18.03s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  47%|████▋     | 207/438 [59:30<1:09:24, 18.03s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:  47%|████▋     | 208/438 [59:30<1:09:06, 18.03s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:  47%|████▋     | 208/438 [59:48<1:09:06, 18.03s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:  48%|████▊     | 209/438 [59:48<1:08:49, 18.03s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:  48%|████▊     | 209/438 [1:00:06<1:08:49, 18.03s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  48%|████▊     | 210/438 [1:00:06<1:08:31, 18.03s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  48%|████▊     | 210/438 [1:00:24<1:08:31, 18.03s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  48%|████▊     | 211/438 [1:00:24<1:08:26, 18.09s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  48%|████▊     | 211/438 [1:00:42<1:08:26, 18.09s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  48%|████▊     | 212/438 [1:00:42<1:08:16, 18.13s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  48%|████▊     | 212/438 [1:01:00<1:08:16, 18.13s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  49%|████▊     | 213/438 [1:01:00<1:07:29, 18.00s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  49%|████▊     | 213/438 [1:01:17<1:07:29, 18.00s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  49%|████▉     | 214/438 [1:01:17<1:06:51, 17.91s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  49%|████▉     | 214/438 [1:01:35<1:06:51, 17.91s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  49%|████▉     | 215/438 [1:01:35<1:06:04, 17.78s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  49%|████▉     | 215/438 [1:01:53<1:06:04, 17.78s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  49%|████▉     | 216/438 [1:01:53<1:06:21, 17.93s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  49%|████▉     | 216/438 [1:02:11<1:06:21, 17.93s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  50%|████▉     | 217/438 [1:02:11<1:06:18, 18.00s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  50%|████▉     | 217/438 [1:02:29<1:06:18, 18.00s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  50%|████▉     | 218/438 [1:02:29<1:06:00, 18.00s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  50%|████▉     | 218/438 [1:02:47<1:06:00, 18.00s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  50%|█████     | 219/438 [1:02:47<1:05:31, 17.95s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  50%|█████     | 219/438 [1:03:05<1:05:31, 17.95s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  50%|█████     | 220/438 [1:03:05<1:05:15, 17.96s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  50%|█████     | 220/438 [1:03:23<1:05:15, 17.96s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  50%|█████     | 221/438 [1:03:23<1:05:05, 18.00s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  50%|█████     | 221/438 [1:03:41<1:05:05, 18.00s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  51%|█████     | 222/438 [1:03:41<1:04:44, 17.98s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  51%|█████     | 222/438 [1:03:59<1:04:44, 17.98s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  51%|█████     | 223/438 [1:03:59<1:04:10, 17.91s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  51%|█████     | 223/438 [1:04:17<1:04:10, 17.91s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  51%|█████     | 224/438 [1:04:17<1:03:41, 17.86s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  51%|█████     | 224/438 [1:04:35<1:03:41, 17.86s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  51%|█████▏    | 225/438 [1:04:35<1:03:27, 17.88s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  51%|█████▏    | 225/438 [1:04:54<1:03:27, 17.88s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  52%|█████▏    | 226/438 [1:04:54<1:04:43, 18.32s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  52%|█████▏    | 226/438 [1:05:13<1:04:43, 18.32s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  52%|█████▏    | 227/438 [1:05:13<1:05:14, 18.55s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  52%|█████▏    | 227/438 [1:05:31<1:05:14, 18.55s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  52%|█████▏    | 228/438 [1:05:31<1:04:08, 18.33s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  52%|█████▏    | 228/438 [1:05:49<1:04:08, 18.33s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  52%|█████▏    | 229/438 [1:05:49<1:03:30, 18.23s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  52%|█████▏    | 229/438 [1:06:07<1:03:30, 18.23s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  53%|█████▎    | 230/438 [1:06:07<1:02:52, 18.14s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  53%|█████▎    | 230/438 [1:06:25<1:02:52, 18.14s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  53%|█████▎    | 231/438 [1:06:25<1:02:24, 18.09s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  53%|█████▎    | 231/438 [1:06:43<1:02:24, 18.09s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  53%|█████▎    | 232/438 [1:06:43<1:02:06, 18.09s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  53%|█████▎    | 232/438 [1:07:01<1:02:06, 18.09s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  53%|█████▎    | 233/438 [1:07:01<1:01:44, 18.07s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  53%|█████▎    | 233/438 [1:07:19<1:01:44, 18.07s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  53%|█████▎    | 234/438 [1:07:19<1:01:23, 18.06s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  53%|█████▎    | 234/438 [1:07:37<1:01:23, 18.06s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:  54%|█████▎    | 235/438 [1:07:37<1:01:06, 18.06s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:  54%|█████▎    | 235/438 [1:07:55<1:01:06, 18.06s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  54%|█████▍    | 236/438 [1:07:55<1:00:19, 17.92s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  54%|█████▍    | 236/438 [1:08:13<1:00:19, 17.92s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  54%|█████▍    | 237/438 [1:08:13<1:00:15, 17.99s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  54%|█████▍    | 237/438 [1:08:31<1:00:15, 17.99s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  54%|█████▍    | 238/438 [1:08:31<1:00:07, 18.04s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  54%|█████▍    | 238/438 [1:08:49<1:00:07, 18.04s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  55%|█████▍    | 239/438 [1:08:49<59:51, 18.05s/it, training_loss=0.128]  \u001B[A\n",
      "Epoch 4:  55%|█████▍    | 239/438 [1:09:07<59:51, 18.05s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  55%|█████▍    | 240/438 [1:09:07<59:40, 18.08s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  55%|█████▍    | 240/438 [1:09:25<59:40, 18.08s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  55%|█████▌    | 241/438 [1:09:25<59:19, 18.07s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  55%|█████▌    | 241/438 [1:09:43<59:19, 18.07s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:  55%|█████▌    | 242/438 [1:09:43<58:53, 18.03s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:  55%|█████▌    | 242/438 [1:10:02<58:53, 18.03s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  55%|█████▌    | 243/438 [1:10:02<58:55, 18.13s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  55%|█████▌    | 243/438 [1:10:19<58:55, 18.13s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:  56%|█████▌    | 244/438 [1:10:19<58:07, 17.97s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:  56%|█████▌    | 244/438 [1:10:37<58:07, 17.97s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  56%|█████▌    | 245/438 [1:10:37<57:30, 17.88s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  56%|█████▌    | 245/438 [1:10:55<57:30, 17.88s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:  56%|█████▌    | 246/438 [1:10:55<57:07, 17.85s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:  56%|█████▌    | 246/438 [1:11:13<57:07, 17.85s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 4:  56%|█████▋    | 247/438 [1:11:13<56:55, 17.88s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 4:  56%|█████▋    | 247/438 [1:11:30<56:55, 17.88s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  57%|█████▋    | 248/438 [1:11:30<56:32, 17.86s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  57%|█████▋    | 248/438 [1:11:49<56:32, 17.86s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  57%|█████▋    | 249/438 [1:11:49<56:48, 18.04s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  57%|█████▋    | 249/438 [1:12:07<56:48, 18.04s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  57%|█████▋    | 250/438 [1:12:07<56:37, 18.07s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  57%|█████▋    | 250/438 [1:12:24<56:37, 18.07s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  57%|█████▋    | 251/438 [1:12:24<55:42, 17.87s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  57%|█████▋    | 251/438 [1:12:42<55:42, 17.87s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  58%|█████▊    | 252/438 [1:12:42<55:31, 17.91s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  58%|█████▊    | 252/438 [1:13:00<55:31, 17.91s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  58%|█████▊    | 253/438 [1:13:00<55:20, 17.95s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  58%|█████▊    | 253/438 [1:13:18<55:20, 17.95s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  58%|█████▊    | 254/438 [1:13:18<55:01, 17.94s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  58%|█████▊    | 254/438 [1:13:36<55:01, 17.94s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  58%|█████▊    | 255/438 [1:13:36<54:44, 17.95s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  58%|█████▊    | 255/438 [1:13:54<54:44, 17.95s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  58%|█████▊    | 256/438 [1:13:54<54:26, 17.95s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  58%|█████▊    | 256/438 [1:14:12<54:26, 17.95s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 4:  59%|█████▊    | 257/438 [1:14:12<54:05, 17.93s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 4:  59%|█████▊    | 257/438 [1:14:29<54:05, 17.93s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  59%|█████▉    | 258/438 [1:14:29<53:07, 17.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  59%|█████▉    | 258/438 [1:14:46<53:07, 17.71s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:  59%|█████▉    | 259/438 [1:14:46<51:47, 17.36s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:  59%|█████▉    | 259/438 [1:15:02<51:47, 17.36s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  59%|█████▉    | 260/438 [1:15:02<50:45, 17.11s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  59%|█████▉    | 260/438 [1:15:19<50:45, 17.11s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  60%|█████▉    | 261/438 [1:15:19<49:49, 16.89s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  60%|█████▉    | 261/438 [1:15:35<49:49, 16.89s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  60%|█████▉    | 262/438 [1:15:35<49:13, 16.78s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  60%|█████▉    | 262/438 [1:15:52<49:13, 16.78s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  60%|██████    | 263/438 [1:15:52<48:36, 16.66s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  60%|██████    | 263/438 [1:16:08<48:36, 16.66s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  60%|██████    | 264/438 [1:16:08<48:20, 16.67s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  60%|██████    | 264/438 [1:16:25<48:20, 16.67s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  61%|██████    | 265/438 [1:16:25<48:13, 16.73s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  61%|██████    | 265/438 [1:16:41<48:13, 16.73s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  61%|██████    | 266/438 [1:16:41<47:34, 16.60s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  61%|██████    | 266/438 [1:16:58<47:34, 16.60s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  61%|██████    | 267/438 [1:16:58<47:19, 16.60s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  61%|██████    | 267/438 [1:17:15<47:19, 16.60s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  61%|██████    | 268/438 [1:17:15<46:52, 16.55s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  61%|██████    | 268/438 [1:17:31<46:52, 16.55s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  61%|██████▏   | 269/438 [1:17:31<46:25, 16.48s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  61%|██████▏   | 269/438 [1:17:47<46:25, 16.48s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  62%|██████▏   | 270/438 [1:17:47<46:16, 16.53s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  62%|██████▏   | 270/438 [1:18:04<46:16, 16.53s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  62%|██████▏   | 271/438 [1:18:04<45:52, 16.48s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  62%|██████▏   | 271/438 [1:18:20<45:52, 16.48s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  62%|██████▏   | 272/438 [1:18:20<45:35, 16.48s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  62%|██████▏   | 272/438 [1:18:37<45:35, 16.48s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  62%|██████▏   | 273/438 [1:18:37<45:47, 16.65s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  62%|██████▏   | 273/438 [1:18:54<45:47, 16.65s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  63%|██████▎   | 274/438 [1:18:54<45:34, 16.68s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  63%|██████▎   | 274/438 [1:19:11<45:34, 16.68s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  63%|██████▎   | 275/438 [1:19:11<45:18, 16.68s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  63%|██████▎   | 275/438 [1:19:27<45:18, 16.68s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  63%|██████▎   | 276/438 [1:19:27<45:02, 16.68s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  63%|██████▎   | 276/438 [1:19:44<45:02, 16.68s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  63%|██████▎   | 277/438 [1:19:44<44:35, 16.62s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  63%|██████▎   | 277/438 [1:20:01<44:35, 16.62s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  63%|██████▎   | 278/438 [1:20:01<45:00, 16.88s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  63%|██████▎   | 278/438 [1:20:18<45:00, 16.88s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  64%|██████▎   | 279/438 [1:20:18<44:34, 16.82s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  64%|██████▎   | 279/438 [1:20:35<44:34, 16.82s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  64%|██████▍   | 280/438 [1:20:35<43:58, 16.70s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  64%|██████▍   | 280/438 [1:20:51<43:58, 16.70s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  64%|██████▍   | 281/438 [1:20:51<43:37, 16.67s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  64%|██████▍   | 281/438 [1:21:08<43:37, 16.67s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  64%|██████▍   | 282/438 [1:21:08<43:16, 16.64s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  64%|██████▍   | 282/438 [1:21:24<43:16, 16.64s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:  65%|██████▍   | 283/438 [1:21:24<42:51, 16.59s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:  65%|██████▍   | 283/438 [1:21:41<42:51, 16.59s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 4:  65%|██████▍   | 284/438 [1:21:41<42:34, 16.59s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 4:  65%|██████▍   | 284/438 [1:21:57<42:34, 16.59s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  65%|██████▌   | 285/438 [1:21:57<42:14, 16.57s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  65%|██████▌   | 285/438 [1:22:14<42:14, 16.57s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  65%|██████▌   | 286/438 [1:22:14<41:59, 16.58s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  65%|██████▌   | 286/438 [1:22:30<41:59, 16.58s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 4:  66%|██████▌   | 287/438 [1:22:30<41:39, 16.55s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 4:  66%|██████▌   | 287/438 [1:22:47<41:39, 16.55s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  66%|██████▌   | 288/438 [1:22:47<41:25, 16.57s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  66%|██████▌   | 288/438 [1:23:03<41:25, 16.57s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  66%|██████▌   | 289/438 [1:23:03<40:59, 16.51s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  66%|██████▌   | 289/438 [1:23:20<40:59, 16.51s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  66%|██████▌   | 290/438 [1:23:20<40:43, 16.51s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  66%|██████▌   | 290/438 [1:23:37<40:43, 16.51s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  66%|██████▋   | 291/438 [1:23:37<40:38, 16.59s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  66%|██████▋   | 291/438 [1:23:53<40:38, 16.59s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:  67%|██████▋   | 292/438 [1:23:53<40:19, 16.57s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:  67%|██████▋   | 292/438 [1:24:10<40:19, 16.57s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  67%|██████▋   | 293/438 [1:24:10<40:06, 16.59s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  67%|██████▋   | 293/438 [1:24:27<40:06, 16.59s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  67%|██████▋   | 294/438 [1:24:27<40:01, 16.68s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  67%|██████▋   | 294/438 [1:24:43<40:01, 16.68s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  67%|██████▋   | 295/438 [1:24:43<39:38, 16.63s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  67%|██████▋   | 295/438 [1:25:00<39:38, 16.63s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  68%|██████▊   | 296/438 [1:25:00<39:20, 16.63s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  68%|██████▊   | 296/438 [1:25:16<39:20, 16.63s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  68%|██████▊   | 297/438 [1:25:16<39:01, 16.61s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  68%|██████▊   | 297/438 [1:25:33<39:01, 16.61s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  68%|██████▊   | 298/438 [1:25:33<38:40, 16.58s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  68%|██████▊   | 298/438 [1:25:49<38:40, 16.58s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  68%|██████▊   | 299/438 [1:25:49<38:11, 16.49s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  68%|██████▊   | 299/438 [1:26:06<38:11, 16.49s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  68%|██████▊   | 300/438 [1:26:06<37:55, 16.49s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  68%|██████▊   | 300/438 [1:26:22<37:55, 16.49s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  69%|██████▊   | 301/438 [1:26:22<37:42, 16.52s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  69%|██████▊   | 301/438 [1:26:39<37:42, 16.52s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  69%|██████▉   | 302/438 [1:26:39<37:21, 16.48s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  69%|██████▉   | 302/438 [1:26:55<37:21, 16.48s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  69%|██████▉   | 303/438 [1:26:55<37:00, 16.45s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  69%|██████▉   | 303/438 [1:27:12<37:00, 16.45s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  69%|██████▉   | 304/438 [1:27:12<36:45, 16.46s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  69%|██████▉   | 304/438 [1:27:28<36:45, 16.46s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  70%|██████▉   | 305/438 [1:27:28<36:33, 16.49s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  70%|██████▉   | 305/438 [1:27:44<36:33, 16.49s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  70%|██████▉   | 306/438 [1:27:44<36:13, 16.47s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  70%|██████▉   | 306/438 [1:28:01<36:13, 16.47s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  70%|███████   | 307/438 [1:28:01<35:55, 16.46s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  70%|███████   | 307/438 [1:28:17<35:55, 16.46s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 4:  70%|███████   | 308/438 [1:28:17<35:38, 16.45s/it, training_loss=0.110]\u001B[A\n",
      "Epoch 4:  70%|███████   | 308/438 [1:28:34<35:38, 16.45s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 4:  71%|███████   | 309/438 [1:28:34<35:22, 16.45s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 4:  71%|███████   | 309/438 [1:28:50<35:22, 16.45s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 4:  71%|███████   | 310/438 [1:28:50<35:05, 16.45s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 4:  71%|███████   | 310/438 [1:29:07<35:05, 16.45s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  71%|███████   | 311/438 [1:29:07<34:47, 16.43s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  71%|███████   | 311/438 [1:29:23<34:47, 16.43s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  71%|███████   | 312/438 [1:29:23<34:33, 16.46s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  71%|███████   | 312/438 [1:29:40<34:33, 16.46s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  71%|███████▏  | 313/438 [1:29:40<34:12, 16.42s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  71%|███████▏  | 313/438 [1:29:56<34:12, 16.42s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  72%|███████▏  | 314/438 [1:29:56<34:01, 16.46s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  72%|███████▏  | 314/438 [1:30:12<34:01, 16.46s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  72%|███████▏  | 315/438 [1:30:12<33:43, 16.45s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  72%|███████▏  | 315/438 [1:30:29<33:43, 16.45s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  72%|███████▏  | 316/438 [1:30:29<33:28, 16.46s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  72%|███████▏  | 316/438 [1:30:45<33:28, 16.46s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  72%|███████▏  | 317/438 [1:30:45<33:13, 16.47s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  72%|███████▏  | 317/438 [1:31:02<33:13, 16.47s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  73%|███████▎  | 318/438 [1:31:02<32:57, 16.48s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  73%|███████▎  | 318/438 [1:31:19<32:57, 16.48s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  73%|███████▎  | 319/438 [1:31:19<32:45, 16.51s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  73%|███████▎  | 319/438 [1:31:35<32:45, 16.51s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  73%|███████▎  | 320/438 [1:31:35<32:29, 16.52s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  73%|███████▎  | 320/438 [1:31:53<32:29, 16.52s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  73%|███████▎  | 321/438 [1:31:53<32:59, 16.92s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  73%|███████▎  | 321/438 [1:32:10<32:59, 16.92s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  74%|███████▎  | 322/438 [1:32:10<32:32, 16.83s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  74%|███████▎  | 322/438 [1:32:26<32:32, 16.83s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  74%|███████▎  | 323/438 [1:32:26<32:05, 16.74s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  74%|███████▎  | 323/438 [1:32:43<32:05, 16.74s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  74%|███████▍  | 324/438 [1:32:43<31:45, 16.71s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  74%|███████▍  | 324/438 [1:32:59<31:45, 16.71s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  74%|███████▍  | 325/438 [1:32:59<31:26, 16.69s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  74%|███████▍  | 325/438 [1:33:16<31:26, 16.69s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 4:  74%|███████▍  | 326/438 [1:33:16<31:01, 16.62s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 4:  74%|███████▍  | 326/438 [1:33:33<31:01, 16.62s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  75%|███████▍  | 327/438 [1:33:33<30:48, 16.65s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  75%|███████▍  | 327/438 [1:33:49<30:48, 16.65s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  75%|███████▍  | 328/438 [1:33:49<30:34, 16.68s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  75%|███████▍  | 328/438 [1:34:06<30:34, 16.68s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  75%|███████▌  | 329/438 [1:34:06<30:19, 16.70s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  75%|███████▌  | 329/438 [1:34:22<30:19, 16.70s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 4:  75%|███████▌  | 330/438 [1:34:22<29:55, 16.62s/it, training_loss=0.114]\u001B[A\n",
      "Epoch 4:  75%|███████▌  | 330/438 [1:34:39<29:55, 16.62s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  76%|███████▌  | 331/438 [1:34:39<29:32, 16.56s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  76%|███████▌  | 331/438 [1:34:55<29:32, 16.56s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  76%|███████▌  | 332/438 [1:34:55<29:11, 16.52s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  76%|███████▌  | 332/438 [1:35:13<29:11, 16.52s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  76%|███████▌  | 333/438 [1:35:13<29:42, 16.97s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  76%|███████▌  | 333/438 [1:35:30<29:42, 16.97s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  76%|███████▋  | 334/438 [1:35:30<29:11, 16.84s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  76%|███████▋  | 334/438 [1:35:47<29:11, 16.84s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  76%|███████▋  | 335/438 [1:35:47<28:50, 16.80s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  76%|███████▋  | 335/438 [1:36:03<28:50, 16.80s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  77%|███████▋  | 336/438 [1:36:03<28:26, 16.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  77%|███████▋  | 336/438 [1:36:20<28:26, 16.73s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  77%|███████▋  | 337/438 [1:36:20<28:07, 16.71s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  77%|███████▋  | 337/438 [1:36:36<28:07, 16.71s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  77%|███████▋  | 338/438 [1:36:36<27:47, 16.67s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  77%|███████▋  | 338/438 [1:36:53<27:47, 16.67s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  77%|███████▋  | 339/438 [1:36:53<27:29, 16.66s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  77%|███████▋  | 339/438 [1:37:10<27:29, 16.66s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:  78%|███████▊  | 340/438 [1:37:10<27:11, 16.65s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 4:  78%|███████▊  | 340/438 [1:37:26<27:11, 16.65s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  78%|███████▊  | 341/438 [1:37:26<26:49, 16.59s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  78%|███████▊  | 341/438 [1:37:43<26:49, 16.59s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  78%|███████▊  | 342/438 [1:37:43<26:30, 16.57s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  78%|███████▊  | 342/438 [1:37:59<26:30, 16.57s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  78%|███████▊  | 343/438 [1:37:59<26:11, 16.54s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  78%|███████▊  | 343/438 [1:38:16<26:11, 16.54s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  79%|███████▊  | 344/438 [1:38:16<25:55, 16.54s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  79%|███████▊  | 344/438 [1:38:33<25:55, 16.54s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  79%|███████▉  | 345/438 [1:38:33<26:00, 16.78s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  79%|███████▉  | 345/438 [1:38:50<26:00, 16.78s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  79%|███████▉  | 346/438 [1:38:50<25:38, 16.72s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  79%|███████▉  | 346/438 [1:39:06<25:38, 16.72s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  79%|███████▉  | 347/438 [1:39:06<25:16, 16.67s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  79%|███████▉  | 347/438 [1:39:23<25:16, 16.67s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  79%|███████▉  | 348/438 [1:39:23<24:55, 16.61s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  79%|███████▉  | 348/438 [1:39:39<24:55, 16.61s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  80%|███████▉  | 349/438 [1:39:39<24:35, 16.58s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  80%|███████▉  | 349/438 [1:39:56<24:35, 16.58s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  80%|███████▉  | 350/438 [1:39:56<24:14, 16.53s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  80%|███████▉  | 350/438 [1:40:12<24:14, 16.53s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  80%|████████  | 351/438 [1:40:12<23:57, 16.52s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  80%|████████  | 351/438 [1:40:29<23:57, 16.52s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 4:  80%|████████  | 352/438 [1:40:29<23:40, 16.51s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 4:  80%|████████  | 352/438 [1:40:45<23:40, 16.51s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:  81%|████████  | 353/438 [1:40:45<23:22, 16.51s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:  81%|████████  | 353/438 [1:41:02<23:22, 16.51s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  81%|████████  | 354/438 [1:41:02<23:05, 16.50s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  81%|████████  | 354/438 [1:41:18<23:05, 16.50s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  81%|████████  | 355/438 [1:41:18<22:46, 16.47s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  81%|████████  | 355/438 [1:41:34<22:46, 16.47s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  81%|████████▏ | 356/438 [1:41:34<22:30, 16.46s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  81%|████████▏ | 356/438 [1:41:51<22:30, 16.46s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  82%|████████▏ | 357/438 [1:41:51<22:13, 16.46s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  82%|████████▏ | 357/438 [1:42:07<22:13, 16.46s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  82%|████████▏ | 358/438 [1:42:07<22:00, 16.51s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  82%|████████▏ | 358/438 [1:42:24<22:00, 16.51s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  82%|████████▏ | 359/438 [1:42:24<21:43, 16.49s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  82%|████████▏ | 359/438 [1:42:40<21:43, 16.49s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  82%|████████▏ | 360/438 [1:42:40<21:25, 16.48s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  82%|████████▏ | 360/438 [1:42:57<21:25, 16.48s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  82%|████████▏ | 361/438 [1:42:57<21:10, 16.50s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  82%|████████▏ | 361/438 [1:43:13<21:10, 16.50s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  83%|████████▎ | 362/438 [1:43:13<20:52, 16.48s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  83%|████████▎ | 362/438 [1:43:30<20:52, 16.48s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  83%|████████▎ | 363/438 [1:43:30<20:36, 16.49s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  83%|████████▎ | 363/438 [1:43:46<20:36, 16.49s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 4:  83%|████████▎ | 364/438 [1:43:46<20:21, 16.51s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 4:  83%|████████▎ | 364/438 [1:44:03<20:21, 16.51s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  83%|████████▎ | 365/438 [1:44:03<20:01, 16.46s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  83%|████████▎ | 365/438 [1:44:19<20:01, 16.46s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  84%|████████▎ | 366/438 [1:44:19<19:46, 16.48s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 4:  84%|████████▎ | 366/438 [1:44:36<19:46, 16.48s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  84%|████████▍ | 367/438 [1:44:36<19:30, 16.48s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  84%|████████▍ | 367/438 [1:44:52<19:30, 16.48s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  84%|████████▍ | 368/438 [1:44:52<19:13, 16.48s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  84%|████████▍ | 368/438 [1:45:09<19:13, 16.48s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  84%|████████▍ | 369/438 [1:45:09<18:56, 16.48s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  84%|████████▍ | 369/438 [1:45:25<18:56, 16.48s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  84%|████████▍ | 370/438 [1:45:25<18:43, 16.52s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  84%|████████▍ | 370/438 [1:45:42<18:43, 16.52s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  85%|████████▍ | 371/438 [1:45:42<18:27, 16.52s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  85%|████████▍ | 371/438 [1:45:58<18:27, 16.52s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  85%|████████▍ | 372/438 [1:45:58<18:06, 16.47s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  85%|████████▍ | 372/438 [1:46:15<18:06, 16.47s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  85%|████████▌ | 373/438 [1:46:15<17:51, 16.49s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  85%|████████▌ | 373/438 [1:46:31<17:51, 16.49s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  85%|████████▌ | 374/438 [1:46:31<17:34, 16.48s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  85%|████████▌ | 374/438 [1:46:48<17:34, 16.48s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  86%|████████▌ | 375/438 [1:46:48<17:15, 16.44s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  86%|████████▌ | 375/438 [1:47:04<17:15, 16.44s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  86%|████████▌ | 376/438 [1:47:04<16:57, 16.41s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  86%|████████▌ | 376/438 [1:47:20<16:57, 16.41s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  86%|████████▌ | 377/438 [1:47:20<16:41, 16.42s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  86%|████████▌ | 377/438 [1:47:37<16:41, 16.42s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 4:  86%|████████▋ | 378/438 [1:47:37<16:24, 16.41s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 4:  86%|████████▋ | 378/438 [1:47:53<16:24, 16.41s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  87%|████████▋ | 379/438 [1:47:53<16:09, 16.43s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  87%|████████▋ | 379/438 [1:48:10<16:09, 16.43s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  87%|████████▋ | 380/438 [1:48:10<15:55, 16.47s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  87%|████████▋ | 380/438 [1:48:26<15:55, 16.47s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  87%|████████▋ | 381/438 [1:48:26<15:38, 16.46s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 4:  87%|████████▋ | 381/438 [1:48:43<15:38, 16.46s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  87%|████████▋ | 382/438 [1:48:43<15:31, 16.63s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  87%|████████▋ | 382/438 [1:49:00<15:31, 16.63s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  87%|████████▋ | 383/438 [1:49:00<15:13, 16.60s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 4:  87%|████████▋ | 383/438 [1:49:16<15:13, 16.60s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  88%|████████▊ | 384/438 [1:49:16<14:56, 16.60s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  88%|████████▊ | 384/438 [1:49:33<14:56, 16.60s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  88%|████████▊ | 385/438 [1:49:33<14:37, 16.55s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  88%|████████▊ | 385/438 [1:49:49<14:37, 16.55s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  88%|████████▊ | 386/438 [1:49:49<14:19, 16.53s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  88%|████████▊ | 386/438 [1:50:06<14:19, 16.53s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 4:  88%|████████▊ | 387/438 [1:50:06<14:00, 16.48s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 4:  88%|████████▊ | 387/438 [1:50:24<14:00, 16.48s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  89%|████████▊ | 388/438 [1:50:24<14:05, 16.90s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  89%|████████▊ | 388/438 [1:50:40<14:05, 16.90s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  89%|████████▉ | 389/438 [1:50:40<13:42, 16.79s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  89%|████████▉ | 389/438 [1:50:57<13:42, 16.79s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  89%|████████▉ | 390/438 [1:50:57<13:24, 16.75s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  89%|████████▉ | 390/438 [1:51:14<13:24, 16.75s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  89%|████████▉ | 391/438 [1:51:14<13:08, 16.77s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  89%|████████▉ | 391/438 [1:51:30<13:08, 16.77s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 4:  89%|████████▉ | 392/438 [1:51:30<12:51, 16.78s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 4:  89%|████████▉ | 392/438 [1:51:48<12:51, 16.78s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  90%|████████▉ | 393/438 [1:51:48<12:42, 16.93s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  90%|████████▉ | 393/438 [1:52:04<12:42, 16.93s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  90%|████████▉ | 394/438 [1:52:04<12:20, 16.83s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  90%|████████▉ | 394/438 [1:52:21<12:20, 16.83s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  90%|█████████ | 395/438 [1:52:21<12:00, 16.75s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  90%|█████████ | 395/438 [1:52:37<12:00, 16.75s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  90%|█████████ | 396/438 [1:52:37<11:40, 16.67s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  90%|█████████ | 396/438 [1:52:54<11:40, 16.67s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  91%|█████████ | 397/438 [1:52:54<11:21, 16.61s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  91%|█████████ | 397/438 [1:53:10<11:21, 16.61s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 4:  91%|█████████ | 398/438 [1:53:10<11:02, 16.57s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 4:  91%|█████████ | 398/438 [1:53:27<11:02, 16.57s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  91%|█████████ | 399/438 [1:53:27<10:45, 16.56s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  91%|█████████ | 399/438 [1:53:43<10:45, 16.56s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 4:  91%|█████████▏| 400/438 [1:53:43<10:29, 16.56s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 4:  91%|█████████▏| 400/438 [1:54:00<10:29, 16.56s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  92%|█████████▏| 401/438 [1:54:00<10:11, 16.52s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4:  92%|█████████▏| 401/438 [1:54:16<10:11, 16.52s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 4:  92%|█████████▏| 402/438 [1:54:16<09:54, 16.52s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 4:  92%|█████████▏| 402/438 [1:54:33<09:54, 16.52s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  92%|█████████▏| 403/438 [1:54:33<09:38, 16.52s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  92%|█████████▏| 403/438 [1:54:49<09:38, 16.52s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  92%|█████████▏| 404/438 [1:54:49<09:21, 16.50s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  92%|█████████▏| 404/438 [1:55:06<09:21, 16.50s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 4:  92%|█████████▏| 405/438 [1:55:06<09:06, 16.55s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 4:  92%|█████████▏| 405/438 [1:55:22<09:06, 16.55s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 4:  93%|█████████▎| 406/438 [1:55:22<08:49, 16.54s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 4:  93%|█████████▎| 406/438 [1:55:39<08:49, 16.54s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  93%|█████████▎| 407/438 [1:55:39<08:32, 16.53s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  93%|█████████▎| 407/438 [1:55:55<08:32, 16.53s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  93%|█████████▎| 408/438 [1:55:55<08:15, 16.51s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  93%|█████████▎| 408/438 [1:56:12<08:15, 16.51s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  93%|█████████▎| 409/438 [1:56:12<07:58, 16.50s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 4:  93%|█████████▎| 409/438 [1:56:28<07:58, 16.50s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 4:  94%|█████████▎| 410/438 [1:56:28<07:42, 16.52s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 4:  94%|█████████▎| 410/438 [1:56:45<07:42, 16.52s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  94%|█████████▍| 411/438 [1:56:45<07:25, 16.52s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 4:  94%|█████████▍| 411/438 [1:57:01<07:25, 16.52s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  94%|█████████▍| 412/438 [1:57:01<07:09, 16.51s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 4:  94%|█████████▍| 412/438 [1:57:18<07:09, 16.51s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  94%|█████████▍| 413/438 [1:57:18<06:52, 16.52s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  94%|█████████▍| 413/438 [1:57:34<06:52, 16.52s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  95%|█████████▍| 414/438 [1:57:34<06:36, 16.51s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  95%|█████████▍| 414/438 [1:57:51<06:36, 16.51s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:  95%|█████████▍| 415/438 [1:57:51<06:19, 16.51s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 4:  95%|█████████▍| 415/438 [1:58:08<06:19, 16.51s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  95%|█████████▍| 416/438 [1:58:08<06:03, 16.53s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  95%|█████████▍| 416/438 [1:58:24<06:03, 16.53s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  95%|█████████▌| 417/438 [1:58:24<05:47, 16.52s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 4:  95%|█████████▌| 417/438 [1:58:41<05:47, 16.52s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  95%|█████████▌| 418/438 [1:58:41<05:30, 16.53s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 4:  95%|█████████▌| 418/438 [1:58:57<05:30, 16.53s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  96%|█████████▌| 419/438 [1:58:57<05:14, 16.56s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 4:  96%|█████████▌| 419/438 [1:59:14<05:14, 16.56s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  96%|█████████▌| 420/438 [1:59:14<04:57, 16.53s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  96%|█████████▌| 420/438 [1:59:30<04:57, 16.53s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  96%|█████████▌| 421/438 [1:59:30<04:41, 16.54s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  96%|█████████▌| 421/438 [1:59:47<04:41, 16.54s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  96%|█████████▋| 422/438 [1:59:47<04:25, 16.59s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  96%|█████████▋| 422/438 [2:00:04<04:25, 16.59s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:  97%|█████████▋| 423/438 [2:00:04<04:09, 16.61s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 4:  97%|█████████▋| 423/438 [2:00:20<04:09, 16.61s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 4:  97%|█████████▋| 424/438 [2:00:20<03:52, 16.58s/it, training_loss=0.145]\u001B[A\n",
      "Epoch 4:  97%|█████████▋| 424/438 [2:00:37<03:52, 16.58s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  97%|█████████▋| 425/438 [2:00:37<03:35, 16.57s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 4:  97%|█████████▋| 425/438 [2:00:53<03:35, 16.57s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  97%|█████████▋| 426/438 [2:00:53<03:18, 16.57s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 4:  97%|█████████▋| 426/438 [2:01:10<03:18, 16.57s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  97%|█████████▋| 427/438 [2:01:10<03:01, 16.54s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4:  97%|█████████▋| 427/438 [2:01:26<03:01, 16.54s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  98%|█████████▊| 428/438 [2:01:26<02:45, 16.53s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 4:  98%|█████████▊| 428/438 [2:01:43<02:45, 16.53s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  98%|█████████▊| 429/438 [2:01:43<02:28, 16.55s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 4:  98%|█████████▊| 429/438 [2:01:59<02:28, 16.55s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  98%|█████████▊| 430/438 [2:01:59<02:11, 16.49s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  98%|█████████▊| 430/438 [2:02:16<02:11, 16.49s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  98%|█████████▊| 431/438 [2:02:16<01:55, 16.56s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 4:  98%|█████████▊| 431/438 [2:02:32<01:55, 16.56s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  99%|█████████▊| 432/438 [2:02:32<01:39, 16.56s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 4:  99%|█████████▊| 432/438 [2:02:49<01:39, 16.56s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  99%|█████████▉| 433/438 [2:02:49<01:22, 16.56s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 4:  99%|█████████▉| 433/438 [2:03:06<01:22, 16.56s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  99%|█████████▉| 434/438 [2:03:06<01:06, 16.55s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 4:  99%|█████████▉| 434/438 [2:03:22<01:06, 16.55s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  99%|█████████▉| 435/438 [2:03:22<00:49, 16.52s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 4:  99%|█████████▉| 435/438 [2:03:39<00:49, 16.52s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4: 100%|█████████▉| 436/438 [2:03:39<00:33, 16.55s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 4: 100%|█████████▉| 436/438 [2:03:55<00:33, 16.55s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4: 100%|█████████▉| 437/438 [2:03:55<00:16, 16.64s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 4: 100%|█████████▉| 437/438 [2:04:09<00:16, 16.64s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 4: 100%|██████████| 438/438 [2:04:09<00:00, 15.82s/it, training_loss=0.115]\u001B[A\n",
      " 60%|██████    | 3/5 [9:17:37<4:48:53, 8666.76s/it]                              \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Trainin loss: 0.38666286608672035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [9:38:04<2:24:30, 8670.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3892127971382851\n",
      "F1 Score (Weighted): 0.02348434924273023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5:   0%|          | 0/438 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 5:   0%|          | 0/438 [00:16<?, ?it/s, training_loss=0.124]\u001B[A\n",
      "Epoch 5:   0%|          | 1/438 [00:16<2:00:57, 16.61s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:   0%|          | 1/438 [00:33<2:00:57, 16.61s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:   0%|          | 2/438 [00:33<2:00:33, 16.59s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:   0%|          | 2/438 [00:49<2:00:33, 16.59s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:   1%|          | 3/438 [00:49<1:59:40, 16.51s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:   1%|          | 3/438 [01:06<1:59:40, 16.51s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:   1%|          | 4/438 [01:06<1:59:26, 16.51s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:   1%|          | 4/438 [01:22<1:59:26, 16.51s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:   1%|          | 5/438 [01:22<1:59:10, 16.51s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:   1%|          | 5/438 [01:39<1:59:10, 16.51s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:   1%|▏         | 6/438 [01:39<1:58:56, 16.52s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:   1%|▏         | 6/438 [01:55<1:58:56, 16.52s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:   2%|▏         | 7/438 [01:55<1:58:53, 16.55s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:   2%|▏         | 7/438 [02:12<1:58:53, 16.55s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:   2%|▏         | 8/438 [02:12<1:58:25, 16.52s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:   2%|▏         | 8/438 [02:28<1:58:25, 16.52s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:   2%|▏         | 9/438 [02:28<1:57:58, 16.50s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:   2%|▏         | 9/438 [02:45<1:57:58, 16.50s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:   2%|▏         | 10/438 [02:45<1:57:46, 16.51s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:   2%|▏         | 10/438 [03:01<1:57:46, 16.51s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:   3%|▎         | 11/438 [03:01<1:57:31, 16.51s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:   3%|▎         | 11/438 [03:18<1:57:31, 16.51s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:   3%|▎         | 12/438 [03:18<1:57:13, 16.51s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:   3%|▎         | 12/438 [03:34<1:57:13, 16.51s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:   3%|▎         | 13/438 [03:34<1:56:43, 16.48s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:   3%|▎         | 13/438 [03:51<1:56:43, 16.48s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:   3%|▎         | 14/438 [03:51<1:57:51, 16.68s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:   3%|▎         | 14/438 [04:10<1:57:51, 16.68s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:   3%|▎         | 15/438 [04:10<2:01:40, 17.26s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:   3%|▎         | 15/438 [04:29<2:01:40, 17.26s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:   4%|▎         | 16/438 [04:29<2:04:22, 17.68s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:   4%|▎         | 16/438 [04:45<2:04:22, 17.68s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:   4%|▍         | 17/438 [04:45<2:01:49, 17.36s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:   4%|▍         | 17/438 [05:02<2:01:49, 17.36s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 5:   4%|▍         | 18/438 [05:02<1:59:31, 17.08s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 5:   4%|▍         | 18/438 [05:18<1:59:31, 17.08s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:   4%|▍         | 19/438 [05:18<1:58:01, 16.90s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:   4%|▍         | 19/438 [05:35<1:58:01, 16.90s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 5:   5%|▍         | 20/438 [05:35<1:56:56, 16.79s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 5:   5%|▍         | 20/438 [05:51<1:56:56, 16.79s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:   5%|▍         | 21/438 [05:51<1:55:58, 16.69s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:   5%|▍         | 21/438 [06:07<1:55:58, 16.69s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:   5%|▌         | 22/438 [06:07<1:55:09, 16.61s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:   5%|▌         | 22/438 [06:24<1:55:09, 16.61s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:   5%|▌         | 23/438 [06:24<1:54:47, 16.60s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:   5%|▌         | 23/438 [06:41<1:54:47, 16.60s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:   5%|▌         | 24/438 [06:41<1:54:31, 16.60s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:   5%|▌         | 24/438 [06:57<1:54:31, 16.60s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:   6%|▌         | 25/438 [06:57<1:54:12, 16.59s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:   6%|▌         | 25/438 [07:14<1:54:12, 16.59s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:   6%|▌         | 26/438 [07:14<1:55:18, 16.79s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:   6%|▌         | 26/438 [07:31<1:55:18, 16.79s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:   6%|▌         | 27/438 [07:31<1:55:05, 16.80s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:   6%|▌         | 27/438 [07:48<1:55:05, 16.80s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:   6%|▋         | 28/438 [07:48<1:54:19, 16.73s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:   6%|▋         | 28/438 [08:04<1:54:19, 16.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:   7%|▋         | 29/438 [08:04<1:53:37, 16.67s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:   7%|▋         | 29/438 [08:21<1:53:37, 16.67s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:   7%|▋         | 30/438 [08:21<1:53:18, 16.66s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:   7%|▋         | 30/438 [08:38<1:53:18, 16.66s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:   7%|▋         | 31/438 [08:38<1:53:06, 16.67s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:   7%|▋         | 31/438 [08:54<1:53:06, 16.67s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:   7%|▋         | 32/438 [08:54<1:52:24, 16.61s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:   7%|▋         | 32/438 [09:11<1:52:24, 16.61s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 5:   8%|▊         | 33/438 [09:11<1:53:19, 16.79s/it, training_loss=0.113]\u001B[A\n",
      "Epoch 5:   8%|▊         | 33/438 [09:28<1:53:19, 16.79s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 5:   8%|▊         | 34/438 [09:28<1:53:10, 16.81s/it, training_loss=0.109]\u001B[A\n",
      "Epoch 5:   8%|▊         | 34/438 [09:45<1:53:10, 16.81s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:   8%|▊         | 35/438 [09:45<1:52:21, 16.73s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:   8%|▊         | 35/438 [10:01<1:52:21, 16.73s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:   8%|▊         | 36/438 [10:01<1:51:46, 16.68s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:   8%|▊         | 36/438 [10:18<1:51:46, 16.68s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:   8%|▊         | 37/438 [10:18<1:51:07, 16.63s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:   8%|▊         | 37/438 [10:35<1:51:07, 16.63s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:   9%|▊         | 38/438 [10:35<1:50:51, 16.63s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:   9%|▊         | 38/438 [10:51<1:50:51, 16.63s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:   9%|▉         | 39/438 [10:51<1:50:32, 16.62s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:   9%|▉         | 39/438 [11:09<1:50:32, 16.62s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 5:   9%|▉         | 40/438 [11:09<1:53:07, 17.05s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 5:   9%|▉         | 40/438 [11:26<1:53:07, 17.05s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:   9%|▉         | 41/438 [11:26<1:52:07, 16.95s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:   9%|▉         | 41/438 [11:42<1:52:07, 16.95s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 5:  10%|▉         | 42/438 [11:42<1:51:08, 16.84s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 5:  10%|▉         | 42/438 [11:59<1:51:08, 16.84s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  10%|▉         | 43/438 [11:59<1:50:27, 16.78s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  10%|▉         | 43/438 [12:16<1:50:27, 16.78s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  10%|█         | 44/438 [12:16<1:49:58, 16.75s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  10%|█         | 44/438 [12:32<1:49:58, 16.75s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  10%|█         | 45/438 [12:32<1:49:17, 16.69s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  10%|█         | 45/438 [12:49<1:49:17, 16.69s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  11%|█         | 46/438 [12:49<1:48:49, 16.66s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  11%|█         | 46/438 [13:06<1:48:49, 16.66s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  11%|█         | 47/438 [13:06<1:48:30, 16.65s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  11%|█         | 47/438 [13:22<1:48:30, 16.65s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 5:  11%|█         | 48/438 [13:22<1:48:02, 16.62s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 5:  11%|█         | 48/438 [13:39<1:48:02, 16.62s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  11%|█         | 49/438 [13:39<1:48:01, 16.66s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  11%|█         | 49/438 [13:56<1:48:01, 16.66s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  11%|█▏        | 50/438 [13:56<1:49:00, 16.86s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  11%|█▏        | 50/438 [14:13<1:49:00, 16.86s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  12%|█▏        | 51/438 [14:13<1:48:15, 16.78s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  12%|█▏        | 51/438 [14:29<1:48:15, 16.78s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  12%|█▏        | 52/438 [14:29<1:47:27, 16.70s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  12%|█▏        | 52/438 [14:46<1:47:27, 16.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  12%|█▏        | 53/438 [14:46<1:46:30, 16.60s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  12%|█▏        | 53/438 [15:02<1:46:30, 16.60s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  12%|█▏        | 54/438 [15:02<1:45:46, 16.53s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  12%|█▏        | 54/438 [15:18<1:45:46, 16.53s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  13%|█▎        | 55/438 [15:18<1:45:21, 16.51s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  13%|█▎        | 55/438 [15:35<1:45:21, 16.51s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  13%|█▎        | 56/438 [15:35<1:45:13, 16.53s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  13%|█▎        | 56/438 [15:51<1:45:13, 16.53s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  13%|█▎        | 57/438 [15:51<1:44:41, 16.49s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  13%|█▎        | 57/438 [16:09<1:44:41, 16.49s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  13%|█▎        | 58/438 [16:09<1:47:06, 16.91s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  13%|█▎        | 58/438 [16:30<1:47:06, 16.91s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 5:  13%|█▎        | 59/438 [16:30<1:53:10, 17.92s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 5:  13%|█▎        | 59/438 [16:49<1:53:10, 17.92s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  14%|█▎        | 60/438 [16:49<1:56:07, 18.43s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  14%|█▎        | 60/438 [17:07<1:56:07, 18.43s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  14%|█▍        | 61/438 [17:07<1:54:07, 18.16s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  14%|█▍        | 61/438 [17:24<1:54:07, 18.16s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  14%|█▍        | 62/438 [17:24<1:52:13, 17.91s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  14%|█▍        | 62/438 [17:41<1:52:13, 17.91s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  14%|█▍        | 63/438 [17:41<1:50:52, 17.74s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  14%|█▍        | 63/438 [17:59<1:50:52, 17.74s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  15%|█▍        | 64/438 [17:59<1:51:08, 17.83s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  15%|█▍        | 64/438 [18:17<1:51:08, 17.83s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  15%|█▍        | 65/438 [18:17<1:50:10, 17.72s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  15%|█▍        | 65/438 [18:34<1:50:10, 17.72s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 5:  15%|█▌        | 66/438 [18:34<1:49:29, 17.66s/it, training_loss=0.149]\u001B[A\n",
      "Epoch 5:  15%|█▌        | 66/438 [18:52<1:49:29, 17.66s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  15%|█▌        | 67/438 [18:52<1:48:23, 17.53s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  15%|█▌        | 67/438 [19:09<1:48:23, 17.53s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  16%|█▌        | 68/438 [19:09<1:47:46, 17.48s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  16%|█▌        | 68/438 [19:27<1:47:46, 17.48s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:  16%|█▌        | 69/438 [19:27<1:48:43, 17.68s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:  16%|█▌        | 69/438 [19:45<1:48:43, 17.68s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  16%|█▌        | 70/438 [19:45<1:49:04, 17.78s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  16%|█▌        | 70/438 [20:03<1:49:04, 17.78s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  16%|█▌        | 71/438 [20:03<1:49:16, 17.87s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  16%|█▌        | 71/438 [20:21<1:49:16, 17.87s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  16%|█▋        | 72/438 [20:21<1:49:24, 17.93s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  16%|█▋        | 72/438 [20:39<1:49:24, 17.93s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  17%|█▋        | 73/438 [20:39<1:49:15, 17.96s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  17%|█▋        | 73/438 [20:58<1:49:15, 17.96s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  17%|█▋        | 74/438 [20:58<1:49:23, 18.03s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  17%|█▋        | 74/438 [21:16<1:49:23, 18.03s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  17%|█▋        | 75/438 [21:16<1:49:00, 18.02s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  17%|█▋        | 75/438 [21:34<1:49:00, 18.02s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  17%|█▋        | 76/438 [21:34<1:48:49, 18.04s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  17%|█▋        | 76/438 [21:52<1:48:49, 18.04s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  18%|█▊        | 77/438 [21:52<1:48:11, 17.98s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  18%|█▊        | 77/438 [22:10<1:48:11, 17.98s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  18%|█▊        | 78/438 [22:10<1:48:56, 18.16s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  18%|█▊        | 78/438 [22:28<1:48:56, 18.16s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  18%|█▊        | 79/438 [22:28<1:48:59, 18.22s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  18%|█▊        | 79/438 [22:46<1:48:59, 18.22s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  18%|█▊        | 80/438 [22:46<1:47:57, 18.09s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  18%|█▊        | 80/438 [23:04<1:47:57, 18.09s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  18%|█▊        | 81/438 [23:04<1:47:19, 18.04s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  18%|█▊        | 81/438 [23:22<1:47:19, 18.04s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  19%|█▊        | 82/438 [23:22<1:47:20, 18.09s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  19%|█▊        | 82/438 [23:41<1:47:20, 18.09s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  19%|█▉        | 83/438 [23:41<1:47:20, 18.14s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  19%|█▉        | 83/438 [23:59<1:47:20, 18.14s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  19%|█▉        | 84/438 [23:59<1:47:21, 18.20s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  19%|█▉        | 84/438 [24:17<1:47:21, 18.20s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  19%|█▉        | 85/438 [24:17<1:47:39, 18.30s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  19%|█▉        | 85/438 [24:36<1:47:39, 18.30s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  20%|█▉        | 86/438 [24:36<1:47:26, 18.31s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  20%|█▉        | 86/438 [24:54<1:47:26, 18.31s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  20%|█▉        | 87/438 [24:54<1:46:33, 18.22s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  20%|█▉        | 87/438 [25:12<1:46:33, 18.22s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  20%|██        | 88/438 [25:12<1:45:21, 18.06s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  20%|██        | 88/438 [25:30<1:45:21, 18.06s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  20%|██        | 89/438 [25:30<1:45:10, 18.08s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  20%|██        | 89/438 [25:47<1:45:10, 18.08s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  21%|██        | 90/438 [25:47<1:44:26, 18.01s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  21%|██        | 90/438 [26:07<1:44:26, 18.01s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  21%|██        | 91/438 [26:07<1:46:18, 18.38s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  21%|██        | 91/438 [26:25<1:46:18, 18.38s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  21%|██        | 92/438 [26:25<1:44:59, 18.21s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  21%|██        | 92/438 [26:42<1:44:59, 18.21s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  21%|██        | 93/438 [26:42<1:44:07, 18.11s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  21%|██        | 93/438 [27:00<1:44:07, 18.11s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  21%|██▏       | 94/438 [27:00<1:43:17, 18.02s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  21%|██▏       | 94/438 [27:19<1:43:17, 18.02s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  22%|██▏       | 95/438 [27:19<1:44:07, 18.22s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  22%|██▏       | 95/438 [27:37<1:44:07, 18.22s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  22%|██▏       | 96/438 [27:37<1:43:00, 18.07s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  22%|██▏       | 96/438 [27:55<1:43:00, 18.07s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  22%|██▏       | 97/438 [27:55<1:42:21, 18.01s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  22%|██▏       | 97/438 [28:12<1:42:21, 18.01s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  22%|██▏       | 98/438 [28:12<1:41:33, 17.92s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  22%|██▏       | 98/438 [28:30<1:41:33, 17.92s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  23%|██▎       | 99/438 [28:30<1:41:17, 17.93s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  23%|██▎       | 99/438 [28:48<1:41:17, 17.93s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  23%|██▎       | 100/438 [28:48<1:41:18, 17.98s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  23%|██▎       | 100/438 [29:06<1:41:18, 17.98s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  23%|██▎       | 101/438 [29:06<1:41:02, 17.99s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  23%|██▎       | 101/438 [29:24<1:41:02, 17.99s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 5:  23%|██▎       | 102/438 [29:24<1:40:18, 17.91s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 5:  23%|██▎       | 102/438 [29:42<1:40:18, 17.91s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  24%|██▎       | 103/438 [29:42<1:40:28, 18.00s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  24%|██▎       | 103/438 [30:00<1:40:28, 18.00s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  24%|██▎       | 104/438 [30:00<1:39:12, 17.82s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  24%|██▎       | 104/438 [30:18<1:39:12, 17.82s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:  24%|██▍       | 105/438 [30:18<1:39:15, 17.88s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:  24%|██▍       | 105/438 [30:36<1:39:15, 17.88s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  24%|██▍       | 106/438 [30:36<1:39:08, 17.92s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  24%|██▍       | 106/438 [30:53<1:39:08, 17.92s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 5:  24%|██▍       | 107/438 [30:53<1:38:14, 17.81s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 5:  24%|██▍       | 107/438 [31:11<1:38:14, 17.81s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  25%|██▍       | 108/438 [31:11<1:38:20, 17.88s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  25%|██▍       | 108/438 [31:29<1:38:20, 17.88s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  25%|██▍       | 109/438 [31:29<1:38:31, 17.97s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  25%|██▍       | 109/438 [31:47<1:38:31, 17.97s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  25%|██▌       | 110/438 [31:47<1:38:19, 17.98s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  25%|██▌       | 110/438 [32:06<1:38:19, 17.98s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:  25%|██▌       | 111/438 [32:06<1:38:27, 18.07s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:  25%|██▌       | 111/438 [32:24<1:38:27, 18.07s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  26%|██▌       | 112/438 [32:24<1:37:51, 18.01s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  26%|██▌       | 112/438 [32:42<1:37:51, 18.01s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  26%|██▌       | 113/438 [32:42<1:37:52, 18.07s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  26%|██▌       | 113/438 [33:00<1:37:52, 18.07s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  26%|██▌       | 114/438 [33:00<1:37:15, 18.01s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  26%|██▌       | 114/438 [33:18<1:37:15, 18.01s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  26%|██▋       | 115/438 [33:18<1:37:02, 18.03s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  26%|██▋       | 115/438 [33:36<1:37:02, 18.03s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 5:  26%|██▋       | 116/438 [33:36<1:37:18, 18.13s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 5:  26%|██▋       | 116/438 [33:54<1:37:18, 18.13s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  27%|██▋       | 117/438 [33:54<1:36:43, 18.08s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  27%|██▋       | 117/438 [34:13<1:36:43, 18.08s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  27%|██▋       | 118/438 [34:13<1:37:04, 18.20s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  27%|██▋       | 118/438 [34:30<1:37:04, 18.20s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  27%|██▋       | 119/438 [34:30<1:35:28, 17.96s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  27%|██▋       | 119/438 [34:48<1:35:28, 17.96s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  27%|██▋       | 120/438 [34:48<1:34:58, 17.92s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  27%|██▋       | 120/438 [35:06<1:34:58, 17.92s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 5:  28%|██▊       | 121/438 [35:06<1:34:38, 17.91s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 5:  28%|██▊       | 121/438 [35:23<1:34:38, 17.91s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 5:  28%|██▊       | 122/438 [35:23<1:34:09, 17.88s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 5:  28%|██▊       | 122/438 [35:41<1:34:09, 17.88s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  28%|██▊       | 123/438 [35:41<1:34:06, 17.92s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  28%|██▊       | 123/438 [35:59<1:34:06, 17.92s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  28%|██▊       | 124/438 [35:59<1:33:32, 17.88s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  28%|██▊       | 124/438 [36:17<1:33:32, 17.88s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  29%|██▊       | 125/438 [36:17<1:33:06, 17.85s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  29%|██▊       | 125/438 [36:35<1:33:06, 17.85s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 5:  29%|██▉       | 126/438 [36:35<1:32:34, 17.80s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 5:  29%|██▉       | 126/438 [36:52<1:32:34, 17.80s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 5:  29%|██▉       | 127/438 [36:52<1:31:43, 17.70s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 5:  29%|██▉       | 127/438 [37:09<1:31:43, 17.70s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  29%|██▉       | 128/438 [37:09<1:30:40, 17.55s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  29%|██▉       | 128/438 [37:27<1:30:40, 17.55s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  29%|██▉       | 129/438 [37:27<1:30:14, 17.52s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  29%|██▉       | 129/438 [37:44<1:30:14, 17.52s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 5:  30%|██▉       | 130/438 [37:44<1:29:29, 17.43s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 5:  30%|██▉       | 130/438 [38:01<1:29:29, 17.43s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  30%|██▉       | 131/438 [38:01<1:29:10, 17.43s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  30%|██▉       | 131/438 [38:19<1:29:10, 17.43s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  30%|███       | 132/438 [38:19<1:28:50, 17.42s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  30%|███       | 132/438 [38:36<1:28:50, 17.42s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  30%|███       | 133/438 [38:36<1:28:37, 17.44s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  30%|███       | 133/438 [38:54<1:28:37, 17.44s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  31%|███       | 134/438 [38:54<1:28:25, 17.45s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  31%|███       | 134/438 [39:12<1:28:25, 17.45s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  31%|███       | 135/438 [39:12<1:29:01, 17.63s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  31%|███       | 135/438 [39:30<1:29:01, 17.63s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 5:  31%|███       | 136/438 [39:30<1:29:00, 17.68s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 5:  31%|███       | 136/438 [39:48<1:29:00, 17.68s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  31%|███▏      | 137/438 [39:48<1:29:07, 17.77s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  31%|███▏      | 137/438 [40:05<1:29:07, 17.77s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 5:  32%|███▏      | 138/438 [40:05<1:28:55, 17.78s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 5:  32%|███▏      | 138/438 [40:23<1:28:55, 17.78s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  32%|███▏      | 139/438 [40:23<1:28:43, 17.80s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  32%|███▏      | 139/438 [40:41<1:28:43, 17.80s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  32%|███▏      | 140/438 [40:41<1:28:45, 17.87s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  32%|███▏      | 140/438 [40:59<1:28:45, 17.87s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  32%|███▏      | 141/438 [40:59<1:28:48, 17.94s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  32%|███▏      | 141/438 [41:18<1:28:48, 17.94s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  32%|███▏      | 142/438 [41:18<1:30:03, 18.26s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  32%|███▏      | 142/438 [41:36<1:30:03, 18.26s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  33%|███▎      | 143/438 [41:36<1:29:11, 18.14s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  33%|███▎      | 143/438 [41:54<1:29:11, 18.14s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  33%|███▎      | 144/438 [41:54<1:28:31, 18.07s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  33%|███▎      | 144/438 [42:12<1:28:31, 18.07s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  33%|███▎      | 145/438 [42:12<1:27:51, 17.99s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  33%|███▎      | 145/438 [42:30<1:27:51, 17.99s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  33%|███▎      | 146/438 [42:30<1:27:03, 17.89s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  33%|███▎      | 146/438 [42:47<1:27:03, 17.89s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  34%|███▎      | 147/438 [42:47<1:26:34, 17.85s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  34%|███▎      | 147/438 [43:05<1:26:34, 17.85s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  34%|███▍      | 148/438 [43:05<1:26:13, 17.84s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  34%|███▍      | 148/438 [43:23<1:26:13, 17.84s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  34%|███▍      | 149/438 [43:23<1:25:54, 17.83s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  34%|███▍      | 149/438 [43:41<1:25:54, 17.83s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  34%|███▍      | 150/438 [43:41<1:25:31, 17.82s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  34%|███▍      | 150/438 [43:59<1:25:31, 17.82s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  34%|███▍      | 151/438 [43:59<1:25:15, 17.83s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  34%|███▍      | 151/438 [44:17<1:25:15, 17.83s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  35%|███▍      | 152/438 [44:17<1:25:08, 17.86s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  35%|███▍      | 152/438 [44:34<1:25:08, 17.86s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  35%|███▍      | 153/438 [44:34<1:24:46, 17.85s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  35%|███▍      | 153/438 [44:52<1:24:46, 17.85s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:  35%|███▌      | 154/438 [44:52<1:23:33, 17.65s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:  35%|███▌      | 154/438 [45:09<1:23:33, 17.65s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  35%|███▌      | 155/438 [45:09<1:22:35, 17.51s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  35%|███▌      | 155/438 [45:26<1:22:35, 17.51s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  36%|███▌      | 156/438 [45:26<1:21:49, 17.41s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  36%|███▌      | 156/438 [45:43<1:21:49, 17.41s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  36%|███▌      | 157/438 [45:43<1:21:23, 17.38s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  36%|███▌      | 157/438 [46:00<1:21:23, 17.38s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 5:  36%|███▌      | 158/438 [46:00<1:20:42, 17.30s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 5:  36%|███▌      | 158/438 [46:18<1:20:42, 17.30s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  36%|███▋      | 159/438 [46:18<1:20:11, 17.25s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  36%|███▋      | 159/438 [46:35<1:20:11, 17.25s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 5:  37%|███▋      | 160/438 [46:35<1:20:01, 17.27s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 5:  37%|███▋      | 160/438 [46:52<1:20:01, 17.27s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:  37%|███▋      | 161/438 [46:52<1:19:50, 17.29s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:  37%|███▋      | 161/438 [47:10<1:19:50, 17.29s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  37%|███▋      | 162/438 [47:10<1:20:13, 17.44s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  37%|███▋      | 162/438 [47:27<1:20:13, 17.44s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  37%|███▋      | 163/438 [47:27<1:19:51, 17.42s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  37%|███▋      | 163/438 [47:45<1:19:51, 17.42s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  37%|███▋      | 164/438 [47:45<1:19:38, 17.44s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  37%|███▋      | 164/438 [48:03<1:19:38, 17.44s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  38%|███▊      | 165/438 [48:03<1:20:04, 17.60s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  38%|███▊      | 165/438 [48:20<1:20:04, 17.60s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 5:  38%|███▊      | 166/438 [48:20<1:19:43, 17.59s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 5:  38%|███▊      | 166/438 [48:38<1:19:43, 17.59s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 5:  38%|███▊      | 167/438 [48:38<1:19:58, 17.71s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 5:  38%|███▊      | 167/438 [48:57<1:19:58, 17.71s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  38%|███▊      | 168/438 [48:57<1:20:15, 17.83s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  38%|███▊      | 168/438 [49:15<1:20:15, 17.83s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  39%|███▊      | 169/438 [49:15<1:20:29, 17.96s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  39%|███▊      | 169/438 [49:33<1:20:29, 17.96s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  39%|███▉      | 170/438 [49:33<1:20:00, 17.91s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  39%|███▉      | 170/438 [49:50<1:20:00, 17.91s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  39%|███▉      | 171/438 [49:50<1:19:39, 17.90s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  39%|███▉      | 171/438 [50:08<1:19:39, 17.90s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  39%|███▉      | 172/438 [50:08<1:19:06, 17.84s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  39%|███▉      | 172/438 [50:26<1:19:06, 17.84s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  39%|███▉      | 173/438 [50:26<1:18:53, 17.86s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  39%|███▉      | 173/438 [50:44<1:18:53, 17.86s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  40%|███▉      | 174/438 [50:44<1:18:57, 17.94s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  40%|███▉      | 174/438 [51:02<1:18:57, 17.94s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  40%|███▉      | 175/438 [51:02<1:18:42, 17.96s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  40%|███▉      | 175/438 [51:20<1:18:42, 17.96s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  40%|████      | 176/438 [51:20<1:18:07, 17.89s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  40%|████      | 176/438 [51:38<1:18:07, 17.89s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  40%|████      | 177/438 [51:38<1:18:06, 17.96s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  40%|████      | 177/438 [51:56<1:18:06, 17.96s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  41%|████      | 178/438 [51:56<1:17:45, 17.94s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  41%|████      | 178/438 [52:14<1:17:45, 17.94s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  41%|████      | 179/438 [52:14<1:17:37, 17.98s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  41%|████      | 179/438 [52:32<1:17:37, 17.98s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  41%|████      | 180/438 [52:32<1:16:45, 17.85s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  41%|████      | 180/438 [52:49<1:16:45, 17.85s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  41%|████▏     | 181/438 [52:49<1:16:08, 17.78s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  41%|████▏     | 181/438 [53:07<1:16:08, 17.78s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  42%|████▏     | 182/438 [53:07<1:16:06, 17.84s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  42%|████▏     | 182/438 [53:25<1:16:06, 17.84s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  42%|████▏     | 183/438 [53:25<1:15:46, 17.83s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  42%|████▏     | 183/438 [53:43<1:15:46, 17.83s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  42%|████▏     | 184/438 [53:43<1:15:53, 17.93s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  42%|████▏     | 184/438 [54:01<1:15:53, 17.93s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  42%|████▏     | 185/438 [54:01<1:15:48, 17.98s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  42%|████▏     | 185/438 [54:19<1:15:48, 17.98s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  42%|████▏     | 186/438 [54:19<1:15:38, 18.01s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  42%|████▏     | 186/438 [54:37<1:15:38, 18.01s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  43%|████▎     | 187/438 [54:37<1:15:04, 17.95s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  43%|████▎     | 187/438 [54:55<1:15:04, 17.95s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  43%|████▎     | 188/438 [54:55<1:14:39, 17.92s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  43%|████▎     | 188/438 [55:13<1:14:39, 17.92s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  43%|████▎     | 189/438 [55:13<1:14:14, 17.89s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  43%|████▎     | 189/438 [55:31<1:14:14, 17.89s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 5:  43%|████▎     | 190/438 [55:31<1:14:04, 17.92s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 5:  43%|████▎     | 190/438 [55:49<1:14:04, 17.92s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  44%|████▎     | 191/438 [55:49<1:13:50, 17.94s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  44%|████▎     | 191/438 [56:07<1:13:50, 17.94s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 5:  44%|████▍     | 192/438 [56:07<1:13:19, 17.88s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 5:  44%|████▍     | 192/438 [56:26<1:13:19, 17.88s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  44%|████▍     | 193/438 [56:26<1:14:55, 18.35s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  44%|████▍     | 193/438 [56:44<1:14:55, 18.35s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  44%|████▍     | 194/438 [56:44<1:14:05, 18.22s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  44%|████▍     | 194/438 [57:02<1:14:05, 18.22s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  45%|████▍     | 195/438 [57:02<1:13:38, 18.18s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  45%|████▍     | 195/438 [57:20<1:13:38, 18.18s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:  45%|████▍     | 196/438 [57:20<1:13:11, 18.15s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:  45%|████▍     | 196/438 [57:38<1:13:11, 18.15s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  45%|████▍     | 197/438 [57:38<1:12:21, 18.01s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  45%|████▍     | 197/438 [57:55<1:12:21, 18.01s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  45%|████▌     | 198/438 [57:55<1:11:45, 17.94s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  45%|████▌     | 198/438 [58:14<1:11:45, 17.94s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  45%|████▌     | 199/438 [58:14<1:11:35, 17.97s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  45%|████▌     | 199/438 [58:32<1:11:35, 17.97s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  46%|████▌     | 200/438 [58:32<1:11:53, 18.12s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  46%|████▌     | 200/438 [58:50<1:11:53, 18.12s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  46%|████▌     | 201/438 [58:50<1:11:23, 18.07s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  46%|████▌     | 201/438 [59:08<1:11:23, 18.07s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 5:  46%|████▌     | 202/438 [59:08<1:11:21, 18.14s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 5:  46%|████▌     | 202/438 [59:27<1:11:21, 18.14s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  46%|████▋     | 203/438 [59:27<1:11:15, 18.19s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  46%|████▋     | 203/438 [59:45<1:11:15, 18.19s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  47%|████▋     | 204/438 [59:45<1:10:43, 18.13s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  47%|████▋     | 204/438 [1:00:03<1:10:43, 18.13s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  47%|████▋     | 205/438 [1:00:03<1:10:18, 18.10s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  47%|████▋     | 205/438 [1:00:21<1:10:18, 18.10s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  47%|████▋     | 206/438 [1:00:21<1:09:51, 18.07s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  47%|████▋     | 206/438 [1:00:39<1:09:51, 18.07s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  47%|████▋     | 207/438 [1:00:39<1:09:45, 18.12s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  47%|████▋     | 207/438 [1:00:57<1:09:45, 18.12s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 5:  47%|████▋     | 208/438 [1:00:57<1:09:11, 18.05s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 5:  47%|████▋     | 208/438 [1:01:15<1:09:11, 18.05s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  48%|████▊     | 209/438 [1:01:15<1:09:04, 18.10s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  48%|████▊     | 209/438 [1:01:33<1:09:04, 18.10s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  48%|████▊     | 210/438 [1:01:33<1:08:40, 18.07s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  48%|████▊     | 210/438 [1:01:51<1:08:40, 18.07s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  48%|████▊     | 211/438 [1:01:51<1:08:13, 18.03s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  48%|████▊     | 211/438 [1:02:10<1:08:13, 18.03s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  48%|████▊     | 212/438 [1:02:10<1:09:16, 18.39s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  48%|████▊     | 212/438 [1:02:28<1:09:16, 18.39s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  49%|████▊     | 213/438 [1:02:28<1:08:50, 18.36s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  49%|████▊     | 213/438 [1:02:47<1:08:50, 18.36s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  49%|████▉     | 214/438 [1:02:47<1:08:25, 18.33s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  49%|████▉     | 214/438 [1:03:05<1:08:25, 18.33s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:  49%|████▉     | 215/438 [1:03:05<1:07:49, 18.25s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:  49%|████▉     | 215/438 [1:03:22<1:07:49, 18.25s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  49%|████▉     | 216/438 [1:03:22<1:06:37, 18.01s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  49%|████▉     | 216/438 [1:03:40<1:06:37, 18.01s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  50%|████▉     | 217/438 [1:03:40<1:06:20, 18.01s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  50%|████▉     | 217/438 [1:03:58<1:06:20, 18.01s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  50%|████▉     | 218/438 [1:03:58<1:06:03, 18.02s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  50%|████▉     | 218/438 [1:04:17<1:06:03, 18.02s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  50%|█████     | 219/438 [1:04:17<1:06:13, 18.14s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  50%|█████     | 219/438 [1:04:35<1:06:13, 18.14s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  50%|█████     | 220/438 [1:04:35<1:06:15, 18.24s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  50%|█████     | 220/438 [1:04:53<1:06:15, 18.24s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  50%|█████     | 221/438 [1:04:53<1:05:56, 18.23s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  50%|█████     | 221/438 [1:05:11<1:05:56, 18.23s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  51%|█████     | 222/438 [1:05:11<1:05:22, 18.16s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  51%|█████     | 222/438 [1:05:29<1:05:22, 18.16s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  51%|█████     | 223/438 [1:05:29<1:04:49, 18.09s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  51%|█████     | 223/438 [1:05:47<1:04:49, 18.09s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  51%|█████     | 224/438 [1:05:47<1:04:31, 18.09s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  51%|█████     | 224/438 [1:06:06<1:04:31, 18.09s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  51%|█████▏    | 225/438 [1:06:06<1:04:25, 18.15s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  51%|█████▏    | 225/438 [1:06:24<1:04:25, 18.15s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  52%|█████▏    | 226/438 [1:06:24<1:04:06, 18.15s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  52%|█████▏    | 226/438 [1:06:42<1:04:06, 18.15s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  52%|█████▏    | 227/438 [1:06:42<1:04:13, 18.26s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  52%|█████▏    | 227/438 [1:07:01<1:04:13, 18.26s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  52%|█████▏    | 228/438 [1:07:01<1:03:51, 18.25s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  52%|█████▏    | 228/438 [1:07:19<1:03:51, 18.25s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:  52%|█████▏    | 229/438 [1:07:19<1:04:16, 18.45s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:  52%|█████▏    | 229/438 [1:07:38<1:04:16, 18.45s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  53%|█████▎    | 230/438 [1:07:38<1:03:38, 18.36s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  53%|█████▎    | 230/438 [1:07:56<1:03:38, 18.36s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  53%|█████▎    | 231/438 [1:07:56<1:02:53, 18.23s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  53%|█████▎    | 231/438 [1:08:14<1:02:53, 18.23s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  53%|█████▎    | 232/438 [1:08:14<1:02:28, 18.19s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  53%|█████▎    | 232/438 [1:08:32<1:02:28, 18.19s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  53%|█████▎    | 233/438 [1:08:32<1:02:16, 18.22s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  53%|█████▎    | 233/438 [1:08:50<1:02:16, 18.22s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  53%|█████▎    | 234/438 [1:08:50<1:01:37, 18.12s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  53%|█████▎    | 234/438 [1:09:08<1:01:37, 18.12s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  54%|█████▎    | 235/438 [1:09:08<1:01:32, 18.19s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  54%|█████▎    | 235/438 [1:09:26<1:01:32, 18.19s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  54%|█████▍    | 236/438 [1:09:26<1:00:36, 18.00s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  54%|█████▍    | 236/438 [1:09:42<1:00:36, 18.00s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  54%|█████▍    | 237/438 [1:09:42<58:53, 17.58s/it, training_loss=0.132]  \u001B[A\n",
      "Epoch 5:  54%|█████▍    | 237/438 [1:09:59<58:53, 17.58s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  54%|█████▍    | 238/438 [1:09:59<57:42, 17.31s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  54%|█████▍    | 238/438 [1:10:16<57:42, 17.31s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 5:  55%|█████▍    | 239/438 [1:10:16<56:42, 17.10s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 5:  55%|█████▍    | 239/438 [1:10:32<56:42, 17.10s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  55%|█████▍    | 240/438 [1:10:32<55:52, 16.93s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  55%|█████▍    | 240/438 [1:10:49<55:52, 16.93s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  55%|█████▌    | 241/438 [1:10:49<55:14, 16.83s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  55%|█████▌    | 241/438 [1:11:05<55:14, 16.83s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 5:  55%|█████▌    | 242/438 [1:11:05<54:40, 16.74s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 5:  55%|█████▌    | 242/438 [1:11:22<54:40, 16.74s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  55%|█████▌    | 243/438 [1:11:22<54:06, 16.65s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  55%|█████▌    | 243/438 [1:11:39<54:06, 16.65s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  56%|█████▌    | 244/438 [1:11:39<54:56, 16.99s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  56%|█████▌    | 244/438 [1:11:56<54:56, 16.99s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  56%|█████▌    | 245/438 [1:11:56<54:17, 16.88s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  56%|█████▌    | 245/438 [1:12:13<54:17, 16.88s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  56%|█████▌    | 246/438 [1:12:13<53:49, 16.82s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  56%|█████▌    | 246/438 [1:12:29<53:49, 16.82s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 5:  56%|█████▋    | 247/438 [1:12:29<53:12, 16.72s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 5:  56%|█████▋    | 247/438 [1:12:46<53:12, 16.72s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  57%|█████▋    | 248/438 [1:12:46<52:43, 16.65s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  57%|█████▋    | 248/438 [1:13:02<52:43, 16.65s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  57%|█████▋    | 249/438 [1:13:02<52:23, 16.63s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  57%|█████▋    | 249/438 [1:13:19<52:23, 16.63s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  57%|█████▋    | 250/438 [1:13:19<51:57, 16.58s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  57%|█████▋    | 250/438 [1:13:35<51:57, 16.58s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  57%|█████▋    | 251/438 [1:13:35<51:38, 16.57s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  57%|█████▋    | 251/438 [1:13:52<51:38, 16.57s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 5:  58%|█████▊    | 252/438 [1:13:52<51:18, 16.55s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 5:  58%|█████▊    | 252/438 [1:14:09<51:18, 16.55s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  58%|█████▊    | 253/438 [1:14:09<51:52, 16.82s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  58%|█████▊    | 253/438 [1:14:26<51:52, 16.82s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  58%|█████▊    | 254/438 [1:14:26<51:25, 16.77s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  58%|█████▊    | 254/438 [1:14:43<51:25, 16.77s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  58%|█████▊    | 255/438 [1:14:43<51:15, 16.80s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  58%|█████▊    | 255/438 [1:14:59<51:15, 16.80s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  58%|█████▊    | 256/438 [1:14:59<50:34, 16.67s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  58%|█████▊    | 256/438 [1:15:16<50:34, 16.67s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  59%|█████▊    | 257/438 [1:15:16<50:04, 16.60s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  59%|█████▊    | 257/438 [1:15:32<50:04, 16.60s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  59%|█████▉    | 258/438 [1:15:32<49:37, 16.54s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  59%|█████▉    | 258/438 [1:15:49<49:37, 16.54s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  59%|█████▉    | 259/438 [1:15:49<49:17, 16.52s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  59%|█████▉    | 259/438 [1:16:05<49:17, 16.52s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  59%|█████▉    | 260/438 [1:16:05<48:56, 16.50s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  59%|█████▉    | 260/438 [1:16:22<48:56, 16.50s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  60%|█████▉    | 261/438 [1:16:22<48:44, 16.52s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  60%|█████▉    | 261/438 [1:16:38<48:44, 16.52s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  60%|█████▉    | 262/438 [1:16:38<48:25, 16.51s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  60%|█████▉    | 262/438 [1:16:55<48:25, 16.51s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 5:  60%|██████    | 263/438 [1:16:55<48:10, 16.51s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 5:  60%|██████    | 263/438 [1:17:11<48:10, 16.51s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  60%|██████    | 264/438 [1:17:11<47:51, 16.50s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  60%|██████    | 264/438 [1:17:27<47:51, 16.50s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  61%|██████    | 265/438 [1:17:27<47:29, 16.47s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  61%|██████    | 265/438 [1:17:44<47:29, 16.47s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  61%|██████    | 266/438 [1:17:44<47:07, 16.44s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  61%|██████    | 266/438 [1:18:00<47:07, 16.44s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  61%|██████    | 267/438 [1:18:00<46:56, 16.47s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  61%|██████    | 267/438 [1:18:17<46:56, 16.47s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  61%|██████    | 268/438 [1:18:17<46:50, 16.53s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  61%|██████    | 268/438 [1:18:33<46:50, 16.53s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  61%|██████▏   | 269/438 [1:18:33<46:27, 16.50s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  61%|██████▏   | 269/438 [1:18:50<46:27, 16.50s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:  62%|██████▏   | 270/438 [1:18:50<46:03, 16.45s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:  62%|██████▏   | 270/438 [1:19:06<46:03, 16.45s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  62%|██████▏   | 271/438 [1:19:06<45:51, 16.47s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  62%|██████▏   | 271/438 [1:19:23<45:51, 16.47s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  62%|██████▏   | 272/438 [1:19:23<45:46, 16.55s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  62%|██████▏   | 272/438 [1:19:39<45:46, 16.55s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  62%|██████▏   | 273/438 [1:19:39<45:24, 16.51s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  62%|██████▏   | 273/438 [1:19:56<45:24, 16.51s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  63%|██████▎   | 274/438 [1:19:56<45:08, 16.51s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  63%|██████▎   | 274/438 [1:20:12<45:08, 16.51s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  63%|██████▎   | 275/438 [1:20:12<44:49, 16.50s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  63%|██████▎   | 275/438 [1:20:29<44:49, 16.50s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  63%|██████▎   | 276/438 [1:20:29<44:30, 16.49s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  63%|██████▎   | 276/438 [1:20:45<44:30, 16.49s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 5:  63%|██████▎   | 277/438 [1:20:45<44:10, 16.46s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 5:  63%|██████▎   | 277/438 [1:21:02<44:10, 16.46s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  63%|██████▎   | 278/438 [1:21:02<43:52, 16.46s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  63%|██████▎   | 278/438 [1:21:18<43:52, 16.46s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 5:  64%|██████▎   | 279/438 [1:21:18<43:34, 16.44s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 5:  64%|██████▎   | 279/438 [1:21:35<43:34, 16.44s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  64%|██████▍   | 280/438 [1:21:35<43:16, 16.44s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  64%|██████▍   | 280/438 [1:21:51<43:16, 16.44s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  64%|██████▍   | 281/438 [1:21:51<43:00, 16.44s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  64%|██████▍   | 281/438 [1:22:07<43:00, 16.44s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  64%|██████▍   | 282/438 [1:22:07<42:42, 16.43s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  64%|██████▍   | 282/438 [1:22:24<42:42, 16.43s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  65%|██████▍   | 283/438 [1:22:24<42:25, 16.42s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  65%|██████▍   | 283/438 [1:22:40<42:25, 16.42s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  65%|██████▍   | 284/438 [1:22:40<42:09, 16.43s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  65%|██████▍   | 284/438 [1:22:57<42:09, 16.43s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  65%|██████▌   | 285/438 [1:22:57<41:56, 16.45s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  65%|██████▌   | 285/438 [1:23:13<41:56, 16.45s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  65%|██████▌   | 286/438 [1:23:13<41:43, 16.47s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  65%|██████▌   | 286/438 [1:23:30<41:43, 16.47s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  66%|██████▌   | 287/438 [1:23:30<41:20, 16.43s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  66%|██████▌   | 287/438 [1:23:46<41:20, 16.43s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  66%|██████▌   | 288/438 [1:23:46<41:00, 16.40s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  66%|██████▌   | 288/438 [1:24:02<41:00, 16.40s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  66%|██████▌   | 289/438 [1:24:02<40:46, 16.42s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  66%|██████▌   | 289/438 [1:24:19<40:46, 16.42s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  66%|██████▌   | 290/438 [1:24:19<40:34, 16.45s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  66%|██████▌   | 290/438 [1:24:35<40:34, 16.45s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  66%|██████▋   | 291/438 [1:24:35<40:13, 16.42s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  66%|██████▋   | 291/438 [1:24:52<40:13, 16.42s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  67%|██████▋   | 292/438 [1:24:52<39:58, 16.43s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  67%|██████▋   | 292/438 [1:25:08<39:58, 16.43s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  67%|██████▋   | 293/438 [1:25:08<39:43, 16.44s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  67%|██████▋   | 293/438 [1:25:25<39:43, 16.44s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 5:  67%|██████▋   | 294/438 [1:25:25<39:31, 16.47s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 5:  67%|██████▋   | 294/438 [1:25:41<39:31, 16.47s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  67%|██████▋   | 295/438 [1:25:41<39:12, 16.45s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  67%|██████▋   | 295/438 [1:25:58<39:12, 16.45s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  68%|██████▊   | 296/438 [1:25:58<38:57, 16.46s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  68%|██████▊   | 296/438 [1:26:14<38:57, 16.46s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  68%|██████▊   | 297/438 [1:26:14<38:36, 16.43s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  68%|██████▊   | 297/438 [1:26:31<38:36, 16.43s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  68%|██████▊   | 298/438 [1:26:31<38:34, 16.53s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  68%|██████▊   | 298/438 [1:26:48<38:34, 16.53s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  68%|██████▊   | 299/438 [1:26:48<38:52, 16.78s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  68%|██████▊   | 299/438 [1:27:05<38:52, 16.78s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  68%|██████▊   | 300/438 [1:27:05<38:33, 16.77s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  68%|██████▊   | 300/438 [1:27:22<38:33, 16.77s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  69%|██████▊   | 301/438 [1:27:22<38:19, 16.79s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  69%|██████▊   | 301/438 [1:27:38<38:19, 16.79s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  69%|██████▉   | 302/438 [1:27:38<37:49, 16.69s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  69%|██████▉   | 302/438 [1:27:55<37:49, 16.69s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  69%|██████▉   | 303/438 [1:27:55<37:23, 16.62s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  69%|██████▉   | 303/438 [1:28:11<37:23, 16.62s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:  69%|██████▉   | 304/438 [1:28:11<37:03, 16.60s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:  69%|██████▉   | 304/438 [1:28:28<37:03, 16.60s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  70%|██████▉   | 305/438 [1:28:28<36:43, 16.57s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  70%|██████▉   | 305/438 [1:28:44<36:43, 16.57s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  70%|██████▉   | 306/438 [1:28:44<36:22, 16.53s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  70%|██████▉   | 306/438 [1:29:01<36:22, 16.53s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  70%|███████   | 307/438 [1:29:01<36:04, 16.52s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  70%|███████   | 307/438 [1:29:17<36:04, 16.52s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  70%|███████   | 308/438 [1:29:17<35:40, 16.47s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  70%|███████   | 308/438 [1:29:33<35:40, 16.47s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  71%|███████   | 309/438 [1:29:33<35:12, 16.38s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  71%|███████   | 309/438 [1:29:50<35:12, 16.38s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 5:  71%|███████   | 310/438 [1:29:50<35:09, 16.48s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 5:  71%|███████   | 310/438 [1:30:06<35:09, 16.48s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 5:  71%|███████   | 311/438 [1:30:06<34:54, 16.49s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 5:  71%|███████   | 311/438 [1:30:23<34:54, 16.49s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 5:  71%|███████   | 312/438 [1:30:23<34:33, 16.46s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 5:  71%|███████   | 312/438 [1:30:39<34:33, 16.46s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  71%|███████▏  | 313/438 [1:30:39<34:13, 16.43s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  71%|███████▏  | 313/438 [1:30:55<34:13, 16.43s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  72%|███████▏  | 314/438 [1:30:55<33:53, 16.40s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  72%|███████▏  | 314/438 [1:31:12<33:53, 16.40s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  72%|███████▏  | 315/438 [1:31:12<33:36, 16.39s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  72%|███████▏  | 315/438 [1:31:28<33:36, 16.39s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  72%|███████▏  | 316/438 [1:31:28<33:15, 16.36s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  72%|███████▏  | 316/438 [1:31:44<33:15, 16.36s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  72%|███████▏  | 317/438 [1:31:44<33:01, 16.38s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  72%|███████▏  | 317/438 [1:32:01<33:01, 16.38s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 5:  73%|███████▎  | 318/438 [1:32:01<32:41, 16.34s/it, training_loss=0.143]\u001B[A\n",
      "Epoch 5:  73%|███████▎  | 318/438 [1:32:17<32:41, 16.34s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  73%|███████▎  | 319/438 [1:32:17<32:27, 16.37s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  73%|███████▎  | 319/438 [1:32:33<32:27, 16.37s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  73%|███████▎  | 320/438 [1:32:33<32:08, 16.35s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  73%|███████▎  | 320/438 [1:32:50<32:08, 16.35s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 5:  73%|███████▎  | 321/438 [1:32:50<31:53, 16.35s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 5:  73%|███████▎  | 321/438 [1:33:06<31:53, 16.35s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  74%|███████▎  | 322/438 [1:33:06<31:38, 16.37s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  74%|███████▎  | 322/438 [1:33:23<31:38, 16.37s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  74%|███████▎  | 323/438 [1:33:23<31:20, 16.35s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  74%|███████▎  | 323/438 [1:33:39<31:20, 16.35s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  74%|███████▍  | 324/438 [1:33:39<31:07, 16.38s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  74%|███████▍  | 324/438 [1:33:55<31:07, 16.38s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  74%|███████▍  | 325/438 [1:33:55<30:50, 16.37s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  74%|███████▍  | 325/438 [1:34:12<30:50, 16.37s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  74%|███████▍  | 326/438 [1:34:12<30:34, 16.38s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  74%|███████▍  | 326/438 [1:34:28<30:34, 16.38s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  75%|███████▍  | 327/438 [1:34:28<30:15, 16.36s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  75%|███████▍  | 327/438 [1:34:44<30:15, 16.36s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  75%|███████▍  | 328/438 [1:34:44<30:00, 16.36s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  75%|███████▍  | 328/438 [1:35:01<30:00, 16.36s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  75%|███████▌  | 329/438 [1:35:01<29:46, 16.39s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  75%|███████▌  | 329/438 [1:35:17<29:46, 16.39s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  75%|███████▌  | 330/438 [1:35:17<29:29, 16.38s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  75%|███████▌  | 330/438 [1:35:34<29:29, 16.38s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 5:  76%|███████▌  | 331/438 [1:35:34<29:13, 16.39s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 5:  76%|███████▌  | 331/438 [1:35:50<29:13, 16.39s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  76%|███████▌  | 332/438 [1:35:50<28:52, 16.35s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  76%|███████▌  | 332/438 [1:36:06<28:52, 16.35s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  76%|███████▌  | 333/438 [1:36:06<28:37, 16.36s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  76%|███████▌  | 333/438 [1:36:23<28:37, 16.36s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  76%|███████▋  | 334/438 [1:36:23<28:20, 16.35s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  76%|███████▋  | 334/438 [1:36:39<28:20, 16.35s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  76%|███████▋  | 335/438 [1:36:39<28:04, 16.36s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  76%|███████▋  | 335/438 [1:36:56<28:04, 16.36s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  77%|███████▋  | 336/438 [1:36:56<27:55, 16.42s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  77%|███████▋  | 336/438 [1:37:15<27:55, 16.42s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  77%|███████▋  | 337/438 [1:37:15<29:10, 17.33s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  77%|███████▋  | 337/438 [1:37:36<29:10, 17.33s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  77%|███████▋  | 338/438 [1:37:36<30:35, 18.36s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  77%|███████▋  | 338/438 [1:37:54<30:35, 18.36s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  77%|███████▋  | 339/438 [1:37:54<29:58, 18.17s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  77%|███████▋  | 339/438 [1:38:12<29:58, 18.17s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  78%|███████▊  | 340/438 [1:38:12<29:55, 18.32s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  78%|███████▊  | 340/438 [1:38:30<29:55, 18.32s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  78%|███████▊  | 341/438 [1:38:30<29:25, 18.20s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  78%|███████▊  | 341/438 [1:38:48<29:25, 18.20s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  78%|███████▊  | 342/438 [1:38:48<28:57, 18.10s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  78%|███████▊  | 342/438 [1:39:05<28:57, 18.10s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  78%|███████▊  | 343/438 [1:39:05<28:22, 17.92s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  78%|███████▊  | 343/438 [1:39:23<28:22, 17.92s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:  79%|███████▊  | 344/438 [1:39:23<27:54, 17.82s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:  79%|███████▊  | 344/438 [1:39:40<27:54, 17.82s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  79%|███████▉  | 345/438 [1:39:40<27:20, 17.64s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  79%|███████▉  | 345/438 [1:39:58<27:20, 17.64s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 5:  79%|███████▉  | 346/438 [1:39:58<27:03, 17.64s/it, training_loss=0.115]\u001B[A\n",
      "Epoch 5:  79%|███████▉  | 346/438 [1:40:15<27:03, 17.64s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 5:  79%|███████▉  | 347/438 [1:40:15<26:34, 17.52s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 5:  79%|███████▉  | 347/438 [1:40:33<26:34, 17.52s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 5:  79%|███████▉  | 348/438 [1:40:33<26:16, 17.52s/it, training_loss=0.121]\u001B[A\n",
      "Epoch 5:  79%|███████▉  | 348/438 [1:40:50<26:16, 17.52s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  80%|███████▉  | 349/438 [1:40:50<26:00, 17.53s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  80%|███████▉  | 349/438 [1:41:07<26:00, 17.53s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  80%|███████▉  | 350/438 [1:41:07<25:26, 17.35s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  80%|███████▉  | 350/438 [1:41:25<25:26, 17.35s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  80%|████████  | 351/438 [1:41:25<25:10, 17.36s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  80%|████████  | 351/438 [1:41:44<25:10, 17.36s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  80%|████████  | 352/438 [1:41:44<25:40, 17.91s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  80%|████████  | 352/438 [1:42:01<25:40, 17.91s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  81%|████████  | 353/438 [1:42:01<25:17, 17.85s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  81%|████████  | 353/438 [1:42:19<25:17, 17.85s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  81%|████████  | 354/438 [1:42:19<24:50, 17.75s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  81%|████████  | 354/438 [1:42:37<24:50, 17.75s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  81%|████████  | 355/438 [1:42:37<24:34, 17.77s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  81%|████████  | 355/438 [1:42:54<24:34, 17.77s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  81%|████████▏ | 356/438 [1:42:54<24:11, 17.70s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  81%|████████▏ | 356/438 [1:43:12<24:11, 17.70s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  82%|████████▏ | 357/438 [1:43:12<23:50, 17.66s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  82%|████████▏ | 357/438 [1:43:29<23:50, 17.66s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  82%|████████▏ | 358/438 [1:43:29<23:29, 17.62s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  82%|████████▏ | 358/438 [1:43:47<23:29, 17.62s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:  82%|████████▏ | 359/438 [1:43:47<23:05, 17.54s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:  82%|████████▏ | 359/438 [1:44:04<23:05, 17.54s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  82%|████████▏ | 360/438 [1:44:04<22:51, 17.59s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  82%|████████▏ | 360/438 [1:44:22<22:51, 17.59s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  82%|████████▏ | 361/438 [1:44:22<22:37, 17.63s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  82%|████████▏ | 361/438 [1:44:39<22:37, 17.63s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 5:  83%|████████▎ | 362/438 [1:44:39<22:11, 17.51s/it, training_loss=0.144]\u001B[A\n",
      "Epoch 5:  83%|████████▎ | 362/438 [1:44:57<22:11, 17.51s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  83%|████████▎ | 363/438 [1:44:57<21:53, 17.51s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  83%|████████▎ | 363/438 [1:45:14<21:53, 17.51s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  83%|████████▎ | 364/438 [1:45:14<21:29, 17.43s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  83%|████████▎ | 364/438 [1:45:31<21:29, 17.43s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 5:  83%|████████▎ | 365/438 [1:45:31<21:06, 17.35s/it, training_loss=0.147]\u001B[A\n",
      "Epoch 5:  83%|████████▎ | 365/438 [1:45:49<21:06, 17.35s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  84%|████████▎ | 366/438 [1:45:49<20:52, 17.40s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  84%|████████▎ | 366/438 [1:46:06<20:52, 17.40s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 5:  84%|████████▍ | 367/438 [1:46:06<20:39, 17.46s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 5:  84%|████████▍ | 367/438 [1:46:24<20:39, 17.46s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 5:  84%|████████▍ | 368/438 [1:46:24<20:23, 17.47s/it, training_loss=0.141]\u001B[A\n",
      "Epoch 5:  84%|████████▍ | 368/438 [1:46:41<20:23, 17.47s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  84%|████████▍ | 369/438 [1:46:41<20:05, 17.46s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  84%|████████▍ | 369/438 [1:46:59<20:05, 17.46s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:  84%|████████▍ | 370/438 [1:46:59<19:43, 17.40s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5:  84%|████████▍ | 370/438 [1:47:16<19:43, 17.40s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  85%|████████▍ | 371/438 [1:47:16<19:27, 17.42s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  85%|████████▍ | 371/438 [1:47:33<19:27, 17.42s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  85%|████████▍ | 372/438 [1:47:33<19:08, 17.40s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  85%|████████▍ | 372/438 [1:47:51<19:08, 17.40s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  85%|████████▌ | 373/438 [1:47:51<18:47, 17.35s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  85%|████████▌ | 373/438 [1:48:08<18:47, 17.35s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  85%|████████▌ | 374/438 [1:48:08<18:38, 17.47s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  85%|████████▌ | 374/438 [1:48:26<18:38, 17.47s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 5:  86%|████████▌ | 375/438 [1:48:26<18:21, 17.48s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 5:  86%|████████▌ | 375/438 [1:48:43<18:21, 17.48s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  86%|████████▌ | 376/438 [1:48:43<18:00, 17.43s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  86%|████████▌ | 376/438 [1:49:01<18:00, 17.43s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  86%|████████▌ | 377/438 [1:49:01<17:42, 17.42s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  86%|████████▌ | 377/438 [1:49:19<17:42, 17.42s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  86%|████████▋ | 378/438 [1:49:19<17:34, 17.57s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  86%|████████▋ | 378/438 [1:49:36<17:34, 17.57s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  87%|████████▋ | 379/438 [1:49:36<17:08, 17.43s/it, training_loss=0.130]\u001B[A\n",
      "Epoch 5:  87%|████████▋ | 379/438 [1:49:53<17:08, 17.43s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  87%|████████▋ | 380/438 [1:49:53<16:46, 17.36s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  87%|████████▋ | 380/438 [1:50:10<16:46, 17.36s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  87%|████████▋ | 381/438 [1:50:10<16:22, 17.24s/it, training_loss=0.122]\u001B[A\n",
      "Epoch 5:  87%|████████▋ | 381/438 [1:50:27<16:22, 17.24s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  87%|████████▋ | 382/438 [1:50:27<16:03, 17.21s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  87%|████████▋ | 382/438 [1:50:44<16:03, 17.21s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  87%|████████▋ | 383/438 [1:50:44<15:47, 17.22s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  87%|████████▋ | 383/438 [1:51:02<15:47, 17.22s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  88%|████████▊ | 384/438 [1:51:02<15:32, 17.26s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  88%|████████▊ | 384/438 [1:51:19<15:32, 17.26s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  88%|████████▊ | 385/438 [1:51:19<15:13, 17.24s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  88%|████████▊ | 385/438 [1:51:36<15:13, 17.24s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  88%|████████▊ | 386/438 [1:51:36<14:59, 17.31s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  88%|████████▊ | 386/438 [1:51:54<14:59, 17.31s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  88%|████████▊ | 387/438 [1:51:54<14:43, 17.33s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  88%|████████▊ | 387/438 [1:52:11<14:43, 17.33s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  89%|████████▊ | 388/438 [1:52:11<14:22, 17.25s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  89%|████████▊ | 388/438 [1:52:28<14:22, 17.25s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  89%|████████▉ | 389/438 [1:52:28<14:05, 17.25s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  89%|████████▉ | 389/438 [1:52:45<14:05, 17.25s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  89%|████████▉ | 390/438 [1:52:45<13:48, 17.26s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  89%|████████▉ | 390/438 [1:53:02<13:48, 17.26s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  89%|████████▉ | 391/438 [1:53:02<13:28, 17.19s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  89%|████████▉ | 391/438 [1:53:20<13:28, 17.19s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  89%|████████▉ | 392/438 [1:53:20<13:11, 17.21s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  89%|████████▉ | 392/438 [1:53:37<13:11, 17.21s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 5:  90%|████████▉ | 393/438 [1:53:37<12:59, 17.32s/it, training_loss=0.117]\u001B[A\n",
      "Epoch 5:  90%|████████▉ | 393/438 [1:53:54<12:59, 17.32s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  90%|████████▉ | 394/438 [1:53:54<12:43, 17.34s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  90%|████████▉ | 394/438 [1:54:12<12:43, 17.34s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  90%|█████████ | 395/438 [1:54:12<12:22, 17.27s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  90%|█████████ | 395/438 [1:54:29<12:22, 17.27s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  90%|█████████ | 396/438 [1:54:29<12:08, 17.34s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  90%|█████████ | 396/438 [1:54:46<12:08, 17.34s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 5:  91%|█████████ | 397/438 [1:54:46<11:49, 17.30s/it, training_loss=0.111]\u001B[A\n",
      "Epoch 5:  91%|█████████ | 397/438 [1:55:04<11:49, 17.30s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  91%|█████████ | 398/438 [1:55:04<11:37, 17.43s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  91%|█████████ | 398/438 [1:55:22<11:37, 17.43s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  91%|█████████ | 399/438 [1:55:22<11:24, 17.54s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  91%|█████████ | 399/438 [1:55:39<11:24, 17.54s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  91%|█████████▏| 400/438 [1:55:39<11:05, 17.51s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  91%|█████████▏| 400/438 [1:55:57<11:05, 17.51s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  92%|█████████▏| 401/438 [1:55:57<10:48, 17.54s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  92%|█████████▏| 401/438 [1:56:14<10:48, 17.54s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  92%|█████████▏| 402/438 [1:56:14<10:31, 17.54s/it, training_loss=0.126]\u001B[A\n",
      "Epoch 5:  92%|█████████▏| 402/438 [1:56:32<10:31, 17.54s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  92%|█████████▏| 403/438 [1:56:32<10:11, 17.47s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  92%|█████████▏| 403/438 [1:56:51<10:11, 17.47s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  92%|█████████▏| 404/438 [1:56:51<10:07, 17.87s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  92%|█████████▏| 404/438 [1:57:08<10:07, 17.87s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  92%|█████████▏| 405/438 [1:57:08<09:45, 17.73s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  92%|█████████▏| 405/438 [1:57:25<09:45, 17.73s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  93%|█████████▎| 406/438 [1:57:25<09:20, 17.52s/it, training_loss=0.123]\u001B[A\n",
      "Epoch 5:  93%|█████████▎| 406/438 [1:57:45<09:20, 17.52s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  93%|█████████▎| 407/438 [1:57:45<09:24, 18.19s/it, training_loss=0.124]\u001B[A\n",
      "Epoch 5:  93%|█████████▎| 407/438 [1:58:03<09:24, 18.19s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  93%|█████████▎| 408/438 [1:58:03<09:10, 18.35s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  93%|█████████▎| 408/438 [1:58:22<09:10, 18.35s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  93%|█████████▎| 409/438 [1:58:22<08:54, 18.43s/it, training_loss=0.137]\u001B[A\n",
      "Epoch 5:  93%|█████████▎| 409/438 [1:58:41<08:54, 18.43s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  94%|█████████▎| 410/438 [1:58:41<08:38, 18.54s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  94%|█████████▎| 410/438 [1:58:59<08:38, 18.54s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  94%|█████████▍| 411/438 [1:58:59<08:15, 18.36s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5:  94%|█████████▍| 411/438 [1:59:16<08:15, 18.36s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  94%|█████████▍| 412/438 [1:59:16<07:50, 18.11s/it, training_loss=0.129]\u001B[A\n",
      "Epoch 5:  94%|█████████▍| 412/438 [1:59:35<07:50, 18.11s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 5:  94%|█████████▍| 413/438 [1:59:35<07:37, 18.31s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 5:  94%|█████████▍| 413/438 [1:59:53<07:37, 18.31s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  95%|█████████▍| 414/438 [1:59:53<07:15, 18.13s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5:  95%|█████████▍| 414/438 [2:00:11<07:15, 18.13s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  95%|█████████▍| 415/438 [2:00:11<06:55, 18.09s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  95%|█████████▍| 415/438 [2:00:29<06:55, 18.09s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 5:  95%|█████████▍| 416/438 [2:00:29<06:37, 18.06s/it, training_loss=0.135]\u001B[A\n",
      "Epoch 5:  95%|█████████▍| 416/438 [2:00:47<06:37, 18.06s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:  95%|█████████▌| 417/438 [2:00:47<06:18, 18.02s/it, training_loss=0.120]\u001B[A\n",
      "Epoch 5:  95%|█████████▌| 417/438 [2:01:05<06:18, 18.02s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 5:  95%|█████████▌| 418/438 [2:01:05<06:00, 18.02s/it, training_loss=0.140]\u001B[A\n",
      "Epoch 5:  95%|█████████▌| 418/438 [2:01:22<06:00, 18.02s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  96%|█████████▌| 419/438 [2:01:22<05:39, 17.87s/it, training_loss=0.119]\u001B[A\n",
      "Epoch 5:  96%|█████████▌| 419/438 [2:01:40<05:39, 17.87s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  96%|█████████▌| 420/438 [2:01:40<05:22, 17.89s/it, training_loss=0.136]\u001B[A\n",
      "Epoch 5:  96%|█████████▌| 420/438 [2:01:58<05:22, 17.89s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  96%|█████████▌| 421/438 [2:01:58<05:03, 17.88s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  96%|█████████▌| 421/438 [2:02:16<05:03, 17.88s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  96%|█████████▋| 422/438 [2:02:16<04:47, 17.96s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  96%|█████████▋| 422/438 [2:02:34<04:47, 17.96s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 5:  97%|█████████▋| 423/438 [2:02:34<04:30, 18.03s/it, training_loss=0.118]\u001B[A\n",
      "Epoch 5:  97%|█████████▋| 423/438 [2:02:52<04:30, 18.03s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  97%|█████████▋| 424/438 [2:02:52<04:10, 17.90s/it, training_loss=0.131]\u001B[A\n",
      "Epoch 5:  97%|█████████▋| 424/438 [2:03:10<04:10, 17.90s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  97%|█████████▋| 425/438 [2:03:10<03:51, 17.82s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  97%|█████████▋| 425/438 [2:03:27<03:51, 17.82s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  97%|█████████▋| 426/438 [2:03:27<03:32, 17.74s/it, training_loss=0.127]\u001B[A\n",
      "Epoch 5:  97%|█████████▋| 426/438 [2:03:45<03:32, 17.74s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 5:  97%|█████████▋| 427/438 [2:03:45<03:14, 17.66s/it, training_loss=0.112]\u001B[A\n",
      "Epoch 5:  97%|█████████▋| 427/438 [2:04:02<03:14, 17.66s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  98%|█████████▊| 428/438 [2:04:02<02:56, 17.60s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  98%|█████████▊| 428/438 [2:04:20<02:56, 17.60s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 5:  98%|█████████▊| 429/438 [2:04:20<02:38, 17.62s/it, training_loss=0.142]\u001B[A\n",
      "Epoch 5:  98%|█████████▊| 429/438 [2:04:38<02:38, 17.62s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 5:  98%|█████████▊| 430/438 [2:04:38<02:22, 17.87s/it, training_loss=0.116]\u001B[A\n",
      "Epoch 5:  98%|█████████▊| 430/438 [2:04:56<02:22, 17.87s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  98%|█████████▊| 431/438 [2:04:56<02:05, 17.91s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  98%|█████████▊| 431/438 [2:05:14<02:05, 17.91s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  99%|█████████▊| 432/438 [2:05:14<01:48, 18.00s/it, training_loss=0.128]\u001B[A\n",
      "Epoch 5:  99%|█████████▊| 432/438 [2:05:33<01:48, 18.00s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  99%|█████████▉| 433/438 [2:05:33<01:30, 18.15s/it, training_loss=0.139]\u001B[A\n",
      "Epoch 5:  99%|█████████▉| 433/438 [2:05:51<01:30, 18.15s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  99%|█████████▉| 434/438 [2:05:51<01:12, 18.20s/it, training_loss=0.133]\u001B[A\n",
      "Epoch 5:  99%|█████████▉| 434/438 [2:06:10<01:12, 18.20s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  99%|█████████▉| 435/438 [2:06:10<00:54, 18.31s/it, training_loss=0.134]\u001B[A\n",
      "Epoch 5:  99%|█████████▉| 435/438 [2:06:28<00:54, 18.31s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5: 100%|█████████▉| 436/438 [2:06:28<00:36, 18.36s/it, training_loss=0.138]\u001B[A\n",
      "Epoch 5: 100%|█████████▉| 436/438 [2:06:46<00:36, 18.36s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5: 100%|█████████▉| 437/438 [2:06:46<00:18, 18.24s/it, training_loss=0.125]\u001B[A\n",
      "Epoch 5: 100%|█████████▉| 437/438 [2:07:02<00:18, 18.24s/it, training_loss=0.132]\u001B[A\n",
      "Epoch 5: 100%|██████████| 438/438 [2:07:02<00:00, 17.39s/it, training_loss=0.132]\u001B[A\n",
      " 80%|████████  | 4/5 [11:45:06<2:24:30, 8670.90s/it]                             \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Trainin loss: 0.386629005749476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [12:07:16<00:00, 8727.20s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3892127971382851\n",
      "F1 Score (Weighted): 0.02348434924273023\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2],\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids) \n",
    "\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "for epoch in tqdm(range(1, EPOCHS + 1)):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2],\n",
    "        }\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "\n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    tqdm.write(f'Trainin loss: {loss_train_avg}')\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "\n",
    "torch.save(model.state_dict(), 'finetuned_BERT_final.model')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T18:55:45.370087Z",
     "start_time": "2024-09-19T06:48:28.935510Z"
    }
   },
   "id": "29d5031168643adf",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: neutral\n",
      "Accuracy: 0.0\n",
      "\n",
      "Class: acceptance\n",
      "Accuracy: 0.0011655011655011655\n",
      "\n",
      "Class: disgust\n",
      "Accuracy: 0.08974358974358974\n",
      "\n",
      "Class: surprise\n",
      "Accuracy: 0.017482517482517484\n",
      "\n",
      "Class: joy\n",
      "Accuracy: 0.0\n",
      "\n",
      "Class: sadness\n",
      "Accuracy: 0.0\n",
      "\n",
      "Class: anger\n",
      "Accuracy: 0.0\n",
      "\n",
      "Class: like\n",
      "Accuracy: 0.0\n",
      "\n",
      "Class: fear\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=9,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "  \n",
    "\n",
    "        \n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('finetuned_BERT_final.model', map_location=torch.device('cpu')))\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "accuracy_per_class(predictions, true_vals)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-19T19:17:44.966343Z",
     "start_time": "2024-09-19T18:55:45.379096Z"
    }
   },
   "id": "7e47ff3a6c533966",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3c74cf1113af2ceb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "539b0d3cd1dc56d5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch['Utterances'], padding=True, truncation=True, max_length=MAX_LEN, return_tensors='pt')\n",
    "#    \n",
    "# def tokenize_fn(batch):\n",
    "#     return tokenizer(batch['Utterances'], padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors='pt')\n",
    "\n",
    "tokenized_dataset = split.map(tokenize_fn, batched=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf4725b4b0c2938a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d0f646dfa3841d6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenized_dataset['train'][0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8e43d3d7ead6d29",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#trainer.train()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afb8fdf882f8a7be",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear = torch.nn.Linear(768, 9) #number of classs\n",
    "\n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids,\n",
    "            attention_mask=attn_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n",
    "\n",
    "# # Freezing BERT layers: (tested, weaker convergence)\n",
    "# for param in model.bert_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83a4aefea952e049",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b83ab6df019c59b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f7e6618581d72a0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training of the model for one epoch\n",
    "def train_model(training_loader, model, optimizer):\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    # set model to training mode (activate droput, batch norm)\n",
    "    model.train()\n",
    "    # initialize the progress bar\n",
    "    loop = tq.tqdm(enumerate(training_loader), total=len(training_loader),\n",
    "                   leave=True, colour='steelblue')\n",
    "    for batch_idx, data in loop:\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(ids, mask, token_type_ids) # (batch,predict)=(32,8)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "        # training accuracy\n",
    "        _, preds = torch.max(outputs, dim=1) # batch dim \n",
    "        _, targ = torch.max(targets, dim=1)  # batch dim\n",
    "        num_samples += len(targ)  # technically adding batch size\n",
    "        correct_predictions += torch.sum(preds == targ)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        # grad descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        #loop.set_description(f\"\")\n",
    "        #loop.set_postfix(batch_loss=loss)\n",
    "\n",
    "    # returning: trained model, model accuracy, mean loss\n",
    "    return model, float(correct_predictions)/num_samples, np.mean(losses)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0b3b0b0de857d67",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def eval_model(validation_loader, model, optimizer):\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    # set model to eval mode (turn off dropout, fix batch norm)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(validation_loader, 0):\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # validation accuracy\n",
    "            _, preds = torch.max(outputs, dim=1) # batch dim \n",
    "            _, targ = torch.max(targets, dim=1)  # batch dim\n",
    "            num_samples += len(targ)  # technically adding batch size\n",
    "            correct_predictions += torch.sum(preds == targ)\n",
    "\n",
    "    return float(correct_predictions)/num_samples, np.mean(losses)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "187cd4131ce94ba1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "be212df01fd54147",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(tokenized_dataset['train'],\n",
    "                                                batch_size=TRAIN_BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0,\n",
    "                                                collate_fn=data_collator\n",
    "                                                )\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(tokenized_dataset['test'],\n",
    "                                              batch_size=VALID_BATCH_SIZE,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=0,\n",
    "                                              collate_fn=data_collator\n",
    "                                              )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae5a736bb41df71b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    model, train_acc, train_loss = train_model(train_data_loader, model, optimizer)\n",
    "    val_acc, val_loss = eval_model(val_data_loader, model, optimizer)\n",
    "\n",
    "    print(f'train_loss={train_loss:.4f}, val_loss={val_loss:.4f} train_acc={train_acc:.4f}, val_acc={val_acc:.4f}')\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    # save the best model\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), os.path.join(data_dir,\"output\",\"best_model_state.bin\"))\n",
    "        best_accuracy = val_acc\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea9c6fdc49bb8be0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3cc86c32beae981"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d78b86e9f9b698e9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "target_list = list(tokenized_dataset.columns)\n",
    "target_list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "120e2360fa4aefab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6949581129d91408"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                batch_size=TRAIN_BATCH_SIZE,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0\n",
    "                                                )\n",
    "\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                              batch_size=VALID_BATCH_SIZE,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=0\n",
    "                                              )\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size=TEST_BATCH_SIZE,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0\n",
    "                                               )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35de033e82340e8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df4088691d16b159",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "12c67e0f261051bc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
