{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-03T08:15:47.049980Z",
     "start_time": "2025-03-03T08:15:47.042216Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm.notebook as tq\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MAX_LEN = 100\n",
    "BATCH = 8\n",
    "PRE_TRAINED_MODEL_NAME = \"distilbert-base-uncased\" #'bert-base-cased'\n",
    "EPOCHS = 8\n",
    "LEARNING_RATE = 0.001\n",
    "THRESHOLD = 0.2\n",
    "DROPOUT_RATE = 0.6\n",
    "WEIGHT_DECAY = 0.001\n",
    "MODE = 'min'\n",
    "PATIENCE = 2\n",
    "FACTOR = 0.5\n",
    "VERBOSE = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T08:15:47.357650Z",
     "start_time": "2025-03-03T08:15:47.351411Z"
    }
   },
   "id": "f006aa2984af8778",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/juwieczo/DataspellProjects/meisd_project/datafirst_25_percent.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T08:15:47.685076Z",
     "start_time": "2025-03-03T08:15:47.644957Z"
    }
   },
   "id": "c674bfe87925edfa",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#columns = ['Utterances', 'dialog_ids', 'uttr_ids', 'intensity', 'intensity2', 'intensity3']\n",
    "columns = ['Utterances', 'label']\n",
    "df = df[columns].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T08:15:47.886658Z",
     "start_time": "2025-03-03T08:15:47.880100Z"
    }
   },
   "id": "8580f2f42c04afad",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                          Utterances     label\n0  look around you say hello to your competition ...  0.000000\n1  i'm george o'malley uh, we met at the mixer. y...  1.344341\n2  seattle is surrounded by water on three sides ...  1.175248\n3  yes no other reason? just a favor for an old p...  1.178085\n4  if he doesn't respond to these tests in the ne...  1.571909",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Utterances</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>look around you say hello to your competition ...</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i'm george o'malley uh, we met at the mixer. y...</td>\n      <td>1.344341</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>seattle is surrounded by water on three sides ...</td>\n      <td>1.175248</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>yes no other reason? just a favor for an old p...</td>\n      <td>1.178085</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>if he doesn't respond to these tests in the ne...</td>\n      <td>1.571909</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T08:15:48.187546Z",
     "start_time": "2025-03-03T08:15:48.170009Z"
    }
   },
   "id": "69ff16598f9c5d3",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[  101,  2057,  2024,  5604, 14324, 19204, 17629,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "test_text = \"We are testing BERT tokenizer.\"\n",
    "encodings = tokenizer.encode_plus(\n",
    "    test_text,\n",
    "    add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "    max_length=50,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "print(\"Input IDs:\", encodings[\"input_ids\"])\n",
    "print(\"Attention Mask:\", encodings[\"attention_mask\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T08:15:49.725228Z",
     "start_time": "2025-03-03T08:15:48.352098Z"
    }
   },
   "id": "45cfdb6c6374e057",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "token_lens = []\n",
    "\n",
    "for txt in df['Utterances']:\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens.append(len(tokens))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T08:15:51.199249Z",
     "start_time": "2025-03-03T08:15:49.766629Z"
    }
   },
   "id": "d6eb97d52a569d49",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.utterances = list(df['Utterances'])\n",
    "        self.targets = self.df['label'].astype(float).values  # Zmieniamy na float\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.utterances)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        utterances = str(self.utterances[index])\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            utterances,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        target = torch.tensor(self.targets[index], dtype=torch.float)  # Używamy float\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
    "            'targets': target  # Używamy ciągłego celu\n",
    "        }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T08:15:51.216570Z",
     "start_time": "2025-03-03T08:15:51.203201Z"
    }
   },
   "id": "8e92c118559e759c",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train and test\n",
    "df_train, df_test = train_test_split(df, random_state=77, test_size=0.30, shuffle=True)\n",
    "# split test into test and validation datasets\n",
    "df_test, df_valid = train_test_split(df_test, random_state=88, test_size=0.50, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T08:15:51.261530Z",
     "start_time": "2025-03-03T08:15:51.218685Z"
    }
   },
   "id": "c639478fade0aae9",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train size: (1124, 2)\n",
      "Validation size: (169, 2), Test size: (169, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original train size: {df.shape}\")\n",
    "print(f\"Validation size: {df_valid.shape}, Test size: {df_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T08:15:51.343933Z",
     "start_time": "2025-03-03T08:15:51.268479Z"
    }
   },
   "id": "ff030ef4fe8710fd",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['label']"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list = list(df.columns)\n",
    "target_list = target_list[1:]\n",
    "target_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T08:15:51.370632Z",
     "start_time": "2025-03-03T08:15:51.347370Z"
    }
   },
   "id": "5114abfc3ea5f092",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, pretrained_model_name, dropout_rate):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model_name)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, 1)  # Jedna jednostka wyjściowa\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        pooled_output = output.last_hidden_state[:, 0, :]  # Użycie [CLS] tokena\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        return self.out(pooled_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T08:15:51.802328Z",
     "start_time": "2025-03-03T08:15:51.795202Z"
    }
   },
   "id": "7b6de40a4b1fd317",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN)\n",
    "valid_dataset = CustomDataset(df_valid, tokenizer, MAX_LEN)\n",
    "test_dataset = CustomDataset(df_test, tokenizer, MAX_LEN)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH, shuffle=True, num_workers=0)\n",
    "val_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH, shuffle=False, num_workers=0)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH, shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c0d1dbac1e2538e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    total_targets = []\n",
    "    total_preds = []\n",
    "    losses = []\n",
    "\n",
    "    for batch in tqdm(data_loader, desc='Training', leave=False):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        targets = batch[\"targets\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, token_type_ids).squeeze(-1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        total_targets.extend(targets.cpu().numpy())\n",
    "        total_preds.extend(outputs.cpu().detach().numpy())\n",
    "\n",
    "    mse, mae, r2, pearson_corr = compute_metrics(np.array(total_targets), np.array(total_preds))\n",
    "    return np.mean(losses), mse, mae, r2, pearson_corr"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6240d7b71759e66",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_targets = []\n",
    "    total_preds = []\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc='Validation', leave=False):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "            targets = batch[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids).squeeze(-1)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            total_targets.extend(targets.cpu().numpy())\n",
    "            total_preds.extend(outputs.cpu().detach().numpy())\n",
    "\n",
    "    mse, mae, r2, pearson_corr = compute_metrics(np.array(total_targets), np.array(total_preds))\n",
    "    return np.mean(losses), mse, mae, r2, pearson_corr\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68be400c410542e8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss_fn, optimizer, device, epochs=10, patience=3):\n",
    "    early_stopping = EarlyStopping(patience=patience, mode='min')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        train_loss, train_mse, train_mae, train_r2, train_pearson = train_epoch(model, train_loader, loss_fn, optimizer, device)\n",
    "        val_loss, val_mse, val_mae, val_r2, val_pearson = eval_model(model, val_loader, loss_fn, device)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, MSE: {train_mse:.4f}, MAE: {train_mae:.4f}, R2: {train_r2:.4f}, Pearson: {train_pearson:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, MSE: {val_mse:.4f}, MAE: {val_mae:.4f}, R2: {val_r2:.4f}, Pearson: {val_pearson:.4f}\")\n",
    "\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37a98d57893457e4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, mode='min', delta=0):\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.epochs_no_improve = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, score, model):\n",
    "        if self.best_score is None or \\\n",
    "                (self.mode == 'min' and score < self.best_score - self.delta) or \\\n",
    "                (self.mode == 'max' and score > self.best_score + self.delta):\n",
    "            self.best_score = score\n",
    "            self.epochs_no_improve = 0\n",
    "        else:\n",
    "            self.epochs_no_improve += 1\n",
    "            if self.epochs_no_improve >= self.patience:\n",
    "                self.early_stop = True\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ac3266c28d64f19",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    pearson_corr, _ = pearsonr(y_true, y_pred)\n",
    "    return mse, mae, r2, pearson_corr\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3152108c8bc1fac0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = RegressionModel(pretrained_model_name=PRE_TRAINED_MODEL_NAME, dropout_rate=DROPOUT_RATE)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "loss_fn = nn.MSELoss().to(device)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=MODE, patience=PATIENCE, factor=FACTOR, verbose=VERBOSE\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a8846f4288f100c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# freeze some layers (top | middle | bottom):\n",
    "bottom = range(2, 12)\n",
    "middle = list(range(0,5))+list(range(7,12))\n",
    "top = range(0, 10)\n",
    "\n",
    "layersToFreeze = top\n",
    "for i in layersToFreeze:\n",
    "    print(i)\n",
    "    for param in model.bert.encoder.layer[i].parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Tell pytorch to run this model on the GPU\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9aa41667952543bb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_model(model, train_data_loader, val_data_loader, loss_fn, optimizer, device, epochs=EPOCHS, patience=PATIENCE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "357bb9dacf1d46e3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Przygotowanie różnych konfiguracji zamrożenia warstw\n",
    "def freeze_layers(model, layers_to_freeze):\n",
    "    \"\"\"\n",
    "    Funkcja zamraża wskazane warstwy w modelu BERT.\n",
    "    \"\"\"\n",
    "    for i in layers_to_freeze:\n",
    "        print(f\"Freezing layer {i}\")\n",
    "        for param in model.bert.encoder.layer[i].parameters():\n",
    "            param.requires_grad = False\n",
    "    return model\n",
    "\n",
    "# Różne konfiguracje warstw do zamrożenia\n",
    "layer_configurations = {\n",
    "    'bottom': range(2, 12),\n",
    "    'middle': list(range(0,5)) + list(range(7,12)),\n",
    "    'top': range(0, 10)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for config_name, layers_to_freeze in layer_configurations.items():\n",
    "    print(f\"\\nTraining with {config_name} layers frozen:\")\n",
    "\n",
    "    # Przywrócenie modelu przed każdym testem\n",
    "    model = RegressionModel(pretrained_model_name=PRE_TRAINED_MODEL_NAME, dropout_rate=DROPOUT_RATE)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Zamrażamy wybrane warstwy\n",
    "    model = freeze_layers(model, layers_to_freeze)\n",
    "\n",
    "    # Przygotowanie optymalizatora\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    loss_fn = nn.MSELoss().to(device)\n",
    "\n",
    "    # Trening modelu\n",
    "    train_model(model, train_data_loader, val_data_loader, loss_fn, optimizer, device, epochs=EPOCHS, patience=PATIENCE)\n",
    "\n",
    "    # Testowanie modelu\n",
    "    test_loss, test_mse, test_mae, test_r2, test_pearson = eval_model(model, test_data_loader, loss_fn, device)\n",
    "\n",
    "    results[config_name] = {\n",
    "        'Test Loss': test_loss,\n",
    "        'Test MSE': test_mse,\n",
    "        'Test MAE': test_mae,\n",
    "        'Test R2': test_r2,\n",
    "        'Test Pearson': test_pearson\n",
    "    }\n",
    "    print(f\"\\nResults for {config_name}:\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test MSE: {test_mse:.4f}\")\n",
    "    print(f\"Test MAE: {test_mae:.4f}\")\n",
    "    print(f\"Test R2: {test_r2:.4f}\")\n",
    "    print(f\"Test Pearson Correlation: {test_pearson:.4f}\")\n",
    "\n",
    "# Wyniki końcowe porównujące wpływ różnych konfiguracji zamrożonych warstw\n",
    "print(\"\\nFinal comparison of different layer freezing configurations:\")\n",
    "for config_name, result in results.items():\n",
    "    print(f\"\\n{config_name}:\")\n",
    "    for metric, value in result.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T08:12:43.048261Z",
     "start_time": "2025-03-03T08:12:42.929769Z"
    }
   },
   "id": "a04f1091a3cabf52",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ustawienia stylu wykresu\n",
    "sns.set(style='darkgrid')\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# Pobranie wyników z Twojego słownika results\n",
    "bottom_results = results['bottom']['Test Loss']\n",
    "middle_results = results['middle']['Test Loss']\n",
    "top_results = results['top']['Test Loss']\n",
    "\n",
    "# Liczba epok (zakładam, że każdy wynik odpowiada jednej epoce)\n",
    "epochs = list(range(1, len(bottom_results) + 1))\n",
    "\n",
    "# Tworzenie DataFrame z wynikami\n",
    "df_results = pd.DataFrame({\n",
    "    'Epoch': epochs,\n",
    "    'Bottom': bottom_results,\n",
    "    'Middle': middle_results,\n",
    "    'Top': top_results\n",
    "})\n",
    "\n",
    "# Ustawienie indeksu na numer epoki\n",
    "df_results = df_results.set_index('Epoch')\n",
    "\n",
    "# Rysowanie wykresu\n",
    "plt.plot(df_results['Bottom'], 'b-o', label=\"Bottom\")\n",
    "plt.plot(df_results['Middle'], 'g-o', label=\"Middle\")\n",
    "plt.plot(df_results['Top'], 'r-o', label=\"Top\")\n",
    "\n",
    "# Opis wykresu\n",
    "plt.title(\"Freeze Different Layers\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks(epochs)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-03T08:12:42.933763Z"
    }
   },
   "id": "8c09dc2d88e50a0b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Dane z wynikami treningu\n",
    "results = {\n",
    "    'no_frozen': {\n",
    "        'Test MSE': 0.1873, 'Test MAE': 0.3314, 'Test R2': 0.4321, 'Test Pearson': 0.7119,\n",
    "        'epochs': [1, 2, 3, 4, 5],\n",
    "        'train_loss': [0.5632, 0.3987, 0.3521, 0.3256, 0.3124],\n",
    "        'val_loss': [0.4213, 0.3894, 0.3741, 0.3629, 0.3557]\n",
    "    },\n",
    "    'bottom_frozen': {\n",
    "        'Test MSE': 0.2015, 'Test MAE': 0.3452, 'Test R2': 0.3984, 'Test Pearson': 0.6897,\n",
    "        'epochs': [1, 2, 3, 4, 5],\n",
    "        'train_loss': [0.5921, 0.4238, 0.3765, 0.3498, 0.3365],\n",
    "        'val_loss': [0.4392, 0.4047, 0.3874, 0.3752, 0.3689]\n",
    "    },\n",
    "    'middle_frozen': {\n",
    "        'Test MSE': 0.2157, 'Test MAE': 0.3583, 'Test R2': 0.3628, 'Test Pearson': 0.6724,\n",
    "        'epochs': [1, 2, 3],\n",
    "        'train_loss': [0.6215, 0.4473, 0.3984],\n",
    "        'val_loss': [0.4537, 0.4198, 0.4021]\n",
    "    },\n",
    "    'top_frozen': {\n",
    "        'Test MSE': 0.2301, 'Test MAE': 0.3726, 'Test R2': 0.3294, 'Test Pearson': 0.6543,\n",
    "        'epochs': [1, 2, 3, 4, 5],\n",
    "        'train_loss': [0.6452, 0.4721, 0.4195, 0.3956, 0.3812],\n",
    "        'val_loss': [0.4682, 0.4328, 0.4156, 0.4039, 0.3971]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Wykres 1: Przebieg treningu\n",
    "plt.figure(figsize=(10, 5))\n",
    "for key, data in results.items():\n",
    "    plt.plot(data['epochs'], data['train_loss'], label=f'Train Loss ({key})', linestyle='dashed')\n",
    "    plt.plot(data['epochs'], data['val_loss'], label=f'Val Loss ({key})')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Wykres 2: Porównanie wyników testowych\n",
    "metrics = ['Test MSE', 'Test MAE', 'Test R2', 'Test Pearson']\n",
    "strategies = list(results.keys())\n",
    "data = {metric: [results[st][metric] for st in strategies] for metric in metrics}\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.2\n",
    "\n",
    "for i, strategy in enumerate(strategies):\n",
    "    plt.bar(x + i * width, [results[strategy][metric] for metric in metrics], width, label=strategy)\n",
    "plt.xticks(x + width, metrics, rotation=45)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Test Performance Metrics Comparison\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Wykres 3: Zależność R2 vs Pearson\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=[results[s]['Test R2'] for s in strategies],\n",
    "                y=[results[s]['Test Pearson'] for s in strategies],\n",
    "                hue=strategies, s=100)\n",
    "plt.xlabel(\"Test R2\")\n",
    "plt.ylabel(\"Test Pearson Correlation\")\n",
    "plt.title(\"Test R2 vs Pearson Correlation\")\n",
    "plt.axhline(0, color='grey', linestyle='--')\n",
    "plt.axvline(0, color='grey', linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-03T08:12:42.943926Z"
    }
   },
   "id": "973c4fb0ee060a9d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import torch.optim.lr_scheduler as lr_scheduler\n",
    "# \n",
    "# PATIENCE = 3 \n",
    "# best_val_loss = float(\"inf\")\n",
    "# epochs_no_improve = 0\n",
    "# \n",
    "# scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=FACTOR, patience=1, verbose=True)\n",
    "# \n",
    "# for epoch in range(EPOCHS):\n",
    "#     print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "# \n",
    "#     train_loss = train_epoch(model, train_data_loader, loss_fn, optimizer, device)\n",
    "#     val_loss = eval_model(model, val_data_loader, loss_fn, device)\n",
    "# \n",
    "#     print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "# \n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         epochs_no_improve = 0\n",
    "#         torch.save(model.state_dict(), \"best_model.pt\")\n",
    "#         print(\"Model saved!\")\n",
    "#     else:\n",
    "#         epochs_no_improve += 1\n",
    "#         print(f'No improvement for {epochs_no_improve} epoch(s).')\n",
    "# \n",
    "#     scheduler.step(val_loss)\n",
    "# \n",
    "#     # Early Stopping\n",
    "#     if epochs_no_improve >= PATIENCE:\n",
    "#         print(\"Early stopping triggered!\")\n",
    "#         break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-03T08:12:43.059487Z"
    }
   },
   "id": "9e0c8ab71384517e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "# \n",
    "# test_loss = eval_model(model, test_data_loader, loss_fn, device)\n",
    "# print(f\"Test loss: {test_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-03T08:12:43.071893Z"
    }
   },
   "id": "793ace46af81f8e7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# \n",
    "# # Przyklad wizualizacji\n",
    "# plt.scatter(total_targets, total_preds, alpha=0.5)\n",
    "# plt.xlabel(\"Prawdziwe wartości\")\n",
    "# plt.ylabel(\"Predykcje\")\n",
    "# plt.title(\"Porównanie predykcji z rzeczywistością\")\n",
    "# plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-03T08:12:42.954248Z"
    }
   },
   "id": "fa633fc1783b18b8",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
